# Story 5.4: Audio Feature Extraction & Mapping

**Epic**: 5 - Stem Separation & Audio Analysis  
**Story**: 5.4  
**Status**: Not Started ðŸ”´  
**Priority**: High  
**Estimated Effort**: 16 hours  
**Dependencies**: Story 5.2 âœ…

## User Story

**As a** music producer or content creator  
**I want to** have the system extract meaningful musical features from my stems using Meyda.js  
**So that** my visualizations respond naturally to the musical structure without manual configuration

## Technical Implementation Details

### Feature Extraction System
```typescript
interface MeydaFeatureSet {
  rms: number;           // Overall energy/intensity
  zcr: number;          // Zero-crossing rate (rhythmic content)
  spectralCentroid: number;  // Brightness/frequency center
  spectralRolloff: number;   // Distribution of frequencies
  spectralFlatness: number;  // Tone vs. noise
  spectralSpread: number;    // Concentration of frequencies
  mfcc: number[];       // Timbre characteristics
  loudness: {
    total: number;
    specific: number[];
  };
  perceptualSpread: number;  // Perceived spectral spread
  perceptualSharpness: number;  // Perceived sharpness
}

interface StemFeatureAnalysis {
  stemType: 'drums' | 'bass' | 'vocals' | 'other';
  timestamp: number;
  features: MeydaFeatureSet;
  derived: {
    intensity: number;     // Normalized RMS
    rhythmicActivity: number;  // From ZCR and spectral features
    tonalContent: number;    // From spectral features
    timbreProfile: number[];  // From MFCC
  };
}

class StemAnalyzer {
  private meydaAnalyzer: MeydaAnalyzer;
  private bufferSize: number = 2048;
  private hopSize: number = 1024;

  constructor(audioContext: AudioContext, sourceNode: AudioNode) {
    this.meydaAnalyzer = Meyda.createMeydaAnalyzer({
      audioContext,
      source: sourceNode,
      bufferSize: this.bufferSize,
      hopSize: this.hopSize,
      featureExtractors: [
        'rms',
        'zcr',
        'spectralCentroid',
        'spectralRolloff',
        'spectralFlatness',
        'spectralSpread',
        'mfcc',
        'loudness',
        'perceptualSpread',
        'perceptualSharpness'
      ]
    });
  }

  start() {
    this.meydaAnalyzer.start();
  }

  stop() {
    this.meydaAnalyzer.stop();
  }
}
```

### Feature Mapping System
```typescript
interface FeatureMapping {
  feature: keyof MeydaFeatureSet;
  visualProperty: 'scale' | 'rotation' | 'color' | 'emission' | 'position';
  transform: {
    range: [number, number];  // Output range
    scale: 'linear' | 'log' | 'exponential';
    smoothing: number;  // 0-1 smoothing factor
  };
}

interface StemVisualizationConfig {
  drums?: FeatureMapping[];
  bass?: FeatureMapping[];
  vocals?: FeatureMapping[];
  other?: FeatureMapping[];
}
```

## Acceptance Criteria

1. Real-time Feature Extraction
   - Extract all specified Meyda features with < 50ms latency
   - Process features at minimum 30fps
   - Handle all stem types efficiently

2. Feature Quality
   - Accurate rhythm detection for drums
   - Reliable pitch tracking for bass
   - Clear intensity mapping for all stems
   - Smooth feature transitions

3. Performance
   - CPU usage < 15% on target systems
   - No audio glitches during analysis
   - Memory usage < 100MB per stem

4. Integration
   - Seamless WebAudio API integration
   - Clean feature data streaming
   - Proper cleanup on stop/disconnect

## Technical Dependencies

1. Meyda.js library
2. Web Audio API
3. AudioWorklet support
4. Stem playback system
5. Visualization engine connection

## Success Metrics

1. Analysis latency < 50ms
2. Frame rate > 30fps
3. CPU usage within target
4. Feature accuracy compared to reference
5. User satisfaction with responsiveness

## Dev Agent Record

- **Status**: Not Started
- **Assigned**: TBD
- **Started**: -
- **Completed**: -
- **Notes**: Core feature for enabling visualization control through audio analysis 