# Story 5.2: Real-time Audio Analysis Integration

**Epic**: 5 - Stem Separation & Audio Analysis  
**Story**: 5.2  
**Status**: In Progress ðŸŸ¡ (50% Complete - 4/8 tasks)  
**Priority**: High  
**Estimated Effort**: 16 hours  

## User Story

**As a** music producer or content creator  
**I want to** have my Spleeter-separated stems automatically analyzed in real-time  
**So that** I can get MIDI-like control over visualizations without needing MIDI files

## Technical Implementation Details

### Audio Analysis Architecture
```typescript
interface AudioFeature {
  type: 'rhythm' | 'pitch' | 'intensity' | 'timbre';
  value: number;
  confidence: number;
  timestamp: number;
}

interface StemAnalysis {
  stemId: string;
  stemType: 'drums' | 'bass' | 'vocals' | 'other' | 'piano'; // Matches Spleeter's output
  features: {
    rhythm: AudioFeature[];
    pitch: AudioFeature[];
    intensity: AudioFeature[];
    timbre: AudioFeature[];
  };
  metadata: {
    bpm: number;
    key: string;
    energy: number;
    clarity: number; // Quality metric for Spleeter separation
  };
}

class AudioAnalyzer {
  private context: AudioContext;
  private meydaAnalyzer: MeydaAnalyzer;
  private features: Set<string>;
  
  constructor(audioContext: AudioContext) {
    this.context = audioContext;
    this.features = new Set([
      'rms', 'zcr', 'spectralCentroid',
      'spectralRolloff', 'loudness',
      'perceptualSpread', 'spectralFlux' // Additional features for better visualization
    ]);
  }

  async analyzeStem(audioBuffer: AudioBuffer): Promise<StemAnalysis> {
    // Initialize Meyda analyzer
    // Process audio features optimized for visualization
    // Return analysis results
  }
}
```

### WebAudio Integration
```typescript
class AudioProcessor {
  private context: AudioContext;
  private sources: Map<string, AudioBufferSourceNode>;
  private analyzers: Map<string, AudioAnalyzer>;
  private bufferSize: number = 512; // Optimized for visualization latency

  async setupProcessing(stems: Record<string, ArrayBuffer>) {
    for (const [stemType, buffer] of Object.entries(stems)) {
      // Create audio buffer with optimal size
      // Connect to analyzer with visualization-focused features
      // Start real-time processing with priority on visual responsiveness
    }
  }

  getFeatures(): Record<string, AudioFeature[]> {
    // Collect features from all analyzers
    // Prioritize features most relevant to visualization
    // Return optimized analysis data
  }
}
```

### Analysis Service
```typescript
export const analysisRouter = router({
  initializeAnalysis: protectedProcedure
    .input(z.object({
      stems: z.record(z.string(), z.string()), // stemType -> stemUrl
      config: analysisConfigSchema,
      visualizationPreset: z.string().optional() // For preset-specific analysis
    }))
    .mutation(async ({ input, ctx }) => {
      // Set up WebAudio context optimized for visualization
      // Initialize analyzers with visualization-specific features
      // Begin real-time processing
    }),

  getAnalysisFeatures: protectedProcedure
    .input(z.object({ 
      sessionId: z.string(),
      timeRange: z.tuple([z.number(), z.number()]),
      featureResolution: z.number() // Control analysis granularity
    }))
    .query(async ({ input }) => {
      // Return features optimized for current visualization needs
    })
});
```

## Acceptance Criteria

### ðŸŽµ Audio Analysis Setup
- [ ] **Meyda.js Integration**: Configure for Spleeter stem analysis
- [ ] **WebAudio Pipeline**: Optimize for visualization responsiveness
- [ ] **Feature Selection**: Focus on visually impactful features
- [ ] **Real-time Processing**: Maintain 60fps analysis rate
- [ ] **Memory Management**: Efficient stem buffer handling

### âš¡ Performance Optimization
- [ ] **Analysis Resolution**: Adaptive based on visualization needs
- [ ] **Feature Prioritization**: Focus on visually relevant data
- [ ] **Buffer Management**: Optimize for Spleeter stem format
- [ ] **Frame Synchronization**: Match visualization frame rate
- [ ] **Resource Monitoring**: Track CPU and memory usage

### ðŸŽ¨ Feature Extraction
- [ ] **Rhythm Detection**: Optimized for Spleeter stems
- [ ] **Energy Analysis**: Focus on visual impact
- [ ] **Intensity Tracking**: Real-time responsiveness
- [ ] **Cross-stem Analysis**: Coordinate between Spleeter outputs
- [ ] **Feature Mapping**: Direct correlation to visual parameters

### ðŸ“± Device Support
- [ ] **Mobile Optimization**: Scale analysis to device capability
- [ ] **Browser Compatibility**: Ensure broad support
- [ ] **Fallback Modes**: Graceful degradation
- [ ] **Performance Testing**: Verify on target devices
- [ ] **Battery Impact**: Optimize power usage

## Technical Dependencies

### External Libraries
- Meyda.js for audio analysis
- WebAudio API
- Web Workers API
- Performance.now() for timing

### Internal Dependencies
- Spleeter stem separation from Story 5.1
- Visualization engine from Epic 2
- Audio playback system

## Success Metrics

- [ ] Analysis maintains 60fps on modern devices
- [ ] 30fps minimum on mobile devices
- [ ] <33ms latency from audio to visualization (2 frames @ 60fps)
- [ ] Memory usage under 80MB
- [ ] CPU usage under 25% on target devices

## Dev Agent Record

### Task Checklist
- [x] Configure analysis for Spleeter stems
- [x] Optimize Meyda.js parameters
- [x] Implement efficient worker processing
- [x] Create visualization-focused feature pipeline
- [-] Build performance monitoring
- [ ] Implement device-specific optimizations
- [ ] Add fallback modes
- [ ] Write performance tests

### Debug Log
| Task | File | Change | Reverted? |
|------|------|---------|-----------|
| Spleeter Analysis | /types/stem-audio-analysis.ts | Created new interfaces for AudioFeature, StemAnalysis, etc. | No |
| Spleeter Analysis | /types/meyda.d.ts | Enhanced MeydaFeatures with visualization features | No |
| Spleeter Analysis | /lib/audio-processor.ts | Created AudioProcessor class for multi-stem analysis | No |
| Spleeter Analysis | tsconfig.json | Updated lib to ES2017 to support Object.entries() | No |
| Meyda Optimization | /lib/audio-analyzer.ts | Enhanced with quality levels, adaptive performance, visualization features | No |
| Worker Processing | /public/workers/audio-analysis-worker.js | Created Web Worker for off-main-thread analysis | No |
| Worker Processing | /lib/audio-worker-manager.ts | Created worker manager with fallback support | No |
| Feature Pipeline | /lib/visualization-feature-pipeline.ts | Created comprehensive feature transformation system | No |
| Feature Pipeline | tsconfig.json | Updated lib to ES2019 for Object.fromEntries support | No |

### Completion Notes
âœ… **Task 1 Complete**: AudioProcessor class implemented with Spleeter stem support, device optimization, and visualization-focused feature extraction. Supports 5 stem types with optimized feature sets per stem.

âœ… **Task 2 Complete**: Meyda.js parameters optimized with adaptive quality levels (high/medium/low), performance monitoring, and visualization-focused feature extraction methods.

âœ… **Task 3 Complete**: Web Worker implementation with AudioWorkerManager provides off-main-thread processing, fallback support, and efficient stem analysis coordination.

âœ… **Task 4 Complete**: VisualizationFeaturePipeline transforms audio features into comprehensive visual parameters with cross-stem correlations, temporal continuity, and stem-specific influence weights.

### Implementation Notes
- Optimize buffer sizes for visualization latency
- Focus on features with direct visual impact
- Cache common analysis patterns
- Use analysis resolution scaling
- Synchronize with visualization frame timing 