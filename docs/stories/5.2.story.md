# Story 5.2: Real-time Audio Analysis Integration

**Epic**: 5 - Stem Separation & Audio Analysis  
**Story**: 5.2  
**Status**: Not Started ðŸ”´  
**Priority**: High  
**Estimated Effort**: 16 hours  

## User Story

**As a** music producer or content creator  
**I want to** have my Spleeter-separated stems automatically analyzed in real-time  
**So that** I can get MIDI-like control over visualizations without needing MIDI files

## Technical Implementation Details

### Audio Analysis Architecture
```typescript
interface AudioFeature {
  type: 'rhythm' | 'pitch' | 'intensity' | 'timbre';
  value: number;
  confidence: number;
  timestamp: number;
}

interface StemAnalysis {
  stemId: string;
  stemType: 'drums' | 'bass' | 'vocals' | 'other' | 'piano'; // Matches Spleeter's output
  features: {
    rhythm: AudioFeature[];
    pitch: AudioFeature[];
    intensity: AudioFeature[];
    timbre: AudioFeature[];
  };
  metadata: {
    bpm: number;
    key: string;
    energy: number;
    clarity: number; // Quality metric for Spleeter separation
  };
}

class AudioAnalyzer {
  private context: AudioContext;
  private meydaAnalyzer: MeydaAnalyzer;
  private features: Set<string>;
  
  constructor(audioContext: AudioContext) {
    this.context = audioContext;
    this.features = new Set([
      'rms', 'zcr', 'spectralCentroid',
      'spectralRolloff', 'loudness',
      'perceptualSpread', 'spectralFlux' // Additional features for better visualization
    ]);
  }

  async analyzeStem(audioBuffer: AudioBuffer): Promise<StemAnalysis> {
    // Initialize Meyda analyzer
    // Process audio features optimized for visualization
    // Return analysis results
  }
}
```

### WebAudio Integration
```typescript
class AudioProcessor {
  private context: AudioContext;
  private sources: Map<string, AudioBufferSourceNode>;
  private analyzers: Map<string, AudioAnalyzer>;
  private bufferSize: number = 512; // Optimized for visualization latency

  async setupProcessing(stems: Record<string, ArrayBuffer>) {
    for (const [stemType, buffer] of Object.entries(stems)) {
      // Create audio buffer with optimal size
      // Connect to analyzer with visualization-focused features
      // Start real-time processing with priority on visual responsiveness
    }
  }

  getFeatures(): Record<string, AudioFeature[]> {
    // Collect features from all analyzers
    // Prioritize features most relevant to visualization
    // Return optimized analysis data
  }
}
```

### Analysis Service
```typescript
export const analysisRouter = router({
  initializeAnalysis: protectedProcedure
    .input(z.object({
      stems: z.record(z.string(), z.string()), // stemType -> stemUrl
      config: analysisConfigSchema,
      visualizationPreset: z.string().optional() // For preset-specific analysis
    }))
    .mutation(async ({ input, ctx }) => {
      // Set up WebAudio context optimized for visualization
      // Initialize analyzers with visualization-specific features
      // Begin real-time processing
    }),

  getAnalysisFeatures: protectedProcedure
    .input(z.object({ 
      sessionId: z.string(),
      timeRange: z.tuple([z.number(), z.number()]),
      featureResolution: z.number() // Control analysis granularity
    }))
    .query(async ({ input }) => {
      // Return features optimized for current visualization needs
    })
});
```

## Acceptance Criteria

### ðŸŽµ Audio Analysis Setup
- [ ] **Meyda.js Integration**: Configure for Spleeter stem analysis
- [ ] **WebAudio Pipeline**: Optimize for visualization responsiveness
- [ ] **Feature Selection**: Focus on visually impactful features
- [ ] **Real-time Processing**: Maintain 60fps analysis rate
- [ ] **Memory Management**: Efficient stem buffer handling

### âš¡ Performance Optimization
- [ ] **Analysis Resolution**: Adaptive based on visualization needs
- [ ] **Feature Prioritization**: Focus on visually relevant data
- [ ] **Buffer Management**: Optimize for Spleeter stem format
- [ ] **Frame Synchronization**: Match visualization frame rate
- [ ] **Resource Monitoring**: Track CPU and memory usage

### ðŸŽ¨ Feature Extraction
- [ ] **Rhythm Detection**: Optimized for Spleeter stems
- [ ] **Energy Analysis**: Focus on visual impact
- [ ] **Intensity Tracking**: Real-time responsiveness
- [ ] **Cross-stem Analysis**: Coordinate between Spleeter outputs
- [ ] **Feature Mapping**: Direct correlation to visual parameters

### ðŸ“± Device Support
- [ ] **Mobile Optimization**: Scale analysis to device capability
- [ ] **Browser Compatibility**: Ensure broad support
- [ ] **Fallback Modes**: Graceful degradation
- [ ] **Performance Testing**: Verify on target devices
- [ ] **Battery Impact**: Optimize power usage

## Technical Dependencies

### External Libraries
- Meyda.js for audio analysis
- WebAudio API
- Web Workers API
- Performance.now() for timing

### Internal Dependencies
- Spleeter stem separation from Story 5.1
- Visualization engine from Epic 2
- Audio playback system

## Success Metrics

- [ ] Analysis maintains 60fps on modern devices
- [ ] 30fps minimum on mobile devices
- [ ] <33ms latency from audio to visualization (2 frames @ 60fps)
- [ ] Memory usage under 80MB
- [ ] CPU usage under 25% on target devices

## Dev Agent Record

### Task Checklist
- [ ] Configure analysis for Spleeter stems
- [ ] Optimize Meyda.js parameters
- [ ] Implement efficient worker processing
- [ ] Create visualization-focused feature pipeline
- [ ] Build performance monitoring
- [ ] Implement device-specific optimizations
- [ ] Add fallback modes
- [ ] Write performance tests

### Implementation Notes
- Optimize buffer sizes for visualization latency
- Focus on features with direct visual impact
- Cache common analysis patterns
- Use analysis resolution scaling
- Synchronize with visualization frame timing 