# Story 4.2: Video Asset Management System

**Epic**: 4 - Remotion Video Composition Platform  
**Story**: 4.2  
**Status**: üî¥ NOT STARTED  
**Priority**: High  
**Estimated Effort**: 12 hours  
**Depends On**: Epic 1 ‚úÖ, Story 4.1 üî¥

## User Story

**As a** musician  
**I want** to upload and organize my video/photo content  
**So that** I can use my personal media in MIDI-reactive compositions  

## Acceptance Criteria

### üìÅ Video/Image Upload System
- [ ] **Video Upload**: Video file upload (.mp4, .mov, .avi) extends existing file system
- [ ] **Image Upload**: Image file upload (.jpg, .png, .gif, .webp) with thumbnail generation
- [ ] **Asset Library UI**: Asset library UI with grid view and metadata display
- [ ] **Media Processing**: Video duration and resolution extraction using FFprobe
- [ ] **Asset Preview**: Asset preview functionality in editor with scrubbing capability
- [ ] **Organization**: Folder organization for asset management within projects
- [ ] **Optimization**: Asset optimization (compression, format conversion) for web delivery
- [ ] **Search & Filter**: Asset search and filtering by type, duration, resolution
- [ ] **Bulk Upload**: Bulk upload functionality with progress tracking

## Technical Implementation

### Database Schema Extensions
```sql
-- Extend file_metadata table for video/image assets
ALTER TABLE file_metadata 
ADD COLUMN duration_seconds FLOAT,
ADD COLUMN resolution_width INTEGER,
ADD COLUMN resolution_height INTEGER,
ADD COLUMN frame_rate FLOAT,
ADD COLUMN video_codec TEXT,
ADD COLUMN audio_codec TEXT,
ADD COLUMN thumbnail_url TEXT,
ADD COLUMN preview_url TEXT;

-- Asset collections for organization
CREATE TABLE asset_collections (
  id TEXT PRIMARY KEY,
  project_id TEXT REFERENCES projects(id) ON DELETE CASCADE,
  name TEXT NOT NULL,
  description TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE TABLE asset_collection_items (
  id TEXT PRIMARY KEY,
  collection_id TEXT REFERENCES asset_collections(id) ON DELETE CASCADE,
  file_id TEXT REFERENCES file_metadata(id) ON DELETE CASCADE,
  sort_order INTEGER DEFAULT 0,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Update file type enum to include new types
ALTER TYPE file_type_enum ADD VALUE IF NOT EXISTS 'video';
ALTER TYPE file_type_enum ADD VALUE IF NOT EXISTS 'image';
```

### Video Processing Service
```typescript
// apps/api/src/services/video-processor.ts
import ffmpeg from 'fluent-ffmpeg';
import sharp from 'sharp';
import { FileMetadata } from '../types/file';

export class VideoProcessor {
  async processVideo(filePath: string): Promise<VideoMetadata> {
    return new Promise((resolve, reject) => {
      ffmpeg.ffprobe(filePath, (err, metadata) => {
        if (err) return reject(err);
        
        const videoStream = metadata.streams.find(s => s.codec_type === 'video');
        const audioStream = metadata.streams.find(s => s.codec_type === 'audio');
        
        resolve({
          duration: metadata.format.duration || 0,
          width: videoStream?.width || 0,
          height: videoStream?.height || 0,
          frameRate: this.parseFrameRate(videoStream?.r_frame_rate),
          videoCodec: videoStream?.codec_name || '',
          audioCodec: audioStream?.codec_name || '',
          bitrate: metadata.format.bit_rate ? parseInt(metadata.format.bit_rate) : 0
        });
      });
    });
  }
  
  async generateThumbnail(videoPath: string, outputPath: string): Promise<string> {
    return new Promise((resolve, reject) => {
      ffmpeg(videoPath)
        .screenshots({
          timestamps: ['10%'],
          filename: 'thumbnail.jpg',
          folder: outputPath,
          size: '320x240'
        })
        .on('end', () => resolve(`${outputPath}/thumbnail.jpg`))
        .on('error', reject);
    });
  }
  
  async generatePreview(videoPath: string, outputPath: string): Promise<string> {
    return new Promise((resolve, reject) => {
      ffmpeg(videoPath)
        .output(`${outputPath}/preview.mp4`)
        .videoCodec('libx264')
        .size('640x480')
        .duration(10) // 10 second preview
        .on('end', () => resolve(`${outputPath}/preview.mp4`))
        .on('error', reject);
    });
  }
  
  private parseFrameRate(frameRate?: string): number {
    if (!frameRate) return 30;
    const [num, den] = frameRate.split('/').map(Number);
    return den ? num / den : num;
  }
}

export interface VideoMetadata {
  duration: number;
  width: number;
  height: number;
  frameRate: number;
  videoCodec: string;
  audioCodec: string;
  bitrate: number;
}
```

### Image Processing Service
```typescript
// apps/api/src/services/image-processor.ts
import sharp from 'sharp';

export class ImageProcessor {
  async processImage(filePath: string): Promise<ImageMetadata> {
    const metadata = await sharp(filePath).metadata();
    
    return {
      width: metadata.width || 0,
      height: metadata.height || 0,
      format: metadata.format || '',
      colorSpace: metadata.space || '',
      hasAlpha: metadata.hasAlpha || false,
      size: metadata.size || 0
    };
  }
  
  async generateThumbnail(imagePath: string, outputPath: string): Promise<string> {
    await sharp(imagePath)
      .resize(320, 240, { 
        fit: 'inside',
        withoutEnlargement: true 
      })
      .jpeg({ quality: 80 })
      .toFile(`${outputPath}/thumbnail.jpg`);
      
    return `${outputPath}/thumbnail.jpg`;
  }
  
  async optimizeForWeb(imagePath: string, outputPath: string): Promise<string> {
    const metadata = await sharp(imagePath).metadata();
    
    // Choose optimal format
    const outputFormat = this.getOptimalFormat(metadata.format);
    
    await sharp(imagePath)
      .resize(1920, 1080, { 
        fit: 'inside',
        withoutEnlargement: true 
      })
      .toFormat(outputFormat, { quality: 85 })
      .toFile(`${outputPath}/optimized.${outputFormat}`);
      
    return `${outputPath}/optimized.${outputFormat}`;
  }
  
  private getOptimalFormat(originalFormat?: string): 'jpeg' | 'png' | 'webp' {
    if (originalFormat === 'png') return 'png';
    return 'jpeg'; // Default to JPEG for photos
  }
}

export interface ImageMetadata {
  width: number;
  height: number;
  format: string;
  colorSpace: string;
  hasAlpha: boolean;
  size: number;
}
```

### Extended File Upload API
```typescript
// apps/api/src/routers/file.ts - Add to existing router
import { VideoProcessor } from '../services/video-processor';
import { ImageProcessor } from '../services/image-processor';

export const fileRouter = router({
  // ... existing routes ...
  
  uploadVideoAsset: protectedProcedure
    .input(z.object({
      projectId: z.string(),
      fileName: z.string(),
      fileSize: z.number(),
      mimeType: z.string()
    }))
    .mutation(async ({ ctx, input }) => {
      // Validate video file type
      const allowedTypes = ['video/mp4', 'video/mov', 'video/avi', 'video/quicktime'];
      if (!allowedTypes.includes(input.mimeType)) {
        throw new TRPCError({
          code: 'BAD_REQUEST',
          message: 'Unsupported video format'
        });
      }
      
      // Generate upload URL for R2
      const uploadUrl = await r2Storage.generateUploadUrl(input.fileName);
      
      // Create file metadata record
      const fileMetadata = await ctx.db.fileMetadata.create({
        data: {
          id: generateFileId(),
          userId: ctx.user.id,
          projectId: input.projectId,
          fileName: input.fileName,
          fileSize: input.fileSize,
          mimeType: input.mimeType,
          fileType: 'video',
          status: 'uploading',
          assetType: 'video'
        }
      });
      
      return {
        fileId: fileMetadata.id,
        uploadUrl,
        fileMetadata
      };
    }),
    
  processVideoAsset: protectedProcedure
    .input(z.object({ fileId: z.string() }))
    .mutation(async ({ ctx, input }) => {
      const file = await ctx.db.fileMetadata.findUnique({
        where: { id: input.fileId }
      });
      
      if (!file || file.userId !== ctx.user.id) {
        throw new TRPCError({ code: 'NOT_FOUND' });
      }
      
      try {
        // Download file from R2 for processing
        const filePath = await r2Storage.downloadFile(file.r2Key);
        
        // Process video metadata
        const videoProcessor = new VideoProcessor();
        const metadata = await videoProcessor.processVideo(filePath);
        
        // Generate thumbnail and preview
        const thumbnailUrl = await videoProcessor.generateThumbnail(filePath, '/tmp/thumbnails');
        const previewUrl = await videoProcessor.generatePreview(filePath, '/tmp/previews');
        
        // Upload processed assets back to R2
        const thumbnailR2Url = await r2Storage.uploadFile(thumbnailUrl, `thumbnails/${file.id}.jpg`);
        const previewR2Url = await r2Storage.uploadFile(previewUrl, `previews/${file.id}.mp4`);
        
        // Update file metadata
        await ctx.db.fileMetadata.update({
          where: { id: input.fileId },
          data: {
            status: 'completed',
            durationSeconds: metadata.duration,
            resolutionWidth: metadata.width,
            resolutionHeight: metadata.height,
            frameRate: metadata.frameRate,
            videoCodec: metadata.videoCodec,
            audioCodec: metadata.audioCodec,
            thumbnailUrl: thumbnailR2Url,
            previewUrl: previewR2Url
          }
        });
        
        return { success: true, metadata };
      } catch (error) {
        await ctx.db.fileMetadata.update({
          where: { id: input.fileId },
          data: { status: 'failed' }
        });
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Video processing failed'
        });
      }
    }),
    
  getUserVideoAssets: protectedProcedure
    .input(z.object({
      projectId: z.string().optional(),
      assetType: z.enum(['video', 'image', 'all']).default('all'),
      limit: z.number().min(1).max(100).default(20),
      offset: z.number().min(0).default(0)
    }))
    .query(async ({ ctx, input }) => {
      const where = {
        userId: ctx.user.id,
        ...(input.projectId && { projectId: input.projectId }),
        ...(input.assetType !== 'all' && { assetType: input.assetType }),
        status: 'completed'
      };
      
      const [files, total] = await Promise.all([
        ctx.db.fileMetadata.findMany({
          where,
          orderBy: { createdAt: 'desc' },
          take: input.limit,
          skip: input.offset
        }),
        ctx.db.fileMetadata.count({ where })
      ]);
      
      return { files, total };
    })
});
```

## Frontend Asset Library Component

### Asset Grid Component
```typescript
// apps/web/src/components/video/AssetLibrary.tsx
import React, { useState } from 'react';
import { trpc } from '@/lib/trpc';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Input } from '@/components/ui/input';
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@/components/ui/select';
import { useUpload } from '@/hooks/use-upload';

interface AssetLibraryProps {
  projectId: string;
  onAssetSelected: (fileId: string) => void;
  selectedAssetId?: string;
}

export const AssetLibrary: React.FC<AssetLibraryProps> = ({
  projectId,
  onAssetSelected,
  selectedAssetId
}) => {
  const [assetType, setAssetType] = useState<'video' | 'image' | 'all'>('all');
  const [searchTerm, setSearchTerm] = useState('');
  
  const { data: assets, refetch } = trpc.file.getUserVideoAssets.useQuery({
    projectId,
    assetType,
    limit: 50
  });
  
  const { uploadFiles, isUploading } = useUpload({
    acceptedTypes: ['video/*', 'image/*'],
    onUploadComplete: (fileId) => {
      // Process the uploaded asset
      processAssetMutation.mutate({ fileId });
    }
  });
  
  const processAssetMutation = trpc.file.processVideoAsset.useMutation({
    onSuccess: () => {
      refetch();
    }
  });
  
  const filteredAssets = assets?.files.filter(file =>
    file.fileName.toLowerCase().includes(searchTerm.toLowerCase())
  ) || [];
  
  return (
    <Card className="bg-stone-200/90 backdrop-blur-md border-stone-400">
      <CardHeader>
        <CardTitle className="text-stone-700 uppercase tracking-wide text-sm">
          Media Assets
        </CardTitle>
        
        {/* Search and Filter Controls */}
        <div className="flex gap-2">
          <Input
            placeholder="Search assets..."
            value={searchTerm}
            onChange={(e) => setSearchTerm(e.target.value)}
            className="bg-stone-100 border-stone-300"
          />
          <Select value={assetType} onValueChange={setAssetType}>
            <SelectTrigger className="w-32 bg-stone-100 border-stone-300">
              <SelectValue />
            </SelectTrigger>
            <SelectContent>
              <SelectItem value="all">All</SelectItem>
              <SelectItem value="video">Videos</SelectItem>
              <SelectItem value="image">Images</SelectItem>
            </SelectContent>
          </Select>
        </div>
      </CardHeader>
      
      <CardContent>
        {/* Upload Zone */}
        <div className="border-2 border-dashed border-stone-400 rounded-lg p-4 mb-4 text-center">
          <Button
            onClick={() => uploadFiles()}
            disabled={isUploading}
            className="bg-stone-600 hover:bg-stone-700"
          >
            {isUploading ? 'Uploading...' : 'Upload Video/Image'}
          </Button>
        </div>
        
        {/* Asset Grid */}
        <div className="grid grid-cols-2 sm:grid-cols-3 md:grid-cols-4 gap-3">
          {filteredAssets.map((asset) => (
            <AssetThumbnail
              key={asset.id}
              asset={asset}
              isSelected={asset.id === selectedAssetId}
              onClick={() => onAssetSelected(asset.id)}
            />
          ))}
        </div>
        
        {filteredAssets.length === 0 && (
          <div className="text-center text-stone-600 py-8">
            <p>No assets found</p>
            <p className="text-sm">Upload videos or images to get started</p>
          </div>
        )}
      </CardContent>
    </Card>
  );
};
```

### Asset Thumbnail Component
```typescript
// apps/web/src/components/video/AssetThumbnail.tsx
import React from 'react';
import { FileMetadata } from '@/types/file';
import { formatDuration, formatFileSize } from '@/lib/utils';

interface AssetThumbnailProps {
  asset: FileMetadata;
  isSelected: boolean;
  onClick: () => void;
}

export const AssetThumbnail: React.FC<AssetThumbnailProps> = ({
  asset,
  isSelected,
  onClick
}) => {
  return (
    <div
      className={`
        cursor-pointer rounded-lg border-2 transition-all
        ${isSelected 
          ? 'border-stone-600 bg-stone-300' 
          : 'border-stone-300 bg-stone-100 hover:border-stone-500'
        }
      `}
      onClick={onClick}
    >
      {/* Thumbnail */}
      <div className="aspect-video rounded-t-lg overflow-hidden">
        {asset.thumbnailUrl ? (
          <img
            src={asset.thumbnailUrl}
            alt={asset.fileName}
            className="w-full h-full object-cover"
          />
        ) : (
          <div className="w-full h-full bg-stone-300 flex items-center justify-center">
            <span className="text-stone-600 text-xs">
              {asset.assetType === 'video' ? 'üé¨' : 'üñºÔ∏è'}
            </span>
          </div>
        )}
      </div>
      
      {/* Metadata */}
      <div className="p-2">
        <p className="text-xs font-mono text-stone-700 truncate">
          {asset.fileName}
        </p>
        <div className="flex justify-between text-xs text-stone-600 mt-1">
          {asset.assetType === 'video' && asset.durationSeconds && (
            <span>{formatDuration(asset.durationSeconds)}</span>
          )}
          {asset.resolutionWidth && asset.resolutionHeight && (
            <span>{asset.resolutionWidth}√ó{asset.resolutionHeight}</span>
          )}
        </div>
        <div className="text-xs text-stone-500 mt-1">
          {formatFileSize(asset.fileSize)}
        </div>
      </div>
    </div>
  );
};
```

## Asset Preview Component

### Video/Image Preview Modal
```typescript
// apps/web/src/components/video/AssetPreview.tsx
import React, { useState } from 'react';
import { Dialog, DialogContent, DialogHeader, DialogTitle } from '@/components/ui/dialog';
import { Button } from '@/components/ui/button';
import { FileMetadata } from '@/types/file';

interface AssetPreviewProps {
  asset: FileMetadata | null;
  isOpen: boolean;
  onClose: () => void;
  onUseAsset: (assetId: string) => void;
}

export const AssetPreview: React.FC<AssetPreviewProps> = ({
  asset,
  isOpen,
  onClose,
  onUseAsset
}) => {
  if (!asset) return null;
  
  return (
    <Dialog open={isOpen} onOpenChange={onClose}>
      <DialogContent className="max-w-4xl bg-stone-200 border-stone-400">
        <DialogHeader>
          <DialogTitle className="text-stone-700">{asset.fileName}</DialogTitle>
        </DialogHeader>
        
        <div className="space-y-4">
          {/* Preview */}
          <div className="aspect-video bg-black rounded-lg overflow-hidden">
            {asset.assetType === 'video' ? (
              <video
                src={asset.previewUrl || asset.r2Url}
                controls
                className="w-full h-full"
              />
            ) : (
              <img
                src={asset.r2Url}
                alt={asset.fileName}
                className="w-full h-full object-contain"
              />
            )}
          </div>
          
          {/* Metadata */}
          <div className="grid grid-cols-2 gap-4 text-sm">
            <div>
              <span className="text-stone-600">Type:</span> {asset.assetType}
            </div>
            <div>
              <span className="text-stone-600">Size:</span> {formatFileSize(asset.fileSize)}
            </div>
            {asset.durationSeconds && (
              <div>
                <span className="text-stone-600">Duration:</span> {formatDuration(asset.durationSeconds)}
              </div>
            )}
            {asset.resolutionWidth && (
              <div>
                <span className="text-stone-600">Resolution:</span> {asset.resolutionWidth}√ó{asset.resolutionHeight}
              </div>
            )}
          </div>
          
          {/* Actions */}
          <div className="flex justify-end gap-2">
            <Button variant="outline" onClick={onClose}>
              Cancel
            </Button>
            <Button 
              onClick={() => onUseAsset(asset.id)}
              className="bg-stone-600 hover:bg-stone-700"
            >
              Use in Composition
            </Button>
          </div>
        </div>
      </DialogContent>
    </Dialog>
  );
};
```

## Testing Strategy

### Unit Tests
```typescript
// apps/api/src/__tests__/video-processor.test.ts
import { VideoProcessor } from '../services/video-processor';

describe('VideoProcessor', () => {
  const processor = new VideoProcessor();
  
  test('should extract video metadata', async () => {
    const metadata = await processor.processVideo('./test-assets/sample.mp4');
    
    expect(metadata.duration).toBeGreaterThan(0);
    expect(metadata.width).toBeGreaterThan(0);
    expect(metadata.height).toBeGreaterThan(0);
    expect(metadata.frameRate).toBeGreaterThan(0);
  });
  
  test('should generate thumbnail', async () => {
    const thumbnailPath = await processor.generateThumbnail(
      './test-assets/sample.mp4',
      './test-output'
    );
    
    expect(thumbnailPath).toContain('thumbnail.jpg');
  });
});
```

### Integration Tests
```typescript
// apps/api/src/__tests__/file-upload.test.ts
describe('Video Asset Upload', () => {
  test('should upload and process video asset', async () => {
    const response = await caller.file.uploadVideoAsset({
      projectId: 'test-project',
      fileName: 'test-video.mp4',
      fileSize: 1024000,
      mimeType: 'video/mp4'
    });
    
    expect(response.fileId).toBeDefined();
    expect(response.uploadUrl).toBeDefined();
  });
});
```

## Definition of Done

### ‚úÖ Functional Requirements
- Users can upload video and image files
- Asset metadata is extracted and stored
- Thumbnails and previews are generated
- Asset library displays uploaded media
- Search and filtering works correctly
- Preview modal shows asset details

### ‚úÖ Technical Requirements
- Extends existing file upload system
- Video processing pipeline is robust
- Database schema supports new asset types
- API endpoints handle video/image uploads
- Error handling for processing failures
- Performance optimized for large files

### ‚úÖ Performance Requirements
- Video processing completes within reasonable time
- Thumbnail generation is fast
- Asset library loads quickly
- Large files don't block the UI
- Memory usage is controlled during processing

## Future Enhancements (Epic 4 Stories)
- Layer management with video assets (Story 4.3)
- MIDI parameter binding to video properties (Story 4.4)
- Video cuts and transitions (Story 4.5)
- Professional export with video layers (Story 4.7)

---

**Dependencies**: Epic 1 (File Upload System), Story 4.1 (Remotion Foundation)  
**Estimated Effort**: 12 hours (4 hours API/processing, 4 hours frontend, 2 hours database, 2 hours testing)  
**Risk Level**: Medium (Video processing complexity, file size handling) 