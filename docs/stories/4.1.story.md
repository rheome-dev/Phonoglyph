# Story 4.1: Remotion Foundation Integration

**Epic**: 4 - Remotion Video Composition Platform  
**Story**: 4.1  
**Status**: ÔøΩ IN PROGRESS  
**Priority**: Critical  
**Estimated Effort**: 16 hours  
**Depends On**: Epic 1 ‚úÖ, Epic 2 ‚úÖ

## User Story

**As a** developer  
**I want** Remotion integrated as the core video composition engine  
**So that** I can build React-based video features while preserving existing Three.js effects  

## Acceptance Criteria

### üîß Remotion Installation & Configuration
- [x] **Monorepo Integration**: Remotion installed and configured in monorepo structure (`apps/video`)
- [x] **Basic Composition**: Basic composition structure created with Three.js wrapper component
- [x] **MIDI Data Flow**: MIDI data flows from existing parser to Remotion props
- [x] **Canvas Integration**: Three.js canvas renders as video layer in Remotion composition
- [x] **Timeline Sync**: Timeline synchronization working between Remotion frames and MIDI events
- [x] **Development Server**: Development server supports hot reloading for composition changes
- [x] **Build Process**: Build process generates both web preview and video export configurations

## Technical Implementation

### Apps/Video Structure
```typescript
// apps/video/package.json
{
  "name": "@midiviz/video",
  "version": "1.0.0",
  "dependencies": {
    "remotion": "^4.0.0",
    "@remotion/cli": "^4.0.0",
    "@remotion/player": "^4.0.0",
    "three": "^0.158.0",
    "@types/three": "^0.158.0"
  },
  "scripts": {
    "dev": "remotion preview",
    "build": "remotion bundle",
    "render": "remotion render"
  }
}
```

### Remotion Configuration
```typescript
// apps/video/remotion.config.ts
import { Config } from '@remotion/cli/config';

Config.setVideoImageFormat('jpeg');
Config.setOverwriteOutput(true);
Config.setPixelFormat('yuv420p');
Config.setCodec('h264');
Config.setCrf(18);
Config.setEntryPoint('./src/index.ts');

// Performance optimizations
Config.setBrowserExecutable(null); // Use default
Config.setTimeoutInMilliseconds(120000);
Config.setConcurrency(1);
```

### Three.js Wrapper Component
```typescript
// apps/video/src/components/ThreeJSLayer.tsx
import React, { useRef, useEffect } from 'react';
import { useCurrentFrame, useVideoConfig } from 'remotion';
import { ThreeCanvas } from './ThreeCanvas';
import type { MIDIData, VisualizationSettings } from '@midiviz/types';

interface ThreeJSLayerProps {
  midiData: MIDIData;
  settings: VisualizationSettings;
  effectType: 'metaballs' | 'particles' | 'midihud' | 'bloom';
  opacity?: number;
}

export const ThreeJSLayer: React.FC<ThreeJSLayerProps> = ({
  midiData,
  settings,
  effectType,
  opacity = 1
}) => {
  const frame = useCurrentFrame();
  const { fps, durationInFrames } = useVideoConfig();
  const canvasRef = useRef<HTMLCanvasElement>(null);
  
  // Convert frame to time for Three.js
  const currentTime = frame / fps;
  
  useEffect(() => {
    if (!canvasRef.current) return;
    
    // Initialize Three.js scene with existing effect
    const threeCanvas = new ThreeCanvas(canvasRef.current, {
      midiData,
      settings,
      effectType,
      currentTime,
      opacity
    });
    
    // Render current frame
    threeCanvas.render();
    
    return () => {
      threeCanvas.dispose();
    };
  }, [frame, midiData, settings, effectType, opacity]);
  
  return (
    <canvas
      ref={canvasRef}
      width={1920}
      height={1080}
      style={{
        width: '100%',
        height: '100%',
        opacity
      }}
    />
  );
};
```

### Main Composition
```typescript
// apps/video/src/Composition.tsx
import React from 'react';
import { Composition } from 'remotion';
import { MidiVisualizerVideo } from './MidiVisualizerVideo';

export const RemotionRoot: React.FC = () => {
  return (
    <>
      <Composition
        id="MidiVisualizer"
        component={MidiVisualizerVideo}
        durationInFrames={3000} // 60 seconds at 30fps
        fps={30}
        width={1920}
        height={1080}
        defaultProps={{
          midiFileId: 'sample',
          effectLayers: [
            { id: '1', type: 'metaballs', opacity: 0.8 },
            { id: '2', type: 'particles', opacity: 0.6 }
          ]
        }}
      />
    </>
  );
};
```

### Video Component
```typescript
// apps/video/src/MidiVisualizerVideo.tsx
import React from 'react';
import { Audio, useCurrentFrame, useVideoConfig } from 'remotion';
import { ThreeJSLayer } from './components/ThreeJSLayer';
import type { MIDIData, EffectLayer } from '@midiviz/types';

interface MidiVisualizerVideoProps {
  midiFileId: string;
  effectLayers: EffectLayer[];
  audioSrc?: string;
  midiData?: MIDIData;
}

export const MidiVisualizerVideo: React.FC<MidiVisualizerVideoProps> = ({
  midiFileId,
  effectLayers,
  audioSrc,
  midiData
}) => {
  const frame = useCurrentFrame();
  const { fps } = useVideoConfig();
  const currentTime = frame / fps;
  
  // TODO: Load MIDI data from API if not provided
  const resolvedMidiData = midiData || getDefaultMidiData();
  
  return (
    <div style={{ 
      width: '100%', 
      height: '100%', 
      background: 'linear-gradient(45deg, #0f172a, #1e293b)' 
    }}>
      {/* Audio track */}
      {audioSrc && <Audio src={audioSrc} />}
      
      {/* Three.js Effect Layers */}
      {effectLayers.map((layer) => (
        <ThreeJSLayer
          key={layer.id}
          midiData={resolvedMidiData}
          settings={layer.settings}
          effectType={layer.type}
          opacity={layer.opacity}
        />
      ))}
    </div>
  );
};
```

## MIDI Timeline Synchronization

### Frame-to-MIDI Mapping
```typescript
// apps/video/src/utils/midiSync.ts
export interface MIDITimelineSync {
  frame: number;
  time: number;
  activeNotes: MIDINote[];
  tempo: number;
  timeSignature: [number, number];
}

export function getMIDIDataAtFrame(
  midiData: MIDIData,
  frame: number,
  fps: number
): MIDITimelineSync {
  const time = frame / fps;
  
  // Find active notes at current time
  const activeNotes = midiData.tracks.flatMap(track =>
    track.notes.filter(note => 
      note.time <= time && (note.time + note.duration) > time
    )
  );
  
  // Get tempo and time signature at current time
  const tempoChange = midiData.tempoChanges
    .slice()
    .reverse()
    .find(change => change.time <= time);
    
  const timeSignatureChange = midiData.timeSignatures
    .slice()
    .reverse()
    .find(change => change.time <= time);
  
  return {
    frame,
    time,
    activeNotes,
    tempo: tempoChange?.bpm || 120,
    timeSignature: timeSignatureChange?.timeSignature || [4, 4]
  };
}
```

## Development Environment

### Hot Reloading Setup
```typescript
// apps/video/src/index.ts
import { registerRoot } from 'remotion';
import { RemotionRoot } from './Composition';

registerRoot(RemotionRoot);

// Development hot reload
if (module.hot) {
  module.hot.accept('./Composition', () => {
    const NextRemotionRoot = require('./Composition').RemotionRoot;
    registerRoot(NextRemotionRoot);
  });
}
```

### Build Configuration
```json
// apps/video/tsconfig.json
{
  "extends": "../../packages/config/tsconfig.json",
  "compilerOptions": {
    "target": "ES2020",
    "lib": ["DOM", "DOM.Iterable", "ES2020"],
    "allowJs": true,
    "skipLibCheck": true,
    "esModuleInterop": true,
    "allowSyntheticDefaultImports": true,
    "strict": true,
    "forceConsistentCasingInFileNames": true,
    "module": "ESNext",
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "react-jsx"
  },
  "include": [
    "src/**/*"
  ],
  "exclude": [
    "node_modules"
  ]
}
```

## Integration with Existing Codebase

### Shared Types Package
```typescript
// packages/types/src/video.ts
export interface EffectLayer {
  id: string;
  type: 'metaballs' | 'particles' | 'midihud' | 'bloom';
  opacity: number;
  settings: VisualizationSettings;
  zIndex: number;
}

export interface VideoComposition {
  id: string;
  name: string;
  projectId: string;
  layers: EffectLayer[];
  duration: number;
  fps: number;
  resolution: {
    width: number;
    height: number;
  };
}
```

### API Integration
```typescript
// apps/api/src/routers/video.ts
import { router, protectedProcedure } from '../trpc';
import { z } from 'zod';

export const videoRouter = router({
  createComposition: protectedProcedure
    .input(z.object({
      projectId: z.string(),
      name: z.string(),
      layers: z.array(effectLayerSchema),
      duration: z.number()
    }))
    .mutation(async ({ ctx, input }) => {
      // Create video composition record
    }),
    
  getComposition: protectedProcedure
    .input(z.object({ id: z.string() }))
    .query(async ({ ctx, input }) => {
      // Fetch composition data for Remotion
    })
});
```

## Testing Strategy

### Unit Tests
```typescript
// apps/video/src/__tests__/midiSync.test.ts
import { getMIDIDataAtFrame } from '../utils/midiSync';
import { createSampleMIDIData } from '@midiviz/test-utils';

describe('MIDI Timeline Synchronization', () => {
  test('should return active notes at specific frame', () => {
    const midiData = createSampleMIDIData();
    const sync = getMIDIDataAtFrame(midiData, 30, 30); // 1 second at 30fps
    
    expect(sync.time).toBe(1);
    expect(sync.activeNotes).toBeDefined();
    expect(sync.tempo).toBeGreaterThan(0);
  });
  
  test('should handle frame-to-time conversion correctly', () => {
    const midiData = createSampleMIDIData();
    const sync = getMIDIDataAtFrame(midiData, 90, 30); // 3 seconds
    
    expect(sync.time).toBe(3);
  });
});
```

### Integration Tests
```typescript
// apps/video/src/__tests__/integration.test.tsx
import React from 'react';
import { render } from '@testing-library/react';
import { ThreeJSLayer } from '../components/ThreeJSLayer';
import { createSampleMIDIData } from '@midiviz/test-utils';

describe('Remotion Three.js Integration', () => {
  test('should render Three.js canvas within Remotion', () => {
    const midiData = createSampleMIDIData();
    const { container } = render(
      <ThreeJSLayer
        midiData={midiData}
        settings={{}}
        effectType="metaballs"
      />
    );
    
    expect(container.querySelector('canvas')).toBeInTheDocument();
  });
});
```

## Performance Considerations

### Canvas Optimization
- Use `preserveDrawingBuffer: true` for video capture
- Implement frame caching for complex Three.js effects
- Optimize texture loading for video layers
- Use efficient MIDI data structures for timeline queries

### Memory Management
- Dispose Three.js resources between frames
- Implement object pooling for frequently created objects
- Clear unused textures and geometries
- Monitor memory usage during long renders

## Definition of Done

### ‚úÖ Functional Requirements
- Remotion development server runs successfully
- Three.js effects render within Remotion compositions
- MIDI data synchronizes with video timeline
- Hot reloading works for composition changes
- Basic video preview generates successfully

### ‚úÖ Technical Requirements
- No breaking changes to existing Three.js effects
- Maintains existing effect quality and performance
- Integrates with existing MIDI parsing system
- Follows monorepo structure conventions
- Type safety maintained across video package

### ‚úÖ Performance Requirements
- Video preview renders at stable framerate
- Memory usage remains reasonable during playback
- Three.js effects maintain visual fidelity in video
- Build process completes without errors
- Development workflow is responsive

## Future Enhancements (Epic 4 Stories)
- Video layer management (Story 4.3)
- MIDI parameter binding (Story 4.4)
- Professional export pipeline (Story 4.7)
- Real-time preview optimization
- Multi-layer composition support

---

## Dev Agent Record

### ‚úÖ Completion Status
- [x] **Core Foundation Setup**: Complete
- [x] **Package Installation**: Remotion 4.0.322, Three.js 0.158.0, React 18.3.1
- [x] **TypeScript Configuration**: Standalone config with proper types
- [x] **Component Architecture**: ThreeJSLayer, ThreeCanvas, MidiVisualizerVideo
- [x] **MIDI Timeline Sync**: getMIDIDataAtFrame utility with frame-to-time conversion
- [x] **Testing Suite**: 7/7 tests passing (4 MIDI sync + 3 integration)
- [x] **Development Server**: Remotion preview server configured

### üß™ Testing Results
```
‚úì MIDI Timeline Synchronization (4 tests) 
  ‚úì should return active notes at specific frame
  ‚úì should handle frame-to-time conversion correctly
  ‚úì should find active notes within time range
  ‚úì should return correct tempo and time signature

‚úì Remotion Three.js Integration (3 tests)
  ‚úì should render Three.js canvas within Remotion
  ‚úì should handle different effect types
  ‚úì should apply opacity correctly
```

### üìù Implementation Notes
- **Type Safety**: Created local type definitions for MIDIData, EffectLayer, VisualizationSettings
- **Hot Reload**: Development server supports composition hot reloading
- **Testing Setup**: Comprehensive mocking for Three.js and Remotion in test environment
- **Canvas Integration**: preserveDrawingBuffer enabled for video capture
- **Memory Management**: Proper disposal patterns for Three.js resources

### üéØ Next Steps for Epic 4
Ready for Story 4.2 (Video Layer Management) and subsequent stories in the Epic 4 roadmap.

---

**Dependencies**: Epic 1 (MIDI Parser), Epic 2 (Three.js Effects)  
**Estimated Effort**: 16 hours (8 hours setup, 4 hours Three.js integration, 4 hours testing/optimization)  
**Risk Level**: Medium (New technology integration with existing complex system) 