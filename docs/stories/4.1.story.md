# Story 4.1: Remotion Foundation Integration

**Epic**: 4 - Remotion Video Composition Platform  
**Story**: 4.1  
**Status**: ðŸ”´ NOT STARTED  
**Priority**: Critical  
**Estimated Effort**: 16 hours  
**Depends On**: Epic 1 âœ…, Epic 2 âœ…

## User Story

**As a** developer  
**I want** Remotion integrated as the core video composition engine  
**So that** I can build React-based video features while preserving existing Three.js effects  

## Acceptance Criteria

### ðŸ”§ Remotion Installation & Configuration
- [ ] **Monorepo Integration**: Remotion installed and configured in monorepo structure (`apps/video`)
- [ ] **Basic Composition**: Basic composition structure created with Three.js wrapper component
- [ ] **MIDI Data Flow**: MIDI data flows from existing parser to Remotion props
- [ ] **Canvas Integration**: Three.js canvas renders as video layer in Remotion composition
- [ ] **Timeline Sync**: Timeline synchronization working between Remotion frames and MIDI events
- [ ] **Development Server**: Development server supports hot reloading for composition changes
- [ ] **Build Process**: Build process generates both web preview and video export configurations

## Technical Implementation

### Apps/Video Structure
```typescript
// apps/video/package.json
{
  "name": "@phonoglyph/video",
  "version": "1.0.0",
  "dependencies": {
    "remotion": "^4.0.0",
    "@remotion/cli": "^4.0.0",
    "@remotion/player": "^4.0.0",
    "three": "^0.158.0",
    "@types/three": "^0.158.0"
  },
  "scripts": {
    "dev": "remotion preview",
    "build": "remotion bundle",
    "render": "remotion render"
  }
}
```

### Remotion Configuration
```typescript
// apps/video/remotion.config.ts
import { Config } from '@remotion/cli/config';

Config.setVideoImageFormat('jpeg');
Config.setOverwriteOutput(true);
Config.setPixelFormat('yuv420p');
Config.setCodec('h264');
Config.setCrf(18);
Config.setEntryPoint('./src/index.ts');

// Performance optimizations
Config.setBrowserExecutable(null); // Use default
Config.setTimeoutInMilliseconds(120000);
Config.setConcurrency(1);
```

### Three.js Wrapper Component
```typescript
// apps/video/src/components/ThreeJSLayer.tsx
import React, { useRef, useEffect } from 'react';
import { useCurrentFrame, useVideoConfig } from 'remotion';
import { ThreeCanvas } from './ThreeCanvas';
import type { MIDIData, VisualizationSettings } from '@phonoglyph/types';

interface ThreeJSLayerProps {
  midiData: MIDIData;
  settings: VisualizationSettings;
  effectType: 'metaballs' | 'particles' | 'midihud' | 'bloom';
  opacity?: number;
}

export const ThreeJSLayer: React.FC<ThreeJSLayerProps> = ({
  midiData,
  settings,
  effectType,
  opacity = 1
}) => {
  const frame = useCurrentFrame();
  const { fps, durationInFrames } = useVideoConfig();
  const canvasRef = useRef<HTMLCanvasElement>(null);
  
  // Convert frame to time for Three.js
  const currentTime = frame / fps;
  
  useEffect(() => {
    if (!canvasRef.current) return;
    
    // Initialize Three.js scene with existing effect
    const threeCanvas = new ThreeCanvas(canvasRef.current, {
      midiData,
      settings,
      effectType,
      currentTime,
      opacity
    });
    
    // Render current frame
    threeCanvas.render();
    
    return () => {
      threeCanvas.dispose();
    };
  }, [frame, midiData, settings, effectType, opacity]);
  
  return (
    <canvas
      ref={canvasRef}
      width={1920}
      height={1080}
      style={{
        width: '100%',
        height: '100%',
        opacity
      }}
    />
  );
};
```

### Main Composition
```typescript
// apps/video/src/Composition.tsx
import React from 'react';
import { Composition } from 'remotion';
import { MidiVisualizerVideo } from './MidiVisualizerVideo';

export const RemotionRoot: React.FC = () => {
  return (
    <>
      <Composition
        id="MidiVisualizer"
        component={MidiVisualizerVideo}
        durationInFrames={3000} // 60 seconds at 30fps
        fps={30}
        width={1920}
        height={1080}
        defaultProps={{
          midiFileId: 'sample',
          effectLayers: [
            { id: '1', type: 'metaballs', opacity: 0.8 },
            { id: '2', type: 'particles', opacity: 0.6 }
          ]
        }}
      />
    </>
  );
};
```

### Video Component
```typescript
// apps/video/src/MidiVisualizerVideo.tsx
import React from 'react';
import { Audio, useCurrentFrame, useVideoConfig } from 'remotion';
import { ThreeJSLayer } from './components/ThreeJSLayer';
import type { MIDIData, EffectLayer } from '@phonoglyph/types';

interface MidiVisualizerVideoProps {
  midiFileId: string;
  effectLayers: EffectLayer[];
  audioSrc?: string;
  midiData?: MIDIData;
}

export const MidiVisualizerVideo: React.FC<MidiVisualizerVideoProps> = ({
  midiFileId,
  effectLayers,
  audioSrc,
  midiData
}) => {
  const frame = useCurrentFrame();
  const { fps } = useVideoConfig();
  const currentTime = frame / fps;
  
  // TODO: Load MIDI data from API if not provided
  const resolvedMidiData = midiData || getDefaultMidiData();
  
  return (
    <div style={{ 
      width: '100%', 
      height: '100%', 
      background: 'linear-gradient(45deg, #0f172a, #1e293b)' 
    }}>
      {/* Audio track */}
      {audioSrc && <Audio src={audioSrc} />}
      
      {/* Three.js Effect Layers */}
      {effectLayers.map((layer) => (
        <ThreeJSLayer
          key={layer.id}
          midiData={resolvedMidiData}
          settings={layer.settings}
          effectType={layer.type}
          opacity={layer.opacity}
        />
      ))}
    </div>
  );
};
```

## MIDI Timeline Synchronization

### Frame-to-MIDI Mapping
```typescript
// apps/video/src/utils/midiSync.ts
export interface MIDITimelineSync {
  frame: number;
  time: number;
  activeNotes: MIDINote[];
  tempo: number;
  timeSignature: [number, number];
}

export function getMIDIDataAtFrame(
  midiData: MIDIData,
  frame: number,
  fps: number
): MIDITimelineSync {
  const time = frame / fps;
  
  // Find active notes at current time
  const activeNotes = midiData.tracks.flatMap(track =>
    track.notes.filter(note => 
      note.time <= time && (note.time + note.duration) > time
    )
  );
  
  // Get tempo and time signature at current time
  const tempoChange = midiData.tempoChanges
    .slice()
    .reverse()
    .find(change => change.time <= time);
    
  const timeSignatureChange = midiData.timeSignatures
    .slice()
    .reverse()
    .find(change => change.time <= time);
  
  return {
    frame,
    time,
    activeNotes,
    tempo: tempoChange?.bpm || 120,
    timeSignature: timeSignatureChange?.timeSignature || [4, 4]
  };
}
```

## Development Environment

### Hot Reloading Setup
```typescript
// apps/video/src/index.ts
import { registerRoot } from 'remotion';
import { RemotionRoot } from './Composition';

registerRoot(RemotionRoot);

// Development hot reload
if (module.hot) {
  module.hot.accept('./Composition', () => {
    const NextRemotionRoot = require('./Composition').RemotionRoot;
    registerRoot(NextRemotionRoot);
  });
}
```

### Build Configuration
```json
// apps/video/tsconfig.json
{
  "extends": "../../packages/config/tsconfig.json",
  "compilerOptions": {
    "target": "ES2020",
    "lib": ["DOM", "DOM.Iterable", "ES2020"],
    "allowJs": true,
    "skipLibCheck": true,
    "esModuleInterop": true,
    "allowSyntheticDefaultImports": true,
    "strict": true,
    "forceConsistentCasingInFileNames": true,
    "module": "ESNext",
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "react-jsx"
  },
  "include": [
    "src/**/*"
  ],
  "exclude": [
    "node_modules"
  ]
}
```

## Integration with Existing Codebase

### Shared Types Package
```typescript
// packages/types/src/video.ts
export interface EffectLayer {
  id: string;
  type: 'metaballs' | 'particles' | 'midihud' | 'bloom';
  opacity: number;
  settings: VisualizationSettings;
  zIndex: number;
}

export interface VideoComposition {
  id: string;
  name: string;
  projectId: string;
  layers: EffectLayer[];
  duration: number;
  fps: number;
  resolution: {
    width: number;
    height: number;
  };
}
```

### API Integration
```typescript
// apps/api/src/routers/video.ts
import { router, protectedProcedure } from '../trpc';
import { z } from 'zod';

export const videoRouter = router({
  createComposition: protectedProcedure
    .input(z.object({
      projectId: z.string(),
      name: z.string(),
      layers: z.array(effectLayerSchema),
      duration: z.number()
    }))
    .mutation(async ({ ctx, input }) => {
      // Create video composition record
    }),
    
  getComposition: protectedProcedure
    .input(z.object({ id: z.string() }))
    .query(async ({ ctx, input }) => {
      // Fetch composition data for Remotion
    })
});
```

## Testing Strategy

### Unit Tests
```typescript
// apps/video/src/__tests__/midiSync.test.ts
import { getMIDIDataAtFrame } from '../utils/midiSync';
import { createSampleMIDIData } from '@midiviz/test-utils';

describe('MIDI Timeline Synchronization', () => {
  test('should return active notes at specific frame', () => {
    const midiData = createSampleMIDIData();
    const sync = getMIDIDataAtFrame(midiData, 30, 30); // 1 second at 30fps
    
    expect(sync.time).toBe(1);
    expect(sync.activeNotes).toBeDefined();
    expect(sync.tempo).toBeGreaterThan(0);
  });
  
  test('should handle frame-to-time conversion correctly', () => {
    const midiData = createSampleMIDIData();
    const sync = getMIDIDataAtFrame(midiData, 90, 30); // 3 seconds
    
    expect(sync.time).toBe(3);
  });
});
```

### Integration Tests
```typescript
// apps/video/src/__tests__/integration.test.tsx
import React from 'react';
import { render } from '@testing-library/react';
import { ThreeJSLayer } from '../components/ThreeJSLayer';
import { createSampleMIDIData } from '@midiviz/test-utils';

describe('Remotion Three.js Integration', () => {
  test('should render Three.js canvas within Remotion', () => {
    const midiData = createSampleMIDIData();
    const { container } = render(
      <ThreeJSLayer
        midiData={midiData}
        settings={{}}
        effectType="metaballs"
      />
    );
    
    expect(container.querySelector('canvas')).toBeInTheDocument();
  });
});
```

## Performance Considerations

### Canvas Optimization
- Use `preserveDrawingBuffer: true` for video capture
- Implement frame caching for complex Three.js effects
- Optimize texture loading for video layers
- Use efficient MIDI data structures for timeline queries

### Memory Management
- Dispose Three.js resources between frames
- Implement object pooling for frequently created objects
- Clear unused textures and geometries
- Monitor memory usage during long renders

## Definition of Done

### âœ… Functional Requirements
- Remotion development server runs successfully
- Three.js effects render within Remotion compositions
- MIDI data synchronizes with video timeline
- Hot reloading works for composition changes
- Basic video preview generates successfully

### âœ… Technical Requirements
- No breaking changes to existing Three.js effects
- Maintains existing effect quality and performance
- Integrates with existing MIDI parsing system
- Follows monorepo structure conventions
- Type safety maintained across video package

### âœ… Performance Requirements
- Video preview renders at stable framerate
- Memory usage remains reasonable during playback
- Three.js effects maintain visual fidelity in video
- Build process completes without errors
- Development workflow is responsive

## Future Enhancements (Epic 4 Stories)
- Video layer management (Story 4.3)
- MIDI parameter binding (Story 4.4)
- Professional export pipeline (Story 4.7)
- Real-time preview optimization
- Multi-layer composition support

---

**Dependencies**: Epic 1 (MIDI Parser), Epic 2 (Three.js Effects)  
**Estimated Effort**: 16 hours (8 hours setup, 4 hours Three.js integration, 4 hours testing/optimization)  
**Risk Level**: Medium (New technology integration with existing complex system) 