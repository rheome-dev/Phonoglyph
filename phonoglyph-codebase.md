This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
app/
  (auth)/
    login/
      page.tsx
    signup/
      page.tsx
  audio-analysis-sandbox/
    page.tsx
    README.md
  auth/
    callback/
      route.ts
    error/
      page.tsx
  creative-visualizer/
    page.tsx
  dashboard/
    page.tsx
  files/
    page.tsx
  profile/
    page.tsx
  fonts.css
  globals.css
  layout.tsx
  page.tsx
components/
  assets/
    asset-preview.tsx
  audio-analysis/
    analysis-comparison.tsx
    analysis-method-controls.tsx
    analysis-parameters.tsx
    analysis-visualization.tsx
    api-test.tsx
    audio-analysis-sandbox.tsx
    auth-status.tsx
  auth/
    auth-guard.tsx
    login-form.tsx
    oauth-buttons.tsx
    profile-menu.tsx
    signup-form.tsx
  auto-save/
    auto-save-indicator.tsx
    auto-save-provider.tsx
    auto-save-settings.tsx
    creative-visualizer-with-auto-save.tsx
    index.ts
    save-history.tsx
  guest/
    conversion-prompt.tsx
    guest-banner.tsx
  hud/
    HudOverlay.tsx
    HudOverlayManager.tsx
    HudOverlayParameterModal.tsx
  layout/
    breadcrumb-nav.tsx
    collapsible-effects-sidebar.tsx
    collapsible-sidebar.tsx
  midi/
    file-selector.tsx
    midi-controls.tsx
    midi-timeline.tsx
    three-visualizer.tsx
  projects/
    project-creation-modal.tsx
    project-dashboard.tsx
    project-picker-modal.tsx
    project-settings.tsx
  providers/
    trpc-provider.tsx
  stem-separation/
    audio-stems-upload.tsx
    midi-stems-upload.tsx
    single-audio-upload.tsx
    stem-separation-upload.tsx
  stem-visualization/
    stem-waveform.tsx
  ui/
    aspect-ratio-selector.tsx
    avatar.tsx
    badge.tsx
    button.tsx
    card.tsx
    confirmation-modal.tsx
    dropdown-menu.tsx
    droppable-parameter.tsx
    DroppableSlider.tsx
    effect-carousel.tsx
    EffectsLibrarySidebar.README.md
    EffectsLibrarySidebar.tsx
    FeatureNode.tsx
    form.tsx
    glass-card.tsx
    glass-modal.tsx
    input.tsx
    label.tsx
    loading-spinner.tsx
    MappingSourcesPanel.tsx
    modulation-attenuator.tsx
    phonoglyph-logo.tsx
    portal-modal.tsx
    progress.tsx
    select.tsx
    separator.tsx
    slider.tsx
    stat-bar.tsx
    status-indicator.tsx
    switch.tsx
    technical-button.tsx
    toast.tsx
    toaster.tsx
  video-composition/
    DraggableFile.tsx
    EffectLayer.tsx
    ImageLayer.tsx
    LayerContainer.tsx
    TestVideoComposition.tsx
    UnifiedTimeline.tsx
    VideoCompositionTimeline.tsx
    VideoLayer.tsx
  dashboard.tsx
  landing-page.tsx
  navigation.tsx
config/
  package.json
db/
  migrations/
    001_initial_schema.sql
    002_supabase_auth_integration.sql
    003_file_metadata_table.sql
    004_midi_files_table.sql
    005_visualization_settings_table.sql
    006_stem_separation_table.sql
    006_video_image_support.sql
    007_enhanced_project_management.sql
    008_fix_rls_infinite_recursion.sql
    009_fix_rls_final.sql
    010_project_scoped_assets.sql
    011_stem_separation_jobs.sql
    012_audio_analysis_cache.sql
    013_add_master_and_stemtype_to_file_metadata.sql
    014_fix_file_metadata_rls.sql
    015_audio_analysis_jobs.sql
    016_make_midi_file_path_optional.sql
    017_edit_states.sql
    migrate.ts
  seeds/
    development.ts
  connection.ts
  prod-ca-2021.crt
hooks/
  use-audio-analysis.ts
  use-audio-features.ts
  use-auth.ts
  use-auto-save.ts
  use-feature-value.ts
  use-stem-audio-controller.ts
  use-toast.ts
  use-upload.ts
lib/
  video-composition/
    parameter-calculator.ts
  visualizer/
    core/
      AudioTextureManager.ts
      MediaLayerManager.ts
      MultiLayerCompositor.ts
      VisualizerManager.ts
    effects/
      BloomEffect.ts
      EffectDefinitions.ts
      EffectRegistry.ts
      MetaballsEffect.ts
      ParticleNetworkEffect.ts
      TestCubeEffect.ts
    aspect-ratios.ts
  auth.ts
  file-validation.ts
  guest-user.ts
  logger.ts
  supabase.ts
  trpc-links.ts
  trpc.ts
  utils.ts
  validations.ts
routers/
  audio-analysis-sandbox.ts
  auth.ts
  auto-save.ts
  file.ts
  guest.ts
  health.ts
  index.ts
  midi.ts
  project.ts
  stem.ts
  user.ts
scripts/
  backfill-audio-analysis.ts
  run-migrations.js
  setup-supabase-schema.sql
  setup-supabase.sql
  start-queue-worker.ts
  test-s3.ts
services/
  asset-manager.ts
  audio-analysis-processor.ts
  audio-analysis-sandbox-service.ts
  audio-analyzer.ts
  auto-save.ts
  media-processor.ts
  midi-parser.ts
  queue-worker.ts
  r2-storage.ts
  stem-processor.ts
  stem-separator.ts
  supabase-storage.ts
test/
  helpers/
    test-supabase.ts
  asset-management.test.ts
  auth-service.test.ts
  basic.test.ts
  database-schema.test.ts
  database-security.test.ts
  file-upload-integration.test.ts
  file-validation.test.ts
  midi-parser.test.ts
  midi-router.test.ts
  particle-audio-spawning.test.ts
  protected-routes.test.tsx
  r2-storage.test.ts
  setup.ts
  supabase-connection.test.ts
  trpc-auth.test.ts
  video-image-validation.test.ts
tests/
  audio-playback.test.ts
  auth-service.test.ts
  basic.test.ts
  protected-routes.test.tsx
  setup.ts
  supabase-connection.test.ts
types/
  dist/
    audio.d.ts
    audio.js
    index.d.ts
    index.js
    performance.d.ts
    performance.js
    type-guards.d.ts
    type-guards.js
    visualization.d.ts
    visualization.js
  audio-analysis.ts
  fluent-ffmpeg.d.ts
  guest.ts
  index.ts
  midi-parser-js.d.ts
  midi.ts
  package.json
  stem-audio-analysis.ts
  stem-visualization.ts
  tsconfig.json
  video-composition.ts
  visualizer.ts
index.ts
trpc.ts
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="db/migrations/001_initial_schema.sql">
-- Initial schema for Phonoglyph application
-- Migration: 001_initial_schema

-- Enable UUID extension
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Users table
CREATE TABLE "users" (
  "id" TEXT NOT NULL PRIMARY KEY DEFAULT uuid_generate_v4()::text,
  "name" TEXT,
  "email" TEXT NOT NULL UNIQUE,
  "image" TEXT,
  "created_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
  "updated_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- Projects table
CREATE TABLE "projects" (
  "id" TEXT NOT NULL PRIMARY KEY DEFAULT uuid_generate_v4()::text,
  "name" TEXT NOT NULL,
  "user_id" TEXT NOT NULL REFERENCES "users"("id") ON DELETE CASCADE,
  "midi_file_path" TEXT NOT NULL,
  "audio_file_path" TEXT,
  "user_video_path" TEXT,
  "render_configuration" JSONB NOT NULL DEFAULT '{}'::jsonb,
  "created_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
  "updated_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- Indexes for better performance
CREATE INDEX "idx_users_email" ON "users"("email");
CREATE INDEX "idx_projects_user_id" ON "projects"("user_id");
CREATE INDEX "idx_projects_created_at" ON "projects"("created_at");

-- Update timestamp triggers
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER update_users_updated_at BEFORE UPDATE ON "users" 
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_projects_updated_at BEFORE UPDATE ON "projects" 
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
</file>

<file path="db/migrations/002_supabase_auth_integration.sql">
-- Migration: 002_supabase_auth_integration
-- Integrate with Supabase authentication and set up Row Level Security

-- Drop the custom users table since we'll use auth.users
DROP TABLE IF EXISTS "users" CASCADE;

-- Update projects table to reference auth.users
ALTER TABLE "projects" 
  ALTER COLUMN "user_id" TYPE UUID USING "user_id"::UUID,
  ADD CONSTRAINT "projects_user_id_fkey" 
    FOREIGN KEY ("user_id") REFERENCES auth.users(id) ON DELETE CASCADE;

-- Create user profiles table for additional user data
CREATE TABLE "user_profiles" (
  "id" UUID NOT NULL PRIMARY KEY REFERENCES auth.users(id) ON DELETE CASCADE,
  "display_name" TEXT,
  "avatar_url" TEXT,
  "bio" TEXT,
  "preferences" JSONB DEFAULT '{}'::jsonb,
  "subscription_tier" TEXT DEFAULT 'free' CHECK (subscription_tier IN ('free', 'premium', 'enterprise')),
  "created_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
  "updated_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- Create project collaborators table for sharing
CREATE TABLE "project_collaborators" (
  "id" UUID NOT NULL PRIMARY KEY DEFAULT uuid_generate_v4(),
  "project_id" TEXT NOT NULL REFERENCES "projects"("id") ON DELETE CASCADE,
  "user_id" UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  "role" TEXT NOT NULL DEFAULT 'viewer' CHECK (role IN ('owner', 'editor', 'viewer')),
  "created_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
  UNIQUE("project_id", "user_id")
);

-- Create audit log table for security tracking
CREATE TABLE "audit_logs" (
  "id" UUID NOT NULL PRIMARY KEY DEFAULT uuid_generate_v4(),
  "user_id" UUID REFERENCES auth.users(id) ON DELETE SET NULL,
  "action" TEXT NOT NULL,
  "resource_type" TEXT NOT NULL,
  "resource_id" TEXT,
  "metadata" JSONB DEFAULT '{}'::jsonb,
  "ip_address" INET,
  "user_agent" TEXT,
  "created_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- Add indexes for performance
CREATE INDEX "idx_user_profiles_display_name" ON "user_profiles"("display_name");
CREATE INDEX "idx_project_collaborators_project_id" ON "project_collaborators"("project_id");
CREATE INDEX "idx_project_collaborators_user_id" ON "project_collaborators"("user_id");
CREATE INDEX "idx_audit_logs_user_id" ON "audit_logs"("user_id");
CREATE INDEX "idx_audit_logs_action" ON "audit_logs"("action");
CREATE INDEX "idx_audit_logs_created_at" ON "audit_logs"("created_at");

-- Update triggers for new tables
DROP TRIGGER IF EXISTS update_user_profiles_updated_at ON "user_profiles";
CREATE TRIGGER update_user_profiles_updated_at BEFORE UPDATE ON "user_profiles" 
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

DROP TRIGGER IF EXISTS update_projects_updated_at ON "projects";
CREATE TRIGGER update_projects_updated_at BEFORE UPDATE ON "projects" 
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

-- =============================================
-- ROW LEVEL SECURITY (RLS) POLICIES
-- =============================================

-- Enable RLS on all tables
ALTER TABLE "projects" ENABLE ROW LEVEL SECURITY;
ALTER TABLE "user_profiles" ENABLE ROW LEVEL SECURITY;
ALTER TABLE "project_collaborators" ENABLE ROW LEVEL SECURITY;
ALTER TABLE "audit_logs" ENABLE ROW LEVEL SECURITY;

-- Projects RLS Policies
-- Users can only see their own projects or projects they're collaborators on
CREATE POLICY "Users can view their own projects" ON "projects"
  FOR SELECT USING (
    auth.uid() = user_id 
    OR EXISTS (
      SELECT 1 FROM "project_collaborators" 
      WHERE project_id = "projects"."id" 
      AND user_id = auth.uid()
    )
  );

-- Users can only insert projects for themselves
CREATE POLICY "Users can create projects for themselves" ON "projects"
  FOR INSERT WITH CHECK (auth.uid() = user_id);

-- Users can only update their own projects or projects they have editor+ access to
CREATE POLICY "Users can update their own projects" ON "projects"
  FOR UPDATE USING (
    auth.uid() = user_id 
    OR EXISTS (
      SELECT 1 FROM "project_collaborators" 
      WHERE project_id = "projects"."id" 
      AND user_id = auth.uid() 
      AND role IN ('owner', 'editor')
    )
  );

-- Users can only delete their own projects
CREATE POLICY "Users can delete their own projects" ON "projects"
  FOR DELETE USING (auth.uid() = user_id);

-- User Profiles RLS Policies
-- Users can view all profiles (for collaboration)
CREATE POLICY "Users can view all profiles" ON "user_profiles"
  FOR SELECT USING (true);

-- Users can only insert/update their own profile
CREATE POLICY "Users can manage their own profile" ON "user_profiles"
  FOR ALL USING (auth.uid() = id);

-- Project Collaborators RLS Policies
-- Users can view collaborators for projects they have access to
CREATE POLICY "Users can view project collaborators" ON "project_collaborators"
  FOR SELECT USING (
    EXISTS (
      SELECT 1 FROM "projects" 
      WHERE id = project_id 
      AND (
        user_id = auth.uid() 
        OR EXISTS (
          SELECT 1 FROM "project_collaborators" pc2 
          WHERE pc2.project_id = project_id 
          AND pc2.user_id = auth.uid()
        )
      )
    )
  );

-- Only project owners can manage collaborators
CREATE POLICY "Project owners can manage collaborators" ON "project_collaborators"
  FOR ALL USING (
    EXISTS (
      SELECT 1 FROM "projects" 
      WHERE id = project_id 
      AND user_id = auth.uid()
    )
  );

-- Audit Logs RLS Policies
-- Users can only view their own audit logs
CREATE POLICY "Users can view their own audit logs" ON "audit_logs"
  FOR SELECT USING (auth.uid() = user_id);

-- System can insert audit logs (no user restriction for INSERT)
CREATE POLICY "System can insert audit logs" ON "audit_logs"
  FOR INSERT WITH CHECK (true);

-- =============================================
-- HELPER FUNCTIONS
-- =============================================

-- Function to create user profile when user signs up
CREATE OR REPLACE FUNCTION create_user_profile()
RETURNS TRIGGER AS $$
BEGIN
  INSERT INTO "user_profiles" (id, display_name, avatar_url)
  VALUES (
    NEW.id,
    COALESCE(NEW.raw_user_meta_data->>'name', NEW.email),
    NEW.raw_user_meta_data->>'avatar_url'
  );
  RETURN NEW;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Trigger to create profile when user signs up
CREATE TRIGGER on_auth_user_created
  AFTER INSERT ON auth.users
  FOR EACH ROW EXECUTE FUNCTION create_user_profile();

-- Function to log audit events
CREATE OR REPLACE FUNCTION log_audit_event(
  p_user_id UUID,
  p_action TEXT,
  p_resource_type TEXT,
  p_resource_id TEXT DEFAULT NULL,
  p_metadata JSONB DEFAULT '{}'::jsonb
)
RETURNS VOID AS $$
BEGIN
  INSERT INTO "audit_logs" (user_id, action, resource_type, resource_id, metadata)
  VALUES (p_user_id, p_action, p_resource_type, p_resource_id, p_metadata);
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Function to check if user can access project
CREATE OR REPLACE FUNCTION user_can_access_project(p_project_id TEXT, p_user_id UUID)
RETURNS BOOLEAN AS $$
BEGIN
  RETURN EXISTS (
    SELECT 1 FROM "projects" 
    WHERE id = p_project_id 
    AND (
      user_id = p_user_id
      OR EXISTS (
        SELECT 1 FROM "project_collaborators" 
        WHERE project_id = p_project_id 
        AND user_id = p_user_id
      )
    )
  );
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
</file>

<file path="db/migrations/003_file_metadata_table.sql">
-- MIDI file processing table for storing parsed MIDI metadata
DROP TABLE IF EXISTS "file_metadata" CASCADE;
CREATE TABLE "file_metadata" (
  "id" UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  "user_id" UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  "file_name" VARCHAR(255) NOT NULL,
  "file_type" VARCHAR(20) NOT NULL,
  "mime_type" VARCHAR(100) NOT NULL,
  "file_size" INTEGER NOT NULL,
  "s3_key" VARCHAR(255) NOT NULL,
  "s3_bucket" VARCHAR(255) NOT NULL,
  "upload_status" VARCHAR(20) NOT NULL DEFAULT 'uploading' CHECK (upload_status IN ('uploading', 'completed', 'failed')),
  "is_master" BOOLEAN NOT NULL DEFAULT FALSE,
  "stem_type" VARCHAR(32),
  "created_at" TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
  "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);

-- Indexes
CREATE INDEX IF NOT EXISTS "idx_file_metadata_user_id" ON "file_metadata"("user_id");
CREATE INDEX IF NOT EXISTS "idx_file_metadata_file_type" ON "file_metadata"("file_type");
CREATE INDEX IF NOT EXISTS "idx_file_metadata_created_at" ON "file_metadata"("created_at");

-- Enable RLS (Row Level Security) for user data protection
ALTER TABLE "file_metadata" ENABLE ROW LEVEL SECURITY;

-- RLS Policy: Users can only access their own files
CREATE POLICY "Users can access own files" ON "file_metadata"
  FOR ALL 
  USING (auth.uid() = user_id);

-- Function to automatically update updated_at timestamp
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ language 'plpgsql';

-- Trigger to auto-update updated_at on record changes
CREATE TRIGGER update_file_metadata_updated_at 
  BEFORE UPDATE ON "file_metadata" 
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
</file>

<file path="db/migrations/004_midi_files_table.sql">
-- MIDI file processing table for storing parsed MIDI metadata
DROP TABLE IF EXISTS "midi_files" CASCADE;
CREATE TABLE "midi_files" (
  "id" UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  "user_id" UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  "file_key" VARCHAR(255) NOT NULL,
  "original_filename" VARCHAR(255) NOT NULL,
  "file_size" INTEGER NOT NULL,
  
  -- Parsed MIDI metadata
  "duration_seconds" DECIMAL(10,3),
  "track_count" INTEGER,
  "note_count" INTEGER,
  "time_signature" VARCHAR(10),
  "key_signature" VARCHAR(10),
  "tempo_bpm" INTEGER,
  
  -- Processing status
  "parsing_status" VARCHAR(20) NOT NULL DEFAULT 'pending' CHECK (parsing_status IN ('pending', 'completed', 'failed')),
  "parsed_data" JSONB,
  "error_message" TEXT,
  
  "created_at" TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
  "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);

-- Create indexes for efficient queries
CREATE INDEX IF NOT EXISTS "idx_midi_files_user_id" ON "midi_files"("user_id");
CREATE INDEX IF NOT EXISTS "idx_midi_files_file_key" ON "midi_files"("file_key");
CREATE INDEX IF NOT EXISTS "idx_midi_files_parsing_status" ON "midi_files"("parsing_status");
CREATE INDEX IF NOT EXISTS "idx_midi_files_created_at" ON "midi_files"("created_at");
CREATE INDEX IF NOT EXISTS "idx_midi_files_duration" ON "midi_files"("duration_seconds");

-- GIN index for efficient JSONB queries on parsed_data
CREATE INDEX IF NOT EXISTS "idx_midi_files_parsed_data" ON "midi_files" USING GIN ("parsed_data");

-- Unique constraint to prevent duplicate processing of same file
CREATE UNIQUE INDEX IF NOT EXISTS "idx_midi_files_user_file_key" ON "midi_files"("user_id", "file_key");

-- Enable RLS (Row Level Security) for user data protection
ALTER TABLE "midi_files" ENABLE ROW LEVEL SECURITY;

-- RLS Policy: Users can only access their own MIDI files
CREATE POLICY "Users can access own MIDI files" ON "midi_files"
  FOR ALL 
  USING (auth.uid() = user_id);

-- Trigger to auto-update updated_at on record changes
CREATE TRIGGER update_midi_files_updated_at 
  BEFORE UPDATE ON "midi_files" 
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
</file>

<file path="db/migrations/005_visualization_settings_table.sql">
-- User visualization preferences table
CREATE TABLE "visualization_settings" (
  "id" UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  "user_id" UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  "midi_file_id" UUID NOT NULL REFERENCES "midi_files"(id) ON DELETE CASCADE,
  
  -- Visualization preferences
  "color_scheme" VARCHAR(20) NOT NULL DEFAULT 'mixed' CHECK (color_scheme IN ('sage', 'slate', 'dusty-rose', 'mixed')),
  "pixels_per_second" INTEGER NOT NULL DEFAULT 50 CHECK (pixels_per_second >= 10 AND pixels_per_second <= 200),
  "show_track_labels" BOOLEAN NOT NULL DEFAULT true,
  "show_velocity" BOOLEAN NOT NULL DEFAULT true,
  "min_key" INTEGER NOT NULL DEFAULT 21 CHECK (min_key >= 0 AND min_key <= 127),
  "max_key" INTEGER NOT NULL DEFAULT 108 CHECK (max_key >= 0 AND max_key <= 127),
  
  "created_at" TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
  "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
  
  -- Ensure key range is valid
  CONSTRAINT "valid_key_range" CHECK (min_key <= max_key)
);

-- Create indexes for efficient queries
CREATE INDEX "idx_visualization_settings_user_id" ON "visualization_settings"("user_id");
CREATE INDEX "idx_visualization_settings_midi_file_id" ON "visualization_settings"("midi_file_id");
CREATE INDEX "idx_visualization_settings_created_at" ON "visualization_settings"("created_at");

-- Unique constraint: one settings record per user per MIDI file
CREATE UNIQUE INDEX "idx_visualization_settings_user_midi_file" 
  ON "visualization_settings"("user_id", "midi_file_id");

-- Enable RLS (Row Level Security) for user data protection
ALTER TABLE "visualization_settings" ENABLE ROW LEVEL SECURITY;

-- RLS Policy: Users can only access their own visualization settings
CREATE POLICY "Users can access own visualization settings" ON "visualization_settings"
  FOR ALL 
  USING (auth.uid() = user_id);

-- Trigger to auto-update updated_at on record changes
CREATE TRIGGER update_visualization_settings_updated_at 
  BEFORE UPDATE ON "visualization_settings" 
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
</file>

<file path="db/migrations/006_stem_separation_table.sql">
-- Stem separation processing table
CREATE TABLE "stem_separations" (
  "id" UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  "user_id" UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  "file_metadata_id" UUID NOT NULL REFERENCES "file_metadata"(id) ON DELETE CASCADE,
  
  -- Processing status
  "status" VARCHAR(20) NOT NULL DEFAULT 'pending' 
    CHECK (status IN ('pending', 'processing', 'completed', 'failed')),
  "error_message" TEXT,
  
  -- Stem file paths in R2
  "drums_stem_key" VARCHAR(255),
  "bass_stem_key" VARCHAR(255),
  "vocals_stem_key" VARCHAR(255),
  "other_stem_key" VARCHAR(255),
  
  -- Processing metadata
  "model_version" VARCHAR(50) NOT NULL DEFAULT '5stems',
  "processing_duration" INTEGER, -- in seconds
  "created_at" TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
  "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);

-- Create indexes for efficient queries
CREATE INDEX "idx_stem_separations_user_id" ON "stem_separations"("user_id");
CREATE INDEX "idx_stem_separations_file_metadata_id" ON "stem_separations"("file_metadata_id");
CREATE INDEX "idx_stem_separations_status" ON "stem_separations"("status");
CREATE INDEX "idx_stem_separations_created_at" ON "stem_separations"("created_at");

-- Unique constraint to prevent duplicate processing
CREATE UNIQUE INDEX "idx_stem_separations_file" 
  ON "stem_separations"("file_metadata_id", "model_version");

-- Enable RLS (Row Level Security) for user data protection
ALTER TABLE "stem_separations" ENABLE ROW LEVEL SECURITY;

-- RLS Policy: Users can only access their own stem separations
CREATE POLICY "Users can access own stem separations" ON "stem_separations"
  FOR ALL 
  USING (auth.uid() = user_id);

-- Trigger to auto-update updated_at on record changes
CREATE TRIGGER update_stem_separations_updated_at 
  BEFORE UPDATE ON "stem_separations" 
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
</file>

<file path="db/migrations/006_video_image_support.sql">
-- Migration: 006_video_image_support
-- Extend file_metadata table for video and image assets

-- Create file_type enum (if it doesn't exist)
DO $$ BEGIN
    CREATE TYPE file_type_enum AS ENUM ('midi', 'audio', 'video', 'image');
EXCEPTION
    WHEN duplicate_object THEN null;
END $$;

-- If enum exists but missing values, add them
DO $$
BEGIN
    IF NOT EXISTS (SELECT 1 FROM pg_enum WHERE enumlabel = 'video' AND enumtypid = 'file_type_enum'::regtype) THEN
        ALTER TYPE file_type_enum ADD VALUE 'video';
    END IF;
    IF NOT EXISTS (SELECT 1 FROM pg_enum WHERE enumlabel = 'image' AND enumtypid = 'file_type_enum'::regtype) THEN
        ALTER TYPE file_type_enum ADD VALUE 'image';
    END IF;
EXCEPTION
    WHEN others THEN
        -- If enum doesn't exist, create it with all values
        DROP TYPE IF EXISTS file_type_enum;
        CREATE TYPE file_type_enum AS ENUM ('midi', 'audio', 'video', 'image');
END $$;

-- Convert file_type column from VARCHAR to enum (if not already)
DO $$
BEGIN
    -- Check if column is already the correct type
    IF EXISTS (
        SELECT 1 FROM information_schema.columns 
        WHERE table_name = 'file_metadata' 
        AND column_name = 'file_type' 
        AND data_type = 'character varying'
    ) THEN
        -- Convert VARCHAR to enum
        ALTER TABLE file_metadata 
        ALTER COLUMN file_type TYPE file_type_enum USING file_type::file_type_enum;
    END IF;
END $$;

-- Add new columns for video and image metadata
ALTER TABLE file_metadata 
ADD COLUMN IF NOT EXISTS video_metadata JSONB,     -- Duration, resolution, frame rate, codec
ADD COLUMN IF NOT EXISTS image_metadata JSONB,     -- Dimensions, color profile, orientation  
ADD COLUMN IF NOT EXISTS thumbnail_url TEXT,       -- Generated thumbnail/poster URL
ADD COLUMN IF NOT EXISTS processing_status TEXT DEFAULT 'completed' CHECK (
  processing_status IN ('pending', 'processing', 'completed', 'failed')
);

-- Add indexes for new columns
CREATE INDEX IF NOT EXISTS "idx_file_metadata_processing_status" ON "file_metadata"("processing_status");
CREATE INDEX IF NOT EXISTS "idx_file_metadata_thumbnail_url" ON "file_metadata"("thumbnail_url") WHERE thumbnail_url IS NOT NULL;
</file>

<file path="db/migrations/007_enhanced_project_management.sql">
-- Enhanced Project Management Schema
-- Migration: 007_enhanced_project_management

-- Extend existing projects table with new fields
ALTER TABLE "projects" 
ADD COLUMN "description" TEXT,
ADD COLUMN "genre" TEXT,
ADD COLUMN "privacy_setting" TEXT DEFAULT 'private' CHECK (privacy_setting IN ('private', 'unlisted', 'public')),
ADD COLUMN "thumbnail_url" TEXT,
ADD COLUMN "primary_midi_file_id" UUID;

-- Create project sharing table for unique URL access
CREATE TABLE "project_shares" (
  "id" UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  "project_id" TEXT NOT NULL REFERENCES "projects"("id") ON DELETE CASCADE,
  "share_token" TEXT NOT NULL UNIQUE,
  "access_type" TEXT DEFAULT 'view' CHECK (access_type IN ('view', 'embed')),
  "expires_at" TIMESTAMP WITH TIME ZONE,
  "view_count" INTEGER DEFAULT 0,
  "created_at" TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  "updated_at" TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Add project relationship to file_metadata table
ALTER TABLE "file_metadata" 
ADD COLUMN "project_id" TEXT REFERENCES "projects"("id") ON DELETE CASCADE;

-- Create indexes for performance on filtering and search
CREATE INDEX IF NOT EXISTS "idx_projects_genre" ON "projects"("genre");
CREATE INDEX IF NOT EXISTS "idx_projects_privacy" ON "projects"("privacy_setting");
CREATE INDEX IF NOT EXISTS "idx_projects_user_privacy" ON "projects"("user_id", "privacy_setting");
CREATE INDEX IF NOT EXISTS "idx_project_shares_token" ON "project_shares"("share_token");
CREATE INDEX IF NOT EXISTS "idx_project_shares_project" ON "project_shares"("project_id");
CREATE INDEX IF NOT EXISTS "idx_file_metadata_project" ON "file_metadata"("project_id");

-- Enable RLS for project sharing table
ALTER TABLE "project_shares" ENABLE ROW LEVEL SECURITY;

-- RLS Policy: Users can manage shares for their own projects
CREATE POLICY "Users can manage own project shares" ON "project_shares"
  FOR ALL 
  USING (
    EXISTS (
      SELECT 1 FROM "projects" 
      WHERE "projects"."id" = "project_shares"."project_id" 
      AND "projects"."user_id" = auth.uid()
    )
  );

-- RLS Policy: Public access to shared projects via token
CREATE POLICY "Public access to shared projects" ON "project_shares"
  FOR SELECT
  TO anon, authenticated
  USING (true);

-- Update existing projects RLS policies for privacy settings
DROP POLICY IF EXISTS "Users can access own projects" ON "projects";

-- Enhanced RLS policy for projects with privacy settings
CREATE POLICY "Users can access own projects" ON "projects"
  FOR ALL 
  USING (user_id = auth.uid());

-- Policy for public access to public projects
CREATE POLICY "Public access to public projects" ON "projects"
  FOR SELECT
  TO anon, authenticated
  USING (privacy_setting = 'public');

-- Policy for shared project access via project_shares
CREATE POLICY "Shared project access" ON "projects"
  FOR SELECT
  TO anon, authenticated
  USING (
    privacy_setting = 'unlisted' AND
    EXISTS (
      SELECT 1 FROM "project_shares"
      WHERE "project_shares"."project_id" = "projects"."id"
    )
  );

-- Add trigger for project_shares updated_at
CREATE TRIGGER update_project_shares_updated_at 
  BEFORE UPDATE ON "project_shares" 
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

-- Add foreign key constraint for primary_midi_file_id (referencing file_metadata)
-- Note: Adding as separate step to handle existing data
ALTER TABLE "projects" 
ADD CONSTRAINT "fk_projects_primary_midi_file" 
FOREIGN KEY ("primary_midi_file_id") 
REFERENCES "file_metadata"("id") 
ON DELETE SET NULL;
</file>

<file path="db/migrations/008_fix_rls_infinite_recursion.sql">
-- Fix RLS Infinite Recursion in Project Collaborators
-- Migration: 008_fix_rls_infinite_recursion

-- Drop the problematic policies that cause circular references
DROP POLICY IF EXISTS "Users can view project collaborators" ON "project_collaborators";
DROP POLICY IF EXISTS "Project owners can manage collaborators" ON "project_collaborators";

-- Create simplified RLS policies for project_collaborators without circular references
-- Users can view collaborators for projects they own
CREATE POLICY "Users can view collaborators for owned projects" ON "project_collaborators"
  FOR SELECT USING (
    EXISTS (
      SELECT 1 FROM "projects" 
      WHERE "projects"."id" = "project_collaborators"."project_id" 
      AND "projects"."user_id" = auth.uid()
    )
  );

-- Users can view their own collaborator records
CREATE POLICY "Users can view own collaborator records" ON "project_collaborators"
  FOR SELECT USING ("project_collaborators"."user_id" = auth.uid());

-- Only project owners can manage (INSERT/UPDATE/DELETE) collaborators
CREATE POLICY "Project owners can manage collaborators" ON "project_collaborators"
  FOR ALL USING (
    EXISTS (
      SELECT 1 FROM "projects" 
      WHERE "projects"."id" = "project_collaborators"."project_id" 
      AND "projects"."user_id" = auth.uid()
    )
  );

-- Also update the projects RLS policy to remove circular reference
DROP POLICY IF EXISTS "Users can view their own projects" ON "projects";

-- Create a simplified policy for projects that doesn't reference collaborators
CREATE POLICY "Users can view their own projects" ON "projects"
  FOR SELECT USING ("projects"."user_id" = auth.uid());

-- Separate policy for collaborator access to projects  
CREATE POLICY "Collaborators can view shared projects" ON "projects"
  FOR SELECT USING (
    EXISTS (
      SELECT 1 FROM "project_collaborators" 
      WHERE "project_collaborators"."project_id" = "projects"."id" 
      AND "project_collaborators"."user_id" = auth.uid()
    )
  );

-- Update the project update policy to also remove circular reference
DROP POLICY IF EXISTS "Users can update their own projects" ON "projects";

CREATE POLICY "Project owners can update projects" ON "projects"
  FOR UPDATE USING ("projects"."user_id" = auth.uid());

CREATE POLICY "Project collaborators can update projects" ON "projects"
  FOR UPDATE USING (
    EXISTS (
      SELECT 1 FROM "project_collaborators" 
      WHERE "project_collaborators"."project_id" = "projects"."id" 
      AND "project_collaborators"."user_id" = auth.uid()
      AND "project_collaborators"."role" IN ('owner', 'editor')
    )
  );
</file>

<file path="db/migrations/009_fix_rls_final.sql">
-- Complete RLS Fix - Remove All Circular Dependencies
-- Migration: 009_fix_rls_final

-- Temporarily disable RLS to clean up policies
ALTER TABLE "projects" DISABLE ROW LEVEL SECURITY;
ALTER TABLE "project_collaborators" DISABLE ROW LEVEL SECURITY;

-- Drop ALL existing problematic policies
DROP POLICY IF EXISTS "Users can access own projects" ON "projects";
DROP POLICY IF EXISTS "Users can view their own projects" ON "projects";
DROP POLICY IF EXISTS "Collaborators can view shared projects" ON "projects";
DROP POLICY IF EXISTS "Users can create projects for themselves" ON "projects";
DROP POLICY IF EXISTS "Project owners can update projects" ON "projects";
DROP POLICY IF EXISTS "Project collaborators can update projects" ON "projects";
DROP POLICY IF EXISTS "Users can update their own projects" ON "projects";
DROP POLICY IF EXISTS "Users can delete their own projects" ON "projects";
DROP POLICY IF EXISTS "Public access to public projects" ON "projects";
DROP POLICY IF EXISTS "Shared project access" ON "projects";

DROP POLICY IF EXISTS "Users can view collaborators for owned projects" ON "project_collaborators";
DROP POLICY IF EXISTS "Users can view own collaborator records" ON "project_collaborators";
DROP POLICY IF EXISTS "Project owners can manage collaborators" ON "project_collaborators";
DROP POLICY IF EXISTS "Users can view project collaborators" ON "project_collaborators";

-- Re-enable RLS
ALTER TABLE "projects" ENABLE ROW LEVEL SECURITY;
ALTER TABLE "project_collaborators" ENABLE ROW LEVEL SECURITY;

-- Create simple, non-circular RLS policies for projects
-- Users can see their own projects
CREATE POLICY "project_owner_access" ON "projects"
  FOR ALL 
  TO authenticated
  USING ("user_id" = auth.uid());

-- Public can see public projects  
CREATE POLICY "public_project_access" ON "projects"
  FOR SELECT
  TO anon, authenticated
  USING ("privacy_setting" = 'public');

-- Simple policies for project_collaborators
-- Users can see collaborator records for projects they own
CREATE POLICY "collaborator_owner_access" ON "project_collaborators"
  FOR ALL
  TO authenticated
  USING (
    "project_id" IN (
      SELECT "id" FROM "projects" 
      WHERE "user_id" = auth.uid()
    )
  );

-- Users can see their own collaborator records  
CREATE POLICY "collaborator_self_access" ON "project_collaborators"
  FOR SELECT
  TO authenticated
  USING ("user_id" = auth.uid());
</file>

<file path="db/migrations/010_project_scoped_assets.sql">
-- Project-Scoped Asset Management - Story 1.7
-- Migration: 010_project_scoped_assets

-- Add asset management fields to file_metadata table
ALTER TABLE "file_metadata" 
ADD COLUMN IF NOT EXISTS "asset_type" TEXT CHECK (asset_type IN ('midi', 'audio', 'video', 'image')),
ADD COLUMN IF NOT EXISTS "is_primary" BOOLEAN DEFAULT false,
ADD COLUMN IF NOT EXISTS "duration_seconds" FLOAT,
ADD COLUMN IF NOT EXISTS "usage_status" TEXT DEFAULT 'unused' CHECK (usage_status IN ('active', 'referenced', 'unused')),
ADD COLUMN IF NOT EXISTS "last_used_at" TIMESTAMPTZ,
ADD COLUMN IF NOT EXISTS "replacement_history" JSONB DEFAULT '[]'::jsonb;

-- Create asset usage tracking table
CREATE TABLE "asset_usage" (
  "id" UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  "file_id" UUID NOT NULL REFERENCES "file_metadata"("id") ON DELETE CASCADE,
  "project_id" TEXT NOT NULL REFERENCES "projects"("id") ON DELETE CASCADE,
  "usage_type" TEXT NOT NULL CHECK (usage_type IN ('visualizer', 'composition', 'export')),
  "usage_context" JSONB DEFAULT '{}'::jsonb,
  "started_at" TIMESTAMPTZ DEFAULT NOW(),
  "ended_at" TIMESTAMPTZ,
  "session_duration" INTERVAL GENERATED ALWAYS AS (ended_at - started_at) STORED,
  "created_at" TIMESTAMPTZ DEFAULT NOW()
);

-- Create storage quota tracking table
CREATE TABLE "project_storage_quotas" (
  "project_id" TEXT PRIMARY KEY REFERENCES "projects"("id") ON DELETE CASCADE,
  "user_subscription_tier" TEXT NOT NULL DEFAULT 'free',
  "total_limit_bytes" BIGINT NOT NULL,
  "used_bytes" BIGINT DEFAULT 0,
  "file_count_limit" INTEGER NOT NULL,
  "file_count_used" INTEGER DEFAULT 0,
  "per_file_size_limit" BIGINT NOT NULL,
  "last_calculated_at" TIMESTAMPTZ DEFAULT NOW(),
  "created_at" TIMESTAMPTZ DEFAULT NOW(),
  "updated_at" TIMESTAMPTZ DEFAULT NOW()
);

-- Create asset folders/categories table
CREATE TABLE "asset_folders" (
  "id" UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  "project_id" TEXT NOT NULL REFERENCES "projects"("id") ON DELETE CASCADE,
  "name" TEXT NOT NULL,
  "description" TEXT,
  "parent_folder_id" UUID REFERENCES "asset_folders"("id") ON DELETE CASCADE,
  "created_at" TIMESTAMPTZ DEFAULT NOW(),
  "updated_at" TIMESTAMPTZ DEFAULT NOW()
);

-- Create asset tags table
CREATE TABLE "asset_tags" (
  "id" UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  "project_id" TEXT NOT NULL REFERENCES "projects"("id") ON DELETE CASCADE,
  "name" TEXT NOT NULL,
  "color" TEXT DEFAULT '#3B82F6',
  "created_at" TIMESTAMPTZ DEFAULT NOW()
);

-- Create asset-tag relationship table
CREATE TABLE "asset_tag_relationships" (
  "id" UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  "file_id" UUID NOT NULL REFERENCES "file_metadata"("id") ON DELETE CASCADE,
  "tag_id" UUID NOT NULL REFERENCES "asset_tags"("id") ON DELETE CASCADE,
  "created_at" TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE("file_id", "tag_id")
);

-- Add folder relationship to file_metadata
ALTER TABLE "file_metadata" 
ADD COLUMN IF NOT EXISTS "folder_id" UUID REFERENCES "asset_folders"("id") ON DELETE SET NULL;

-- Create indexes for performance
CREATE INDEX IF NOT EXISTS "idx_file_metadata_project_type" ON "file_metadata"("project_id", "asset_type");
CREATE INDEX IF NOT EXISTS "idx_file_metadata_usage_status" ON "file_metadata"("usage_status");
CREATE INDEX IF NOT EXISTS "idx_file_metadata_is_primary" ON "file_metadata"("is_primary") WHERE is_primary = true;
CREATE INDEX IF NOT EXISTS "idx_asset_usage_file_project" ON "asset_usage"("file_id", "project_id");
CREATE INDEX IF NOT EXISTS "idx_asset_usage_type_date" ON "asset_usage"("usage_type", "started_at");
CREATE INDEX IF NOT EXISTS "idx_asset_folders_project" ON "asset_folders"("project_id");
CREATE INDEX IF NOT EXISTS "idx_asset_tags_project" ON "asset_tags"("project_id");
CREATE INDEX IF NOT EXISTS "idx_asset_tag_relationships_file" ON "asset_tag_relationships"("file_id");
CREATE INDEX IF NOT EXISTS "idx_asset_tag_relationships_tag" ON "asset_tag_relationships"("tag_id");

-- Enable RLS for new tables
ALTER TABLE "asset_usage" ENABLE ROW LEVEL SECURITY;
ALTER TABLE "project_storage_quotas" ENABLE ROW LEVEL SECURITY;
ALTER TABLE "asset_folders" ENABLE ROW LEVEL SECURITY;
ALTER TABLE "asset_tags" ENABLE ROW LEVEL SECURITY;
ALTER TABLE "asset_tag_relationships" ENABLE ROW LEVEL SECURITY;

-- RLS Policies for asset_usage
CREATE POLICY "Users can access own asset usage" ON "asset_usage"
  FOR ALL 
  USING (
    EXISTS (
      SELECT 1 FROM "projects" 
      WHERE "projects"."id" = "asset_usage"."project_id" 
      AND "projects"."user_id" = auth.uid()
    )
  );

-- RLS Policies for project_storage_quotas
CREATE POLICY "Users can access own storage quotas" ON "project_storage_quotas"
  FOR ALL 
  USING (
    EXISTS (
      SELECT 1 FROM "projects" 
      WHERE "projects"."id" = "project_storage_quotas"."project_id" 
      AND "projects"."user_id" = auth.uid()
    )
  );

-- RLS Policies for asset_folders
CREATE POLICY "Users can access own asset folders" ON "asset_folders"
  FOR ALL 
  USING (
    EXISTS (
      SELECT 1 FROM "projects" 
      WHERE "projects"."id" = "asset_folders"."project_id" 
      AND "projects"."user_id" = auth.uid()
    )
  );

-- RLS Policies for asset_tags
CREATE POLICY "Users can access own asset tags" ON "asset_tags"
  FOR ALL 
  USING (
    EXISTS (
      SELECT 1 FROM "projects" 
      WHERE "projects"."id" = "asset_tags"."project_id" 
      AND "projects"."user_id" = auth.uid()
    )
  );

-- RLS Policies for asset_tag_relationships
CREATE POLICY "Users can access own asset tag relationships" ON "asset_tag_relationships"
  FOR ALL 
  USING (
    EXISTS (
      SELECT 1 FROM "file_metadata" fm
      JOIN "projects" p ON fm.project_id = p.id
      WHERE fm.id = "asset_tag_relationships"."file_id" 
      AND p.user_id = auth.uid()
    )
  );

-- Add triggers for updated_at columns
CREATE TRIGGER update_project_storage_quotas_updated_at 
  BEFORE UPDATE ON "project_storage_quotas" 
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_asset_folders_updated_at 
  BEFORE UPDATE ON "asset_folders" 
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

-- Function to calculate project storage usage
CREATE OR REPLACE FUNCTION calculate_project_storage_usage(project_id_param TEXT)
RETURNS TABLE(used_bytes BIGINT, file_count INTEGER) AS $$
BEGIN
  RETURN QUERY
  SELECT 
    COALESCE(SUM(fm.file_size), 0)::BIGINT as used_bytes,
    COUNT(fm.id)::INTEGER as file_count
  FROM file_metadata fm
  WHERE fm.project_id = project_id_param
    AND fm.upload_status = 'completed';
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Function to update storage quota
CREATE OR REPLACE FUNCTION update_project_storage_quota(project_id_param TEXT)
RETURNS VOID AS $$
DECLARE
  usage_record RECORD;
BEGIN
  -- Get current usage
  SELECT * INTO usage_record FROM calculate_project_storage_usage(project_id_param);
  
  -- Update or insert quota record
  INSERT INTO project_storage_quotas (
    project_id, 
    user_subscription_tier, 
    total_limit_bytes, 
    used_bytes, 
    file_count_limit, 
    file_count_used, 
    per_file_size_limit
  )
  VALUES (
    project_id_param,
    'free', -- Default tier, will be updated by application logic
    104857600, -- 100MB for free tier
    usage_record.used_bytes,
    10, -- 10 files for free tier
    usage_record.file_count,
    52428800 -- 50MB per file for free tier
  )
  ON CONFLICT (project_id) 
  DO UPDATE SET
    used_bytes = EXCLUDED.used_bytes,
    file_count_used = EXCLUDED.file_count_used,
    updated_at = NOW();
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Trigger to update storage quota when files are added/removed
CREATE OR REPLACE FUNCTION trigger_update_storage_quota()
RETURNS TRIGGER AS $$
BEGIN
  IF TG_OP = 'INSERT' THEN
    PERFORM update_project_storage_quota(NEW.project_id);
    RETURN NEW;
  ELSIF TG_OP = 'UPDATE' THEN
    IF OLD.project_id != NEW.project_id THEN
      PERFORM update_project_storage_quota(OLD.project_id);
      PERFORM update_project_storage_quota(NEW.project_id);
    ELSE
      PERFORM update_project_storage_quota(NEW.project_id);
    END IF;
    RETURN NEW;
  ELSIF TG_OP = 'DELETE' THEN
    PERFORM update_project_storage_quota(OLD.project_id);
    RETURN OLD;
  END IF;
  RETURN NULL;
END;
$$ LANGUAGE plpgsql;

-- Create trigger for file_metadata changes
CREATE TRIGGER trigger_file_metadata_storage_update
  AFTER INSERT OR UPDATE OR DELETE ON "file_metadata"
  FOR EACH ROW EXECUTE FUNCTION trigger_update_storage_quota();
</file>

<file path="db/migrations/011_stem_separation_jobs.sql">
-- Create stem separation jobs table
CREATE TABLE stem_separation_jobs (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  file_key TEXT NOT NULL,
  status TEXT NOT NULL CHECK (status IN ('queued', 'processing', 'completed', 'failed')),
  config JSONB NOT NULL,
  progress INTEGER NOT NULL DEFAULT 0,
  estimated_time_remaining INTEGER,
  results JSONB,
  error TEXT,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- Add RLS policies
ALTER TABLE stem_separation_jobs ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can view their own stem separation jobs"
  ON stem_separation_jobs
  FOR SELECT
  TO authenticated
  USING (auth.uid() = user_id);

CREATE POLICY "Users can create their own stem separation jobs"
  ON stem_separation_jobs
  FOR INSERT
  TO authenticated
  WITH CHECK (auth.uid() = user_id);

CREATE POLICY "Users can update their own stem separation jobs"
  ON stem_separation_jobs
  FOR UPDATE
  TO authenticated
  USING (auth.uid() = user_id)
  WITH CHECK (auth.uid() = user_id);

-- Create function to update updated_at timestamp
CREATE OR REPLACE FUNCTION update_stem_separation_jobs_updated_at()
RETURNS TRIGGER AS $$
BEGIN
  NEW.updated_at = CURRENT_TIMESTAMP;
  RETURN NEW;
END;
$$ language 'plpgsql';

-- Create trigger to update updated_at timestamp
CREATE TRIGGER update_stem_separation_jobs_updated_at
  BEFORE UPDATE
  ON stem_separation_jobs
  FOR EACH ROW
  EXECUTE FUNCTION update_stem_separation_jobs_updated_at();
</file>

<file path="db/migrations/012_audio_analysis_cache.sql">
-- Audio analysis cache table for pre-computed stem analysis
CREATE TABLE "audio_analysis_cache" (
  "id" UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  "user_id" UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  "file_metadata_id" UUID NOT NULL REFERENCES "file_metadata"(id) ON DELETE CASCADE,
  "stem_type" VARCHAR(50) NOT NULL, -- 'drums', 'bass', 'vocals', 'other', 'master'
  
  -- Analysis metadata
  "analysis_version" VARCHAR(20) NOT NULL DEFAULT '1.0',
  "sample_rate" INTEGER NOT NULL,
  "duration" DECIMAL(10,3) NOT NULL, -- in seconds
  "buffer_size" INTEGER NOT NULL,
  "features_extracted" TEXT[] NOT NULL, -- array of feature names
  
  -- Cached analysis data (JSON)
  "analysis_data" JSONB NOT NULL, -- contains frequency data, time data, feature markers
  
  -- Waveform data for visualization
  "waveform_data" JSONB, -- contains waveform points and feature markers
  
  -- Performance metrics
  "analysis_duration" INTEGER, -- milliseconds
  "created_at" TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
  "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);

-- Create indexes for efficient queries
CREATE INDEX "idx_audio_analysis_cache_user_id" ON "audio_analysis_cache"("user_id");
CREATE INDEX "idx_audio_analysis_cache_file_metadata_id" ON "audio_analysis_cache"("file_metadata_id");
CREATE INDEX "idx_audio_analysis_cache_stem_type" ON "audio_analysis_cache"("stem_type");
CREATE INDEX "idx_audio_analysis_cache_created_at" ON "audio_analysis_cache"("created_at");

-- Unique constraint to prevent duplicate analysis
CREATE UNIQUE INDEX "idx_audio_analysis_cache_unique" 
  ON "audio_analysis_cache"("file_metadata_id", "stem_type", "analysis_version");

-- Enable RLS (Row Level Security) for user data protection
ALTER TABLE "audio_analysis_cache" ENABLE ROW LEVEL SECURITY;

-- RLS Policy: Users can only access their own audio analysis cache
CREATE POLICY "Users can access own audio analysis cache" ON "audio_analysis_cache"
  FOR ALL 
  USING (auth.uid() = user_id);

-- Trigger to auto-update updated_at on record changes
CREATE TRIGGER update_audio_analysis_cache_updated_at 
  BEFORE UPDATE ON "audio_analysis_cache" 
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

-- Add analysis status to stem_separations table
ALTER TABLE "stem_separations" 
ADD COLUMN "analysis_status" VARCHAR(20) DEFAULT 'pending' 
  CHECK (analysis_status IN ('pending', 'processing', 'completed', 'failed'));

-- Add analysis completion timestamp
ALTER TABLE "stem_separations" 
ADD COLUMN "analysis_completed_at" TIMESTAMP WITH TIME ZONE;

-- Create index for analysis status queries
CREATE INDEX "idx_stem_separations_analysis_status" ON "stem_separations"("analysis_status");
</file>

<file path="db/migrations/013_add_master_and_stemtype_to_file_metadata.sql">
-- Migration: 013_add_master_and_stemtype_to_file_metadata.sql
-- Adds is_master (boolean) and stem_type (varchar) columns to file_metadata for stem project support

ALTER TABLE "file_metadata"
  ADD COLUMN IF NOT EXISTS "is_master" BOOLEAN NOT NULL DEFAULT FALSE,
  ADD COLUMN IF NOT EXISTS "stem_type" VARCHAR(32);

-- Optionally, add an index for faster queries by stem_type or is_master
CREATE INDEX IF NOT EXISTS "idx_file_metadata_stem_type" ON "file_metadata"("stem_type");
CREATE INDEX IF NOT EXISTS "idx_file_metadata_is_master" ON "file_metadata"("is_master");
</file>

<file path="db/migrations/014_fix_file_metadata_rls.sql">
-- Migration: 014_fix_file_metadata_rls
-- Reason: The existing RLS policy for file_metadata only allows users to access files
-- they own directly (user_id = auth.uid()). It does not account for project-based
-- access, where a project owner should be able to manage all files within their project,
-- regardless of who uploaded them. This prevents project-level operations like deletion.

-- Drop the old, restrictive policy
DROP POLICY IF EXISTS "Users can access own files" ON "file_metadata";

-- Create a new, more flexible policy that grants access if the user:
-- 1. Is the direct owner of the file (maintains original behavior).
-- 2. Is the owner of the project to which the file belongs.
CREATE POLICY "Project members can access project files" ON "file_metadata"
  FOR ALL
  USING (
    (auth.uid() = user_id) OR
    (EXISTS (
      SELECT 1
      FROM projects
      WHERE projects.id = file_metadata.project_id AND projects.user_id = auth.uid()
    ))
  );
</file>

<file path="db/migrations/015_audio_analysis_jobs.sql">
-- Migration: 015_audio_analysis_jobs
-- Reason: Create a dedicated table for managing asynchronous audio analysis jobs,
-- improving performance by moving the slow analysis process to a background worker.

CREATE TABLE "audio_analysis_jobs" (
  "id" UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  "user_id" UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  "file_metadata_id" UUID NOT NULL REFERENCES "file_metadata"("id") ON DELETE CASCADE,
  "status" TEXT NOT NULL DEFAULT 'pending' CHECK (status IN ('pending', 'processing', 'completed', 'failed')),
  "error" TEXT,
  "created_at" TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
  "updated_at" TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- Add indexes for performance
CREATE INDEX IF NOT EXISTS "idx_audio_analysis_jobs_status" ON "audio_analysis_jobs"("status");
CREATE INDEX IF NOT EXISTS "idx_audio_analysis_jobs_created_at" ON "audio_analysis_jobs"("created_at");

-- Add RLS policies
ALTER TABLE "audio_analysis_jobs" ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can manage their own audio analysis jobs" ON "audio_analysis_jobs"
  FOR ALL
  USING (auth.uid() = user_id);

-- Trigger to auto-update updated_at on record changes
CREATE OR REPLACE FUNCTION update_audio_analysis_jobs_updated_at()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER trigger_update_audio_analysis_jobs_updated_at 
  BEFORE UPDATE ON "audio_analysis_jobs" 
  FOR EACH ROW EXECUTE FUNCTION update_audio_analysis_jobs_updated_at();
</file>

<file path="db/migrations/016_make_midi_file_path_optional.sql">
-- Make midi_file_path optional in projects table
-- Migration: 016_make_midi_file_path_optional

-- Make midi_file_path optional by dropping NOT NULL constraint
ALTER TABLE "projects" 
ALTER COLUMN "midi_file_path" DROP NOT NULL;

-- Add a comment explaining the change
COMMENT ON COLUMN "projects"."midi_file_path" IS 'Optional path to MIDI file. Projects can be created without MIDI files initially.';
</file>

<file path="db/migrations/017_edit_states.sql">
-- Edit States Table for Auto-Save Functionality
-- Migration: 017_edit_states

-- Create edit_states table for storing auto-save data
CREATE TABLE "edit_states" (
  "id" TEXT NOT NULL PRIMARY KEY DEFAULT uuid_generate_v4()::text,
  "user_id" UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  "project_id" TEXT NOT NULL REFERENCES projects(id) ON DELETE CASCADE,
  "timestamp" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
  "data" JSONB NOT NULL,
  "version" INTEGER NOT NULL DEFAULT 1,
  "is_current" BOOLEAN NOT NULL DEFAULT false,
  "created_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes for efficient querying
CREATE INDEX "idx_edit_states_user_project" ON "edit_states" ("user_id", "project_id");
CREATE INDEX "idx_edit_states_current" ON "edit_states" ("is_current") WHERE "is_current" = true;
CREATE INDEX "idx_edit_states_timestamp" ON "edit_states" ("timestamp");
CREATE INDEX "idx_edit_states_version" ON "edit_states" ("version");

-- Enable RLS for edit_states table
ALTER TABLE "edit_states" ENABLE ROW LEVEL SECURITY;

-- RLS Policy: Users can only access their own edit states
CREATE POLICY "Users can access own edit states" ON "edit_states"
  FOR ALL 
  USING (user_id = auth.uid());

-- RLS Policy: Users can view edit states for projects they have access to
CREATE POLICY "Users can view project edit states" ON "edit_states"
  FOR SELECT
  TO authenticated
  USING (
    EXISTS (
      SELECT 1 FROM "projects" 
      WHERE "projects"."id" = "edit_states"."project_id" 
      AND (
        "projects"."user_id" = auth.uid() OR
        "projects"."privacy_setting" = 'public' OR
        (
          "projects"."privacy_setting" = 'unlisted' AND
          EXISTS (
            SELECT 1 FROM "project_shares"
            WHERE "project_shares"."project_id" = "projects"."id"
          )
        )
      )
    )
  );

-- Add trigger for updated_at (though we don't have an updated_at column, keeping consistent with other tables)
-- Note: edit_states uses timestamp field for tracking when the state was saved

-- Add comments for documentation
COMMENT ON TABLE "edit_states" IS 'Stores auto-save states for user editing sessions';
COMMENT ON COLUMN "edit_states"."user_id" IS 'Reference to authenticated user';
COMMENT ON COLUMN "edit_states"."project_id" IS 'Reference to the project being edited';
COMMENT ON COLUMN "edit_states"."timestamp" IS 'When this edit state was saved';
COMMENT ON COLUMN "edit_states"."data" IS 'JSONB containing visualization parameters, stem mappings, effect settings, and timeline state';
COMMENT ON COLUMN "edit_states"."version" IS 'Version number for conflict resolution';
COMMENT ON COLUMN "edit_states"."is_current" IS 'Indicates if this is the most recent state for the project';
</file>

<file path="db/migrations/migrate.ts">
import fs from 'fs'
import path from 'path'
import { pool } from '../connection'
import { logger } from '../lib/logger';

async function runMigrations() {
  try {
    // Create migrations table if it doesn't exist
    await pool.query(`
      CREATE TABLE IF NOT EXISTS migrations (
        id SERIAL PRIMARY KEY,
        name VARCHAR(255) NOT NULL UNIQUE,
        executed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `)

    // Get all migration files
    const migrationsDir = path.join(__dirname)
    const migrationFiles = fs.readdirSync(migrationsDir)
      .filter(file => file.endsWith('.sql'))
      .sort()

    // Get already executed migrations
    const executedResult = await pool.query('SELECT name FROM migrations')
    const executedMigrations = executedResult.rows.map(row => row.name)

    // Execute pending migrations
    for (const file of migrationFiles) {
      if (!executedMigrations.includes(file)) {
        logger.log(` Running migration: ${file}`)
        
        const migrationSQL = fs.readFileSync(path.join(migrationsDir, file), 'utf8')
        
        // Execute migration
        await pool.query(migrationSQL)
        
        // Record migration as executed
        await pool.query('INSERT INTO migrations (name) VALUES ($1)', [file])
        
        logger.log(` Migration completed: ${file}`)
      } else {
        logger.log(` Migration already executed: ${file}`)
      }
    }

    logger.log(' All migrations completed successfully!')
  } catch (error) {
    logger.error(' Migration failed:', error)
    process.exit(1)
  }
}

// Run migrations if this file is executed directly
if (require.main === module) {
  runMigrations().then(() => {
    pool.end()
    process.exit(0)
  })
}

export { runMigrations }
</file>

<file path="db/seeds/development.ts">
import { pool } from '../connection'
import { logger } from '../lib/logger';

export async function seedDevelopmentData() {
  try {
    logger.log(' Seeding development data...')

    // Insert test user
    const userResult = await pool.query(`
      INSERT INTO users (name, email, image) 
      VALUES ($1, $2, $3) 
      ON CONFLICT (email) DO UPDATE SET 
        name = EXCLUDED.name, 
        image = EXCLUDED.image
      RETURNING id
    `, ['Test User', 'test@phonoglyph.com', 'https://via.placeholder.com/150'])

    const userId = userResult.rows[0].id
    logger.log(` Test user created/updated: ${userId}`)

    // Insert test project
    const projectResult = await pool.query(`
      INSERT INTO projects (name, user_id, midi_file_path, render_configuration) 
      VALUES ($1, $2, $3, $4) 
      ON CONFLICT DO NOTHING
      RETURNING id
    `, [
      'Sample MIDI Project',
      userId,
      '/uploads/sample.mid',
      JSON.stringify({
        resolution: '1920x1080',
        fps: 60,
        theme: 'default',
        effects: ['piano-roll', 'particles']
      })
    ])

    if (projectResult.rows.length > 0) {
      logger.log(` Test project created: ${projectResult.rows[0].id}`)
    } else {
      logger.log(' Test project already exists')
    }

    logger.log(' Development data seeded successfully!')
  } catch (error) {
    logger.error(' Seeding failed:', error)
    throw error
  }
}

// Run seeding if this file is executed directly
if (require.main === module) {
  seedDevelopmentData().then(() => {
    pool.end()
    process.exit(0)
  }).catch((error) => {
    logger.error(error)
    pool.end()
    process.exit(1)
  })
}
</file>

<file path="db/connection.ts">
import { Pool, PoolConfig } from 'pg'
import dotenv from 'dotenv'
import fs from 'fs'
import path from 'path'
import { logger } from '../lib/logger';

dotenv.config()

let caCert: string | undefined;
try {
  // Construct a reliable path to the certificate from the project root directory.
  const certPath = path.join(process.cwd(), 'apps/api/src/db/prod-ca-2021.crt');
  if (fs.existsSync(certPath)) {
    caCert = fs.readFileSync(certPath).toString();
    logger.log(' Successfully loaded Supabase CA certificate from file.');
  } else {
    // Fallback for different execution contexts, like tests.
    const fallbackPath = path.join(__dirname, 'prod-ca-2021.crt');
    if (fs.existsSync(fallbackPath)) {
      caCert = fs.readFileSync(fallbackPath).toString();
      logger.log(' Successfully loaded Supabase CA certificate from fallback path.');
    } else {
      logger.warn(` CA certificate file not found. Looked in:\n1. ${certPath}\n2. ${fallbackPath}`);
    }
  }
} catch (error) {
    logger.error(' Error reading CA certificate file:', error);
    caCert = undefined;
}

const connectionString = process.env.DATABASE_URL;

const prodDbConfig: PoolConfig = {
  connectionString: connectionString,
  max: 20,
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 10000,
};

// If the Supabase CA certificate is loaded, enforce SSL with it.
// This is the recommended and most secure way to connect to Supabase.
if (caCert) {
  prodDbConfig.ssl = {
    rejectUnauthorized: true,
    ca: caCert,
  };
}

// Database configuration - use Supabase DATABASE_URL if available
const dbConfig = connectionString
  ? prodDbConfig
  : {
      user: process.env.DB_USER || 'postgres',
      host: process.env.DB_HOST || 'localhost',
      database: process.env.DB_NAME || 'phonoglyph',
      password: process.env.DB_PASSWORD || 'password',
      port: parseInt(process.env.DB_PORT || '5432'),
      max: 20,
      idleTimeoutMillis: 30000,
      connectionTimeoutMillis: 2000,
    }

// Create connection pool
export const pool = new Pool(dbConfig)

// Test database connection
export async function testConnection() {
  try {
    const client = await pool.connect()
    const result = await client.query('SELECT NOW()')
    client.release()
    logger.log(' Database connected successfully:', result.rows[0])
    return true
  } catch (err) {
    logger.error(' Database connection failed:', err)
    return false
  }
}

// Graceful shutdown
process.on('SIGINT', () => {
  logger.log(' Closing database pool...')
  pool.end()
  process.exit(0)
})

export default pool
</file>

<file path="db/prod-ca-2021.crt">
-----BEGIN CERTIFICATE-----
MIIDxDCCAqygAwIBAgIUbLxMod62P2ktCiAkxnKJwtE9VPYwDQYJKoZIhvcNAQEL
BQAwazELMAkGA1UEBhMCVVMxEDAOBgNVBAgMB0RlbHdhcmUxEzARBgNVBAcMCk5l
dyBDYXN0bGUxFTATBgNVBAoMDFN1cGFiYXNlIEluYzEeMBwGA1UEAwwVU3VwYWJh
c2UgUm9vdCAyMDIxIENBMB4XDTIxMDQyODEwNTY1M1oXDTMxMDQyNjEwNTY1M1ow
azELMAkGA1UEBhMCVVMxEDAOBgNVBAgMB0RlbHdhcmUxEzARBgNVBAcMCk5ldyBD
YXN0bGUxFTATBgNVBAoMDFN1cGFiYXNlIEluYzEeMBwGA1UEAwwVU3VwYWJhc2Ug
Um9vdCAyMDIxIENBMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAqQXW
QyHOB+qR2GJobCq/CBmQ40G0oDmCC3mzVnn8sv4XNeWtE5XcEL0uVih7Jo4Dkx1Q
DmGHBH1zDfgs2qXiLb6xpw/CKQPypZW1JssOTMIfQppNQ87K75Ya0p25Y3ePS2t2
GtvHxNjUV6kjOZjEn2yWEcBdpOVCUYBVFBNMB4YBHkNRDa/+S4uywAoaTWnCJLUi
cvTlHmMw6xSQQn1UfRQHk50DMCEJ7Cy1RxrZJrkXXRP3LqQL2ijJ6F4yMfh+Gyb4
O4XajoVj/+R4GwywKYrrS8PrSNtwxr5StlQO8zIQUSMiq26wM8mgELFlS/32Uclt
NaQ1xBRizkzpZct9DwIDAQABo2AwXjALBgNVHQ8EBAMCAQYwHQYDVR0OBBYEFKjX
uXY32CztkhImng4yJNUtaUYsMB8GA1UdIwQYMBaAFKjXuXY32CztkhImng4yJNUt
aUYsMA8GA1UdEwEB/wQFMAMBAf8wDQYJKoZIhvcNAQELBQADggEBAB8spzNn+4VU
tVxbdMaX+39Z50sc7uATmus16jmmHjhIHz+l/9GlJ5KqAMOx26mPZgfzG7oneL2b
VW+WgYUkTT3XEPFWnTp2RJwQao8/tYPXWEJDc0WVQHrpmnWOFKU/d3MqBgBm5y+6
jB81TU/RG2rVerPDWP+1MMcNNy0491CTL5XQZ7JfDJJ9CCmXSdtTl4uUQnSuv/Qx
Cea13BX2ZgJc7Au30vihLhub52De4P/4gonKsNHYdbWjg7OWKwNv/zitGDVDB9Y2
CMTyZKG3XEu5Ghl1LEnI3QmEKsqaCLv12BnVjbkSeZsMnevJPs1Ye6TjjJwdik5P
o/bKiIz+Fq8=
-----END CERTIFICATE-----
</file>

<file path="lib/file-validation.ts">
import { z } from 'zod'

// File type definitions - EXTENDED for video and image
export type FileType = 'midi' | 'audio' | 'video' | 'image'

// Video and Image metadata interfaces
export interface VideoMetadata {
  duration: number;           // seconds
  width: number;             // pixels
  height: number;            // pixels
  frameRate: number;         // fps
  codec: string;             // h264, h265, etc.
  bitrate: number;           // kbps
  aspectRatio: string;       // "16:9", "4:3", etc.
}

export interface ImageMetadata {
  width: number;             // pixels
  height: number;            // pixels
  colorProfile: string;      // sRGB, Adobe RGB, etc.
  orientation: number;       // EXIF orientation
  hasAlpha: boolean;         // transparency channel
  fileFormat: string;        // JPEG, PNG, GIF
}

export interface ValidatedFile {
  fileName: string
  fileType: FileType
  mimeType: string
  fileSize: number
  isValid: boolean
  errors: string[]
}

// File size limits from environment variables - EXTENDED
export const FILE_SIZE_LIMITS = {
  midi: parseInt(process.env.MAX_MIDI_FILE_SIZE || '5242880'), // 5MB
  audio: parseInt(process.env.MAX_AUDIO_FILE_SIZE || '52428800'), // 50MB
  video: parseInt(process.env.MAX_VIDEO_FILE_SIZE || '524288000'), // 500MB
  image: parseInt(process.env.MAX_IMAGE_FILE_SIZE || '26214400'), // 25MB
} as const

// Allowed MIME types - EXTENDED
export const ALLOWED_MIME_TYPES = {
  midi: [
    'audio/midi',
    'audio/x-midi',
    'application/x-midi',
    'audio/mid',
  ] as string[],
  audio: [
    'audio/mpeg',
    'audio/mp3',
    'audio/wav',
    'audio/wave',
    'audio/x-wav',
  ] as string[],
  video: [
    'video/mp4',
    'video/mov',
    'video/quicktime',
    'video/webm',
  ] as string[],
  image: [
    'image/jpeg',
    'image/jpg',
    'image/png',
    'image/gif',
    'image/webp',
  ] as string[],
}

// Allowed file extensions - EXTENDED
export const ALLOWED_EXTENSIONS = {
  midi: ['.mid', '.midi'],
  audio: ['.mp3', '.wav'],
  video: ['.mp4', '.mov', '.webm'],
  image: ['.jpg', '.jpeg', '.png', '.gif', '.webp'],
} as const

// Magic bytes for file header validation - EXTENDED
export const MAGIC_BYTES = {
  midi: [
    [0x4d, 0x54, 0x68, 0x64], // "MThd" - Standard MIDI file header
  ],
  mp3: [
    [0xff, 0xfb], // MPEG-1 Layer 3
    [0xff, 0xf3], // MPEG-2 Layer 3
    [0xff, 0xf2], // MPEG-2.5 Layer 3
    [0x49, 0x44, 0x33], // ID3 tag
  ],
  wav: [
    [0x52, 0x49, 0x46, 0x46], // "RIFF" header
  ],
  mp4: [
    [0x00, 0x00, 0x00, 0x20, 0x66, 0x74, 0x79, 0x70], // MP4 signature
    [0x00, 0x00, 0x00, 0x18, 0x66, 0x74, 0x79, 0x70], // Alternative MP4
  ],
  webm: [
    [0x1a, 0x45, 0xdf, 0xa3], // WebM/Matroska signature
  ],
  jpeg: [
    [0xff, 0xd8, 0xff], // JPEG signature
  ],
  png: [
    [0x89, 0x50, 0x4e, 0x47, 0x0d, 0x0a, 0x1a, 0x0a], // PNG signature
  ],
  gif: [
    [0x47, 0x49, 0x46, 0x38, 0x37, 0x61], // GIF87a
    [0x47, 0x49, 0x46, 0x38, 0x39, 0x61], // GIF89a
  ],
  webp: [
    [0x52, 0x49, 0x46, 0x46], // RIFF container for WebP
  ],
} as const

// Validation configurations for new file types
export const videoValidation = {
  maxSize: 500 * 1024 * 1024,  // 500MB
  allowedTypes: [
    'video/mp4',
    'video/mov', 
    'video/quicktime',
    'video/webm'
  ],
  maxDuration: 600,            // 10 minutes max
  maxResolution: {
    width: 3840,               // 4K max
    height: 2160
  }
};

export const imageValidation = {
  maxSize: 25 * 1024 * 1024,   // 25MB
  allowedTypes: [
    'image/jpeg',
    'image/jpg', 
    'image/png',
    'image/gif',
    'image/webp'
  ],
  maxResolution: {
    width: 8192,               // 8K max
    height: 8192
  }
};

// Zod schema for file upload input - EXTENDED
export const FileUploadSchema = z.object({
  fileName: z.string().min(1, 'File name is required').max(255, 'File name too long'),
  fileSize: z.number().positive('File size must be positive'),
  mimeType: z.string().min(1, 'MIME type is required'),
})

export type FileUploadInput = z.infer<typeof FileUploadSchema>

// Validate file extension - EXTENDED
export function validateFileExtension(fileName: string): FileType | null {
  const extension = fileName.toLowerCase().substring(fileName.lastIndexOf('.'))
  
  if (ALLOWED_EXTENSIONS.midi.includes(extension as any)) {
    return 'midi'
  }
  
  if (ALLOWED_EXTENSIONS.audio.includes(extension as any)) {
    return 'audio'
  }
  
  if (ALLOWED_EXTENSIONS.video.includes(extension as any)) {
    return 'video'
  }
  
  if (ALLOWED_EXTENSIONS.image.includes(extension as any)) {
    return 'image'
  }
  
  return null
}

// Validate MIME type
export function validateMimeType(mimeType: string, fileType: FileType): boolean {
  return ALLOWED_MIME_TYPES[fileType].includes(mimeType)
}

// Validate file size
export function validateFileSize(fileSize: number, fileType: FileType): boolean {
  return fileSize <= FILE_SIZE_LIMITS[fileType]
}

// Validate file header (magic bytes) - EXTENDED
export function validateFileHeader(buffer: ArrayBuffer, fileType: FileType): boolean {
  const uint8Array = new Uint8Array(buffer.slice(0, 12)) // Check first 12 bytes
  
  switch (fileType) {
    case 'midi':
      // Check for MIDI "MThd" header
      return [0x4d, 0x54, 0x68, 0x64].every((byte, i) => uint8Array[i] === byte)
      
    case 'audio':
      // For audio, we need to check the actual extension/mime type
      if (buffer.byteLength < 4) return false
      
      // Check for MP3
      if ([0xff, 0xfb].every((byte, i) => uint8Array[i] === byte) ||
          [0xff, 0xf3].every((byte, i) => uint8Array[i] === byte) ||
          [0xff, 0xf2].every((byte, i) => uint8Array[i] === byte) ||
          [0x49, 0x44, 0x33].every((byte, i) => uint8Array[i] === byte)) {
        return true
      }
      
      // Check for WAV
      if ([0x52, 0x49, 0x46, 0x46].every((byte, i) => uint8Array[i] === byte) &&
          uint8Array.length >= 12 &&
          [0x57, 0x41, 0x56, 0x45].every((byte, i) => uint8Array[i + 8] === byte)) {
        return true
      }
      
      return false
      
    case 'video':
      if (buffer.byteLength < 8) return false
      
      // Check for MP4
      if (uint8Array.length >= 8 && 
          ([0x66, 0x74, 0x79, 0x70].every((byte, i) => uint8Array[i + 4] === byte))) {
        return true
      }
      
      // Check for WebM
      if ([0x1a, 0x45, 0xdf, 0xa3].every((byte, i) => uint8Array[i] === byte)) {
        return true
      }
      
      return false
      
    case 'image':
      if (buffer.byteLength < 8) return false
      
      // Check for JPEG
      if ([0xff, 0xd8, 0xff].every((byte, i) => uint8Array[i] === byte)) {
        return true
      }
      
      // Check for PNG
      if ([0x89, 0x50, 0x4e, 0x47, 0x0d, 0x0a, 0x1a, 0x0a].every((byte, i) => uint8Array[i] === byte)) {
        return true
      }
      
      // Check for GIF
      if ([0x47, 0x49, 0x46, 0x38].every((byte, i) => uint8Array[i] === byte) &&
          (uint8Array[4] === 0x37 || uint8Array[4] === 0x39) &&
          uint8Array[5] === 0x61) {
        return true
      }
      
      // Check for WebP (RIFF container)
      if ([0x52, 0x49, 0x46, 0x46].every((byte, i) => uint8Array[i] === byte) &&
          uint8Array.length >= 12 &&
          [0x57, 0x45, 0x42, 0x50].every((byte, i) => uint8Array[i + 8] === byte)) {
        return true
      }
      
      return false
      
    default:
      return false
  }
}

// Main file validation function - UPDATED
export function validateFile(input: FileUploadInput): ValidatedFile {
  const errors: string[] = []
  const { fileName, fileSize, mimeType } = input
  
  // Validate file extension and determine type
  const fileType = validateFileExtension(fileName)
  if (!fileType) {
    errors.push('Invalid file type. Allowed types: .mid, .midi, .mp3, .wav, .mp4, .mov, .webm, .jpg, .jpeg, .png, .gif, .webp')
  }
  
  let result: ValidatedFile = {
    fileName,
    fileType: fileType || 'midi', // Default to midi to avoid type errors
    mimeType,
    fileSize,
    isValid: false,
    errors,
  }
  
  if (!fileType) {
    return result
  }
  
  // Update result with determined file type
  result.fileType = fileType
  
  // Validate MIME type
  if (!validateMimeType(mimeType, fileType)) {
    errors.push(`Invalid MIME type for ${fileType} file. Allowed types: ${ALLOWED_MIME_TYPES[fileType].join(', ')}`)
  }
  
  // Validate file size
  if (!validateFileSize(fileSize, fileType)) {
    const maxSizeMB = FILE_SIZE_LIMITS[fileType] / (1024 * 1024)
    errors.push(`File size exceeds limit. Maximum size for ${fileType} files: ${maxSizeMB}MB`)
  }
  
  // Validate file name
  if (fileName.length > 255) {
    errors.push('File name is too long (maximum 255 characters)')
  }
  
  result.errors = errors
  result.isValid = errors.length === 0
  
  return result
}

// Sanitize file name for storage
export function sanitizeFileName(fileName: string): string {
  // Replace unsafe characters with underscores
  return fileName
    .replace(/[^a-zA-Z0-9.-]/g, '_')
    .replace(/_{2,}/g, '_') // Replace multiple underscores with single
    .replace(/^_+|_+$/g, '') // Remove leading/trailing underscores
}

// Get file extension
export function getFileExtension(fileName: string): string {
  return fileName.toLowerCase().substring(fileName.lastIndexOf('.'))
}

// Check if file is executable (security check)
export function isExecutableFile(fileName: string): boolean {
  const executableExtensions = [
    '.exe', '.bat', '.cmd', '.com', '.scr', '.pif',
    '.sh', '.bash', '.zsh', '.csh', '.fish',
    '.ps1', '.vbs', '.js', '.jar', '.app',
  ]
  
  const extension = getFileExtension(fileName)
  return executableExtensions.includes(extension)
}

// Rate limiting helper for uploads
export function createUploadRateLimit() {
  const uploads = new Map<string, number[]>()
  const WINDOW_MS = 60 * 1000 // 1 minute
  const MAX_UPLOADS = 10 // Max uploads per minute per user
  
  return {
    checkRateLimit: (userId: string): boolean => {
      const now = Date.now()
      const userUploads = uploads.get(userId) || []
      
      // Remove old timestamps
      const recentUploads = userUploads.filter(timestamp => 
        now - timestamp < WINDOW_MS
      )
      
      // Check if under limit
      if (recentUploads.length >= MAX_UPLOADS) {
        return false
      }
      
      // Add current upload
      recentUploads.push(now)
      uploads.set(userId, recentUploads)
      
      return true
    },
    
    getRemainingUploads: (userId: string): number => {
      const now = Date.now()
      const userUploads = uploads.get(userId) || []
      const recentUploads = userUploads.filter(timestamp => 
        now - timestamp < WINDOW_MS
      )
      
      return Math.max(0, MAX_UPLOADS - recentUploads.length)
    }
  }
}
</file>

<file path="lib/logger.ts">
// Backend logging utility to control console spam
const DEBUG_ENABLED = process.env.NODE_ENV === 'development' && 
  process.env.DEBUG_LOGGING === 'true';

export const logger = {
  log: (...args: any[]) => {
    if (DEBUG_ENABLED) {
      console.log(...args);
    }
  },
  warn: (...args: any[]) => {
    if (DEBUG_ENABLED) {
      console.warn(...args);
    }
  },
  error: (...args: any[]) => {
    // Always log errors regardless of debug setting
    console.error(...args);
  },
  info: (...args: any[]) => {
    if (DEBUG_ENABLED) {
      console.info(...args);
    }
  },
  debug: (...args: any[]) => {
    if (DEBUG_ENABLED) {
      console.log('', ...args);
    }
  },
  auth: (...args: any[]) => {
    if (DEBUG_ENABLED) {
      console.log('', ...args);
    }
  }
};
</file>

<file path="lib/supabase.ts">
import { createClient } from '@supabase/supabase-js'
import dotenv from 'dotenv'
import { logger } from '../lib/logger';

dotenv.config()

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY

if (!supabaseUrl || !supabaseServiceKey || !supabaseAnonKey) {
  logger.warn('Supabase environment variables not found. Using dummy values for development.')
}

// Server-side client with service role key for admin operations
export const supabaseAdmin = createClient(
  supabaseUrl || 'https://dummy.supabase.co',
  supabaseServiceKey || 'dummy-service-key'
)

// Client for user-scoped operations (uses anon key)
export const supabase = createClient(
  supabaseUrl || 'https://dummy.supabase.co', 
  supabaseAnonKey || 'dummy-anon-key'
)

// Function to create Supabase client with user session
export function createSupabaseServerClient(accessToken?: string) {
  if (!supabaseUrl || !supabaseAnonKey) {
    logger.warn('Supabase not configured properly')
    return supabase
  }

  const client = createClient(supabaseUrl, supabaseAnonKey, {
    global: {
      headers: accessToken ? {
        Authorization: `Bearer ${accessToken}`,
      } : {},
    },
  })

  return client
}
</file>

<file path="lib/supabase.ts">
import { createClient } from '@supabase/supabase-js'
import dotenv from 'dotenv'
import { logger } from '../lib/logger';

dotenv.config()

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY

if (!supabaseUrl || !supabaseServiceKey || !supabaseAnonKey) {
  logger.warn('Supabase environment variables not found. Using dummy values for development.')
}

// Server-side client with service role key for admin operations
export const supabaseAdmin = createClient(
  supabaseUrl || 'https://dummy.supabase.co',
  supabaseServiceKey || 'dummy-service-key'
)

// Client for user-scoped operations (uses anon key)
export const supabase = createClient(
  supabaseUrl || 'https://dummy.supabase.co', 
  supabaseAnonKey || 'dummy-anon-key'
)

// Function to create Supabase client with user session
export function createSupabaseServerClient(accessToken?: string) {
  if (!supabaseUrl || !supabaseAnonKey) {
    logger.warn('Supabase not configured properly')
    return supabase
  }

  const client = createClient(supabaseUrl, supabaseAnonKey, {
    global: {
      headers: accessToken ? {
        Authorization: `Bearer ${accessToken}`,
      } : {},
    },
  })

  return client
}
</file>

<file path="routers/audio-analysis-sandbox.ts">
import { z } from 'zod';
import { router, protectedProcedure, flexibleProcedure, publicProcedure } from '../trpc';
import { TRPCError } from '@trpc/server';
import { logger } from '../lib/logger';

// Schema for sandbox analysis data
const SandboxAnalysisSchema = z.object({
  transients: z.array(z.object({
    time: z.number(),
    intensity: z.number(),
    frequency: z.number(),
  })),
  chroma: z.array(z.object({
    time: z.number(),
    pitch: z.number(),
    confidence: z.number(),
    note: z.string(),
  })),
  rms: z.array(z.object({
    time: z.number(),
    value: z.number(),
  })),
  waveform: z.array(z.number()),
  metadata: z.object({
    sampleRate: z.number(),
    duration: z.number(),
    bufferSize: z.number(),
    analysisParams: z.any(),
  }),
});

// Schema for cached sandbox analysis
const CachedSandboxAnalysisSchema = z.object({
  id: z.string(),
  fileMetadataId: z.string(),
  stemType: z.string(),
  analysisData: SandboxAnalysisSchema,
  waveformData: z.object({
    points: z.array(z.number()),
    duration: z.number(),
    sampleRate: z.number(),
    markers: z.array(z.any()),
  }),
  metadata: z.object({
    sampleRate: z.number(),
    duration: z.number(),
    bufferSize: z.number(),
    featuresExtracted: z.array(z.string()),
    analysisDuration: z.number(),
  }),
});

export const audioAnalysisSandboxRouter = router({
  // Simple test endpoint to verify the router is working
  test: publicProcedure
    .query(() => {
      return {
        success: true,
        message: 'Audio Analysis Sandbox API is working!',
        timestamp: new Date().toISOString(),
      };
    }),

  // Save sandbox analysis to cache
  saveSandboxAnalysis: protectedProcedure
    .input(CachedSandboxAnalysisSchema)
    .mutation(async ({ ctx, input }) => {
      const userId = ctx.user.id;

      try {
        // Verify that the user has access to this file
        const { data: file, error: fileError } = await ctx.supabase
          .from('file_metadata')
          .select('id, user_id')
          .eq('id', input.fileMetadataId)
          .single();

        if (fileError || !file) {
          throw new TRPCError({ 
            code: 'NOT_FOUND', 
            message: 'File not found or access denied' 
          });
        }

        if (file.user_id !== userId) {
          throw new TRPCError({ 
            code: 'FORBIDDEN', 
            message: 'You do not have access to this file' 
          });
        }

        // Save the sandbox analysis data
        const { error: saveError } = await ctx.supabase
          .from('audio_analysis_cache')
          .insert({
            user_id: userId,
            file_metadata_id: input.fileMetadataId,
            stem_type: input.stemType,
            analysis_version: '2.0-sandbox', // Mark as sandbox version
            sample_rate: input.metadata.sampleRate,
            duration: input.metadata.duration,
            buffer_size: input.metadata.bufferSize,
            features_extracted: input.metadata.featuresExtracted,
            analysis_data: input.analysisData,
            waveform_data: input.waveformData,
            analysis_duration: input.metadata.analysisDuration,
          });

        if (saveError) {
          logger.error('Failed to save sandbox analysis:', saveError);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: `Failed to save sandbox analysis: ${saveError.message}`,
          });
        }

        return { 
          success: true, 
          message: 'Sandbox analysis saved successfully' 
        };
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        
        logger.error('Error saving sandbox analysis:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to save sandbox analysis',
        });
      }
    }),

  // Get sandbox analysis from cache
  getSandboxAnalysis: protectedProcedure
    .input(z.object({
      fileId: z.string(),
      stemType: z.string().optional().default('master'),
    }))
    .query(async ({ ctx, input }) => {
      const userId = ctx.user.id;

      try {
        // Get the cached analysis
        const { data: analysis, error: analysisError } = await ctx.supabase
          .from('audio_analysis_cache')
          .select('*')
          .eq('file_metadata_id', input.fileId)
          .eq('user_id', userId)
          .eq('stem_type', input.stemType)
          .eq('analysis_version', '2.0-sandbox')
          .order('created_at', { ascending: false })
          .limit(1)
          .single();

        if (analysisError || !analysis) {
          return null;
        }

        return {
          id: analysis.id,
          fileMetadataId: analysis.file_metadata_id,
          stemType: analysis.stem_type,
          analysisData: analysis.analysis_data,
          waveformData: analysis.waveform_data,
          metadata: {
            sampleRate: analysis.sample_rate,
            duration: analysis.duration,
            bufferSize: analysis.buffer_size,
            featuresExtracted: analysis.features_extracted,
            analysisDuration: analysis.analysis_duration,
          },
        };
      } catch (error) {
        logger.error('Error getting sandbox analysis:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to get sandbox analysis',
        });
      }
    }),

  // Compare sandbox analysis with existing cached analysis
  compareAnalysis: protectedProcedure
    .input(z.object({
      fileId: z.string(),
      stemType: z.string().optional().default('master'),
    }))
    .query(async ({ ctx, input }) => {
      const userId = ctx.user.id;

      try {
        // Get both sandbox and regular cached analysis
        const [sandboxResult, regularResult] = await Promise.all([
          ctx.supabase
            .from('audio_analysis_cache')
            .select('*')
            .eq('file_metadata_id', input.fileId)
            .eq('user_id', userId)
            .eq('stem_type', input.stemType)
            .eq('analysis_version', '2.0-sandbox')
            .order('created_at', { ascending: false })
            .limit(1)
            .single(),
          ctx.supabase
            .from('audio_analysis_cache')
            .select('*')
            .eq('file_metadata_id', input.fileId)
            .eq('user_id', userId)
            .eq('stem_type', input.stemType)
            .neq('analysis_version', '2.0-sandbox')
            .order('created_at', { ascending: false })
            .limit(1)
            .single(),
        ]);

        const sandboxAnalysis = sandboxResult.data;
        const regularAnalysis = regularResult.data;

        if (!sandboxAnalysis && !regularAnalysis) {
          return null;
        }

        // Compare the analyses
        const comparison = {
          hasSandbox: !!sandboxAnalysis,
          hasRegular: !!regularAnalysis,
          sandbox: sandboxAnalysis ? {
            transients: sandboxAnalysis.analysis_data?.transients?.length || 0,
            chroma: sandboxAnalysis.analysis_data?.chroma?.length || 0,
            rms: sandboxAnalysis.analysis_data?.rms?.length || 0,
            createdAt: sandboxAnalysis.created_at,
          } : null,
          regular: regularAnalysis ? {
            transients: regularAnalysis.analysis_data?.transients?.length || 0,
            chroma: regularAnalysis.analysis_data?.chroma?.length || 0,
            rms: regularAnalysis.analysis_data?.rms?.length || 0,
            createdAt: regularAnalysis.created_at,
          } : null,
        };

        return comparison;
      } catch (error) {
        logger.error('Error comparing analysis:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to compare analysis',
        });
      }
    }),

  // Get all sandbox analyses for a user
  getSandboxAnalyses: flexibleProcedure
    .input(z.object({
      limit: z.number().optional().default(10),
      offset: z.number().optional().default(0),
    }))
    .query(async ({ ctx, input }) => {
      const userId = ctx.user.id;

      try {
        const { data: analyses, error } = await ctx.supabase
          .from('audio_analysis_cache')
          .select(`
            *,
            file_metadata (
              file_name,
              file_type
            )
          `)
          .eq('user_id', userId)
          .eq('analysis_version', '2.0-sandbox')
          .order('created_at', { ascending: false })
          .range(input.offset, input.offset + input.limit - 1);

        if (error) {
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: `Failed to get sandbox analyses: ${error.message}`,
          });
        }

        return analyses || [];
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        
        logger.error('Error getting sandbox analyses:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to get sandbox analyses',
        });
      }
    }),

  // Delete sandbox analysis
  deleteSandboxAnalysis: protectedProcedure
    .input(z.object({
      analysisId: z.string(),
    }))
    .mutation(async ({ ctx, input }) => {
      const userId = ctx.user.id;

      try {
        // Verify ownership
        const { data: analysis, error: fetchError } = await ctx.supabase
          .from('audio_analysis_cache')
          .select('id, user_id')
          .eq('id', input.analysisId)
          .eq('user_id', userId)
          .eq('analysis_version', '2.0-sandbox')
          .single();

        if (fetchError || !analysis) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'Sandbox analysis not found or access denied',
          });
        }

        // Delete the analysis
        const { error: deleteError } = await ctx.supabase
          .from('audio_analysis_cache')
          .delete()
          .eq('id', input.analysisId)
          .eq('user_id', userId);

        if (deleteError) {
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: `Failed to delete sandbox analysis: ${deleteError.message}`,
          });
        }

        return { 
          success: true, 
          message: 'Sandbox analysis deleted successfully' 
        };
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        
        logger.error('Error deleting sandbox analysis:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to delete sandbox analysis',
        });
      }
    }),
});
</file>

<file path="routers/auth.ts">
import { z } from 'zod';
import { router, publicProcedure, protectedProcedure } from '../trpc';
import { TRPCError } from '@trpc/server';

export const authRouter = router({
  // Get current session
  session: publicProcedure
    .query(({ ctx }) => {
      return {
        authenticated: !!ctx.user,
        user: ctx.user || null,
      };
    }),

  // Get current user details
  me: protectedProcedure
    .query(({ ctx }) => {
      return {
        user: ctx.user,
        session: !!ctx.session,
        authenticated: true,
      };
    }),
});
</file>

<file path="routers/auto-save.ts">
import { z } from 'zod';
import { router, protectedProcedure, flexibleProcedure } from '../trpc';
import { TRPCError } from '@trpc/server';
import { logger } from '../lib/logger';

// Validation schemas
const saveStateSchema = z.object({
  projectId: z.string().min(1, 'Project ID is required'),
  data: z.record(z.any()).refine((data) => {
    // Validate that data contains expected structure
    return data && typeof data === 'object';
  }, 'Invalid edit state data'),
  version: z.number().min(1, 'Version must be at least 1').optional(),
});

const restoreStateSchema = z.object({
  stateId: z.string().min(1, 'State ID is required'),
});

const getProjectStatesSchema = z.object({
  projectId: z.string().min(1, 'Project ID is required'),
  limit: z.number().min(1).max(50).default(10),
  offset: z.number().min(0).default(0),
});

const deleteStateSchema = z.object({
  stateId: z.string().min(1, 'State ID is required'),
});

const clearProjectHistorySchema = z.object({
  projectId: z.string().min(1, 'Project ID is required'),
});

export const autoSaveRouter = router({
  // Save current edit state
  saveState: protectedProcedure
    .input(saveStateSchema)
    .mutation(async ({ input, ctx }) => {
      try {
        // First, mark all existing states for this project as not current
        await ctx.supabase
          .from('edit_states')
          .update({ is_current: false })
          .eq('project_id', input.projectId)
          .eq('user_id', ctx.user.id);

        // Get the next version number
        const { data: latestState } = await ctx.supabase
          .from('edit_states')
          .select('version')
          .eq('project_id', input.projectId)
          .eq('user_id', ctx.user.id)
          .order('version', { ascending: false })
          .limit(1)
          .single();

        const nextVersion = (latestState?.version || 0) + 1;

        // Create new edit state
        const { data: editState, error } = await ctx.supabase
          .from('edit_states')
          .insert({
            user_id: ctx.user.id,
            project_id: input.projectId,
            data: input.data,
            version: nextVersion,
            is_current: true,
          })
          .select()
          .single();

        if (error) {
          logger.error('Database error saving edit state:', error);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to save edit state',
          });
        }

        // Log audit event
        await ctx.supabase.rpc('log_audit_event', {
          p_user_id: ctx.user.id,
          p_action: 'auto_save.save_state',
          p_resource_type: 'edit_state',
          p_resource_id: editState.id,
          p_metadata: { project_id: input.projectId, version: nextVersion },
        });

        return editState;
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error saving edit state:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to save edit state',
        });
      }
    }),

  // Get current state for a project
  getCurrentState: protectedProcedure
    .input(z.object({ projectId: z.string().min(1, 'Project ID is required') }))
    .query(async ({ input, ctx }) => {
      try {
        const { data: editState, error } = await ctx.supabase
          .from('edit_states')
          .select('*')
          .eq('project_id', input.projectId)
          .eq('user_id', ctx.user.id)
          .eq('is_current', true)
          .single();

        if (error) {
          if (error.code === 'PGRST116') {
            // No current state found, return null
            return null;
          }
          logger.error('Database error fetching current state:', error);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to fetch current state',
          });
        }

        return editState;
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error fetching current state:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch current state',
        });
      }
    }),

  // Restore a specific edit state
  restoreState: protectedProcedure
    .input(restoreStateSchema)
    .mutation(async ({ input, ctx }) => {
      try {
        // Get the state to restore
        const { data: editState, error: fetchError } = await ctx.supabase
          .from('edit_states')
          .select('*')
          .eq('id', input.stateId)
          .eq('user_id', ctx.user.id)
          .single();

        if (fetchError) {
          if (fetchError.code === 'PGRST116') {
            throw new TRPCError({
              code: 'NOT_FOUND',
              message: 'Edit state not found or access denied',
            });
          }
          logger.error('Database error fetching edit state:', fetchError);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to fetch edit state',
          });
        }

        // Mark all existing states for this project as not current
        await ctx.supabase
          .from('edit_states')
          .update({ is_current: false })
          .eq('project_id', editState.project_id)
          .eq('user_id', ctx.user.id);

        // Create a new state based on the restored one
        const { data: newState, error: createError } = await ctx.supabase
          .from('edit_states')
          .insert({
            user_id: ctx.user.id,
            project_id: editState.project_id,
            data: editState.data,
            version: editState.version + 1,
            is_current: true,
          })
          .select()
          .single();

        if (createError) {
          logger.error('Database error creating restored state:', createError);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to restore edit state',
          });
        }

        // Log audit event
        await ctx.supabase.rpc('log_audit_event', {
          p_user_id: ctx.user.id,
          p_action: 'auto_save.restore_state',
          p_resource_type: 'edit_state',
          p_resource_id: newState.id,
          p_metadata: { 
            original_state_id: input.stateId,
            project_id: editState.project_id,
            version: newState.version 
          },
        });

        return newState;
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error restoring edit state:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to restore edit state',
        });
      }
    }),

  // Get edit history for a project
  getProjectStates: protectedProcedure
    .input(getProjectStatesSchema)
    .query(async ({ input, ctx }) => {
      try {
        const { data: editStates, error } = await ctx.supabase
          .from('edit_states')
          .select('*')
          .eq('project_id', input.projectId)
          .eq('user_id', ctx.user.id)
          .order('timestamp', { ascending: false })
          .range(input.offset, input.offset + input.limit - 1);

        if (error) {
          logger.error('Database error fetching project states:', error);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to fetch project states',
          });
        }

        return editStates || [];
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error fetching project states:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch project states',
        });
      }
    }),

  // Delete a specific edit state
  deleteState: protectedProcedure
    .input(deleteStateSchema)
    .mutation(async ({ input, ctx }) => {
      try {
        // Check if this is the current state
        const { data: editState, error: fetchError } = await ctx.supabase
          .from('edit_states')
          .select('is_current, project_id')
          .eq('id', input.stateId)
          .eq('user_id', ctx.user.id)
          .single();

        if (fetchError) {
          if (fetchError.code === 'PGRST116') {
            throw new TRPCError({
              code: 'NOT_FOUND',
              message: 'Edit state not found or access denied',
            });
          }
          logger.error('Database error fetching edit state:', fetchError);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to fetch edit state',
          });
        }

        // Delete the state
        const { error: deleteError } = await ctx.supabase
          .from('edit_states')
          .delete()
          .eq('id', input.stateId)
          .eq('user_id', ctx.user.id);

        if (deleteError) {
          logger.error('Database error deleting edit state:', deleteError);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to delete edit state',
          });
        }

        // If this was the current state, make the most recent state current
        if (editState.is_current) {
          const { data: latestState } = await ctx.supabase
            .from('edit_states')
            .select('id')
            .eq('project_id', editState.project_id)
            .eq('user_id', ctx.user.id)
            .order('timestamp', { ascending: false })
            .limit(1)
            .single();

          if (latestState) {
            await ctx.supabase
              .from('edit_states')
              .update({ is_current: true })
              .eq('id', latestState.id);
          }
        }

        // Log audit event
        await ctx.supabase.rpc('log_audit_event', {
          p_user_id: ctx.user.id,
          p_action: 'auto_save.delete_state',
          p_resource_type: 'edit_state',
          p_resource_id: input.stateId,
          p_metadata: { 
            was_current: editState.is_current,
            project_id: editState.project_id 
          },
        });

        return { success: true };
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error deleting edit state:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to delete edit state',
        });
      }
    }),

  // Clear all edit history for a project
  clearProjectHistory: protectedProcedure
    .input(clearProjectHistorySchema)
    .mutation(async ({ input, ctx }) => {
      try {
        // Delete all edit states for this project
        const { error } = await ctx.supabase
          .from('edit_states')
          .delete()
          .eq('project_id', input.projectId)
          .eq('user_id', ctx.user.id);

        if (error) {
          logger.error('Database error clearing project history:', error);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to clear project history',
          });
        }

        // Log audit event
        await ctx.supabase.rpc('log_audit_event', {
          p_user_id: ctx.user.id,
          p_action: 'auto_save.clear_history',
          p_resource_type: 'project',
          p_resource_id: input.projectId,
          p_metadata: { action: 'clear_edit_history' },
        });

        return { success: true };
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error clearing project history:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to clear project history',
        });
      }
    }),
});
</file>

<file path="routers/file.ts">
import { z } from 'zod'
import { router, protectedProcedure } from '../trpc'
import { TRPCError } from '@trpc/server'
import { generateUploadUrl, generateDownloadUrl, generateS3Key, deleteFile, r2Client, BUCKET_NAME, uploadThumbnail, generateThumbnailKey, generateThumbnailUrl } from '../services/r2-storage'
import { PutObjectCommand } from '@aws-sdk/client-s3'
import { 
  validateFile, 
  FileUploadSchema, 
  createUploadRateLimit,
  isExecutableFile,
  sanitizeFileName 
} from '../lib/file-validation'
import { MediaProcessor } from '../services/media-processor'
import { AssetManager } from '../services/asset-manager'
import { logger } from '../lib/logger';

// Create rate limiter instance
const uploadRateLimit = createUploadRateLimit()

// File metadata schema for database storage - EXTENDED
const FileMetadataSchema = z.object({
  id: z.string(),
  fileName: z.string(),
  fileType: z.enum(['midi', 'audio', 'video', 'image']), // EXTENDED
  mimeType: z.string(),
  fileSize: z.number(),
  s3Key: z.string(),
  s3Bucket: z.string(),
  uploadStatus: z.enum(['uploading', 'completed', 'failed']),
})

export const fileRouter = router({
  
  // Generate pre-signed URL for file upload - EXTENDED
  getUploadUrl: protectedProcedure
    .input(FileUploadSchema)
    .mutation(async ({ ctx, input }) => {
      const userId = ctx.user.id
      
      try {
        // Rate limiting check
        if (!uploadRateLimit.checkRateLimit(userId)) {
          throw new TRPCError({
            code: 'TOO_MANY_REQUESTS',
            message: 'Upload rate limit exceeded. Please wait before uploading more files.',
          })
        }

        // Security check - reject executable files
        if (isExecutableFile(input.fileName)) {
          throw new TRPCError({
            code: 'BAD_REQUEST',
            message: 'Executable files are not allowed for security reasons.',
          })
        }

        // Validate file
        const validation = validateFile(input)
        if (!validation.isValid) {
          throw new TRPCError({
            code: 'BAD_REQUEST',
            message: `File validation failed: ${validation.errors.join(', ')}`,
          })
        }

        // Sanitize file name and generate S3 key
        const sanitizedFileName = sanitizeFileName(input.fileName)
        const s3Key = generateS3Key(userId, sanitizedFileName, validation.fileType)

        // Generate pre-signed URL
        const uploadUrl = await generateUploadUrl(s3Key, input.mimeType, 3600) // 1 hour expiry

        // Create file metadata record in database
        const fileId = `file_${Date.now()}_${Math.random().toString(36).substring(2)}`
        
        const { error: dbError } = await ctx.supabase
          .from('file_metadata')
          .insert({
            id: fileId,
            user_id: userId,
            file_name: sanitizedFileName,
            file_type: validation.fileType,
            mime_type: input.mimeType,
            file_size: input.fileSize,
            s3_key: s3Key,
            s3_bucket: process.env.CLOUDFLARE_R2_BUCKET || 'phonoglyph-uploads',
            processing_status: MediaProcessor.requiresProcessing(validation.fileType) ? 'pending' : 'completed',
          })

        if (dbError) {
          logger.error('Database error creating file metadata:', dbError)
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to create file record',
          })
        }

        return {
          fileId,
          uploadUrl,
          s3Key,
          expiresIn: 3600,
          fileInfo: {
            fileName: sanitizedFileName,
            fileType: validation.fileType,
            fileSize: input.fileSize,
          },
        }

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error generating upload URL:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to generate upload URL',
        })
      }
    }),

  // Direct upload endpoint to avoid CORS issues - EXTENDED
  uploadFile: protectedProcedure
    .input(z.object({
      fileName: z.string(),
      fileType: z.enum(['midi', 'audio', 'video', 'image']), // EXTENDED
      mimeType: z.string(),
      fileSize: z.number(),
      fileData: z.string(), // Base64 encoded file data
      projectId: z.string().optional(), // NEW: Associate with project
      isMaster: z.boolean().optional(), // NEW: Tag as master track
      stemType: z.string().optional(), // NEW: Tag stem type
    }))
    .mutation(async ({ ctx, input }) => {
      const userId = ctx.user.id
      
      try {
        // Rate limiting check
        if (!uploadRateLimit.checkRateLimit(userId)) {
          throw new TRPCError({
            code: 'TOO_MANY_REQUESTS',
            message: 'Upload rate limit exceeded. Please wait before uploading more files.',
          })
        }

        // Security check - reject executable files
        if (isExecutableFile(input.fileName)) {
          throw new TRPCError({
            code: 'BAD_REQUEST',
            message: 'Executable files are not allowed for security reasons.',
          })
        }

        // Validate file
        const validation = validateFile({
          fileName: input.fileName,
          fileSize: input.fileSize,
          mimeType: input.mimeType,
        })
        
        if (!validation.isValid) {
          throw new TRPCError({
            code: 'BAD_REQUEST',
            message: `File validation failed: ${validation.errors.join(', ')}`,
          })
        }

        // Sanitize file name and generate S3 key
        const sanitizedFileName = sanitizeFileName(input.fileName)
        const s3Key = generateS3Key(userId, sanitizedFileName, validation.fileType)

        // Decode base64 file data
        const fileBuffer = Buffer.from(input.fileData, 'base64')

        // Upload directly to R2 through backend
        const command = new PutObjectCommand({
          Bucket: BUCKET_NAME,
          Key: s3Key,
          Body: fileBuffer,
          ContentType: input.mimeType,
        })

        await (r2Client as any).send(command)

        // Create file metadata record
        const { data, error: dbError } = await ctx.supabase
          .from('file_metadata')
          .insert({
            user_id: userId,
            file_name: sanitizedFileName,
            file_type: validation.fileType,
            mime_type: input.mimeType,
            file_size: input.fileSize,
            s3_key: s3Key,
            s3_bucket: BUCKET_NAME,
            upload_status: 'completed',
            processing_status: MediaProcessor.requiresProcessing(validation.fileType) ? 'pending' : 'completed',
            project_id: input.projectId, // NEW: Associate with project
            is_master: input.isMaster || false, // NEW: Store master tag
            stem_type: input.stemType || null, // NEW: Store stem type
          })
          .select('id')
          .single();

        if (dbError) {
          logger.error('Database error creating file metadata:', dbError)
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to create file record',
          })
        }

        // Trigger audio analysis and caching for audio files
        if (validation.fileType === 'audio') {
          // Instead of synchronous analysis, create a job for the queue worker
          const { error: jobError } = await ctx.supabase
            .from('audio_analysis_jobs')
            .insert({
              user_id: userId,
              file_metadata_id: data.id,
              status: 'pending',
            });

          if (jobError) {
            // Log the error but don't block the upload from completing
            logger.error(` Failed to create audio analysis job for file ${sanitizedFileName}:`, jobError);
          } else {
            logger.log(` Audio analysis job queued for file ${sanitizedFileName}`);
          }
        }

        // Process video/image files for metadata and thumbnails
        if (MediaProcessor.requiresProcessing(validation.fileType) && (validation.fileType === 'video' || validation.fileType === 'image')) {
          try {
            const processing = await MediaProcessor.processUploadedFile(
              fileBuffer,
              sanitizedFileName,
              validation.fileType,
              data.id
            )

            // Upload thumbnail to R2
            await uploadThumbnail(processing.thumbnailKey, processing.thumbnail)

            // Update file metadata with processing results
            const metadataField = validation.fileType === 'video' ? 'video_metadata' : 'image_metadata'
            const { error: updateError } = await ctx.supabase
              .from('file_metadata')
              .update({
                [metadataField]: processing.metadata,
                thumbnail_url: processing.thumbnailKey,
                processing_status: 'completed'
              })
              .eq('id', data.id)

            if (updateError) {
              logger.error('Failed to update file metadata:', updateError)
              // Don't throw error here - file upload was successful
            }

          } catch (processingError) {
            logger.error('Media processing failed:', processingError)
            // Update status to failed but don't throw error
            await ctx.supabase
              .from('file_metadata')
              .update({ processing_status: 'failed' })
              .eq('id', data.id)
          }
        }

        return {
          fileId: data.id,
          success: true,
          fileInfo: {
            fileName: sanitizedFileName,
            fileType: validation.fileType,
            fileSize: input.fileSize,
          },
        }

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error uploading file:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to upload file',
        })
      }
    }),

  // Confirm upload completion
  confirmUpload: protectedProcedure
    .input(z.object({ 
      fileId: z.string(),
      success: z.boolean().optional().default(true)
    }))
    .mutation(async ({ ctx, input }) => {
      const userId = ctx.user.id

      try {
        // Get file metadata
        const { data: fileData, error: fetchError } = await ctx.supabase
          .from('file_metadata')
          .select('*')
          .eq('id', input.fileId)
          .eq('user_id', userId)
          .single()

        if (fetchError || !fileData) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'File not found or access denied',
          })
        }

        // Update upload status
        const newStatus = input.success ? 'completed' : 'failed'
        
        const { error: updateError } = await ctx.supabase
          .from('file_metadata')
          .update({ 
            upload_status: newStatus,
            updated_at: new Date().toISOString(),
          })
          .eq('id', input.fileId)
          .eq('user_id', userId)

        if (updateError) {
          logger.error('Database error updating file status:', updateError)
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to update file status',
          })
        }

        // If upload failed, clean up S3
        if (!input.success) {
          try {
            await deleteFile(fileData.s3_key)
          } catch (cleanupError) {
            logger.error('Failed to cleanup failed upload:', cleanupError)
            // Don't throw - the database update was successful
          }
        }

        return {
          success: true,
          fileId: input.fileId,
          status: newStatus,
        }

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error confirming upload:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to confirm upload',
        })
      }
    }),

  // Save audio analysis data from the client-side worker
  saveAudioAnalysis: protectedProcedure
    .input(z.object({
      fileId: z.string(),
      analysisData: z.any(), // In a real app, this should be a strict Zod schema
    }))
    .mutation(async ({ ctx, input }) => {
      const { fileId, analysisData } = input;
      const userId = ctx.user.id;

      try {
        // First, verify that the user has access to this file
        const { data: file, error: fileError } = await ctx.supabase
          .from('file_metadata')
          .select('id, user_id, stem_type')
          .eq('id', fileId)
          .single();

        if (fileError || !file) {
          throw new TRPCError({ code: 'NOT_FOUND', message: 'File not found.' });
        }

        if (file.user_id !== userId) {
          throw new TRPCError({ code: 'FORBIDDEN', message: 'You do not have access to this file.' });
        }

        // Save the analysis data
        const { error: saveError } = await ctx.supabase
          .from('audio_analysis_cache')
          .insert({
            file_metadata_id: fileId,
            user_id: userId,
            stem_type: file.stem_type || 'master',
            analysis_data: analysisData,
            // Add other relevant fields from your analysis data
          });

        if (saveError) {
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: `Failed to save analysis data: ${saveError.message}`,
          });
        }
        
        // Update the file's processing status
        await ctx.supabase
          .from('file_metadata')
          .update({ processing_status: 'completed' })
          .eq('id', fileId);

        return { success: true };
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error saving audio analysis:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'An unexpected error occurred while saving the analysis.',
        });
      }
    }),

  // Get a list of files for the current user
  getUserFiles: protectedProcedure
    .input(z.object({
      fileType: z.enum(['midi', 'audio', 'video', 'image', 'all']).optional().default('all'), // EXTENDED
      limit: z.number().min(1).max(50).optional().default(20),
      offset: z.number().min(0).optional().default(0),
      projectId: z.string().optional(), // NEW: Filter by project
    }))
    .query(async ({ ctx, input }) => {
      const userId = ctx.user.id

      try {
        let query = ctx.supabase
          .from('file_metadata')
          .select('*')
          .eq('user_id', userId)
          .eq('upload_status', 'completed')
          .order('created_at', { ascending: false })
          .range(input.offset, input.offset + input.limit - 1)

        if (input.fileType !== 'all') {
          query = query.eq('file_type', input.fileType)
        }

        if (input.projectId) {
          query = query.eq('project_id', input.projectId)
        }

        const { data: files, error } = await query

        if (error) {
          logger.error('Database error fetching user files:', error)
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to fetch files',
          })
        }

        // Generate thumbnail URLs for files that have them
        const filesWithThumbnails = await Promise.all(
          (files || []).map(async (file: any) => {
            if (file.thumbnail_url) {
              try {
                const thumbnailUrl = await generateThumbnailUrl(file.thumbnail_url)
                return { ...file, thumbnail_url: thumbnailUrl }
              } catch (error) {
                logger.error('Failed to generate thumbnail URL:', error)
                return file
              }
            }
            return file
          })
        )

        return {
          files: filesWithThumbnails,
          hasMore: files?.length === input.limit,
        }

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error fetching user files:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch files',
        })
      }
    }),

  // Get download URL for a file
  getDownloadUrl: protectedProcedure
    .input(z.object({ fileId: z.string() }))
    .mutation(async ({ ctx, input }) => {
      const userId = ctx.user.id

      try {
        // Get file metadata
        const { data: fileData, error } = await ctx.supabase
          .from('file_metadata')
          .select('*')
          .eq('id', input.fileId)
          .eq('user_id', userId)
          .eq('upload_status', 'completed')
          .single()

        if (error || !fileData) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'File not found or access denied',
          })
        }

        // Generate download URL
        const downloadUrl = await generateDownloadUrl(fileData.s3_key, 3600) // 1 hour expiry

        return {
          downloadUrl,
          fileName: fileData.file_name,
          fileSize: fileData.file_size,
          fileType: fileData.file_type,
          expiresIn: 3600,
        }

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error generating download URL:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to generate download URL',
        })
      }
    }),

  // Delete a file
  deleteFile: protectedProcedure
    .input(z.object({ fileId: z.string() }))
    .mutation(async ({ ctx, input }) => {
      const userId = ctx.user.id

      try {
        // Get file metadata
        const { data: fileData, error: fetchError } = await ctx.supabase
          .from('file_metadata')
          .select('*')
          .eq('id', input.fileId)
          .eq('user_id', userId)
          .single()

        if (fetchError || !fileData) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'File not found or access denied',
          })
        }

        // Delete from S3
        await deleteFile(fileData.s3_key)

        // Delete from database
        const { error: deleteError } = await ctx.supabase
          .from('file_metadata')
          .delete()
          .eq('id', input.fileId)
          .eq('user_id', userId)

        if (deleteError) {
          logger.error('Database error deleting file:', deleteError)
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to delete file record',
          })
        }

        return {
          success: true,
          fileId: input.fileId,
        }

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error deleting file:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to delete file',
        })
      }
    }),

  // Get upload statistics for rate limiting
  getUploadStats: protectedProcedure
    .query(({ ctx }) => {
      const userId = ctx.user.id
      const remainingUploads = uploadRateLimit.getRemainingUploads(userId)
      
      return {
        remainingUploads,
        maxUploadsPerMinute: 10,
        resetTime: Date.now() + (60 * 1000), // 1 minute from now
      }
    }),

  // Get processing status for video/image files
  getProcessingStatus: protectedProcedure
    .input(z.object({ fileId: z.string() }))
    .query(async ({ ctx, input }) => {
      const userId = ctx.user.id

      try {
        const { data: file, error } = await ctx.supabase
          .from('file_metadata')
          .select('processing_status, file_type, video_metadata, image_metadata, thumbnail_url')
          .eq('id', input.fileId)
          .eq('user_id', userId)
          .single()

        if (error || !file) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'File not found or access denied',
          })
        }

        return {
          status: file.processing_status,
          fileType: file.file_type,
          hasMetadata: !!(file.video_metadata || file.image_metadata),
          hasThumbnail: !!file.thumbnail_url,
        }

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error fetching processing status:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch processing status',
        })
      }
    }),

  // NEW: Asset Management Endpoints

  // Get project assets with enhanced filtering
  getProjectAssets: protectedProcedure
    .input(z.object({
      projectId: z.string(),
      assetType: z.enum(['midi', 'audio', 'video', 'image', 'all']).optional().default('all'),
      usageStatus: z.enum(['active', 'referenced', 'unused', 'all']).optional().default('all'),
      folderId: z.string().optional(),
      tagIds: z.array(z.string()).optional(),
      search: z.string().optional(),
      limit: z.number().min(1).max(100).optional().default(50),
      offset: z.number().min(0).optional().default(0),
    }))
    .query(async ({ ctx, input }) => {
      const userId = ctx.user.id
      const assetManager = new AssetManager(ctx.supabase)

      try {
        let query = ctx.supabase
          .from('file_metadata')
          .select(`
            *,
            asset_folders(name),
            asset_tag_relationships(
              asset_tags(id, name, color)
            )
          `)
          .eq('user_id', userId)
          .eq('project_id', input.projectId)
          .eq('upload_status', 'completed')
          .order('created_at', { ascending: false })
          .range(input.offset, input.offset + input.limit - 1)

        if (input.assetType !== 'all') {
          query = query.eq('asset_type', input.assetType)
        }

        if (input.usageStatus !== 'all') {
          query = query.eq('usage_status', input.usageStatus)
        }

        if (input.folderId) {
          query = query.eq('folder_id', input.folderId)
        }

        if (input.search) {
          query = query.ilike('file_name', `%${input.search}%`)
        }

        const { data: files, error } = await query

        if (error) {
          logger.error('Database error fetching project assets:', error)
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to fetch project assets',
          })
        }

        // Filter by tags if specified
        let filteredFiles = files || []
        if (input.tagIds && input.tagIds.length > 0) {
          filteredFiles = filteredFiles.filter((file: any) => {
            const fileTags = file.asset_tag_relationships?.map((rel: any) => rel.asset_tags.id) || []
            return input.tagIds!.some(tagId => fileTags.includes(tagId))
          })
        }

        // Generate thumbnail URLs
        const filesWithThumbnails = await Promise.all(
          filteredFiles.map(async (file: any) => {
            if (file.thumbnail_url) {
              try {
                const thumbnailUrl = await generateThumbnailUrl(file.thumbnail_url)
                return { ...file, thumbnail_url: thumbnailUrl }
              } catch (error) {
                logger.error('Failed to generate thumbnail URL:', error)
                return file
              }
            }
            return file
          })
        )

        return {
          files: filesWithThumbnails,
          hasMore: filteredFiles.length === input.limit,
        }

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error fetching project assets:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch project assets',
        })
      }
    }),

  // Start asset usage tracking
  startAssetUsage: protectedProcedure
    .input(z.object({
      fileId: z.string(),
      projectId: z.string(),
      usageType: z.enum(['visualizer', 'composition', 'export']),
      usageContext: z.record(z.any()).optional(),
    }))
    .mutation(async ({ ctx, input }) => {
      const userId = ctx.user.id
      const assetManager = new AssetManager(ctx.supabase)

      try {
        // Verify file belongs to user and project
        const { data: file, error: fileError } = await ctx.supabase
          .from('file_metadata')
          .select('id')
          .eq('id', input.fileId)
          .eq('user_id', userId)
          .eq('project_id', input.projectId)
          .single()

        if (fileError || !file) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'File not found or access denied',
          })
        }

        const usageId = await assetManager.startUsageTracking(
          input.fileId,
          input.projectId,
          input.usageType,
          input.usageContext
        )

        return { usageId }

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error starting asset usage tracking:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to start usage tracking',
        })
      }
    }),

  // End asset usage tracking
  endAssetUsage: protectedProcedure
    .input(z.object({
      usageId: z.string(),
    }))
    .mutation(async ({ ctx, input }) => {
      const userId = ctx.user.id
      const assetManager = new AssetManager(ctx.supabase)

      try {
        // Verify usage record belongs to user
        const { data: usage, error: usageError } = await ctx.supabase
          .from('asset_usage')
          .select('id')
          .eq('id', input.usageId)
          .eq('project_id', 
            ctx.supabase
              .from('projects')
              .select('id')
              .eq('user_id', userId)
          )
          .single()

        if (usageError || !usage) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'Usage record not found or access denied',
          })
        }

        await assetManager.endUsageTracking(input.usageId)

        return { success: true }

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error ending asset usage tracking:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to end usage tracking',
        })
      }
    }),

  // Get storage quota for project
  getStorageQuota: protectedProcedure
    .input(z.object({
      projectId: z.string(),
    }))
    .query(async ({ ctx, input }) => {
      const userId = ctx.user.id
      const assetManager = new AssetManager(ctx.supabase)

      try {
        // Verify project belongs to user
        const { data: project, error: projectError } = await ctx.supabase
          .from('projects')
          .select('id')
          .eq('id', input.projectId)
          .eq('user_id', userId)
          .single()

        if (projectError || !project) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'Project not found or access denied',
          })
        }

        const quota = await assetManager.getStorageQuota(input.projectId)

        return quota

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error fetching storage quota:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch storage quota',
        })
      }
    }),

  // Create asset folder
  createAssetFolder: protectedProcedure
    .input(z.object({
      projectId: z.string(),
      name: z.string().min(1).max(100),
      description: z.string().optional(),
      parentFolderId: z.string().optional(),
    }))
    .mutation(async ({ ctx, input }) => {
      const userId = ctx.user.id
      const assetManager = new AssetManager(ctx.supabase)

      try {
        // Verify project belongs to user
        const { data: project, error: projectError } = await ctx.supabase
          .from('projects')
          .select('id')
          .eq('id', input.projectId)
          .eq('user_id', userId)
          .single()

        if (projectError || !project) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'Project not found or access denied',
          })
        }

        const folder = await assetManager.createFolder(
          input.projectId,
          input.name,
          input.description,
          input.parentFolderId
        )

        return folder

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error creating asset folder:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to create asset folder',
        })
      }
    }),

  // Get asset folders
  getAssetFolders: protectedProcedure
    .input(z.object({
      projectId: z.string(),
    }))
    .query(async ({ ctx, input }) => {
      const userId = ctx.user.id
      const assetManager = new AssetManager(ctx.supabase)

      try {
        // Verify project belongs to user
        const { data: project, error: projectError } = await ctx.supabase
          .from('projects')
          .select('id')
          .eq('id', input.projectId)
          .eq('user_id', userId)
          .single()

        if (projectError || !project) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'Project not found or access denied',
          })
        }

        const folders = await assetManager.getFolders(input.projectId)

        return folders

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error fetching asset folders:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch asset folders',
        })
      }
    }),

  // Create asset tag
  createAssetTag: protectedProcedure
    .input(z.object({
      projectId: z.string(),
      name: z.string().min(1).max(50),
      color: z.string().regex(/^#[0-9A-F]{6}$/i).optional(),
    }))
    .mutation(async ({ ctx, input }) => {
      const userId = ctx.user.id
      const assetManager = new AssetManager(ctx.supabase)

      try {
        // Verify project belongs to user
        const { data: project, error: projectError } = await ctx.supabase
          .from('projects')
          .select('id')
          .eq('id', input.projectId)
          .eq('user_id', userId)
          .single()

        if (projectError || !project) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'Project not found or access denied',
          })
        }

        const tag = await assetManager.createTag(
          input.projectId,
          input.name,
          input.color
        )

        return tag

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error creating asset tag:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to create asset tag',
        })
      }
    }),

  // Get asset tags
  getAssetTags: protectedProcedure
    .input(z.object({
      projectId: z.string(),
    }))
    .query(async ({ ctx, input }) => {
      const userId = ctx.user.id
      const assetManager = new AssetManager(ctx.supabase)

      try {
        // Verify project belongs to user
        const { data: project, error: projectError } = await ctx.supabase
          .from('projects')
          .select('id')
          .eq('id', input.projectId)
          .eq('user_id', userId)
          .single()

        if (projectError || !project) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'Project not found or access denied',
          })
        }

        const tags = await assetManager.getTags(input.projectId)

        return tags

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error fetching asset tags:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch asset tags',
        })
      }
    }),

  // Add tag to file
  addTagToFile: protectedProcedure
    .input(z.object({
      fileId: z.string(),
      tagId: z.string(),
    }))
    .mutation(async ({ ctx, input }) => {
      const userId = ctx.user.id
      const assetManager = new AssetManager(ctx.supabase)

      try {
        // Verify file belongs to user
        const { data: file, error: fileError } = await ctx.supabase
          .from('file_metadata')
          .select('id')
          .eq('id', input.fileId)
          .eq('user_id', userId)
          .single()

        if (fileError || !file) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'File not found or access denied',
          })
        }

        await assetManager.addTagToFile(input.fileId, input.tagId)

        return { success: true }

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error adding tag to file:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to add tag to file',
        })
      }
    }),

  // Remove tag from file
  removeTagFromFile: protectedProcedure
    .input(z.object({
      fileId: z.string(),
      tagId: z.string(),
    }))
    .mutation(async ({ ctx, input }) => {
      const userId = ctx.user.id
      const assetManager = new AssetManager(ctx.supabase)

      try {
        // Verify file belongs to user
        const { data: file, error: fileError } = await ctx.supabase
          .from('file_metadata')
          .select('id')
          .eq('id', input.fileId)
          .eq('user_id', userId)
          .single()

        if (fileError || !file) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'File not found or access denied',
          })
        }

        await assetManager.removeTagFromFile(input.fileId, input.tagId)

        return { success: true }

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error removing tag from file:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to remove tag from file',
        })
      }
    }),

  // Replace asset
  replaceAsset: protectedProcedure
    .input(z.object({
      oldFileId: z.string(),
      newFileId: z.string(),
      preserveMetadata: z.boolean().optional().default(true),
    }))
    .mutation(async ({ ctx, input }) => {
      const userId = ctx.user.id
      const assetManager = new AssetManager(ctx.supabase)

      try {
        // Verify both files belong to user
        const { data: files, error: filesError } = await ctx.supabase
          .from('file_metadata')
          .select('id')
          .in('id', [input.oldFileId, input.newFileId])
          .eq('user_id', userId)

        if (filesError || !files || files.length !== 2) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'One or both files not found or access denied',
          })
        }

        await assetManager.replaceAsset(
          input.oldFileId,
          input.newFileId,
          input.preserveMetadata
        )

        return { success: true }

      } catch (error) {
        if (error instanceof TRPCError) throw error
        
        logger.error('Error replacing asset:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to replace asset',
        })
      }
    }),
})
</file>

<file path="routers/guest.ts">
import { router, guestFriendlyProcedure, flexibleProcedure } from '../trpc';
import { isGuestUser, type GuestUser } from '../types/guest';
import type { User } from 'phonoglyph-types';

export const guestRouter = router({
    // Get session info for any user type
    sessionInfo: guestFriendlyProcedure
      .query(({ ctx }) => {
        if (!ctx.user) {
          return {
            type: 'none',
            authenticated: false,
            isGuest: false,
            user: null,
          }
        }
  
        if (ctx.isGuest && isGuestUser(ctx.user)) {
           const guestUser = ctx.user as GuestUser;
           return {
            type: 'guest',
            authenticated: false,
            isGuest: true,
            user: {
              id: guestUser.id,
              sessionId: guestUser.sessionId,
              createdAt: guestUser.createdAt,
            },
            limitations: {
              maxProjects: 3,
              dataRetention: '7 days',
              features: ['basic_upload', 'simple_visualization'],
            },
          }
        }
  
        const authUser = ctx.user as User
        return {
          type: 'authenticated',
          authenticated: true,
          isGuest: false,
          user: {
            id: authUser.id,
            email: authUser.email,
            name: authUser.name,
          },
          limitations: null,
        }
      }),
  
    // Basic project operations for guests
    listProjects: flexibleProcedure
      .query(({ ctx }) => {
        if (ctx.isGuest) {
          return {
            projects: [],
            isGuest: true,
            message: 'Guest projects are stored locally. Sign up to save your work!',
            conversionPrompt: {
              title: 'Save Your Work Forever',
              description: 'Create an account to keep your projects safe and access them from any device.',
              benefits: ['Unlimited projects', 'Cloud storage', 'Advanced features'],
            },
          }
        }
  
        // This part would fetch projects for authenticated users
        return {
            projects: [], // Replace with actual project fetching logic
            isGuest: false,
        }
      }),
});
</file>

<file path="routers/health.ts">
import { router, publicProcedure } from '../trpc';

export const healthRouter = router({
  check: publicProcedure
    .query(() => {
      return {
        status: 'healthy',
        timestamp: new Date().toISOString(),
        message: 'tRPC server is running! '
      }
    }),
});
</file>

<file path="routers/index.ts">
import { router } from '../trpc';
import { healthRouter } from './health';
import { guestRouter } from './guest';
import { authRouter } from './auth';
import { userRouter } from './user';
import { projectRouter } from './project';
import { fileRouter } from './file';
import { midiRouter } from './midi';
import { stemRouter } from './stem';
import { autoSaveRouter } from './auto-save';
import { audioAnalysisSandboxRouter } from './audio-analysis-sandbox';

export const appRouter = router({
  health: healthRouter,
  auth: authRouter,
  user: userRouter,
  guest: guestRouter,
  project: projectRouter,
  file: fileRouter,
  midi: midiRouter,
  stem: stemRouter,
  autoSave: autoSaveRouter,
  audioAnalysisSandbox: audioAnalysisSandboxRouter,
});

export type AppRouter = typeof appRouter;
</file>

<file path="routers/midi.ts">
import { z } from 'zod';
import { router, protectedProcedure } from '../trpc';
import { TRPCError } from '@trpc/server';
import { getFileBuffer } from '../services/r2-storage';
import { parseMidiFile, validateMidiBuffer } from '../services/midi-parser';
import { MIDIData } from 'phonoglyph-types';
import { logger } from '../lib/logger';

// Validation schemas
const VisualizationSettingsSchema = z.object({
  colorScheme: z.enum(['sage', 'slate', 'dusty-rose', 'mixed']).default('mixed'),
  pixelsPerSecond: z.number().min(10).max(200).default(50),
  showTrackLabels: z.boolean().default(true),
  showVelocity: z.boolean().default(true),
  minKey: z.number().min(0).max(127).default(21),
  maxKey: z.number().min(0).max(127).default(108),
});

export const midiRouter = router({
  
  // Parse uploaded MIDI file
  parseMidiFile: protectedProcedure
    .input(z.object({
      fileId: z.string(),
    }))
    .mutation(async ({ ctx, input }) => {
      const userId = ctx.user.id;

      try {
        // Get file metadata from database
        const { data: fileData, error: fetchError } = await ctx.supabase
          .from('file_metadata')
          .select('*')
          .eq('id', input.fileId)
          .eq('user_id', userId)
          .eq('file_type', 'midi')
          .single();

        if (fetchError || !fileData) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'MIDI file not found or access denied',
          });
        }

        // Check if file upload is complete
        if (fileData.upload_status !== 'completed') {
          throw new TRPCError({
            code: 'BAD_REQUEST',
            message: 'File upload is not complete',
          });
        }

        // Check if already parsed
        const { data: existingMidi } = await ctx.supabase
          .from('midi_files')
          .select('*')
          .eq('file_key', fileData.s3_key)
          .eq('user_id', userId)
          .single();

        if (existingMidi && existingMidi.parsing_status === 'completed') {
          return {
            success: true,
            midiFileId: existingMidi.id,
            data: existingMidi.parsed_data as MIDIData,
            cached: true,
          };
        }

        // Get file buffer from R2
        const fileBuffer = await getFileBuffer(fileData.s3_key);

        // Validate MIDI format
        if (!validateMidiBuffer(fileBuffer)) {
          throw new TRPCError({
            code: 'BAD_REQUEST',
            message: 'Invalid MIDI file format',
          });
        }

        // Parse MIDI file
        const parsingResult = await parseMidiFile(fileBuffer, fileData.file_name);

        if (!parsingResult.success || !parsingResult.data) {
          // Update parsing status to failed
          await ctx.supabase
            .from('midi_files')
            .upsert({
              user_id: userId,
              file_key: fileData.s3_key,
              original_filename: fileData.file_name,
              file_size: fileData.file_size,
              parsing_status: 'failed',
              error_message: parsingResult.error,
            });

          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: parsingResult.error || 'Failed to parse MIDI file',
          });
        }

        // Store parsed data in database
        const { data: midiRecord, error: insertError } = await ctx.supabase
          .from('midi_files')
          .upsert({
            user_id: userId,
            file_key: fileData.s3_key,
            original_filename: fileData.file_name,
            file_size: fileData.file_size,
            duration_seconds: parsingResult.data.file.duration,
            track_count: parsingResult.data.tracks.length,
            note_count: parsingResult.data.tracks.reduce((sum, track) => sum + track.notes.length, 0),
            time_signature: `${parsingResult.data.file.timeSignature[0]}/${parsingResult.data.file.timeSignature[1]}`,
            key_signature: parsingResult.data.file.keySignature,
            tempo_bpm: parsingResult.data.tempoChanges[0]?.bpm || 120,
            parsing_status: 'completed',
            parsed_data: parsingResult.data,
            error_message: null,
          })
          .select()
          .single();

        if (insertError) {
          logger.error('Database error storing MIDI data:', insertError);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to store parsed MIDI data',
          });
        }

        return {
          success: true,
          midiFileId: midiRecord.id,
          data: parsingResult.data,
          cached: false,
        };

      } catch (error) {
        if (error instanceof TRPCError) throw error;
        
        logger.error('Error parsing MIDI file:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to parse MIDI file',
        });
      }
    }),

  // Get visualization data for a MIDI file
  getVisualizationData: protectedProcedure
    .input(z.object({
      fileId: z.string(),
    }))
    .query(async ({ ctx, input }) => {
      const userId = ctx.user.id;

      try {
        // Get MIDI file data
        const { data: midiFile, error: fetchError } = await ctx.supabase
          .from('midi_files')
          .select('*')
          .eq('id', input.fileId)
          .eq('user_id', userId)
          .single();

        if (fetchError || !midiFile) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'MIDI file not found or access denied',
          });
        }

        if (midiFile.parsing_status !== 'completed') {
          throw new TRPCError({
            code: 'BAD_REQUEST',
            message: 'MIDI file has not been parsed yet',
          });
        }

        // Get user's visualization settings
        const { data: settings } = await ctx.supabase
          .from('visualization_settings')
          .select('*')
          .eq('user_id', userId)
          .eq('midi_file_id', input.fileId)
          .single();

        return {
          midiData: midiFile.parsed_data as MIDIData,
          settings: settings || null,
          metadata: {
            id: midiFile.id,
            fileName: midiFile.original_filename,
            duration: midiFile.duration_seconds,
            trackCount: midiFile.track_count,
            noteCount: midiFile.note_count,
            timeSignature: midiFile.time_signature,
            keySignature: midiFile.key_signature,
            tempoBpm: midiFile.tempo_bpm,
          },
        };

      } catch (error) {
        if (error instanceof TRPCError) throw error;
        
        logger.error('Error getting visualization data:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to get visualization data',
        });
      }
    }),

  // Save visualization preferences
  saveVisualizationSettings: protectedProcedure
    .input(z.object({
      fileId: z.string(),
      settings: VisualizationSettingsSchema,
    }))
    .mutation(async ({ ctx, input }) => {
      const userId = ctx.user.id;

      try {
        // Verify user owns the MIDI file
        const { data: midiFile, error: fetchError } = await ctx.supabase
          .from('midi_files')
          .select('id')
          .eq('id', input.fileId)
          .eq('user_id', userId)
          .single();

        if (fetchError || !midiFile) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'MIDI file not found or access denied',
          });
        }

        // Upsert visualization settings
        const { error: upsertError } = await ctx.supabase
          .from('visualization_settings')
          .upsert({
            user_id: userId,
            midi_file_id: input.fileId,
            color_scheme: input.settings.colorScheme,
            pixels_per_second: input.settings.pixelsPerSecond,
            show_track_labels: input.settings.showTrackLabels,
            show_velocity: input.settings.showVelocity,
            min_key: input.settings.minKey,
            max_key: input.settings.maxKey,
          });

        if (upsertError) {
          logger.error('Database error saving visualization settings:', upsertError);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to save visualization settings',
          });
        }

        return {
          success: true,
          message: 'Visualization settings saved successfully',
        };

      } catch (error) {
        if (error instanceof TRPCError) throw error;
        
        logger.error('Error saving visualization settings:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to save visualization settings',
        });
      }
    }),

  // Get user's MIDI files list
  getUserMidiFiles: protectedProcedure
    .input(z.object({
      limit: z.number().min(1).max(50).default(20),
      offset: z.number().min(0).default(0),
      status: z.enum(['all', 'completed', 'failed', 'pending']).default('all'),
      projectId: z.string().optional(), // NEW: Filter by project
    }))
    .query(async ({ ctx, input }) => {
      const userId = ctx.user.id;

      try {
        let midiFiles;
        
        if (input.projectId) {
          // When filtering by project, first get file_metadata for the project
          const { data: fileMetadata, error: fileError } = await ctx.supabase
            .from('file_metadata')
            .select('s3_key')
            .eq('user_id', userId)
            .eq('project_id', input.projectId)
            .eq('file_type', 'midi');
            
          if (fileError) {
            logger.error('Database error fetching file metadata:', fileError);
            throw new TRPCError({
              code: 'INTERNAL_SERVER_ERROR',
              message: 'Failed to fetch project files',
            });
          }
          
          if (!fileMetadata || fileMetadata.length === 0) {
            // No files in this project
            return {
              files: [],
              hasMore: false,
            };
          }
          
          // Get the s3_keys for files in this project
          const s3Keys = fileMetadata.map((f: any) => f.s3_key);
          
          // Now query midi_files for those s3_keys
          let query = ctx.supabase
            .from('midi_files')
            .select('*')
            .eq('user_id', userId)
            .in('file_key', s3Keys)
            .order('created_at', { ascending: false })
            .range(input.offset, input.offset + input.limit - 1);
            
          if (input.status !== 'all') {
            query = query.eq('parsing_status', input.status);
          }
          
          const { data, error } = await query;
          midiFiles = data;
          
          if (error) {
            logger.error('Database error fetching MIDI files:', error);
            throw new TRPCError({
              code: 'INTERNAL_SERVER_ERROR',
              message: 'Failed to fetch MIDI files',
            });
          }
        } else {
          // Standard query without project filtering
          let query = ctx.supabase
            .from('midi_files')
            .select('*')
            .eq('user_id', userId)
            .order('created_at', { ascending: false })
            .range(input.offset, input.offset + input.limit - 1);
            
          if (input.status !== 'all') {
            query = query.eq('parsing_status', input.status);
          }
          
          const { data, error } = await query;
          midiFiles = data;
          
          if (error) {
            // If the table doesn't exist yet, return empty result instead of error
            if (error.code === '42P01') { // Table doesn't exist
              logger.log('MIDI files table does not exist yet, returning empty result');
              return {
                files: [],
                hasMore: false,
              };
            }
            
            logger.error('Database error fetching MIDI files:', error);
            throw new TRPCError({
              code: 'INTERNAL_SERVER_ERROR',
              message: 'Failed to fetch MIDI files',
            });
          }
        }

        return {
          files: (midiFiles || []).map((file: any) => ({
            id: file.id,
            fileName: file.original_filename,
            fileSize: file.file_size,
            duration: file.duration_seconds,
            trackCount: file.track_count,
            noteCount: file.note_count,
            status: file.parsing_status,
            createdAt: file.created_at,
            errorMessage: file.error_message,
          })),
          hasMore: midiFiles.length === input.limit,
        };

      } catch (error) {
        if (error instanceof TRPCError) throw error;
        
        logger.error('Error fetching user MIDI files:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch MIDI files',
        });
      }
    }),
});
</file>

<file path="routers/project.ts">
import { z } from 'zod';
import { router, protectedProcedure, flexibleProcedure } from '../trpc';
import { TRPCError } from '@trpc/server';
import type { Project, ProjectCollaborator, ProjectWithCollaborators, ProjectShare } from 'phonoglyph-types';
import { createProjectSchema, updateProjectSchema } from 'phonoglyph-types';
import { logger } from '../lib/logger';

// Additional validation schemas for new endpoints

const projectIdSchema = z.object({
  id: z.string().min(1, 'Project ID is required'),
});

// Additional validation schemas for new endpoints
const projectSearchSchema = z.object({
  query: z.string().optional(),
  privacy_setting: z.enum(['private', 'unlisted', 'public']).optional(),
  sort_by: z.enum(['created_at', 'updated_at', 'name']).default('created_at'),
  sort_order: z.enum(['asc', 'desc']).default('desc'),
  limit: z.number().min(1).max(50).default(20),
  offset: z.number().min(0).default(0),
});

const projectShareSchema = z.object({
  project_id: z.string().min(1, 'Project ID is required'),
  access_type: z.enum(['view', 'embed']).default('view'),
  expires_at: z.string().datetime().optional(),
});

const getSharedProjectSchema = z.object({
  share_token: z.string().min(1, 'Share token is required'),
});

const duplicateProjectSchema = z.object({
  project_id: z.string().min(1, 'Project ID is required'),
  new_name: z.string().min(1, 'New project name is required').max(100, 'Project name too long'),
  copy_files: z.boolean().default(true),
});

const addCollaboratorSchema = z.object({
  project_id: z.string().min(1, 'Project ID is required'),
  user_id: z.string().uuid('Invalid user ID'),
  role: z.enum(['editor', 'viewer']),
});

const updateCollaboratorSchema = z.object({
  project_id: z.string().min(1, 'Project ID is required'),
  user_id: z.string().uuid('Invalid user ID'),
  role: z.enum(['owner', 'editor', 'viewer']),
});

export const projectRouter = router({
  // Get all projects for the authenticated user
  list: protectedProcedure
    .query(async ({ ctx }) => {
      try {
        // RLS automatically filters projects based on user access
        const { data: projects, error } = await ctx.supabase
          .from('projects')
          .select('*')
          .order('created_at', { ascending: false });

        if (error) {
          logger.error('Database error fetching projects:', error);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to fetch projects',
          });
        }

        // Log audit event
        await ctx.supabase.rpc('log_audit_event', {
          p_user_id: ctx.user.id,
          p_action: 'project.list',
          p_resource_type: 'project',
          p_metadata: { count: projects?.length || 0 },
        });

        return projects as Project[];
      } catch (error) {
        logger.error('Error fetching projects:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch projects',
        });
      }
    }),

  // Get a specific project by ID
  get: protectedProcedure
    .input(projectIdSchema)
    .query(async ({ input, ctx }) => {
      try {
        // RLS automatically filters based on user access
        const { data: project, error } = await ctx.supabase
          .from('projects')
          .select('*')
          .eq('id', input.id)
          .single();

        if (error) {
          if (error.code === 'PGRST116') {
            throw new TRPCError({
              code: 'NOT_FOUND',
              message: 'Project not found or access denied',
            });
          }
          logger.error('Database error fetching project:', error);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to fetch project',
          });
        }

        // Log audit event
        await ctx.supabase.rpc('log_audit_event', {
          p_user_id: ctx.user.id,
          p_action: 'project.get',
          p_resource_type: 'project',
          p_resource_id: input.id,
        });

        return project as Project;
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error fetching project:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch project',
        });
      }
    }),

  // Create a new project
  create: protectedProcedure
    .input(createProjectSchema)
    .mutation(async ({ input, ctx }) => {
      try {
        logger.log('=== API DEBUG PROJECT CREATION ===');
        logger.log('Raw input received:', JSON.stringify(input, null, 2));
        logger.log('input.name:', input.name);
        logger.log('input.name type:', typeof input.name);
        logger.log('=== END API DEBUG ===');
        
        const projectId = `proj_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

        const { data: project, error } = await ctx.supabase
          .from('projects')
          .insert({
            id: projectId,
            name: input.name,
            description: input.description,
            privacy_setting: input.privacy_setting,
            user_id: ctx.user.id,
            midi_file_path: input.midi_file_path,
            audio_file_path: input.audio_file_path,
            user_video_path: input.user_video_path,
            render_configuration: input.render_configuration,
          })
          .select()
          .single();

        if (error) {
          logger.error('Database error creating project:', error);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to create project',
          });
        }

        // Log audit event
        await ctx.supabase.rpc('log_audit_event', {
          p_user_id: ctx.user.id,
          p_action: 'project.create',
          p_resource_type: 'project',
          p_resource_id: project.id,
          p_metadata: { name: input.name },
        });

        return project as Project;
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error creating project:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to create project',
        });
      }
    }),

  // Update an existing project
  update: protectedProcedure
    .input(updateProjectSchema)
    .mutation(async ({ input, ctx }) => {
      try {
        const { id, ...updateData } = input;

        const { data: project, error } = await ctx.supabase
          .from('projects')
          .update(updateData)
          .eq('id', id)
          .select()
          .single();

        if (error) {
          if (error.code === 'PGRST116') {
            throw new TRPCError({
              code: 'NOT_FOUND',
              message: 'Project not found or access denied',
            });
          }
          logger.error('Database error updating project:', error);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to update project',
          });
        }

        // Log audit event
        await ctx.supabase.rpc('log_audit_event', {
          p_user_id: ctx.user.id,
          p_action: 'project.update',
          p_resource_type: 'project',
          p_resource_id: id,
          p_metadata: updateData,
        });

        return project as Project;
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error updating project:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to update project',
        });
      }
    }),

  // Delete a project
  delete: protectedProcedure
    .input(projectIdSchema)
    .mutation(async ({ input, ctx }) => {
      try {
        // Step 1: Fetch all file metadata associated with the project
        const { data: files, error: filesError } = await ctx.supabase
          .from('file_metadata')
          .select('id, s3_key')
          .eq('project_id', input.id);

        if (filesError) {
          logger.error('Database error fetching project files:', filesError);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to fetch project files for deletion.',
          });
        }

        // Step 2: If files exist, delete them from storage
        if (files && files.length > 0) {
          const filePaths = files.map((f: { s3_key: string | null }) => f.s3_key).filter((p: string | null): p is string => !!p);
          
          if (filePaths.length > 0) {
            const { error: storageError } = await ctx.supabase.storage
              .from('assets')
              .remove(filePaths);

            if (storageError) {
              logger.error('Storage error deleting project files:', storageError);
              throw new TRPCError({
                code: 'INTERNAL_SERVER_ERROR',
                message: 'Failed to delete project assets from storage.',
              });
            }
          }

          // Step 3: Delete the file metadata records
          const fileIds = files.map((f: { id: string }) => f.id);
          const { error: deleteMetaError } = await ctx.supabase
            .from('file_metadata')
            .delete()
            .in('id', fileIds);
          
          if (deleteMetaError) {
            logger.error('Database error deleting file metadata:', deleteMetaError);
            // Note: at this point, files might be deleted from storage but not DB.
            // This is a situation that may require a cleanup job.
            throw new TRPCError({
              code: 'INTERNAL_SERVER_ERROR',
              message: 'Failed to clean up project file metadata.',
            });
          }
        }

        // Step 4: Delete the project itself
        const { data: project, error } = await ctx.supabase
          .from('projects')
          .delete()
          .eq('id', input.id)
          .select()
          .single();

        if (error) {
          if (error.code === 'PGRST116') {
            throw new TRPCError({
              code: 'NOT_FOUND',
              message: 'Project not found or access denied',
            });
          }
          logger.error('Database error deleting project:', error);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to delete project',
          });
        }

        // Log audit event
        await ctx.supabase.rpc('log_audit_event', {
          p_user_id: ctx.user.id,
          p_action: 'project.delete',
          p_resource_type: 'project',
          p_resource_id: input.id,
          p_metadata: { name: project.name },
        });

        return { success: true, deletedProject: project as Project };
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error deleting project:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to delete project',
        });
      }
    }),

  // Search projects with filtering
  search: protectedProcedure
    .input(projectSearchSchema)
    .query(async ({ input, ctx }) => {
      try {
        let query = ctx.supabase
          .from('projects')
          .select(`
            *,
            file_metadata!project_id (
              id,
              file_size
            )
          `)
          .eq('user_id', ctx.user.id);

        // Apply filters
        if (input.query) {
          query = query.ilike('name', `%${input.query}%`);
        }
        if (input.privacy_setting) {
          query = query.eq('privacy_setting', input.privacy_setting);
        }

        // Apply sorting
        query = query.order(input.sort_by, { ascending: input.sort_order === 'asc' });

        // Apply pagination
        query = query.range(input.offset, input.offset + input.limit - 1);

        const { data: projects, error } = await query;

        if (error) {
          logger.error('Database error searching projects:', error);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to search projects',
          });
        }

        // Compute additional fields
        const projectsWithMetadata = projects?.map((project: any) => ({
          ...project,
          file_count: project.file_metadata?.length || 0,
          total_file_size: project.file_metadata?.reduce((sum: number, file: any) => sum + (file.file_size || 0), 0) || 0,
        })) || [];

        return projectsWithMetadata;
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error searching projects:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to search projects',
        });
      }
    }),

  // Duplicate a project
  duplicate: protectedProcedure
    .input(duplicateProjectSchema)
    .mutation(async ({ input, ctx }) => {
      try {
        // First get the original project
        const { data: originalProject, error: fetchError } = await ctx.supabase
          .from('projects')
          .select('*')
          .eq('id', input.project_id)
          .eq('user_id', ctx.user.id)
          .single();

        if (fetchError || !originalProject) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'Project not found or access denied',
          });
        }

        const newProjectId = `proj_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

        // Create duplicate project
        const { data: newProject, error: createError } = await ctx.supabase
          .from('projects')
          .insert({
            id: newProjectId,
            name: input.new_name,
            description: originalProject.description,
            privacy_setting: 'private', // Always start as private
            user_id: ctx.user.id,
            midi_file_path: originalProject.midi_file_path,
            audio_file_path: originalProject.audio_file_path,
            user_video_path: originalProject.user_video_path,
            render_configuration: originalProject.render_configuration,
          })
          .select()
          .single();

        if (createError) {
          logger.error('Database error duplicating project:', createError);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to duplicate project',
          });
        }

        // Log audit event
        await ctx.supabase.rpc('log_audit_event', {
          p_user_id: ctx.user.id,
          p_action: 'project.duplicate',
          p_resource_type: 'project',
          p_resource_id: newProject.id,
          p_metadata: { original_project_id: input.project_id, new_name: input.new_name },
        });

        return newProject as Project;
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error duplicating project:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to duplicate project',
        });
      }
    }),

  // Create project share
  share: protectedProcedure
    .input(projectShareSchema)
    .mutation(async ({ input, ctx }) => {
      try {
        // Verify project ownership
        const { data: project, error: fetchError } = await ctx.supabase
          .from('projects')
          .select('*')
          .eq('id', input.project_id)
          .eq('user_id', ctx.user.id)
          .single();

        if (fetchError || !project) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'Project not found or access denied',
          });
        }

        // Generate unique share token
        const shareToken = `share_${Date.now()}_${Math.random().toString(36).substr(2, 16)}`;

        const { data: share, error: createError } = await ctx.supabase
          .from('project_shares')
          .insert({
            project_id: input.project_id,
            share_token: shareToken,
            access_type: input.access_type,
            expires_at: input.expires_at,
          })
          .select()
          .single();

        if (createError) {
          logger.error('Database error creating project share:', createError);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to create project share',
          });
        }

        // Log audit event
        await ctx.supabase.rpc('log_audit_event', {
          p_user_id: ctx.user.id,
          p_action: 'project.share',
          p_resource_type: 'project',
          p_resource_id: input.project_id,
          p_metadata: { access_type: input.access_type, share_token: shareToken },
        });

        return share as ProjectShare;
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error creating project share:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to create project share',
        });
      }
    }),

  // Get shared project (public access)
  getShared: flexibleProcedure
    .input(getSharedProjectSchema)
    .query(async ({ input, ctx }) => {
      try {
        // Get project via share token
        const { data: share, error: shareError } = await ctx.supabase
          .from('project_shares')
          .select(`
            *,
            projects (*)
          `)
          .eq('share_token', input.share_token)
          .single();

        if (shareError || !share || !share.projects) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'Shared project not found or expired',
          });
        }

        // Check if share has expired
        if (share.expires_at && new Date(share.expires_at) < new Date()) {
          throw new TRPCError({
            code: 'FORBIDDEN',
            message: 'Share link has expired',
          });
        }

        // Increment view count
        await ctx.supabase
          .from('project_shares')
          .update({ view_count: share.view_count + 1 })
          .eq('id', share.id);

        return {
          project: share.projects as Project,
          share_info: {
            access_type: share.access_type,
            view_count: share.view_count + 1,
          }
        };
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error fetching shared project:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch shared project',
        });
      }
    }),

  // Add a collaborator to a project
  addCollaborator: protectedProcedure
    .input(addCollaboratorSchema)
    .mutation(async ({ input, ctx }) => {
      try {
        // Check if user can manage this project (owner only)
        const { data: canAccess } = await ctx.supabase
          .rpc('user_can_access_project', {
            p_project_id: input.project_id,
            p_user_id: ctx.user.id,
          });

        if (!canAccess) {
          throw new TRPCError({
            code: 'FORBIDDEN',
            message: 'You do not have permission to manage this project',
          });
        }

        const { data: collaborator, error } = await ctx.supabase
          .from('project_collaborators')
          .insert({
            project_id: input.project_id,
            user_id: input.user_id,
            role: input.role,
          })
          .select()
          .single();

        if (error) {
          if (error.code === '23505') {
            throw new TRPCError({
              code: 'CONFLICT',
              message: 'User is already a collaborator on this project',
            });
          }
          logger.error('Database error adding collaborator:', error);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to add collaborator',
          });
        }

        // Log audit event
        await ctx.supabase.rpc('log_audit_event', {
          p_user_id: ctx.user.id,
          p_action: 'project.add_collaborator',
          p_resource_type: 'project',
          p_resource_id: input.project_id,
          p_metadata: { collaborator_id: input.user_id, role: input.role },
        });

        return collaborator as ProjectCollaborator;
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error adding collaborator:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to add collaborator',
        });
      }
    }),

  // Update collaborator role
  updateCollaborator: protectedProcedure
    .input(updateCollaboratorSchema)
    .mutation(async ({ input, ctx }) => {
      try {
        const { data: collaborator, error } = await ctx.supabase
          .from('project_collaborators')
          .update({ role: input.role })
          .eq('project_id', input.project_id)
          .eq('user_id', input.user_id)
          .select()
          .single();

        if (error) {
          if (error.code === 'PGRST116') {
            throw new TRPCError({
              code: 'NOT_FOUND',
              message: 'Collaborator not found or access denied',
            });
          }
          logger.error('Database error updating collaborator:', error);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to update collaborator',
          });
        }

        // Log audit event
        await ctx.supabase.rpc('log_audit_event', {
          p_user_id: ctx.user.id,
          p_action: 'project.update_collaborator',
          p_resource_type: 'project',
          p_resource_id: input.project_id,
          p_metadata: { collaborator_id: input.user_id, new_role: input.role },
        });

        return collaborator as ProjectCollaborator;
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error updating collaborator:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to update collaborator',
        });
      }
    }),

  // Remove collaborator from project
  removeCollaborator: protectedProcedure
    .input(z.object({
      project_id: z.string().min(1, 'Project ID is required'),
      user_id: z.string().uuid('Invalid user ID'),
    }))
    .mutation(async ({ input, ctx }) => {
      try {
        const { data: collaborator, error } = await ctx.supabase
          .from('project_collaborators')
          .delete()
          .eq('project_id', input.project_id)
          .eq('user_id', input.user_id)
          .select()
          .single();

        if (error) {
          if (error.code === 'PGRST116') {
            throw new TRPCError({
              code: 'NOT_FOUND',
              message: 'Collaborator not found or access denied',
            });
          }
          logger.error('Database error removing collaborator:', error);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to remove collaborator',
          });
        }

        // Log audit event
        await ctx.supabase.rpc('log_audit_event', {
          p_user_id: ctx.user.id,
          p_action: 'project.remove_collaborator',
          p_resource_type: 'project',
          p_resource_id: input.project_id,
          p_metadata: { collaborator_id: input.user_id },
        });

        return { success: true, removedCollaborator: collaborator as ProjectCollaborator };
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error removing collaborator:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to remove collaborator',
        });
      }
    }),

  // Get audit logs for projects owned by the user
  auditLogs: protectedProcedure
    .input(z.object({
      project_id: z.string().optional(),
      limit: z.number().min(1).max(100).default(50),
      offset: z.number().min(0).default(0),
    }))
    .query(async ({ input, ctx }) => {
      try {
        let query = ctx.supabase
          .from('audit_logs')
          .select('*')
          .eq('user_id', ctx.user.id)
          .eq('resource_type', 'project')
          .order('created_at', { ascending: false })
          .range(input.offset, input.offset + input.limit - 1);

        if (input.project_id) {
          query = query.eq('resource_id', input.project_id);
        }

        const { data: logs, error } = await query;

        if (error) {
          logger.error('Database error fetching audit logs:', error);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to fetch audit logs',
          });
        }

        return logs || [];
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error fetching audit logs:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch audit logs',
        });
      }
    }),
});
</file>

<file path="routers/stem.ts">
import { z } from 'zod';
import { router, protectedProcedure, flexibleProcedure } from '../trpc';
import { TRPCError } from '@trpc/server';
import { StemSeparator, StemSeparationConfigSchema } from '../services/stem-separator';
import { generateS3Key, generateUploadUrl, getFileBuffer } from '../services/r2-storage';
import { join } from 'path';
import { promises as fs } from 'fs';
import { tmpdir } from 'os';
import { logger } from '../lib/logger';

export const stemRouter = router({
  // Create a new stem separation job
  createSeparationJob: protectedProcedure
    .input(z.object({
      fileId: z.string(),
      config: StemSeparationConfigSchema,
    }))
    .mutation(async ({ ctx, input }) => {
      const userId = ctx.user.id;

      try {
        // Get file metadata from database
        const { data: fileData, error: fetchError } = await ctx.supabase
          .from('file_metadata')
          .select('*')
          .eq('id', input.fileId)
          .eq('user_id', userId)
          .eq('file_type', 'audio')
          .single();

        if (fetchError || !fileData) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'Audio file not found or access denied',
          });
        }

        // Create stem separation job
        const initialJob = StemSeparator.createJob(input.config);

        // Store job in database
        const { error: insertError } = await ctx.supabase
          .from('stem_separation_jobs')
          .insert({
            id: initialJob.id,
            user_id: userId,
            file_key: fileData.s3_key,
            status: initialJob.status,
            config: input.config,
          });

        if (insertError) {
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to create stem separation job',
          });
        }

        // Start processing in background
        const outputDir = join(tmpdir(), initialJob.id);
        await fs.mkdir(outputDir, { recursive: true });

        StemSeparator.processStem(initialJob.id, fileData.s3_key, outputDir)
          .then(async () => {
            const updatedJob = StemSeparator.getJob(initialJob.id);
            if (!updatedJob?.results) return;

            // Upload stems to R2, create file metadata, and analyze them
            const stemUploads = Object.entries(updatedJob.results.stems).map(async ([stemName, stemPath]) => {
              const stemKey = generateS3Key(userId, `${stemName}.${input.config.quality.outputFormat}`, 'audio');
              const uploadUrl = await generateUploadUrl(stemKey, `audio/${input.config.quality.outputFormat}`);
              
              // Read stem file and upload to R2
              const stemBuffer = await fs.readFile(stemPath);
              await fetch(uploadUrl, {
                method: 'PUT',
                body: stemBuffer,
                headers: {
                  'Content-Type': `audio/${input.config.quality.outputFormat}`,
                },
              });

              // Create file metadata record for the stem
              const { data: stemFileData, error: stemFileError } = await ctx.supabase
                .from('file_metadata')
                .insert({
                  user_id: userId,
                  file_name: `${stemName}.${input.config.quality.outputFormat}`,
                  file_type: 'audio',
                  mime_type: `audio/${input.config.quality.outputFormat}`,
                  file_size: stemBuffer.length,
                  s3_key: stemKey,
                  s3_bucket: process.env.R2_BUCKET_NAME || 'phonoglyph-storage',
                  upload_status: 'completed',
                  processing_status: 'completed',
                  project_id: fileData.project_id, // Associate with same project
                })
                .select('id')
                .single();

              if (stemFileError) {
                logger.error(`Failed to create file metadata for ${stemName} stem:`, stemFileError);
                return { [stemName]: stemKey };
              }

              // Analyze the stem and cache the results
              try {
                const { AudioAnalyzer } = await import('../services/audio-analyzer');
                const audioAnalyzer = new AudioAnalyzer();
                await audioAnalyzer.analyzeAndCache(
                  stemFileData.id, // Use the new stem file metadata ID
                  userId,
                  stemName,
                  stemBuffer
                );
                logger.log(` Analyzed and cached ${stemName} stem`);
              } catch (analysisError) {
                logger.error(` Failed to analyze ${stemName} stem:`, analysisError);
                // Continue with other stems even if analysis fails
              }

              return { [stemName]: stemKey };
            });

            const stemKeys = Object.assign({}, ...(await Promise.all(stemUploads)));

            // Update job in database with results
            await ctx.supabase
              .from('stem_separation_jobs')
              .update({
                status: 'completed',
                progress: 100,
                results: { stems: stemKeys },
                analysis_status: 'completed',
                analysis_completed_at: new Date().toISOString(),
              })
              .eq('id', initialJob.id);

            // Cleanup temporary files
            await fs.rm(outputDir, { recursive: true, force: true });
          })
          .catch(async (error) => {
            logger.error('Stem separation failed:', error);
            
            // Update job status to failed
            await ctx.supabase
              .from('stem_separation_jobs')
              .update({
                status: 'failed',
                analysis_status: 'failed',
              })
              .eq('id', initialJob.id);

            // Cleanup temporary files
            try {
              await fs.rm(outputDir, { recursive: true, force: true });
            } catch (cleanupError) {
              logger.error('Failed to cleanup temporary files:', cleanupError);
            }
          });

        return { jobId: initialJob.id };
      } catch (error) {
        logger.error('Failed to create stem separation job:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: error instanceof Error ? error.message : 'Unknown error',
        });
      }
    }),

  // Get job status
  getJobStatus: protectedProcedure
    .input(z.object({
      jobId: z.string(),
    }))
    .query(async ({ ctx, input }) => {
      const userId = ctx.user.id;

      try {
        const { data: job, error } = await ctx.supabase
          .from('stem_separation_jobs')
          .select('*')
          .eq('id', input.jobId)
          .eq('user_id', userId)
          .single();

        if (error || !job) {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'Job not found or access denied',
          });
        }

        return {
          id: job.id,
          status: job.status,
          progress: job.progress,
          analysisStatus: job.analysis_status,
          results: job.results,
          error: job.error,
        };
      } catch (error) {
        logger.error('Failed to get job status:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: error instanceof Error ? error.message : 'Unknown error',
        });
      }
    }),

  // Get cached audio analysis for multiple files
  getCachedAnalysis: flexibleProcedure
    .input(z.object({
      fileIds: z.array(z.string()),
      stemType: z.string().optional(),
    }))
    .query(async ({ ctx, input }) => {
      const userId = ctx.user.id;
      try {
        const { AudioAnalyzer } = await import('../services/audio-analyzer');
        const audioAnalyzer = new AudioAnalyzer();
        return await audioAnalyzer.getBatchCachedAnalysis(
          input.fileIds,
          userId,
          input.stemType
        );
      } catch (error) {
        logger.error('Failed to get batch cached analysis:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: error instanceof Error ? error.message : 'Unknown error',
        });
      }
    }),

  // Cache analysis data generated on the client
  cacheClientSideAnalysis: protectedProcedure
    .input(z.object({
      fileMetadataId: z.string(),
      stemType: z.string(),
      analysisData: z.record(z.string(), z.array(z.number())),
      waveformData: z.object({
        points: z.array(z.number()),
        sampleRate: z.number(),
        duration: z.number(),
        markers: z.array(z.object({
          time: z.number(),
          type: z.enum(['beat', 'onset', 'peak', 'drop']),
          intensity: z.number(),
          frequency: z.number().optional(),
        })),
      }),
      metadata: z.object({
        sampleRate: z.number(),
        duration: z.number(),
        bufferSize: z.number(),
        featuresExtracted: z.array(z.string()),
      }),
    }))
    .mutation(async ({ ctx, input }) => {
      const { fileMetadataId, stemType, analysisData, waveformData, metadata } = input;
      const userId = ctx.user.id;
      const startTime = Date.now();

      try {
        const { data: existing, error: existingError } = await ctx.supabase
          .from('audio_analysis_cache')
          .select('id')
          .eq('file_metadata_id', fileMetadataId)
          .eq('stem_type', stemType)
          .single();

        if (existingError && existingError.code !== 'PGRST116') { // Ignore 'not found' error
          throw new TRPCError({ code: 'INTERNAL_SERVER_ERROR', message: `Error checking for existing analysis: ${existingError.message}` });
        }

        if (existing) {
          logger.log(`Analysis for file ${fileMetadataId} and stem ${stemType} already exists. Skipping cache.`);
          return { success: true, cached: false, message: "Analysis already cached." };
        }

        const { data: cachedAnalysis, error } = await ctx.supabase
          .from('audio_analysis_cache')
          .insert({
            user_id: userId,
            file_metadata_id: fileMetadataId,
            stem_type: stemType,
            analysis_version: '1.1-client', // Mark as client-generated
            sample_rate: metadata.sampleRate,
            duration: metadata.duration,
            buffer_size: metadata.bufferSize,
            features_extracted: metadata.featuresExtracted,
            analysis_data: analysisData,
            waveform_data: waveformData,
            analysis_duration: Date.now() - startTime,
          })
          .select()
          .single();

        if (error) {
          throw new TRPCError({ code: 'INTERNAL_SERVER_ERROR', message: `Failed to cache client-side analysis: ${error.message}` });
        }
        
        return { success: true, cached: true, data: cachedAnalysis };

      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Failed to cache client-side analysis:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: error instanceof Error ? error.message : 'Unknown error',
        });
      }
    }),

  // List user's stem separation jobs
  listJobs: protectedProcedure
    .input(z.object({
      limit: z.number().min(1).max(100).default(20),
      offset: z.number().min(0).default(0),
    }))
    .query(async ({ ctx, input }) => {
      const userId = ctx.user.id;

      try {
        const { data: jobs, error } = await ctx.supabase
          .from('stem_separation_jobs')
          .select('*')
          .eq('user_id', userId)
          .order('created_at', { ascending: false })
          .range(input.offset, input.offset + input.limit - 1);

        if (error) {
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to fetch jobs',
          });
        }

        return jobs || [];
      } catch (error) {
        logger.error('Failed to list jobs:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: error instanceof Error ? error.message : 'Unknown error',
        });
      }
    }),
});
</file>

<file path="routers/user.ts">
import { z } from 'zod';
import { router, protectedProcedure } from '../trpc';
import { TRPCError } from '@trpc/server';
import type { UserProfile } from 'phonoglyph-types';
import { logger } from '../lib/logger';

const updateProfileSchema = z.object({
  display_name: z.string().min(1, 'Display name is required').max(100, 'Display name too long').optional(),
  avatar_url: z.string().url('Invalid avatar URL').optional(),
  bio: z.string().max(500, 'Bio too long').optional(),
  preferences: z.record(z.any()).optional(),
});

export const userRouter = router({
  // Get user profile
  profile: protectedProcedure
    .query(({ ctx }) => {
      return {
        id: ctx.user.id,
        email: ctx.user.email,
        name: ctx.user.name,
        avatar_url: ctx.user.image,
        created_at: ctx.user.created_at,
      }
    }),

  // Update user profile
  updateProfile: protectedProcedure
    .input(z.object({
      name: z.string().min(1).optional(),
      avatar_url: z.string().url().optional(),
    }))
    .mutation(async ({ ctx, input }) => {
      const { error } = await ctx.supabase.auth.updateUser({
        data: input,
      })

      if (error) {
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: error.message,
        })
      }

      return {
        success: true,
        message: 'Profile updated successfully',
      }
    }),

  // Delete user account and all associated data
  deleteAccount: protectedProcedure
    .input(z.object({
      confirmation: z.literal('DELETE_MY_ACCOUNT'),
    }))
    .mutation(async ({ input, ctx }) => {
      try {
        // Log audit event before deletion
        await ctx.supabase.rpc('log_audit_event', {
          p_user_id: ctx.user.id,
          p_action: 'user.delete_account',
          p_resource_type: 'user',
          p_resource_id: ctx.user.id,
          p_metadata: { confirmation: input.confirmation },
        });

        // Delete user from Supabase auth (this will cascade delete all related data)
        const { error } = await ctx.supabase.auth.admin.deleteUser(ctx.user.id);

        if (error) {
          logger.error('Database error deleting user account:', error);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to delete user account',
          });
        }

        return { success: true, message: 'Account deleted successfully' };
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error deleting user account:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to delete user account',
        });
      }
    }),

  // Get user's audit logs
  auditLogs: protectedProcedure
    .input(z.object({
      limit: z.number().min(1).max(100).default(50),
      offset: z.number().min(0).default(0),
    }))
    .query(async ({ input, ctx }) => {
      try {
        const { data: logs, error } = await ctx.supabase
          .from('audit_logs')
          .select('*')
          .eq('user_id', ctx.user.id)
          .order('created_at', { ascending: false })
          .range(input.offset, input.offset + input.limit - 1);

        if (error) {
          logger.error('Database error fetching audit logs:', error);
          throw new TRPCError({
            code: 'INTERNAL_SERVER_ERROR',
            message: 'Failed to fetch audit logs',
          });
        }

        return logs || [];
      } catch (error) {
        if (error instanceof TRPCError) throw error;
        logger.error('Error fetching audit logs:', error);
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch audit logs',
        });
      }
    }),
});
</file>

<file path="scripts/backfill-audio-analysis.ts">
import { createSupabaseServerClient } from '../lib/supabase';
import dotenv from 'dotenv';
import { logger } from '../lib/logger';

dotenv.config();

async function backfillAudioAnalysis() {
  const supabase = createSupabaseServerClient();
  // Remove this line:
  // const audioAnalyzer = new AudioAnalyzer();

  // Find all audio files with upload_status 'completed' and no cached analysis
  const { data: files, error } = await supabase
    .from('file_metadata')
    .select('*')
    .eq('file_type', 'audio')
    .eq('upload_status', 'completed');

  if (error) {
    logger.error('Failed to fetch audio files:', error);
    process.exit(1);
  }

  let analyzedCount = 0;
  for (const file of files) {
    // Check if analysis already exists
    const { data: existing, error: analysisError } = await supabase
      .from('audio_analysis_cache')
      .select('id')
      .eq('file_metadata_id', file.id)
      .maybeSingle();

    if (analysisError) {
      logger.error(`Failed to check analysis for file ${file.id}:`, analysisError);
      continue;
    }
    if (existing) {
      logger.log(`Analysis already exists for file ${file.file_name} (${file.id}), skipping.`);
      continue;
    }

    // Download file buffer from storage
    try {
      const { data: fileBuffer, error: bufferError } = await supabase.storage
        .from(file.s3_bucket)
        .download(file.s3_key);
      if (bufferError || !fileBuffer) {
        logger.error(`Failed to download buffer for file ${file.file_name}:`, bufferError);
        continue;
      }
      const arrayBuffer = await fileBuffer.arrayBuffer();
      const nodeBuffer = Buffer.from(arrayBuffer);
      // Analyze and cache the file
      const { AudioAnalyzer } = await import('../services/audio-analyzer');
      const audioAnalyzer = new AudioAnalyzer();
      await audioAnalyzer.analyzeAndCache(
        file.id,
        file.user_id,
        'master', // or use file.file_name or another label if needed
        nodeBuffer
      );
      analyzedCount++;
      logger.log(` Backfilled analysis for file ${file.file_name} (${file.id})`);
    } catch (err) {
      logger.error(` Failed to analyze file ${file.file_name} (${file.id}):`, err);
    }
  }
  logger.log(`Backfill complete. Analyzed ${analyzedCount} files.`);
}

backfillAudioAnalysis().catch((err) => {
  logger.error('Backfill script failed:', err);
  process.exit(1);
});
</file>

<file path="scripts/run-migrations.js">
import { logger } from '../lib/logger';
#!/usr/bin/env node

const { spawn } = require('child_process');
const path = require('path');

// Set the path to the .env file in the root directory
const envPath = path.resolve(__dirname, '../../../.env');

// Use spawn to run ts-node with the required dotenv configuration
const migrationProcess = spawn(
  'npx',
  [
    'ts-node',
    '-r',
    'dotenv/config',
    path.resolve(__dirname, '../db/migrations/migrate.ts')
  ],
  {
    stdio: 'inherit', // Inherit stdin, stdout, and stderr
    shell: true,
    env: {
      ...process.env,
      DOTENV_CONFIG_PATH: envPath
    }
  }
);

migrationProcess.on('close', (code) => {
  logger.log(`Migration process exited with code ${code}`);
  if (code !== 0) {
    logger.error('Migration failed. Please check the output above.');
    process.exit(1);
  } else {
    logger.log('Migration completed successfully.');
  }
});

migrationProcess.on('error', (err) => {
  logger.error('Failed to start migration process:', err);
  process.exit(1);
});
</file>

<file path="scripts/setup-supabase-schema.sql">
-- MIDI Visualization Database Schema Setup
-- Execute this script in your Supabase SQL Editor

-- ===================================================================
-- MIDI FILES TABLE
-- ===================================================================

-- MIDI file processing table for storing parsed MIDI metadata
CREATE TABLE IF NOT EXISTS "midi_files" (
  "id" UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  "user_id" UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  "file_key" VARCHAR(255) NOT NULL,
  "original_filename" VARCHAR(255) NOT NULL,
  "file_size" INTEGER NOT NULL,
  
  -- Parsed MIDI metadata
  "duration_seconds" DECIMAL(10,3),
  "track_count" INTEGER,
  "note_count" INTEGER,
  "time_signature" VARCHAR(10),
  "key_signature" VARCHAR(10),
  "tempo_bpm" INTEGER,
  
  -- Processing status
  "parsing_status" VARCHAR(20) NOT NULL DEFAULT 'pending' 
    CHECK (parsing_status IN ('pending', 'completed', 'failed')),
  "parsed_data" JSONB,
  "error_message" TEXT,
  
  "created_at" TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
  "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);

-- Create indexes for efficient queries
CREATE INDEX IF NOT EXISTS "idx_midi_files_user_id" ON "midi_files"("user_id");
CREATE INDEX IF NOT EXISTS "idx_midi_files_file_key" ON "midi_files"("file_key");
CREATE INDEX IF NOT EXISTS "idx_midi_files_parsing_status" ON "midi_files"("parsing_status");
CREATE INDEX IF NOT EXISTS "idx_midi_files_created_at" ON "midi_files"("created_at");
CREATE INDEX IF NOT EXISTS "idx_midi_files_duration" ON "midi_files"("duration_seconds");

-- GIN index for efficient JSONB queries on parsed_data
CREATE INDEX IF NOT EXISTS "idx_midi_files_parsed_data" ON "midi_files" USING GIN ("parsed_data");

-- Unique constraint to prevent duplicate processing of same file
CREATE UNIQUE INDEX IF NOT EXISTS "idx_midi_files_user_file_key" 
  ON "midi_files"("user_id", "file_key");

-- Enable RLS (Row Level Security) for user data protection
ALTER TABLE "midi_files" ENABLE ROW LEVEL SECURITY;

-- RLS Policy: Users can only access their own MIDI files
DROP POLICY IF EXISTS "Users can access own MIDI files" ON "midi_files";
CREATE POLICY "Users can access own MIDI files" ON "midi_files"
  FOR ALL USING (auth.uid() = user_id);

-- ===================================================================
-- VISUALIZATION SETTINGS TABLE  
-- ===================================================================

-- User visualization preferences table
CREATE TABLE IF NOT EXISTS "visualization_settings" (
  "id" UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  "user_id" UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  "midi_file_id" UUID NOT NULL REFERENCES "midi_files"(id) ON DELETE CASCADE,
  
  -- Visualization preferences
  "color_scheme" VARCHAR(20) NOT NULL DEFAULT 'mixed' 
    CHECK (color_scheme IN ('sage', 'slate', 'dusty-rose', 'mixed')),
  "pixels_per_second" INTEGER NOT NULL DEFAULT 50 
    CHECK (pixels_per_second >= 10 AND pixels_per_second <= 200),
  "show_track_labels" BOOLEAN NOT NULL DEFAULT true,
  "show_velocity" BOOLEAN NOT NULL DEFAULT true,
  "min_key" INTEGER NOT NULL DEFAULT 21 
    CHECK (min_key >= 0 AND min_key <= 127),
  "max_key" INTEGER NOT NULL DEFAULT 108 
    CHECK (max_key >= 0 AND max_key <= 127),
  
  "created_at" TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
  "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
  
  -- Ensure key range is valid
  CONSTRAINT "valid_key_range" CHECK (min_key <= max_key)
);

-- Create indexes for efficient queries
CREATE INDEX IF NOT EXISTS "idx_visualization_settings_user_id" 
  ON "visualization_settings"("user_id");
CREATE INDEX IF NOT EXISTS "idx_visualization_settings_midi_file_id" 
  ON "visualization_settings"("midi_file_id");
CREATE INDEX IF NOT EXISTS "idx_visualization_settings_created_at" 
  ON "visualization_settings"("created_at");

-- Unique constraint: one settings record per user per MIDI file
CREATE UNIQUE INDEX IF NOT EXISTS "idx_visualization_settings_user_midi_file" 
  ON "visualization_settings"("user_id", "midi_file_id");

-- Enable RLS (Row Level Security) for user data protection
ALTER TABLE "visualization_settings" ENABLE ROW LEVEL SECURITY;

-- RLS Policy: Users can only access their own visualization settings
DROP POLICY IF EXISTS "Users can access own visualization settings" ON "visualization_settings";
CREATE POLICY "Users can access own visualization settings" ON "visualization_settings"
  FOR ALL USING (auth.uid() = user_id);

-- ===================================================================
-- UPDATE TRIGGERS
-- ===================================================================

-- Function to automatically update updated_at timestamp (if not exists)
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ language 'plpgsql';

-- Trigger to auto-update updated_at on midi_files changes
DROP TRIGGER IF EXISTS update_midi_files_updated_at ON "midi_files";
CREATE TRIGGER update_midi_files_updated_at 
  BEFORE UPDATE ON "midi_files" 
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

-- Trigger to auto-update updated_at on visualization_settings changes
DROP TRIGGER IF EXISTS update_visualization_settings_updated_at ON "visualization_settings";
CREATE TRIGGER update_visualization_settings_updated_at 
  BEFORE UPDATE ON "visualization_settings" 
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

-- ===================================================================
-- VERIFICATION QUERIES
-- ===================================================================

-- Verify tables were created successfully
SELECT 
  schemaname,
  tablename,
  tableowner,
  tablespace,
  hasindexes,
  hasrules,
  hastriggers
FROM pg_tables 
WHERE tablename IN ('midi_files', 'visualization_settings')
  AND schemaname = 'public';

-- Verify RLS is enabled
SELECT 
  schemaname,
  tablename,
  rowsecurity
FROM pg_tables 
WHERE tablename IN ('midi_files', 'visualization_settings')
  AND schemaname = 'public';

-- List all policies
SELECT 
  schemaname,
  tablename,
  policyname,
  permissive,
  roles,
  cmd,
  qual
FROM pg_policies 
WHERE tablename IN ('midi_files', 'visualization_settings');

-- ===================================================================
-- COMPLETION MESSAGE
-- ===================================================================

DO $$
BEGIN
  RAISE NOTICE ' MIDI Visualization database schema setup completed successfully!';
  RAISE NOTICE ' Created tables: midi_files, visualization_settings';
  RAISE NOTICE ' Created indexes for optimal query performance';
  RAISE NOTICE ' Enabled Row Level Security (RLS)';
  RAISE NOTICE ' Created policies for user data protection';
  RAISE NOTICE ' Set up automatic timestamp triggers';
  RAISE NOTICE '';
  RAISE NOTICE ' Your database is now ready for MIDI file processing and visualization!';
END $$;
</file>

<file path="scripts/setup-supabase.sql">
-- Supabase Database Setup Script
-- Run this in Supabase SQL Editor or via migration

-- Enable UUID extension (should already be enabled in Supabase)
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Drop existing tables if they exist (be careful in production!)
DROP TABLE IF EXISTS "project_collaborators" CASCADE;
DROP TABLE IF EXISTS "projects" CASCADE;
DROP TABLE IF EXISTS "user_profiles" CASCADE;
DROP TABLE IF EXISTS "audit_logs" CASCADE;
DROP TABLE IF EXISTS "users" CASCADE; -- Drop old custom users table

-- =============================================
-- CORE TABLES
-- =============================================

-- Projects table (references auth.users)
CREATE TABLE "projects" (
  "id" TEXT NOT NULL PRIMARY KEY,
  "name" TEXT NOT NULL,
  "user_id" UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  "midi_file_path" TEXT NOT NULL,
  "audio_file_path" TEXT,
  "user_video_path" TEXT,
  "render_configuration" JSONB NOT NULL DEFAULT '{}'::jsonb,
  "created_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
  "updated_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- User profiles table for additional user data
CREATE TABLE "user_profiles" (
  "id" UUID NOT NULL PRIMARY KEY REFERENCES auth.users(id) ON DELETE CASCADE,
  "display_name" TEXT,
  "avatar_url" TEXT,
  "bio" TEXT,
  "preferences" JSONB DEFAULT '{}'::jsonb,
  "subscription_tier" TEXT DEFAULT 'free' CHECK (subscription_tier IN ('free', 'premium', 'enterprise')),
  "created_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
  "updated_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- Project collaborators table for sharing
CREATE TABLE "project_collaborators" (
  "id" UUID NOT NULL PRIMARY KEY DEFAULT uuid_generate_v4(),
  "project_id" TEXT NOT NULL REFERENCES "projects"("id") ON DELETE CASCADE,
  "user_id" UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  "role" TEXT NOT NULL DEFAULT 'viewer' CHECK (role IN ('owner', 'editor', 'viewer')),
  "created_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
  UNIQUE("project_id", "user_id")
);

-- Audit log table for security tracking
CREATE TABLE "audit_logs" (
  "id" UUID NOT NULL PRIMARY KEY DEFAULT uuid_generate_v4(),
  "user_id" UUID REFERENCES auth.users(id) ON DELETE SET NULL,
  "action" TEXT NOT NULL,
  "resource_type" TEXT NOT NULL,
  "resource_id" TEXT,
  "metadata" JSONB DEFAULT '{}'::jsonb,
  "ip_address" INET,
  "user_agent" TEXT,
  "created_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- =============================================
-- INDEXES
-- =============================================

CREATE INDEX "idx_projects_user_id" ON "projects"("user_id");
CREATE INDEX "idx_projects_created_at" ON "projects"("created_at");
CREATE INDEX "idx_user_profiles_display_name" ON "user_profiles"("display_name");
CREATE INDEX "idx_project_collaborators_project_id" ON "project_collaborators"("project_id");
CREATE INDEX "idx_project_collaborators_user_id" ON "project_collaborators"("user_id");
CREATE INDEX "idx_audit_logs_user_id" ON "audit_logs"("user_id");
CREATE INDEX "idx_audit_logs_action" ON "audit_logs"("action");
CREATE INDEX "idx_audit_logs_created_at" ON "audit_logs"("created_at");

-- =============================================
-- UPDATE TRIGGERS
-- =============================================

-- Update timestamp function
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ language 'plpgsql';

-- Update triggers
CREATE TRIGGER update_projects_updated_at BEFORE UPDATE ON "projects" 
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_user_profiles_updated_at BEFORE UPDATE ON "user_profiles" 
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

-- =============================================
-- ROW LEVEL SECURITY (RLS) POLICIES
-- =============================================

-- Enable RLS on all tables
ALTER TABLE "projects" ENABLE ROW LEVEL SECURITY;
ALTER TABLE "user_profiles" ENABLE ROW LEVEL SECURITY;
ALTER TABLE "project_collaborators" ENABLE ROW LEVEL SECURITY;
ALTER TABLE "audit_logs" ENABLE ROW LEVEL SECURITY;

-- Projects RLS Policies
CREATE POLICY "Users can view their own projects" ON "projects"
  FOR SELECT USING (
    auth.uid() = user_id 
    OR EXISTS (
      SELECT 1 FROM "project_collaborators" 
      WHERE project_id = "projects"."id" 
      AND user_id = auth.uid()
    )
  );

CREATE POLICY "Users can create projects for themselves" ON "projects"
  FOR INSERT WITH CHECK (auth.uid() = user_id);

CREATE POLICY "Users can update their own projects" ON "projects"
  FOR UPDATE USING (
    auth.uid() = user_id 
    OR EXISTS (
      SELECT 1 FROM "project_collaborators" 
      WHERE project_id = "projects"."id" 
      AND user_id = auth.uid() 
      AND role IN ('owner', 'editor')
    )
  );

CREATE POLICY "Users can delete their own projects" ON "projects"
  FOR DELETE USING (auth.uid() = user_id);

-- User Profiles RLS Policies
CREATE POLICY "Users can view all profiles" ON "user_profiles"
  FOR SELECT USING (true);

CREATE POLICY "Users can manage their own profile" ON "user_profiles"
  FOR ALL USING (auth.uid() = id);

-- Project Collaborators RLS Policies
CREATE POLICY "Users can view project collaborators" ON "project_collaborators"
  FOR SELECT USING (
    EXISTS (
      SELECT 1 FROM "projects" 
      WHERE id = project_id 
      AND (
        user_id = auth.uid() 
        OR EXISTS (
          SELECT 1 FROM "project_collaborators" pc2 
          WHERE pc2.project_id = project_id 
          AND pc2.user_id = auth.uid()
        )
      )
    )
  );

CREATE POLICY "Project owners can manage collaborators" ON "project_collaborators"
  FOR ALL USING (
    EXISTS (
      SELECT 1 FROM "projects" 
      WHERE id = project_id 
      AND user_id = auth.uid()
    )
  );

-- Audit Logs RLS Policies
CREATE POLICY "Users can view their own audit logs" ON "audit_logs"
  FOR SELECT USING (auth.uid() = user_id);

CREATE POLICY "System can insert audit logs" ON "audit_logs"
  FOR INSERT WITH CHECK (true);

-- =============================================
-- HELPER FUNCTIONS
-- =============================================

-- Function to create user profile when user signs up
CREATE OR REPLACE FUNCTION create_user_profile()
RETURNS TRIGGER AS $$
BEGIN
  INSERT INTO "user_profiles" (id, display_name, avatar_url)
  VALUES (
    NEW.id,
    COALESCE(NEW.raw_user_meta_data->>'name', NEW.email),
    NEW.raw_user_meta_data->>'avatar_url'
  );
  RETURN NEW;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Trigger to create profile when user signs up
DROP TRIGGER IF EXISTS on_auth_user_created ON auth.users;
CREATE TRIGGER on_auth_user_created
  AFTER INSERT ON auth.users
  FOR EACH ROW EXECUTE FUNCTION create_user_profile();

-- Function to log audit events
CREATE OR REPLACE FUNCTION log_audit_event(
  p_user_id UUID,
  p_action TEXT,
  p_resource_type TEXT,
  p_resource_id TEXT DEFAULT NULL,
  p_metadata JSONB DEFAULT '{}'::jsonb
)
RETURNS VOID AS $$
BEGIN
  INSERT INTO "audit_logs" (user_id, action, resource_type, resource_id, metadata)
  VALUES (p_user_id, p_action, p_resource_type, p_resource_id, p_metadata);
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Function to check if user can access project
CREATE OR REPLACE FUNCTION user_can_access_project(p_project_id TEXT, p_user_id UUID)
RETURNS BOOLEAN AS $$
BEGIN
  RETURN EXISTS (
    SELECT 1 FROM "projects" 
    WHERE id = p_project_id 
    AND (
      user_id = p_user_id
      OR EXISTS (
        SELECT 1 FROM "project_collaborators" 
        WHERE project_id = p_project_id 
        AND user_id = p_user_id
      )
    )
  );
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- =============================================
-- SAMPLE DATA (OPTIONAL - for testing)
-- =============================================

-- Uncomment below to insert sample data
/*
-- Insert sample user profile (replace with actual user ID from auth.users)
INSERT INTO "user_profiles" (id, display_name, bio) 
VALUES ('00000000-0000-0000-0000-000000000000', 'Sample User', 'This is a sample user profile');

-- Insert sample project
INSERT INTO "projects" (id, name, user_id, midi_file_path, render_configuration)
VALUES (
  'sample_project_001',
  'My First MIDI Project',
  '00000000-0000-0000-0000-000000000000',
  '/uploads/sample.mid',
  '{"tempo": 120, "effects": ["reverb"]}'
);
*/

-- =============================================
-- MIGRATIONS TRACKING
-- =============================================

-- Create migrations table
CREATE TABLE IF NOT EXISTS "_migrations" (
  "id" SERIAL PRIMARY KEY,
  "filename" TEXT NOT NULL UNIQUE,
  "executed_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- Record initial setup
INSERT INTO "_migrations" (filename) 
VALUES ('001_initial_schema.sql'), ('002_supabase_auth_integration.sql')
ON CONFLICT (filename) DO NOTHING;

-- =============================================
-- VERIFICATION QUERIES
-- =============================================

-- Verify tables were created
SELECT 
  schemaname,
  tablename,
  tableowner
FROM pg_tables 
WHERE schemaname = 'public'
  AND tablename IN ('projects', 'user_profiles', 'project_collaborators', 'audit_logs')
ORDER BY tablename;

-- Verify RLS is enabled
SELECT 
  schemaname,
  tablename,
  rowsecurity
FROM pg_tables 
WHERE schemaname = 'public'
  AND tablename IN ('projects', 'user_profiles', 'project_collaborators', 'audit_logs')
  AND rowsecurity = true
ORDER BY tablename;

-- Verify functions exist
SELECT 
  routine_name,
  routine_type
FROM information_schema.routines
WHERE routine_schema = 'public'
  AND routine_name IN ('create_user_profile', 'log_audit_event', 'user_can_access_project')
ORDER BY routine_name;
</file>

<file path="scripts/start-queue-worker.ts">
import { QueueWorker } from '../services/queue-worker';
import { logger } from '../lib/logger';
 
logger.log('Starting queue worker...');
QueueWorker.start().catch(error => {
  logger.error('Queue worker failed:', error);
  process.exit(1);
});
</file>

<file path="scripts/test-s3.ts">
#!/usr/bin/env tsx

import dotenv from 'dotenv'
import { testS3Connection, validateS3Config, initializeS3 } from '../services/r2-storage'
import { logger } from '../lib/logger';

// Load environment variables
dotenv.config()

async function main() {
  logger.log(' Testing Cloudflare R2 Configuration...\n')

  try {
    // Test 1: Validate environment variables
    logger.log('1 Validating R2 environment variables...')
    validateS3Config()
    logger.log(' Environment variables are configured\n')

    // Test 2: Test R2 connectivity
    logger.log('2 Testing R2 connectivity...')
    const isConnected = await testS3Connection()
    if (isConnected) {
      logger.log(' R2 connection successful\n')
    } else {
      logger.log(' R2 connection failed\n')
      process.exit(1)
    }

    // Test 3: Initialize R2 (create bucket + CORS if needed)
    logger.log('3 Initializing R2 service...')
    await initializeS3()
    logger.log(' R2 service initialization complete\n')

    logger.log(' All R2 tests passed!')
    process.exit(0)

  } catch (error) {
    logger.error(' R2 test failed:', error)
    process.exit(1)
  }
}

// Run if this script is executed directly
if (require.main === module) {
  main()
}
</file>

<file path="services/asset-manager.ts">
import { SupabaseClient } from '@supabase/supabase-js'
import { TRPCError } from '@trpc/server'
import { logger } from '../lib/logger';

export interface AssetUsage {
  id: string
  fileId: string
  projectId: string
  usageType: 'visualizer' | 'composition' | 'export'
  usageContext: Record<string, any>
  startedAt: string
  endedAt?: string
  sessionDuration?: number
}

export interface StorageQuota {
  projectId: string
  userSubscriptionTier: 'free' | 'premium' | 'enterprise'
  totalLimitBytes: number
  usedBytes: number
  fileCountLimit: number
  fileCountUsed: number
  perFileSizeLimit: number
  lastCalculatedAt: string
}

export interface AssetFolder {
  id: string
  projectId: string
  name: string
  description?: string
  parentFolderId?: string
  createdAt: string
  updatedAt: string
}

export interface AssetTag {
  id: string
  projectId: string
  name: string
  color: string
  createdAt: string
}

export class AssetManager {
  constructor(private supabase: SupabaseClient) {}

  // Asset Usage Tracking
  async startUsageTracking(
    fileId: string,
    projectId: string,
    usageType: 'visualizer' | 'composition' | 'export',
    usageContext: Record<string, any> = {}
  ): Promise<string> {
    const { data, error } = await this.supabase
      .from('asset_usage')
      .insert({
        file_id: fileId,
        project_id: projectId,
        usage_type: usageType,
        usage_context: usageContext,
        started_at: new Date().toISOString()
      })
      .select('id')
      .single()

    if (error) {
      logger.error('Error starting usage tracking:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to start usage tracking'
      })
    }

    // Update file usage status
    await this.updateFileUsageStatus(fileId, 'active')

    return data.id
  }

  async endUsageTracking(usageId: string): Promise<void> {
    const { error } = await this.supabase
      .from('asset_usage')
      .update({
        ended_at: new Date().toISOString()
      })
      .eq('id', usageId)

    if (error) {
      logger.error('Error ending usage tracking:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to end usage tracking'
      })
    }
  }

  async updateFileUsageStatus(fileId: string, status: 'active' | 'referenced' | 'unused'): Promise<void> {
    const { error } = await this.supabase
      .from('file_metadata')
      .update({
        usage_status: status,
        last_used_at: status === 'unused' ? null : new Date().toISOString()
      })
      .eq('id', fileId)

    if (error) {
      logger.error('Error updating file usage status:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to update file usage status'
      })
    }
  }

  async getAssetUsage(fileId: string, projectId: string): Promise<AssetUsage[]> {
    const { data, error } = await this.supabase
      .from('asset_usage')
      .select('*')
      .eq('file_id', fileId)
      .eq('project_id', projectId)
      .order('started_at', { ascending: false })

    if (error) {
      logger.error('Error fetching asset usage:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to fetch asset usage'
      })
    }

    return data || []
  }

  // Storage Quota Management
  async getStorageQuota(projectId: string): Promise<StorageQuota> {
    const { data, error } = await this.supabase
      .from('project_storage_quotas')
      .select('*')
      .eq('project_id', projectId)
      .single()

    if (error) {
      logger.error('Error fetching storage quota:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to fetch storage quota'
      })
    }

    return {
      projectId: data.project_id,
      userSubscriptionTier: data.user_subscription_tier,
      totalLimitBytes: data.total_limit_bytes,
      usedBytes: data.used_bytes,
      fileCountLimit: data.file_count_limit,
      fileCountUsed: data.file_count_used,
      perFileSizeLimit: data.per_file_size_limit,
      lastCalculatedAt: data.last_calculated_at
    }
  }

  async checkStorageQuota(projectId: string, fileSize: number): Promise<{ allowed: boolean; reason?: string }> {
    const quota = await this.getStorageQuota(projectId)
    
    // Check total storage limit
    if (quota.usedBytes + fileSize > quota.totalLimitBytes) {
      return {
        allowed: false,
        reason: `Storage limit exceeded. Available: ${this.formatBytes(quota.totalLimitBytes - quota.usedBytes)}`
      }
    }

    // Check file count limit
    if (quota.fileCountUsed >= quota.fileCountLimit) {
      return {
        allowed: false,
        reason: `File count limit exceeded. Maximum: ${quota.fileCountLimit} files`
      }
    }

    // Check per-file size limit
    if (fileSize > quota.perFileSizeLimit) {
      return {
        allowed: false,
        reason: `File size exceeds limit. Maximum: ${this.formatBytes(quota.perFileSizeLimit)}`
      }
    }

    return { allowed: true }
  }

  async updateSubscriptionTier(projectId: string, tier: 'free' | 'premium' | 'enterprise'): Promise<void> {
    const limits = this.getTierLimits(tier)
    
    const { error } = await this.supabase
      .from('project_storage_quotas')
      .upsert({
        project_id: projectId,
        user_subscription_tier: tier,
        total_limit_bytes: limits.totalLimitBytes,
        file_count_limit: limits.fileCountLimit,
        per_file_size_limit: limits.perFileSizeLimit
      })

    if (error) {
      logger.error('Error updating subscription tier:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to update subscription tier'
      })
    }
  }

  private getTierLimits(tier: 'free' | 'premium' | 'enterprise') {
    switch (tier) {
      case 'free':
        return {
          totalLimitBytes: 100 * 1024 * 1024, // 100MB
          fileCountLimit: 10,
          perFileSizeLimit: 50 * 1024 * 1024 // 50MB
        }
      case 'premium':
        return {
          totalLimitBytes: 1024 * 1024 * 1024, // 1GB
          fileCountLimit: 100,
          perFileSizeLimit: 100 * 1024 * 1024 // 100MB
        }
      case 'enterprise':
        return {
          totalLimitBytes: 10 * 1024 * 1024 * 1024, // 10GB
          fileCountLimit: 1000,
          perFileSizeLimit: 500 * 1024 * 1024 // 500MB
        }
    }
  }

  private formatBytes(bytes: number): string {
    if (bytes === 0) return '0 Bytes'
    const k = 1024
    const sizes = ['Bytes', 'KB', 'MB', 'GB']
    const i = Math.floor(Math.log(bytes) / Math.log(k))
    return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i]
  }

  // Asset Organization
  async createFolder(projectId: string, name: string, description?: string, parentFolderId?: string): Promise<AssetFolder> {
    const { data, error } = await this.supabase
      .from('asset_folders')
      .insert({
        project_id: projectId,
        name,
        description,
        parent_folder_id: parentFolderId
      })
      .select('*')
      .single()

    if (error) {
      logger.error('Error creating folder:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to create folder'
      })
    }

    return {
      id: data.id,
      projectId: data.project_id,
      name: data.name,
      description: data.description,
      parentFolderId: data.parent_folder_id,
      createdAt: data.created_at,
      updatedAt: data.updated_at
    }
  }

  async getFolders(projectId: string): Promise<AssetFolder[]> {
    const { data, error } = await this.supabase
      .from('asset_folders')
      .select('*')
      .eq('project_id', projectId)
      .order('name')

    if (error) {
      logger.error('Error fetching folders:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to fetch folders'
      })
    }

    return (data || []).map((folder: any) => ({
      id: folder.id,
      projectId: folder.project_id,
      name: folder.name,
      description: folder.description,
      parentFolderId: folder.parent_folder_id,
      createdAt: folder.created_at,
      updatedAt: folder.updated_at
    }))
  }

  async createTag(projectId: string, name: string, color: string = '#3B82F6'): Promise<AssetTag> {
    const { data, error } = await this.supabase
      .from('asset_tags')
      .insert({
        project_id: projectId,
        name,
        color
      })
      .select('*')
      .single()

    if (error) {
      logger.error('Error creating tag:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to create tag'
      })
    }

    return {
      id: data.id,
      projectId: data.project_id,
      name: data.name,
      color: data.color,
      createdAt: data.created_at
    }
  }

  async getTags(projectId: string): Promise<AssetTag[]> {
    const { data, error } = await this.supabase
      .from('asset_tags')
      .select('*')
      .eq('project_id', projectId)
      .order('name')

    if (error) {
      logger.error('Error fetching tags:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to fetch tags'
      })
    }

    return (data || []).map((tag: any) => ({
      id: tag.id,
      projectId: tag.project_id,
      name: tag.name,
      color: tag.color,
      createdAt: tag.created_at
    }))
  }

  async addTagToFile(fileId: string, tagId: string): Promise<void> {
    const { error } = await this.supabase
      .from('asset_tag_relationships')
      .insert({
        file_id: fileId,
        tag_id: tagId
      })

    if (error) {
      logger.error('Error adding tag to file:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to add tag to file'
      })
    }
  }

  async removeTagFromFile(fileId: string, tagId: string): Promise<void> {
    const { error } = await this.supabase
      .from('asset_tag_relationships')
      .delete()
      .eq('file_id', fileId)
      .eq('tag_id', tagId)

    if (error) {
      logger.error('Error removing tag from file:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to remove tag from file'
      })
    }
  }

  async getFileTags(fileId: string): Promise<AssetTag[]> {
    // First get the tag IDs for this file
    const { data: relationships, error: relError } = await this.supabase
      .from('asset_tag_relationships')
      .select('tag_id')
      .eq('file_id', fileId)

    if (relError) {
      logger.error('Error fetching file tag relationships:', relError)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to fetch file tag relationships'
      })
    }

    if (!relationships || relationships.length === 0) {
      return []
    }

    // Then get the actual tag data
    const tagIds = relationships.map((rel: any) => rel.tag_id)
    const { data: tags, error: tagError } = await this.supabase
      .from('asset_tags')
      .select('*')
      .in('id', tagIds)
      .order('name')

    if (tagError) {
      logger.error('Error fetching file tags:', tagError)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to fetch file tags'
      })
    }

    return (tags || []).map((tag: any) => ({
      id: tag.id,
      projectId: tag.project_id,
      name: tag.name,
      color: tag.color,
      createdAt: tag.created_at
    }))
  }

  // Asset Replacement
  async replaceAsset(
    oldFileId: string,
    newFileId: string,
    preserveMetadata: boolean = true
  ): Promise<void> {
    // Get old file metadata
    const { data: oldFile, error: oldFileError } = await this.supabase
      .from('file_metadata')
      .select('*')
      .eq('id', oldFileId)
      .single()

    if (oldFileError || !oldFile) {
      throw new TRPCError({
        code: 'NOT_FOUND',
        message: 'Original file not found'
      })
    }

    // Get new file metadata
    const { data: newFile, error: newFileError } = await this.supabase
      .from('file_metadata')
      .select('*')
      .eq('id', newFileId)
      .single()

    if (newFileError || !newFile) {
      throw new TRPCError({
        code: 'NOT_FOUND',
        message: 'Replacement file not found'
      })
    }

    // Update replacement history
    const replacementHistory = oldFile.replacement_history || []
    replacementHistory.push(oldFileId)

    // Update new file with old file's metadata if preserving
    const updateData: any = {
      replacement_history: replacementHistory
    }

    if (preserveMetadata) {
      updateData.project_id = oldFile.project_id
      updateData.folder_id = oldFile.folder_id
      updateData.asset_type = oldFile.asset_type
      updateData.is_primary = oldFile.is_primary
      updateData.usage_status = oldFile.usage_status
    }

    const { error: updateError } = await this.supabase
      .from('file_metadata')
      .update(updateData)
      .eq('id', newFileId)

    if (updateError) {
      logger.error('Error updating replacement file:', updateError)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to update replacement file'
      })
    }

    // Copy tags from old file to new file
    const oldFileTags = await this.getFileTags(oldFileId)
    for (const tag of oldFileTags) {
      await this.addTagToFile(newFileId, tag.id)
    }

    // Mark old file as replaced
    const { error: markError } = await this.supabase
      .from('file_metadata')
      .update({
        usage_status: 'unused',
        is_primary: false
      })
      .eq('id', oldFileId)

    if (markError) {
      logger.error('Error marking old file as replaced:', markError)
      // Don't throw error here as the main operation succeeded
    }
  }
}
</file>

<file path="services/audio-analysis-processor.ts">
import { createClient } from '@supabase/supabase-js';
import { AudioAnalyzer } from './audio-analyzer';
import { getFileBuffer } from './r2-storage';
import { buffer } from 'stream/consumers';
import { logger } from '../lib/logger';

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

export class AudioAnalysisProcessor {
  static async processJob(job: { id: string, user_id: string, file_metadata_id: string }): Promise<void> {
    await this.updateJobStatus(job.id, 'processing');

    try {
      const { data: fileMetadata, error: fileError } = await supabase
        .from('file_metadata')
        .select('s3_key, file_name, id')
        .eq('id', job.file_metadata_id)
        .single();

      if (fileError || !fileMetadata) {
        throw new Error(`Failed to fetch file metadata for job ${job.id}: ${fileError?.message}`);
      }
      
      const fileBuffer = await getFileBuffer(fileMetadata.s3_key);
      const audioAnalyzer = new AudioAnalyzer();
      const stemType = fileMetadata.file_name.replace(/\.[^/.]+$/, '');

      await audioAnalyzer.analyzeAndCache(
        fileMetadata.id,
        job.user_id,
        stemType,
        fileBuffer
      );

      await this.updateJobStatus(job.id, 'completed');
    } catch (error: any) {
      logger.error(`Error processing audio analysis job ${job.id}:`, error);
      await this.updateJobStatus(job.id, 'failed', error.message);
    }
  }

  private static async updateJobStatus(jobId: string, status: 'processing' | 'completed' | 'failed', error?: string): Promise<void> {
    const { error: updateError } = await supabase
      .from('audio_analysis_jobs')
      .update({ status, error: error, updated_at: new Date().toISOString() })
      .eq('id', jobId);

    if (updateError) {
      logger.error(`Failed to update status for audio analysis job ${jobId}:`, updateError);
    }
  }
}
</file>

<file path="services/audio-analyzer.ts">
import { createClient } from '@supabase/supabase-js';
import { getFileBuffer } from './r2-storage';
import { logger } from '../lib/logger';
import { Reader } from 'wav';
import { Writable } from 'stream';
import ffmpeg from 'fluent-ffmpeg';
import { PassThrough } from 'stream';

// Audio analysis types

/**
 * Represents the detailed, time-series audio analysis data for a single track.
 * The keys are feature names (e.g., "rms", "spectralCentroid", "mfcc_0").
 * The values are arrays of numbers, representing the feature's value over time.
 */
export type AudioAnalysisData = Record<string, number[]>;


export interface FeatureMarker {
  time: number;
  type: 'beat' | 'onset' | 'peak' | 'drop';
  intensity: number;
  frequency?: number;
}

export interface WaveformData {
  points: number[];
  sampleRate: number;
  duration: number;
  markers: FeatureMarker[];
}

export interface CachedAnalysis {
  id: string;
  fileMetadataId: string;
  stemType: string;
  analysisData: AudioAnalysisData; // This now correctly refers to the time-series data type
  waveformData: WaveformData;
  metadata: {
    sampleRate: number;
    duration: number;
    bufferSize: number;
    featuresExtracted: string[];
    analysisDuration: number;
  };
}

export class AudioAnalyzer {
  private supabase: any;

  constructor() {
    const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL || process.env.SUPABASE_URL;
    const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY;
    
    if (!supabaseUrl) {
      throw new Error('SUPABASE_URL or NEXT_PUBLIC_SUPABASE_URL environment variable is required');
    }
    
    if (!supabaseKey) {
      throw new Error('SUPABASE_SERVICE_ROLE_KEY environment variable is required');
    }
    
    this.supabase = createClient(supabaseUrl, supabaseKey);
  }

  /**
   * Analyze an audio file and cache the results
   */
  async analyzeAndCache(
    fileMetadataId: string,
    userId: string,
    stemType: string,
    audioBuffer: Buffer
  ): Promise<CachedAnalysis> {
    const startTime = Date.now();
    
    try {
      logger.log(` Starting audio analysis for ${stemType} stem (file: ${fileMetadataId})`);
      
      // Convert any audio format to WAV first
      const wavBuffer = await this.convertToWav(audioBuffer);

      // Analyze the audio buffer
      const analysisData = await this.analyzeAudioBuffer(wavBuffer);
      const waveformData = await this.generateWaveformData(wavBuffer);
      
      const analysisDuration = Date.now() - startTime;
      
      // Prepare metadata
      const metadata = {
        sampleRate: 44100, // Assuming standard sample rate
        duration: waveformData.duration,
        bufferSize: 512, // The buffer size used for chunking analysis
        featuresExtracted: Object.keys(analysisData),
        analysisDuration
      };
      
      // Cache the analysis results
      const { data: cachedAnalysis, error } = await this.supabase
        .from('audio_analysis_cache')
        .insert({
          user_id: userId,
          file_metadata_id: fileMetadataId,
          stem_type: stemType,
          analysis_version: '1.0',
          sample_rate: metadata.sampleRate,
          duration: metadata.duration,
          buffer_size: metadata.bufferSize,
          features_extracted: metadata.featuresExtracted,
          analysis_data: analysisData,
          waveform_data: waveformData,
          analysis_duration: analysisDuration
        })
        .select()
        .single();
      
      if (error) {
        throw new Error(`Failed to cache analysis: ${error.message}`);
      }
      
      logger.log(` Audio analysis completed for ${stemType} stem in ${analysisDuration}ms`);
      
      return {
        id: cachedAnalysis.id,
        fileMetadataId,
        stemType,
        analysisData,
        waveformData,
        metadata
      };
      
    } catch (error) {
      logger.error(` Audio analysis failed for ${stemType} stem:`, error);
      throw error;
    }
  }

  /**
   * Retrieve cached analysis for a file
   */
  async getCachedAnalysis(
    fileMetadataId: string,
    userId: string,
    stemType?: string
  ): Promise<CachedAnalysis | null> {
    try {
      // Check if this is a guest user
      const isGuestUser = userId.startsWith('guest_');
      
      let query = this.supabase
        .from('audio_analysis_cache')
        .select('*')
        .eq('file_metadata_id', fileMetadataId);
      
      // Only filter by user_id for authenticated users
      if (!isGuestUser) {
        query = query.eq('user_id', userId);
      }
      
      if (stemType) {
        query = query.eq('stem_type', stemType);
      }
      
      const { data, error } = await query;
      
      logger.log('getCachedAnalysis query:', { fileMetadataId, userId, stemType });
      logger.log('getCachedAnalysis result:', data);
      
      if (error) {
        throw new Error(`Failed to retrieve cached analysis: ${error.message}`);
      }
      
      // For guest users, return null since they won't have cached analysis
      if (isGuestUser) {
        return null;
      }
      
      if (Array.isArray(data) && data.length > 0) {
        const row = data[0];
        return {
          id: row.id,
          fileMetadataId: row.file_metadata_id,
          stemType: row.stem_type,
          analysisData: row.analysis_data,
          waveformData: row.waveform_data,
          metadata: {
            sampleRate: row.sample_rate,
            duration: row.duration,
            bufferSize: row.buffer_size,
            featuresExtracted: row.features_extracted,
            analysisDuration: row.analysis_duration
          }
        };
      }
      return null;
    } catch (error) {
      logger.error(' Failed to retrieve cached analysis:', error);
      throw error;
    }
  }

  /**
   * Retrieve cached analysis for multiple files
   */
  async getBatchCachedAnalysis(
    fileMetadataIds: string[],
    userId: string,
    stemType?: string
  ): Promise<CachedAnalysis[]> {
    try {
      // Check if this is a guest user
      const isGuestUser = userId.startsWith('guest_');
      if (isGuestUser) return [];

      let query = this.supabase
        .from('audio_analysis_cache')
        .select('*')
        .in('file_metadata_id', fileMetadataIds)
        .eq('user_id', userId);

      if (stemType) {
        query = query.eq('stem_type', stemType);
      }

      const { data, error } = await query;
      if (error) {
        throw new Error(`Failed to retrieve batch cached analysis: ${error.message}`);
      }
      if (!Array.isArray(data) || data.length === 0) return [];
      return data.map(row => ({
        id: row.id,
        fileMetadataId: row.file_metadata_id,
        stemType: row.stem_type,
        analysisData: row.analysis_data,
        waveformData: row.waveform_data,
        metadata: {
          sampleRate: row.sample_rate,
          duration: row.duration,
          bufferSize: row.buffer_size,
          featuresExtracted: row.features_extracted,
          analysisDuration: row.analysis_duration
        }
      }));
    } catch (error) {
      logger.error('getBatchCachedAnalysis error:', error);
      throw error;
    }
  }

  /**
   * Convert any audio format to a WAV buffer for analysis
   */
  private async convertToWav(inputBuffer: Buffer): Promise<Buffer> {
    return new Promise((resolve, reject) => {
      const readableStream = new PassThrough();
      readableStream.end(inputBuffer);

      const chunks: Buffer[] = [];
      const writableStream = new Writable({
        write(chunk, encoding, callback) {
          chunks.push(chunk);
          callback();
        }
      });

      writableStream.on('finish', () => {
        resolve(Buffer.concat(chunks));
      });

      writableStream.on('error', err => {
        reject(new Error(`FFmpeg conversion error: ${err.message}`));
      });

      ffmpeg(readableStream)
        .toFormat('wav')
        .on('error', (err) => {
          // This error handler is crucial for catching FFmpeg-specific errors
          reject(new Error(`FFmpeg processing error: ${err.message}`));
        })
        .pipe(writableStream);
    });
  }

  /**
   * Analyze an audio buffer and return structured data
   */
  private async analyzeAudioBuffer(buffer: Buffer): Promise<AudioAnalysisData> {
    try {
      const samples = await this.getAudioSamples(buffer);
      const sampleRate = 44100; // Standard assumption
      const frameSize = 1024; // A common frame size for analysis
      const hopLength = 512;   // Overlap for smoother results

      // Expanded feature set for comprehensive analysis
      const features: AudioAnalysisData = {
        rms: [],
        spectralCentroid: [],
        spectralRolloff: [],
        spectralFlatness: [],
        spectralSpread: [],
        zcr: [],
        loudness: [],
        energy: [],
        mfcc_0: [],
        mfcc_1: [],
        mfcc_2: [],
        mfcc_3: [],
        mfcc_4: [],
        mfcc_5: [],
        mfcc_6: [],
        mfcc_7: [],
        mfcc_8: [],
        mfcc_9: [],
        mfcc_10: [],
        mfcc_11: [],
        mfcc_12: [],
        perceptualSpread: [],
        perceptualSharpness: [],
        chroma_0: [], chroma_1: [], chroma_2: [], chroma_3: [], chroma_4: [], chroma_5: [],
        chroma_6: [], chroma_7: [], chroma_8: [], chroma_9: [], chroma_10: [], chroma_11: [],
      };
      
      const featureNames = Object.keys(features) as (keyof typeof features)[];

      // Process audio in frames
      for (let i = 0; i + frameSize <= samples.length; i += hopLength) {
        const frame = samples.subarray(i, i + frameSize);
        
        for (const featureName of featureNames) {
          let value: number;
          switch (featureName) {
            case 'rms':
              value = this.calculateRMS(frame);
              break;
            case 'spectralCentroid':
              value = this.calculateSpectralCentroid(frame);
              break;
            case 'spectralRolloff':
              value = this.calculateSpectralRolloff(frame);
              break;
            case 'spectralFlatness':
              value = this.calculateSpectralFlatness(frame);
              break;
            case 'spectralSpread':
              value = this.calculateSpectralSpread(frame);
              break;
            case 'zcr':
              value = this.calculateZCR(frame);
              break;
            case 'loudness':
              value = this.calculateLoudness(frame);
              break;
            case 'energy':
              value = this.calculateEnergy(frame);
              break;
            case 'perceptualSpread':
              value = this.calculatePerceptualSpread(frame);
              break;
            case 'perceptualSharpness':
              value = this.calculatePerceptualSharpness(frame);
              break;
                          default:
                if (featureName.startsWith('mfcc_')) {
                  const parts = featureName.split('_');
                  const mfccIndex = parts[1] ? parseInt(parts[1]) : 0;
                  const mfccValues = this.calculateMFCC(frame);
                  value = mfccValues[mfccIndex] || 0;
                } else if (featureName.startsWith('chroma_')) {
                  const parts = featureName.split('_');
                  const chromaIndex = parts[1] ? parseInt(parts[1]) : 0;
                  const chromaValues = this.calculateChromaVector(frame);
                  value = chromaValues[chromaIndex] || 0;
                } else {
                  value = 0;
                }
          }
          const featureArray = features[featureName];
          if(featureArray) {
            featureArray.push(value);
          }
        }
      }

      // Normalize all feature arrays between 0 and 1
      for (const featureName of featureNames) {
        const values = features[featureName];
        if (!values || values.length === 0) continue;

        const maxVal = Math.max(...values);
        const minVal = Math.min(...values);
        const range = maxVal - minVal;
        
        if (range > 0) {
          features[featureName] = values.map(v => (v - minVal) / range);
        } else if (maxVal > 0) {
          // If all values are the same but non-zero, normalize to 0.5
          features[featureName] = values.map(() => 0.5);
        }
      }

      return features;

    } catch (error) {
      logger.error('Error analyzing audio buffer:', error);
      throw new Error('Failed to analyze audio buffer.');
    }
  }

  private async getAudioSamples(buffer: Buffer): Promise<Int16Array> {
    return new Promise((resolve, reject) => {
      const readable = new PassThrough();
      readable.end(buffer);
      const chunks: Buffer[] = [];
      readable
        .pipe(new Reader())
        .on('format', format => {
          if (format.audioFormat !== 1) { // 1 is PCM
            return reject(new Error('Only WAV files with PCM audio format are supported for direct analysis.'));
          }
        })
        .pipe(new Writable({
          write(chunk, encoding, callback) {
            chunks.push(chunk);
            callback();
          }
        }))
        .on('finish', () => {
          const pcmData = Buffer.concat(chunks);
          // Assuming 16-bit signed PCM
          const samples = new Int16Array(pcmData.buffer, pcmData.byteOffset, pcmData.length / 2);
          resolve(samples);
        })
        .on('error', reject);
    });
  }

  /**
   * Generate waveform data from an audio buffer
   */
  private async generateWaveformData(buffer: Buffer): Promise<WaveformData> {
    return new Promise((resolve, reject) => {
      const reader = new Reader();
      const samples: number[] = [];
      let format: any = {};

      reader.on('format', (f: any) => {
        format = f;
      });

      reader.on('data', (chunk: Buffer) => {
        if (!format || !format.byteRate || !format.sampleRate) return;
        for (let i = 0; i < chunk.length; i += 2) { // Assuming 16-bit audio
          if (chunk.length >= i + 2) {
            samples.push(chunk.readInt16LE(i) / 32768); // Normalize to -1 to 1
          }
        }
      });

      reader.on('end', () => {
        if (!format.sampleRate || samples.length === 0) {
          // Fallback for non-WAV files or empty files
          const duration = 10; // Assume 10s
          const sampleRate = 44100;
          const numPoints = 1000;
          const points = Array.from({ length: numPoints }, () => (Math.random() * 2 - 1) * 0.1);
          logger.warn(' Could not decode WAV, generating fallback waveform.');
          return resolve({
            points: points,
            sampleRate: sampleRate,
            duration: duration,
            markers: [],
          });
        }
        
        const downsampleFactor = Math.max(1, Math.floor(samples.length / 2000)); // Max 2000 points
        const downsampled: number[] = [];
        for (let i = 0; i < samples.length; i += downsampleFactor) {
          const sample = samples[i];
          if (sample !== undefined) {
            downsampled.push(sample);
          }
        }

        const duration = samples.length / format.sampleRate;
        
        resolve({
          points: downsampled,
          sampleRate: format.sampleRate,
          duration: duration,
          markers: [], // Placeholder for future marker detection
        });
      });

      reader.on('error', (err: Error) => {
        logger.error(' Error decoding audio file for waveform:', err);
        // Fallback for decoding errors
        const duration = 10;
        const sampleRate = 44100;
        const numPoints = 1000;
        const points = Array.from({ length: numPoints }, () => (Math.random() * 2 - 1) * 0.1);
        resolve({
          points: points,
          sampleRate: sampleRate,
          duration: duration,
          markers: [],
        });
      });

      // Pipe the buffer into the WAV reader
      const bufferStream = new Writable();
      bufferStream._write = (chunk: any, encoding: any, next: any) => {
        reader.write(chunk);
        next();
      };
      bufferStream.end(buffer);
    });
  }

  // Helper methods for audio analysis
  private calculateRMS(samples: Int16Array): number {
    let sumOfSquares = 0;
    for (let i = 0; i < samples.length; i++) {
      sumOfSquares += ((samples[i] ?? 0) / 32768) ** 2;
    }
    return Math.sqrt(sumOfSquares / samples.length);
  }

  private calculateSpectralCentroid(samples: Int16Array): number {
    let weightedSum = 0;
    let sum = 0;
    const fftData = this.performFFT(samples);

    for (let i = 0; i < fftData.length; i++) {
      const freq = (i * 44100) / fftData.length;
      const magnitude = Math.abs(fftData[i] ?? 0);
      weightedSum += freq * magnitude;
      sum += magnitude;
    }

    return sum > 0 ? weightedSum / sum : 0;
  }

  private calculateSpectralRolloff(samples: Int16Array): number {
    const fftData = this.performFFT(samples);
    const totalEnergy = fftData.reduce((sum, val) => sum + Math.abs(val) ** 2, 0);
    const threshold = totalEnergy * 0.85; // 85% energy threshold
    
    let cumulativeEnergy = 0;
    for (let i = 0; i < fftData.length; i++) {
      cumulativeEnergy += Math.abs(fftData[i] ?? 0) ** 2;
      if (cumulativeEnergy >= threshold) {
        return (i * 44100) / fftData.length;
      }
    }
    return 22050; // Nyquist frequency as fallback
  }

  private calculateSpectralFlatness(samples: Int16Array): number {
    const fftData = this.performFFT(samples);
    const magnitudes = fftData.map(val => Math.abs(val ?? 0));
    
    const geometricMean = Math.exp(
      magnitudes.reduce((sum, mag) => sum + Math.log(Math.max(mag, 1e-10)), 0) / magnitudes.length
    );
    const arithmeticMean = magnitudes.reduce((sum, mag) => sum + mag, 0) / magnitudes.length;
    
    return arithmeticMean > 0 ? geometricMean / arithmeticMean : 0;
  }

  private calculateSpectralSpread(samples: Int16Array): number {
    const fftData = this.performFFT(samples);
    const centroid = this.calculateSpectralCentroid(samples);
    
    let weightedSum = 0;
    let sum = 0;
    
    for (let i = 0; i < fftData.length; i++) {
      const freq = (i * 44100) / fftData.length;
      const magnitude = Math.abs(fftData[i] ?? 0);
      const diff = freq - centroid;
      weightedSum += (diff ** 2) * magnitude;
      sum += magnitude;
    }
    
    return sum > 0 ? Math.sqrt(weightedSum / sum) : 0;
  }

  private calculateZCR(samples: Int16Array): number {
    let crossings = 0;
    for (let i = 1; i < samples.length; i++) {
      const prev = (samples[i - 1] ?? 0) / 32768;
      const curr = (samples[i] ?? 0) / 32768;
      if ((prev >= 0 && curr < 0) || (prev < 0 && curr >= 0)) {
        crossings++;
      }
    }
    return crossings / samples.length;
  }

  private calculateLoudness(samples: Int16Array): number {
    // Simplified loudness calculation using A-weighting approximation
    const fftData = this.performFFT(samples);
    let weightedSum = 0;
    
    for (let i = 0; i < fftData.length; i++) {
      const freq = (i * 44100) / fftData.length;
      const magnitude = Math.abs(fftData[i] ?? 0);
      
      // Simplified A-weighting curve
      let aWeight = 1;
      if (freq < 1000) {
        aWeight = 0.5 + 0.5 * (freq / 1000);
      } else if (freq > 1000) {
        aWeight = 1 - 0.3 * Math.log10(freq / 1000);
      }
      
      weightedSum += magnitude * aWeight;
    }
    
    return weightedSum / fftData.length;
  }

  private calculateMFCC(samples: Int16Array): number[] {
    // Simplified MFCC calculation
    const fftData = this.performFFT(samples);
    const magnitudes = fftData.map(val => Math.abs(val ?? 0));
    
    // Simple mel-scale filter bank (13 coefficients)
    const mfcc = [];
    for (let i = 0; i < 13; i++) {
      let sum = 0;
      for (let j = 0; j < magnitudes.length; j++) {
        const freq = (j * 44100) / magnitudes.length;
        const melFreq = 2595 * Math.log10(1 + freq / 700);
        const filterWeight = Math.exp(-((melFreq - i * 200) ** 2) / (2 * 100 ** 2));
        sum += (magnitudes[j] ?? 0) * filterWeight;
      }
      mfcc.push(Math.log(Math.max(sum, 1e-10)));
    }
    
    return mfcc;
  }

  private calculateEnergy(samples: Int16Array): number {
    let sum = 0;
    for (let i = 0; i < samples.length; i++) {
      sum += ((samples[i] ?? 0) / 32768) ** 2;
    }
    return sum / samples.length;
  }

  private calculatePerceptualSpread(samples: Int16Array): number {
    // Simplified perceptual spread using spectral centroid and spread
    const centroid = this.calculateSpectralCentroid(samples);
    const spread = this.calculateSpectralSpread(samples);
    return spread / Math.max(centroid, 1);
  }

  private calculatePerceptualSharpness(samples: Int16Array): number {
    // Simplified sharpness calculation
    const fftData = this.performFFT(samples);
    let weightedSum = 0;
    let sum = 0;
    
    for (let i = 0; i < fftData.length; i++) {
      const freq = (i * 44100) / fftData.length;
      const magnitude = Math.abs(fftData[i] ?? 0);
      
      // Sharpness increases with frequency
      const sharpnessWeight = Math.min(freq / 10000, 1);
      weightedSum += magnitude * sharpnessWeight;
      sum += magnitude;
    }
    
    return sum > 0 ? weightedSum / sum : 0;
  }

  private calculateChromaVector(samples: Int16Array): number[] {
    // Simplified chroma vector (12 semitones)
    const fftData = this.performFFT(samples);
    const chroma = new Array(12).fill(0);
    
    for (let i = 0; i < fftData.length; i++) {
      const freq = (i * 44100) / fftData.length;
      if (freq > 0) {
        // Convert frequency to semitone
        const semitone = Math.round(12 * Math.log2(freq / 440)) % 12;
        const magnitude = Math.abs(fftData[i] ?? 0);
        chroma[semitone] += magnitude;
      }
    }
    
    // Normalize
    const maxVal = Math.max(...chroma);
    return maxVal > 0 ? chroma.map(val => val / maxVal) : chroma;
  }

  private generateFrequencyData(samples: Int16Array): number[] {
    const fftData = this.performFFT(samples);
    return Array.from(fftData.slice(0, fftData.length / 2)).map(val => Math.abs(val ?? 0));
  }

  private generateTimeData(samples: Int16Array): number[] {
    const downsampled: number[] = [];
    const factor = Math.floor(samples.length / 1024);
    if (factor < 1) return Array.from(samples).map(s => (s ?? 0) / 32768);
    for (let i = 0; i < samples.length; i += factor) {
      const sample = samples[i];
      if (sample !== undefined) {
        downsampled.push(sample / 32768);
      }
    }
    return downsampled;
  }

  private calculateBandEnergy(frequencies: number[], minFreq: number, maxFreq: number): number {
    if (frequencies.length === 0) return 0;
    const sampleRate = 44100;
    const binWidth = sampleRate / 2 / frequencies.length;
    
    const startBin = Math.floor(minFreq / binWidth);
    const endBin = Math.ceil(maxFreq / binWidth);
    
    let sum = 0;
    for (let i = startBin; i <= endBin && i < frequencies.length; i++) {
      const freq = frequencies[i];
      if (freq !== undefined) {
        sum += freq;
      }
    }
    return sum;
  }

  private detectFeatureMarkers(samples: Int16Array): FeatureMarker[] {
    // Simplified placeholder
    return [];
  }

  /**
   * Simplified FFT implementation
   */
  private performFFT(samples: Int16Array): Float32Array {
    const floatSamples = new Float32Array(samples.length);
    for (let i = 0; i < samples.length; i++) {
      const sample = samples[i];
      floatSamples[i] = sample !== undefined ? sample / 32768 : 0;
    }
    return this.simpleFFT(floatSamples);
  }

  private simpleFFT(samples: Float32Array): Float32Array {
    const N = samples.length;
    if (N <= 1) return samples;

    // Radix-2 FFT
    if (N % 2 !== 0) {
      // For non-power-of-2, you'd need a more complex FFT or padding.
      // For simplicity, we'll just return magnitudes of 0.
      logger.warn(`FFT size is not a power of 2 (${N}), which is not optimal. Padding or a different FFT algorithm should be used.`);
      return new Float32Array(N / 2);
    }

    const even = this.simpleFFT(samples.filter((_, i) => i % 2 === 0));
    const odd = this.simpleFFT(samples.filter((_, i) => i % 2 !== 0));

    const result = new Float32Array(N / 2);
    for (let k = 0; k < N / 2; k++) {
      const t_val = odd[k];
      const e_val = even[k];

      if (t_val !== undefined && e_val !== undefined) {
        const t = t_val * Math.cos(-2 * Math.PI * k / N);
        const e = e_val;
        result[k] = Math.sqrt((e + t) ** 2);
      } else {
        result[k] = 0; // Assign a default value if components are undefined
      }
    }
    return result;
  }
}
</file>

<file path="services/auto-save.ts">
import { SupabaseClient } from '@supabase/supabase-js'
import { TRPCError } from '@trpc/server'
import { logger } from '../lib/logger'

export interface AutoSaveConfig {
  enabled: boolean
  interval: number // milliseconds
  maxHistory: number // number of saved states to keep
  debounceTime: number // milliseconds
}

export interface EditState {
  id: string
  userId: string
  projectId: string
  timestamp: Date
  data: {
    visualizationParams: Record<string, any>
    stemMappings: Record<string, any>
    effectSettings: Record<string, any>
    timelineState: any
  }
  version: number
  isCurrent: boolean
}

export interface SaveStateOptions {
  projectId: string
  userId: string
  data: Record<string, any>
  version?: number
  compress?: boolean
}

export interface RestoreStateOptions {
  stateId: string
  userId: string
}

export class AutoSaveService {
  constructor(private supabase: SupabaseClient) {}

  // Save current edit state
  async saveState(options: SaveStateOptions): Promise<EditState> {
    try {
      // First, mark all existing states for this project as not current
      await this.supabase
        .from('edit_states')
        .update({ is_current: false })
        .eq('project_id', options.projectId)
        .eq('user_id', options.userId)

      // Get the next version number
      const { data: latestState } = await this.supabase
        .from('edit_states')
        .select('version')
        .eq('project_id', options.projectId)
        .eq('user_id', options.userId)
        .order('version', { ascending: false })
        .limit(1)
        .single()

      const nextVersion = (latestState?.version || 0) + 1

      // Prepare data for storage
      const stateData = options.compress 
        ? this.compressStateData(options.data)
        : options.data

      // Create new edit state
      const { data: editState, error } = await this.supabase
        .from('edit_states')
        .insert({
          user_id: options.userId,
          project_id: options.projectId,
          data: stateData,
          version: nextVersion,
          is_current: true,
        })
        .select()
        .single()

      if (error) {
        logger.error('Database error saving edit state:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to save edit state',
        })
      }

      // Clean up old states if we exceed max history
      await this.cleanupOldStates(options.projectId, options.userId)

      return this.mapDatabaseToEditState(editState)
    } catch (error) {
      if (error instanceof TRPCError) throw error
      logger.error('Error saving edit state:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to save edit state',
      })
    }
  }

  // Get current state for a project
  async getCurrentState(projectId: string, userId: string): Promise<EditState | null> {
    try {
      const { data: editState, error } = await this.supabase
        .from('edit_states')
        .select('*')
        .eq('project_id', projectId)
        .eq('user_id', userId)
        .eq('is_current', true)
        .single()

      if (error) {
        if (error.code === 'PGRST116') {
          // No current state found, return null
          return null
        }
        logger.error('Database error fetching current state:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch current state',
        })
      }

      return this.mapDatabaseToEditState(editState)
    } catch (error) {
      if (error instanceof TRPCError) throw error
      logger.error('Error fetching current state:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to fetch current state',
      })
    }
  }

  // Restore a specific edit state
  async restoreState(options: RestoreStateOptions): Promise<EditState> {
    try {
      // Get the state to restore
      const { data: editState, error: fetchError } = await this.supabase
        .from('edit_states')
        .select('*')
        .eq('id', options.stateId)
        .eq('user_id', options.userId)
        .single()

      if (fetchError) {
        if (fetchError.code === 'PGRST116') {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'Edit state not found or access denied',
          })
        }
        logger.error('Database error fetching edit state:', fetchError)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch edit state',
        })
      }

      // Mark all existing states for this project as not current
      await this.supabase
        .from('edit_states')
        .update({ is_current: false })
        .eq('project_id', editState.project_id)
        .eq('user_id', options.userId)

      // Create a new state based on the restored one
      const { data: newState, error: createError } = await this.supabase
        .from('edit_states')
        .insert({
          user_id: options.userId,
          project_id: editState.project_id,
          data: editState.data,
          version: editState.version + 1,
          is_current: true,
        })
        .select()
        .single()

      if (createError) {
        logger.error('Database error creating restored state:', createError)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to restore edit state',
        })
      }

      return this.mapDatabaseToEditState(newState)
    } catch (error) {
      if (error instanceof TRPCError) throw error
      logger.error('Error restoring edit state:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to restore edit state',
      })
    }
  }

  // Get edit history for a project
  async getProjectStates(
    projectId: string, 
    userId: string, 
    limit: number = 10, 
    offset: number = 0
  ): Promise<EditState[]> {
    try {
      const { data: editStates, error } = await this.supabase
        .from('edit_states')
        .select('*')
        .eq('project_id', projectId)
        .eq('user_id', userId)
        .order('timestamp', { ascending: false })
        .range(offset, offset + limit - 1)

      if (error) {
        logger.error('Database error fetching project states:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch project states',
        })
      }

      return (editStates || []).map(state => this.mapDatabaseToEditState(state))
    } catch (error) {
      if (error instanceof TRPCError) throw error
      logger.error('Error fetching project states:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to fetch project states',
      })
    }
  }

  // Delete a specific edit state
  async deleteState(stateId: string, userId: string): Promise<void> {
    try {
      // Check if this is the current state
      const { data: editState, error: fetchError } = await this.supabase
        .from('edit_states')
        .select('is_current, project_id')
        .eq('id', stateId)
        .eq('user_id', userId)
        .single()

      if (fetchError) {
        if (fetchError.code === 'PGRST116') {
          throw new TRPCError({
            code: 'NOT_FOUND',
            message: 'Edit state not found or access denied',
          })
        }
        logger.error('Database error fetching edit state:', fetchError)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch edit state',
        })
      }

      // Delete the state
      const { error: deleteError } = await this.supabase
        .from('edit_states')
        .delete()
        .eq('id', stateId)
        .eq('user_id', userId)

      if (deleteError) {
        logger.error('Database error deleting edit state:', deleteError)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to delete edit state',
        })
      }

      // If this was the current state, make the most recent state current
      if (editState.is_current) {
        const { data: latestState } = await this.supabase
          .from('edit_states')
          .select('id')
          .eq('project_id', editState.project_id)
          .eq('user_id', userId)
          .order('timestamp', { ascending: false })
          .limit(1)
          .single()

        if (latestState) {
          await this.supabase
            .from('edit_states')
            .update({ is_current: true })
            .eq('id', latestState.id)
        }
      }
    } catch (error) {
      if (error instanceof TRPCError) throw error
      logger.error('Error deleting edit state:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to delete edit state',
      })
    }
  }

  // Clear all edit history for a project
  async clearProjectHistory(projectId: string, userId: string): Promise<void> {
    try {
      const { error } = await this.supabase
        .from('edit_states')
        .delete()
        .eq('project_id', projectId)
        .eq('user_id', userId)

      if (error) {
        logger.error('Database error clearing project history:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to clear project history',
        })
      }
    } catch (error) {
      if (error instanceof TRPCError) throw error
      logger.error('Error clearing project history:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to clear project history',
      })
    }
  }

  // Clean up old states to maintain history limit
  private async cleanupOldStates(projectId: string, userId: string, maxHistory: number = 10): Promise<void> {
    try {
      // Get count of states for this project
      const { count } = await this.supabase
        .from('edit_states')
        .select('*', { count: 'exact', head: true })
        .eq('project_id', projectId)
        .eq('user_id', userId)

      if (count && count > maxHistory) {
        // Get IDs of states to delete (keep the most recent ones)
        const { data: statesToDelete } = await this.supabase
          .from('edit_states')
          .select('id')
          .eq('project_id', projectId)
          .eq('user_id', userId)
          .order('timestamp', { ascending: true })
          .limit(count - maxHistory)

        if (statesToDelete && statesToDelete.length > 0) {
          const idsToDelete = statesToDelete.map(state => state.id)
          
          await this.supabase
            .from('edit_states')
            .delete()
            .in('id', idsToDelete)
        }
      }
    } catch (error) {
      logger.error('Error cleaning up old states:', error)
      // Don't throw error for cleanup failures
    }
  }

  // Compress state data to reduce storage size
  private compressStateData(data: Record<string, any>): Record<string, any> {
    try {
      // Simple compression: remove null/undefined values and compress large objects
      const compressed = JSON.parse(JSON.stringify(data, (key, value) => {
        if (value === null || value === undefined) return undefined
        if (typeof value === 'object' && Object.keys(value).length === 0) return undefined
        return value
      }))
      
      return compressed
    } catch (error) {
      logger.error('Error compressing state data:', error)
      return data // Return original data if compression fails
    }
  }

  // Map database record to EditState interface
  private mapDatabaseToEditState(dbRecord: any): EditState {
    return {
      id: dbRecord.id,
      userId: dbRecord.user_id,
      projectId: dbRecord.project_id,
      timestamp: new Date(dbRecord.timestamp),
      data: dbRecord.data,
      version: dbRecord.version,
      isCurrent: dbRecord.is_current,
    }
  }

  // Validate edit state data structure
  validateStateData(data: Record<string, any>): boolean {
    try {
      // Check for required top-level keys
      const requiredKeys = ['visualizationParams', 'stemMappings', 'effectSettings', 'timelineState']
      const hasRequiredKeys = requiredKeys.every(key => key in data)
      
      if (!hasRequiredKeys) {
        return false
      }

      // Validate data types
      const isValid = 
        typeof data.visualizationParams === 'object' &&
        typeof data.stemMappings === 'object' &&
        typeof data.effectSettings === 'object'

      return isValid
    } catch (error) {
      logger.error('Error validating state data:', error)
      return false
    }
  }

  // Get storage statistics for a project
  async getStorageStats(projectId: string, userId: string): Promise<{
    totalStates: number
    totalSizeBytes: number
    averageStateSizeBytes: number
    oldestState: Date | null
    newestState: Date | null
  }> {
    try {
      const { data: states, error } = await this.supabase
        .from('edit_states')
        .select('timestamp, data')
        .eq('project_id', projectId)
        .eq('user_id', userId)
        .order('timestamp', { ascending: true })

      if (error) {
        logger.error('Database error fetching storage stats:', error)
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to fetch storage stats',
        })
      }

      if (!states || states.length === 0) {
        return {
          totalStates: 0,
          totalSizeBytes: 0,
          averageStateSizeBytes: 0,
          oldestState: null,
          newestState: null,
        }
      }

      const totalStates = states.length
      const totalSizeBytes = states.reduce((acc, state) => {
        return acc + JSON.stringify(state.data).length
      }, 0)
      const averageStateSizeBytes = Math.round(totalSizeBytes / totalStates)
      const oldestState = new Date(states[0]?.timestamp || new Date())
      const newestState = new Date(states[states.length - 1]?.timestamp || new Date())

      return {
        totalStates,
        totalSizeBytes,
        averageStateSizeBytes,
        oldestState,
        newestState,
      }
    } catch (error) {
      if (error instanceof TRPCError) throw error
      logger.error('Error getting storage stats:', error)
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: 'Failed to get storage stats',
      })
    }
  }
}
</file>

<file path="services/media-processor.ts">
import { VideoMetadata, ImageMetadata } from '../lib/file-validation'
import { logger } from '../lib/logger';

export class MediaProcessor {
  
  /**
   * Extract video metadata from buffer
   * For now, this is a placeholder implementation - in production would use ffprobe
   */
  static async extractVideoMetadata(buffer: Buffer, fileName: string): Promise<VideoMetadata> {
    // Placeholder implementation - would use ffprobe in production
    // For development, return mock data based on file extension
    const extension = fileName.toLowerCase().split('.').pop()
    
    // Mock metadata for development
    const mockMetadata: VideoMetadata = {
      duration: 60, // 1 minute default
      width: 1920,
      height: 1080,
      frameRate: 30,
      codec: extension === 'webm' ? 'vp9' : 'h264',
      bitrate: 5000, // 5 Mbps
      aspectRatio: '16:9'
    }
    
    // Note: Using mock metadata for development - replace with actual ffprobe implementation in production
    
    return mockMetadata
  }
  
  /**
   * Generate video thumbnail from buffer
   * For now, this is a placeholder - in production would use ffmpeg
   */
  static async generateVideoThumbnail(
    buffer: Buffer, 
    fileName: string,
    timestampSec: number = 1
  ): Promise<Buffer> {
    // Placeholder implementation - would use ffmpeg in production
    // Return a minimal 1x1 pixel JPEG as placeholder
    const placeholderJpeg = Buffer.from([
      0xff, 0xd8, 0xff, 0xe0, 0x00, 0x10, 0x4a, 0x46, 0x49, 0x46, 0x00, 0x01,
      0x01, 0x01, 0x00, 0x48, 0x00, 0x48, 0x00, 0x00, 0xff, 0xdb, 0x00, 0x43,
      0x00, 0x08, 0x06, 0x06, 0x07, 0x06, 0x05, 0x08, 0x07, 0x07, 0x07, 0x09,
      0x09, 0x08, 0x0a, 0x0c, 0x14, 0x0d, 0x0c, 0x0b, 0x0b, 0x0c, 0x19, 0x12,
      0x13, 0x0f, 0x14, 0x1d, 0x1a, 0x1f, 0x1e, 0x1d, 0x1a, 0x1c, 0x1c, 0x20,
      0x24, 0x2e, 0x27, 0x20, 0x22, 0x2c, 0x23, 0x1c, 0x1c, 0x28, 0x37, 0x29,
      0x2c, 0x30, 0x31, 0x34, 0x34, 0x34, 0x1f, 0x27, 0x39, 0x3d, 0x38, 0x32,
      0x3c, 0x2e, 0x33, 0x34, 0x32, 0xff, 0xc0, 0x00, 0x11, 0x08, 0x00, 0x01,
      0x00, 0x01, 0x01, 0x01, 0x11, 0x00, 0x02, 0x11, 0x01, 0x03, 0x11, 0x01,
      0xff, 0xc4, 0x00, 0x14, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08, 0xff, 0xc4,
      0x00, 0x14, 0x10, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xff, 0xda, 0x00, 0x0c,
      0x03, 0x01, 0x00, 0x02, 0x11, 0x03, 0x11, 0x00, 0x3f, 0x00, 0xb2, 0xc0,
      0x07, 0xff, 0xd9
    ])
    
    // Note: Using mock thumbnail for development - replace with actual ffmpeg implementation in production
    // const thumbnail = await this.runFFMpeg(buffer, timestampSec);
    
    return placeholderJpeg
  }
  
  /**
   * Extract image metadata from buffer
   * For now, this is a placeholder - in production would use sharp
   */
  static async extractImageMetadata(buffer: Buffer, fileName: string): Promise<ImageMetadata> {
    const extension = fileName.toLowerCase().split('.').pop()
    
    // Mock metadata for development
    const mockMetadata: ImageMetadata = {
      width: 1920,
      height: 1080,
      colorProfile: 'sRGB',
      orientation: 1, // Normal orientation
      hasAlpha: extension === 'png' || extension === 'gif' || extension === 'webp',
      fileFormat: extension?.toUpperCase() || 'JPEG'
    }
    
    // Note: Using mock image processing for development - replace with actual sharp implementation in production
    // const metadata = await sharp(buffer).metadata();
    
    return mockMetadata
  }
  
  /**
   * Generate image thumbnail
   * For now, this is a placeholder - in production would use sharp
   */
  static async generateImageThumbnail(
    buffer: Buffer,
    fileName: string,
    maxWidth: number = 300,
    maxHeight: number = 300
  ): Promise<Buffer> {
    // Placeholder implementation - return a small JPEG thumbnail
    const placeholderThumbnail = Buffer.from([
      0xff, 0xd8, 0xff, 0xe0, 0x00, 0x10, 0x4a, 0x46, 0x49, 0x46, 0x00, 0x01,
      0x01, 0x01, 0x00, 0x48, 0x00, 0x48, 0x00, 0x00, 0xff, 0xdb, 0x00, 0x43,
      0x00, 0x08, 0x06, 0x06, 0x07, 0x06, 0x05, 0x08, 0x07, 0x07, 0x07, 0x09,
      0x09, 0x08, 0x0a, 0x0c, 0x14, 0x0d, 0x0c, 0x0b, 0x0b, 0x0c, 0x19, 0x12,
      0x13, 0x0f, 0x14, 0x1d, 0x1a, 0x1f, 0x1e, 0x1d, 0x1a, 0x1c, 0x1c, 0x20,
      0x24, 0x2e, 0x27, 0x20, 0x22, 0x2c, 0x23, 0x1c, 0x1c, 0x28, 0x37, 0x29,
      0x2c, 0x30, 0x31, 0x34, 0x34, 0x34, 0x1f, 0x27, 0x39, 0x3d, 0x38, 0x32,
      0x3c, 0x2e, 0x33, 0x34, 0x32, 0xff, 0xc0, 0x00, 0x11, 0x08, 0x00, 0x01,
      0x00, 0x01, 0x01, 0x01, 0x11, 0x00, 0x02, 0x11, 0x01, 0x03, 0x11, 0x01,
      0xff, 0xc4, 0x00, 0x14, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08, 0xff, 0xc4,
      0x00, 0x14, 0x10, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xff, 0xda, 0x00, 0x0c,
      0x03, 0x01, 0x00, 0x02, 0x11, 0x03, 0x11, 0x00, 0x3f, 0x00, 0xb2, 0xc0,
      0x07, 0xff, 0xd9
    ])
    
    // Note: Using mock thumbnail for development - replace with actual sharp implementation in production
    // const thumbnail = await sharp(buffer)
    //   .resize(maxWidth, maxHeight, { fit: 'inside', withoutEnlargement: true })
    //   .jpeg({ quality: 80 })
    //   .toBuffer();
    
    return placeholderThumbnail
  }
  
  /**
   * Process uploaded file - extract metadata and generate thumbnails
   * This would run in background after file upload
   */
  static async processUploadedFile(
    buffer: Buffer,
    fileName: string,
    fileType: 'video' | 'image',
    fileId: string
  ): Promise<{
    metadata: VideoMetadata | ImageMetadata;
    thumbnail: Buffer;
    thumbnailKey: string;
  }> {
    try {
      let metadata: VideoMetadata | ImageMetadata
      let thumbnail: Buffer
      
      if (fileType === 'video') {
        metadata = await this.extractVideoMetadata(buffer, fileName)
        thumbnail = await this.generateVideoThumbnail(buffer, fileName)
      } else {
        metadata = await this.extractImageMetadata(buffer, fileName)
        thumbnail = await this.generateImageThumbnail(buffer, fileName)
      }
      
      // Generate thumbnail key for storage
      const extension = fileName.split('.').pop()
      const thumbnailKey = `thumbnails/${fileId}_thumb.jpg`
      
      return {
        metadata,
        thumbnail,
        thumbnailKey
      }
      
    } catch (error) {
      logger.error('Error processing media file:', error)
      throw error
    }
  }
  
  /**
   * Generate R2 storage key for thumbnails
   */
  static generateThumbnailKey(originalKey: string): string {
    const lastDotIndex = originalKey.lastIndexOf('.')
    const baseKey = lastDotIndex > -1 ? originalKey.substring(0, lastDotIndex) : originalKey
    return `${baseKey}_thumb.jpg`
  }
  
  /**
   * Check if file type requires processing
   */
  static requiresProcessing(fileType: string): boolean {
    return fileType === 'video' || fileType === 'image'
  }
}
</file>

<file path="services/midi-parser.ts">
import MidiParser from 'midi-parser-js';
import { randomUUID } from 'crypto';
import { MIDIData, MIDINote, MIDITrack, TempoEvent, MIDIParsingResult } from 'phonoglyph-types';
import { logger } from '../lib/logger';

// Color palette for track visualization
const TRACK_COLORS = [
  '#84a98c', // sage
  '#6b7c93', // slate  
  '#b08a8a', // dusty rose
  '#a8a29e', // warm gray
  '#8da3b0', // soft blue
];

/**
 * Convert MIDI note number to note name
 */
function midiNoteToName(midiNote: number): string {
  const noteNames = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
  const octave = Math.floor(midiNote / 12) - 1;
  const noteName = noteNames[midiNote % 12];
  return `${noteName}${octave}`;
}

/**
 * Convert MIDI ticks to seconds
 */
function ticksToSeconds(ticks: number, ticksPerQuarter: number, microsecondsPerQuarter: number): number {
  return (ticks / ticksPerQuarter) * (microsecondsPerQuarter / 1000000);
}

/**
 * Extract tempo events from MIDI track
 */
function extractTempoEvents(tracks: any[], ticksPerQuarter: number): TempoEvent[] {
  const tempoEvents: TempoEvent[] = [];
  
  tracks.forEach(track => {
    track.event?.forEach((event: any) => {
      if (event.metaType === 81) { // Set Tempo meta event
        const microsecondsPerQuarter = (event.data[0] << 16) | (event.data[1] << 8) | event.data[2];
        const bpm = Math.round(60000000 / microsecondsPerQuarter);
        
        tempoEvents.push({
          tick: event.deltaTime || 0,
          bpm,
          microsecondsPerQuarter
        });
      }
    });
  });
  
  // Default tempo if none found
  if (tempoEvents.length === 0) {
    tempoEvents.push({
      tick: 0,
      bpm: 120,
      microsecondsPerQuarter: 500000
    });
  }
  
  return tempoEvents.sort((a, b) => a.tick - b.tick);
}

/**
 * Parse MIDI buffer and extract structured data
 */
export async function parseMidiFile(buffer: Buffer, filename: string): Promise<MIDIParsingResult> {
  try {
    // Parse MIDI file
    const midiData = MidiParser.parse(buffer);
    
    if (!midiData || !midiData.track) {
      return {
        success: false,
        error: 'Invalid MIDI file format'
      };
    }

    const ticksPerQuarter = midiData.timeDivision || 480;
    const tempoEvents = extractTempoEvents(midiData.track, ticksPerQuarter);
    const defaultTempo = tempoEvents[0]?.microsecondsPerQuarter || 500000;

    // Process tracks and extract notes
    const tracks: MIDITrack[] = [];
    let totalDuration = 0;
    
    midiData.track.forEach((track: any, trackIndex: number) => {
      const notes: MIDINote[] = [];
      const noteOnEvents: Map<string, any> = new Map(); // key: `${channel}-${note}`
      let currentTick = 0;
      
      // Get track name from meta events
      let trackName = `Track ${trackIndex + 1}`;
      let instrumentName = 'Unknown';
      
      track.event?.forEach((event: any) => {
        currentTick += event.deltaTime || 0;
        
        // Track name meta event
        if (event.metaType === 3 && event.data) {
          const nameChars = String.fromCharCode(...event.data);
          if (nameChars && nameChars.trim()) {
            trackName = nameChars.trim();
          }
        }
        
        // Program change event (instrument)
        if (event.type === 12 && event.data) {
          instrumentName = `Program ${event.data[0] || 0}`;
        }
        
        // Note On event
        if (event.type === 9 && event.data && event.data[1] > 0) {
          const noteKey = `${event.channel}-${event.data[0]}`;
          noteOnEvents.set(noteKey, {
            ...event,
            tick: currentTick
          });
        }
        
        // Note Off event (or Note On with velocity 0)
        if ((event.type === 8) || (event.type === 9 && event.data && event.data[1] === 0)) {
          const noteKey = `${event.channel}-${event.data[0]}`;
          const noteOnEvent = noteOnEvents.get(noteKey);
          
          if (noteOnEvent && noteOnEvent.data) {
            const startTime = ticksToSeconds(noteOnEvent.tick, ticksPerQuarter, defaultTempo);
            const endTime = ticksToSeconds(currentTick, ticksPerQuarter, defaultTempo);
            const duration = endTime - startTime;
            
            notes.push({
              id: randomUUID(),
              track: trackIndex,
              channel: noteOnEvent.channel || 0,
              note: noteOnEvent.data[0],
              pitch: noteOnEvent.data[0], // Same as note for web compatibility
              velocity: noteOnEvent.data[1],
              startTime,
              start: startTime, // Same as startTime for web compatibility
              duration,
              name: midiNoteToName(noteOnEvent.data[0])
            });
            
            noteOnEvents.delete(noteKey);
            totalDuration = Math.max(totalDuration, endTime);
          }
        }
      });
      
      // Only add tracks that have notes
      if (notes.length > 0) {
        tracks.push({
          id: randomUUID(),
          name: trackName,
          instrument: instrumentName,
          channel: trackIndex,
          notes,
          color: TRACK_COLORS[trackIndex % TRACK_COLORS.length] || '#84a98c'
        });
      }
    });

    const result: MIDIData = {
      file: {
        name: filename,
        size: buffer.length,
        duration: totalDuration,
        ticksPerQuarter,
        timeSignature: [4, 4], // Default, could be extracted from meta events
        keySignature: 'C major' // Default, could be extracted from meta events
      },
      tracks,
      tempoChanges: tempoEvents
    };

    return {
      success: true,
      data: result
    };

  } catch (error) {
    logger.error('MIDI parsing error:', error);
    return {
      success: false,
      error: `Failed to parse MIDI file: ${error instanceof Error ? error.message : 'Unknown error'}`
    };
  }
}

/**
 * Validate MIDI file buffer
 */
export function validateMidiBuffer(buffer: Buffer): boolean {
  // Check for MIDI header signature "MThd"
  if (buffer.length < 4) return false;
  
  const header = buffer.subarray(0, 4).toString('ascii');
  return header === 'MThd';
}
</file>

<file path="services/queue-worker.ts">
import { createClient } from '@supabase/supabase-js';
import { StemProcessor } from './stem-processor';
import { AudioAnalysisProcessor } from './audio-analysis-processor';
import { logger } from '../lib/logger';

// Initialize Supabase client
const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

interface StemSeparationJob {
  id: string;
  user_id: string;
  file_metadata_id: string;
  status: string;
}

interface AudioAnalysisJob {
  id: string;
  user_id: string;
  file_metadata_id: string;
  status: string;
}

export class QueueWorker {
  private static isRunning = false;
  private static readonly POLL_INTERVAL = 5000; // 5 seconds

  /**
   * Start the queue worker
   */
  static async start() {
    if (this.isRunning) {
      logger.log('Queue worker is already running');
      return;
    }

    this.isRunning = true;
    logger.log(' Starting queue worker...');

    while (this.isRunning) {
      try {
        // Get next pending stem separation job
        const { data: stemJobs, error: stemFetchError } = await supabase
          .from('stem_separations')
          .select(`
            id,
            user_id,
            file_metadata_id,
            status
          `)
          .eq('status', 'pending')
          .order('created_at', { ascending: true })
          .limit(1)
          .returns<StemSeparationJob[]>();

        if (stemFetchError) {
          logger.error('Error fetching stem jobs:', stemFetchError);
        } else if (stemJobs && stemJobs.length > 0) {
          const job = stemJobs[0]!;
          logger.log(` Processing stem separation job: ${job.id}`);
          await StemProcessor.processStemSeparation(job.file_metadata_id, job.user_id);
          logger.log(` Completed stem separation job: ${job.id}`);
          continue; // Process one job per cycle
        }

        // Get next pending audio analysis job
        const { data: audioJobs, error: audioFetchError } = await supabase
          .from('audio_analysis_jobs')
          .select(`
            id,
            user_id,
            file_metadata_id,
            status
          `)
          .eq('status', 'pending')
          .order('created_at', { ascending: true })
          .limit(1)
          .returns<AudioAnalysisJob[]>();

        if (audioFetchError) {
          logger.error('Error fetching audio analysis jobs:', audioFetchError);
        } else if (audioJobs && audioJobs.length > 0) {
          const job = audioJobs[0]!;
          logger.log(` Processing audio analysis job: ${job.id}`);
          await AudioAnalysisProcessor.processJob(job);
          logger.log(` Completed audio analysis job: ${job.id}`);
          continue; // Process one job per cycle
        }
        
        // No pending jobs, wait before next poll
        await new Promise(resolve => setTimeout(resolve, this.POLL_INTERVAL));

      } catch (error) {
        logger.error('Queue worker error:', error);
        await new Promise(resolve => setTimeout(resolve, this.POLL_INTERVAL));
      }
    }
  }

  /**
   * Stop the queue worker
   */
  static stop() {
    logger.log(' Stopping queue worker...');
    this.isRunning = false;
  }
}

// Handle process termination
process.on('SIGINT', () => {
  QueueWorker.stop();
  process.exit(0);
});

process.on('SIGTERM', () => {
  QueueWorker.stop();
  process.exit(0);
});
</file>

<file path="services/r2-storage.ts">
import { S3Client, CreateBucketCommand, PutBucketCorsCommand, HeadBucketCommand } from '@aws-sdk/client-s3';
import { getSignedUrl } from '@aws-sdk/s3-request-presigner';
import { PutObjectCommand, GetObjectCommand, DeleteObjectCommand } from '@aws-sdk/client-s3';
import { logger } from '../lib/logger';

// Cloudflare R2 Configuration (S3-Compatible)
const r2Config = {
  region: 'auto', // R2 uses 'auto' region
  endpoint: `https://${process.env.CLOUDFLARE_ACCOUNT_ID}.r2.cloudflarestorage.com`,
  credentials: {
    accessKeyId: process.env.CLOUDFLARE_R2_ACCESS_KEY_ID!,
    secretAccessKey: process.env.CLOUDFLARE_R2_SECRET_ACCESS_KEY!,
  },
  // R2-specific configuration
  forcePathStyle: true, // Required for R2
};

export const r2Client = new S3Client(r2Config);
export const BUCKET_NAME = process.env.CLOUDFLARE_R2_BUCKET || 'phonoglyph-uploads';

// Validate required environment variables
export function validateR2Config(): void {
  const required = ['CLOUDFLARE_ACCOUNT_ID', 'CLOUDFLARE_R2_ACCESS_KEY_ID', 'CLOUDFLARE_R2_SECRET_ACCESS_KEY', 'CLOUDFLARE_R2_BUCKET'];
  const missing = required.filter(key => !process.env[key]);
  
  if (missing.length > 0) {
    throw new Error(`Missing required Cloudflare R2 environment variables: ${missing.join(', ')}`);
  }
}

// Create R2 bucket if it doesn't exist
export async function createBucketIfNotExists(): Promise<void> {
  try {
    // Check if bucket exists
    await (r2Client as any).send(new HeadBucketCommand({ Bucket: BUCKET_NAME }));
    logger.log(` R2 bucket '${BUCKET_NAME}' already exists`);
  } catch (error: any) {
    if (error.name === 'NotFound') {
      try {
        await (r2Client as any).send(new CreateBucketCommand({ Bucket: BUCKET_NAME }));
        logger.log(` Created R2 bucket '${BUCKET_NAME}'`);
      } catch (createError) {
        logger.error(' Failed to create R2 bucket:', createError);
        throw createError;
      }
    } else {
      logger.error(' Error checking R2 bucket:', error);
      throw error;
    }
  }
}

// Configure CORS for web uploads
export async function configureBucketCors(): Promise<void> {
  const corsConfiguration = {
    CORSRules: [
      {
        AllowedOrigins: [
          process.env.FRONTEND_URL || 'http://localhost:3000',
          'https://*.vercel.app', // For preview deployments
        ],
        AllowedMethods: ['GET', 'PUT', 'POST', 'DELETE', 'HEAD'],
        AllowedHeaders: [
          'Origin',
          'X-Requested-With',
          'Content-Type',
          'Accept',
          'Authorization',
          'Cache-Control',
          'x-amz-date',
          'x-amz-security-token',
        ],
        ExposeHeaders: ['ETag'],
        MaxAgeSeconds: 3000,
      },
    ],
  };

  try {
    await (r2Client as any).send(new PutBucketCorsCommand({
      Bucket: BUCKET_NAME,
      CORSConfiguration: corsConfiguration,
    }));
    logger.log(` Configured CORS for R2 bucket '${BUCKET_NAME}'`);
  } catch (error) {
    logger.error(' Failed to configure CORS:', error);
    throw error;
  }
}

// Generate pre-signed URL for file upload
export async function generateUploadUrl(
  key: string,
  contentType: string,
  expiresIn: number = 3600
): Promise<string> {
  const command = new PutObjectCommand({
    Bucket: BUCKET_NAME,
    Key: key,
    ContentType: contentType,
  });

  try {
    const url = await getSignedUrl(r2Client, command, { expiresIn });
    return url;
  } catch (error) {
    logger.error(' Failed to generate upload URL:', error);
    throw error;
  }
}

// Generate pre-signed URL for file download
export async function generateDownloadUrl(
  key: string,
  expiresIn: number = 3600
): Promise<string> {
  const command = new GetObjectCommand({
    Bucket: BUCKET_NAME,
    Key: key,
  });

  try {
    const url = await getSignedUrl(r2Client, command, { expiresIn });
    return url;
  } catch (error) {
    logger.error(' Failed to generate download URL:', error);
    throw error;
  }
}

// Get file data as Buffer for processing
export async function getFileBuffer(key: string): Promise<Buffer> {
  const command = new GetObjectCommand({
    Bucket: BUCKET_NAME,
    Key: key,
  });

  try {
    const response = await (r2Client as any).send(command);
    
    if (!response.Body) {
      throw new Error(`File not found: ${key}`);
    }

    // Convert ReadableStream to Buffer
    const chunks: Uint8Array[] = [];
    const reader = response.Body.transformToWebStream().getReader();
    
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      chunks.push(value);
    }
    
    return Buffer.concat(chunks);
  } catch (error) {
    logger.error(` Failed to get file buffer for ${key}:`, error);
    throw error;
  }
}

// Delete file from R2
export async function deleteFile(key: string): Promise<void> {
  const command = new DeleteObjectCommand({
    Bucket: BUCKET_NAME,
    Key: key,
  });

  try {
    await (r2Client as any).send(command);
    logger.log(` Deleted file: ${key}`);
  } catch (error) {
    logger.error(` Failed to delete file ${key}:`, error);
    throw error;
  }
}

// Generate S3 key with proper organization - EXTENDED for video/image
export function generateS3Key(
  userId: string, 
  fileName: string, 
  fileType: 'midi' | 'audio' | 'video' | 'image'
): string {
  const timestamp = Date.now();
  const sanitizedFileName = fileName.replace(/[^a-zA-Z0-9.-]/g, '_');
  return `${fileType}/${userId}/${timestamp}_${sanitizedFileName}`;
}

// Generate thumbnail key for processed media
export function generateThumbnailKey(originalKey: string): string {
  const lastDotIndex = originalKey.lastIndexOf('.');
  const baseKey = lastDotIndex > -1 ? originalKey.substring(0, lastDotIndex) : originalKey;
  return `${baseKey}_thumb.jpg`;
}

// Upload thumbnail to R2
export async function uploadThumbnail(
  thumbnailKey: string,
  thumbnailBuffer: Buffer
): Promise<string> {
  const command = new PutObjectCommand({
    Bucket: BUCKET_NAME,
    Key: thumbnailKey,
    Body: thumbnailBuffer,
    ContentType: 'image/jpeg',
    CacheControl: 'public, max-age=31536000', // 1 year cache
  });

  try {
    await (r2Client as any).send(command);
    return thumbnailKey;
  } catch (error) {
    logger.error(' Failed to upload thumbnail:', error);
    throw error;
  }
}

// Generate download URL for thumbnails
export async function generateThumbnailUrl(
  thumbnailKey: string,
  expiresIn: number = 3600
): Promise<string> {
  try {
    const url = await generateDownloadUrl(thumbnailKey, expiresIn);
    return url;
  } catch (error) {
    logger.error(' Failed to generate thumbnail URL:', error);
    throw error;
  }
}

// Initialize R2 service
export async function initializeR2(): Promise<void> {
  logger.log(' Initializing Cloudflare R2 service...');
  
  try {
    validateR2Config();
    await createBucketIfNotExists();
    
    // Try to configure CORS, but don't fail if permissions are insufficient
    try {
      await configureBucketCors();
    } catch (corsError: any) {
      if (corsError.Code === 'AccessDenied') {
        logger.log('  CORS configuration skipped (insufficient permissions - this is OK for development)');
      } else {
        throw corsError;
      }
    }
    
    logger.log(' R2 service initialized successfully');
  } catch (error) {
    logger.error(' Failed to initialize R2 service:', error);
    throw error;
  }
}

// Test R2 connectivity
export async function testR2Connection(): Promise<boolean> {
  try {
    await (r2Client as any).send(new HeadBucketCommand({ Bucket: BUCKET_NAME }));
    return true;
  } catch (error) {
    logger.error(' R2 connection test failed:', error);
    return false;
  }
}

// Legacy compatibility - export as s3Client for existing code
export { r2Client as s3Client };
export { initializeR2 as initializeS3 };
export { testR2Connection as testS3Connection };
export { validateR2Config as validateS3Config };
</file>

<file path="services/stem-processor.ts">
import { createClient } from '@supabase/supabase-js';
import { getFileBuffer, generateS3Key, r2Client, BUCKET_NAME } from './r2-storage';
import { PutObjectCommand } from '@aws-sdk/client-s3';
import { spawn } from 'child_process';
import { randomUUID } from 'crypto';
import path from 'path';
import fs from 'fs';
import { logger } from '../lib/logger';

// Initialize Supabase client
const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

export interface StemProcessingResult {
  success: boolean;
  error?: string;
  stems?: {
    drums: string;
    bass: string;
    vocals: string;
    other: string;
  };
  processingDuration?: number;
}

export class StemProcessor {
  private static readonly SPLEETER_IMAGE = 'deezer/spleeter:3.8';
  private static readonly OUTPUT_DIR = '/tmp/stems';

  /**
   * Process audio file and separate into stems
   */
  static async processStemSeparation(
    fileMetadataId: string,
    userId: string
  ): Promise<StemProcessingResult> {
    try {
      // Get file metadata
      const { data: fileMetadata, error: fetchError } = await supabase
        .from('file_metadata')
        .select('*')
        .eq('id', fileMetadataId)
        .single();

      if (fetchError || !fileMetadata) {
        throw new Error('File metadata not found');
      }

      // Create stem separation record
      const { data: stemRecord, error: createError } = await supabase
        .from('stem_separations')
        .insert({
          user_id: userId,
          file_metadata_id: fileMetadataId,
          status: 'processing'
        })
        .select()
        .single();

      if (createError) {
        throw new Error('Failed to create stem separation record');
      }

      // Get file from R2
      const fileBuffer = await getFileBuffer(fileMetadata.s3_key);
      
      // Create temporary directory for processing
      const processingId = randomUUID();
      const processingDir = path.join(this.OUTPUT_DIR, processingId);
      fs.mkdirSync(processingDir, { recursive: true });

      // Write file to temp directory
      const inputPath = path.join(processingDir, 'input.wav');
      fs.writeFileSync(inputPath, fileBuffer);

      // Process with Spleeter
      const startTime = Date.now();
      await this.runSpleeter(inputPath, processingDir);
      const processingDuration = Math.round((Date.now() - startTime) / 1000);

      // Upload stems to R2 and create file metadata records
      const uploadedStems = await this.uploadStems(processingDir, userId, { project_id: fileMetadata.project_id });

      // Prepare the stem keys for the database update
      const stemKeysForDb = {
        drums: uploadedStems.drums?.s3Key,
        bass: uploadedStems.bass?.s3Key,
        vocals: uploadedStems.vocals?.s3Key,
        other: uploadedStems.other?.s3Key,
      };

      // Update stem separation record
      const { error: updateError } = await supabase
        .from('stem_separations')
        .update({
          status: 'completed',
          drums_stem_key: stemKeysForDb.drums,
          bass_stem_key: stemKeysForDb.bass,
          vocals_stem_key: stemKeysForDb.vocals,
          other_stem_key: stemKeysForDb.other,
          processing_duration: processingDuration
        })
        .eq('id', stemRecord.id);

      if (updateError) {
        throw new Error('Failed to update stem separation record');
      }

      // Clean up
      fs.rmSync(processingDir, { recursive: true, force: true });

      return {
        success: true,
        stems: {
          drums: stemKeysForDb.drums || '',
          bass: stemKeysForDb.bass || '',
          vocals: stemKeysForDb.vocals || '',
          other: stemKeysForDb.other || '',
        },
        processingDuration
      };

    } catch (error) {
      logger.error('Stem separation failed:', error);

      // Update record with error
      await supabase
        .from('stem_separations')
        .update({
          status: 'failed',
          error_message: error instanceof Error ? error.message : 'Unknown error'
        })
        .eq('id', fileMetadataId);

      return {
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error'
      };
    }
  }

  /**
   * Run Spleeter in Docker container
   */
  private static async runSpleeter(inputPath: string, outputDir: string): Promise<void> {
    return new Promise((resolve, reject) => {
      const spleeter = spawn('docker', [
        'run',
        '--platform=linux/amd64', // For M1/M2 compatibility
        '--rm',
        '-v', `${inputPath}:/input.wav`,
        '-v', `${outputDir}:/output`,
        this.SPLEETER_IMAGE,
        'separate',
        '-p', 'spleeter:4stems',
        '-o', '/output',
        '/input.wav'
      ]);

      let errorOutput = '';

      spleeter.stdout.on('data', (data) => {
        logger.log(`Spleeter output: ${data}`);
      });

      spleeter.stderr.on('data', (data) => {
        errorOutput += data.toString();
        logger.error(`Spleeter error: ${data}`);
      });

      spleeter.on('close', (code) => {
        if (code === 0) {
          resolve();
        } else {
          reject(new Error(`Spleeter failed with code ${code}: ${errorOutput}`));
        }
      });
    });
  }

  /**
   * Upload stems to R2 storage and create metadata records for them.
   */
  private static async uploadStems(
    processingDir: string,
    userId: string,
    originalFile: { project_id?: string }
  ): Promise<{
    drums?: { s3Key: string; fileId: string };
    bass?: { s3Key: string; fileId: string };
    vocals?: { s3Key: string; fileId: string };
    other?: { s3Key: string; fileId: string };
  }> {
    const upload = async (type: string) => {
      try {
        return await this.uploadStem(processingDir, `${type}.wav`, userId, originalFile.project_id);
      } catch (error) {
        logger.warn(`Could not process stem type ${type}:`, error);
        return undefined;
      }
    };

    const [drums, bass, vocals, other] = await Promise.all([
      upload('drums'),
      upload('bass'),
      upload('vocals'),
      upload('other'),
    ]);

    return { drums, bass, vocals, other };
  }

  /**
   * Upload a single stem file to R2 and create its metadata record
   */
  private static async uploadStem(
    processingDir: string,
    stemFile: string,
    userId: string,
    projectId?: string
  ): Promise<{ s3Key: string, fileId: string }> {
    const stemPath = path.join(processingDir, 'input', stemFile);
    if (!fs.existsSync(stemPath)) {
      throw new Error(`Stem file not found at ${stemPath}`);
    }
    
    const stemBuffer = fs.readFileSync(stemPath);
    const s3Key = generateS3Key(userId, stemFile, 'audio');

    const command = new PutObjectCommand({
      Bucket: BUCKET_NAME,
      Key: s3Key,
      Body: stemBuffer,
      ContentType: 'audio/wav'
    });

    await r2Client.send(command);

    // Create file metadata record for the stem
    const { data: newFile, error: createError } = await supabase
      .from('file_metadata')
      .insert({
        user_id: userId,
        project_id: projectId,
        file_name: stemFile,
        file_type: 'audio',
        mime_type: 'audio/wav',
        file_size: stemBuffer.length,
        s3_key: s3Key,
        s3_bucket: BUCKET_NAME,
        upload_status: 'completed',
        processing_status: 'pending', // Set to pending for client-side analysis
        stem_type: stemFile.replace('.wav', '')
      })
      .select('id')
      .single();

    if (createError) {
      throw new Error(`Failed to create file metadata for stem ${stemFile}: ${createError.message}`);
    }

    return { s3Key, fileId: newFile.id };
  }
}
</file>

<file path="services/stem-separator.ts">
import { z } from 'zod';
import { randomUUID } from 'crypto';
import { getFileBuffer } from './r2-storage';
import { spawn } from 'child_process';
import { join } from 'path';
import { promises as fs } from 'fs';
import { logger } from '../lib/logger';

// Validation schema for stem separation config
export const StemSeparationConfigSchema = z.object({
  model: z.literal('spleeter'),
  modelVariant: z.enum(['2stems', '4stems', '5stems']),
  stems: z.object({
    drums: z.boolean().optional(),
    bass: z.boolean().optional(),
    vocals: z.boolean().default(true),
    other: z.boolean().default(true),
    piano: z.boolean().optional(),
  }),
  quality: z.object({
    sampleRate: z.enum(['44100', '48000']).default('44100'),
    outputFormat: z.enum(['wav', 'mp3']).default('wav'),
    bitrate: z.number().optional(),
  }),
});

export type StemSeparationConfig = z.infer<typeof StemSeparationConfigSchema>;

export interface StemSeparationJob {
  id: string;
  status: 'queued' | 'processing' | 'completed' | 'failed';
  config: StemSeparationConfig;
  progress: number;
  estimatedTimeRemaining?: number;
  results?: {
    stems: Record<string, string>; // URLs to separated stems
  };
  error?: string;
}

export class StemSeparator {
  private static jobs = new Map<string, StemSeparationJob>();

  /**
   * Create a new stem separation job
   */
  static createJob(config: StemSeparationConfig): StemSeparationJob {
    const job: StemSeparationJob = {
      id: randomUUID(),
      status: 'queued',
      config,
      progress: 0,
    };

    this.jobs.set(job.id, job);
    return job;
  }

  /**
   * Get job status
   */
  static getJob(jobId: string): StemSeparationJob | undefined {
    return this.jobs.get(jobId);
  }

  /**
   * Process audio file using Spleeter
   */
  static async processStem(
    jobId: string,
    fileKey: string,
    outputDir: string
  ): Promise<void> {
    const job = this.jobs.get(jobId);
    if (!job) throw new Error('Job not found');

    try {
      job.status = 'processing';
      this.jobs.set(jobId, job);

      // Get file buffer from storage
      const buffer = await getFileBuffer(fileKey);

      // Create temporary input file
      const inputPath = join(outputDir, 'input.wav');
      const outputPath = join(outputDir, 'output');

      // Write buffer to temporary file
      await fs.writeFile(inputPath, buffer);

      // Run Spleeter in Docker
      await new Promise<void>((resolve, reject) => {
        const docker = spawn('docker', [
          'run',
          '--rm',
          '-v', `${outputDir}:/app/input`,
          '-v', `${outputDir}:/app/output`,
          'spleeter',
          'python',
          'process-audio.py',
          '--model', job.config.modelVariant,
          '--output-format', job.config.quality.outputFormat,
          '--sample-rate', job.config.quality.sampleRate,
        ]);

        docker.stdout.on('data', (data) => {
          logger.log(`Spleeter stdout: ${data}`);
          // Update progress based on output
          if (data.toString().includes('Progress')) {
            const match = data.toString().match(/Progress: (\d+)%/);
            if (match) {
              job.progress = parseInt(match[1], 10);
              this.jobs.set(jobId, job);
            }
          }
        });

        docker.stderr.on('data', (data) => {
          logger.error(`Spleeter stderr: ${data}`);
        });

        docker.on('close', (code) => {
          if (code === 0) {
            resolve();
          } else {
            reject(new Error(`Spleeter process exited with code ${code}`));
          }
        });
      });

      // Update job with results
      job.status = 'completed';
      job.progress = 100;
      job.results = {
        stems: {
          // Add stem file paths based on config
          vocals: join(outputPath, 'vocals.wav'),
          other: join(outputPath, 'accompaniment.wav'),
          ...(job.config.stems.drums && { drums: join(outputPath, 'drums.wav') }),
          ...(job.config.stems.bass && { bass: join(outputPath, 'bass.wav') }),
          ...(job.config.stems.piano && { piano: join(outputPath, 'piano.wav') }),
        },
      };

      this.jobs.set(jobId, job);

    } catch (error) {
      job.status = 'failed';
      job.error = error instanceof Error ? error.message : 'Unknown error';
      this.jobs.set(jobId, job);
      throw error;
    }
  }
}
</file>

<file path="services/supabase-storage.ts">

</file>

<file path="test/helpers/test-supabase.ts">
import { createClient } from '@supabase/supabase-js'

export function createTestSupabaseClient() {
  return createClient(
    process.env.SUPABASE_URL || 'http://localhost:54321',
    process.env.SUPABASE_ANON_KEY || 'test-key',
    {
      auth: {
        autoRefreshToken: false,
        persistSession: false
      }
    }
  )
}
</file>

<file path="test/asset-management.test.ts">
import { describe, it, expect, beforeEach, afterEach } from 'vitest'
import { AssetManager } from '../services/asset-manager'
import { createTestSupabaseClient } from './helpers/test-supabase'

describe('AssetManager', () => {
  let assetManager: AssetManager
  let testSupabase: any

  beforeEach(async () => {
    testSupabase = createTestSupabaseClient()
    assetManager = new AssetManager(testSupabase)
  })

  afterEach(async () => {
    // Clean up test data
    await testSupabase.from('asset_usage').delete().neq('id', '00000000-0000-0000-0000-000000000000')
    await testSupabase.from('asset_tag_relationships').delete().neq('id', '00000000-0000-0000-0000-000000000000')
    await testSupabase.from('asset_tags').delete().neq('id', '00000000-0000-0000-0000-000000000000')
    await testSupabase.from('asset_folders').delete().neq('id', '00000000-0000-0000-0000-000000000000')
    await testSupabase.from('project_storage_quotas').delete().neq('project_id', 'test')
    await testSupabase.from('file_metadata').delete().neq('id', '00000000-0000-0000-0000-000000000000')
    await testSupabase.from('projects').delete().neq('id', 'test')
  })

  describe('Asset Usage Tracking', () => {
    it('should start usage tracking for a file', async () => {
      // Create test project and file
      const projectId = 'test-project-1'
      const fileId = 'test-file-1'
      
      await testSupabase.from('projects').insert({
        id: projectId,
        user_id: 'test-user',
        name: 'Test Project'
      })

      await testSupabase.from('file_metadata').insert({
        id: fileId,
        user_id: 'test-user',
        project_id: projectId,
        file_name: 'test.mid',
        file_type: 'midi',
        mime_type: 'audio/midi',
        file_size: 1024,
        s3_key: 'test-key',
        s3_bucket: 'test-bucket',
        upload_status: 'completed'
      })

      const usageId = await assetManager.startUsageTracking(
        fileId,
        projectId,
        'visualizer',
        { settings: { tempo: 120 } }
      )

      expect(usageId).toBeDefined()

      // Verify usage record was created
      const { data: usage } = await testSupabase
        .from('asset_usage')
        .select('*')
        .eq('id', usageId)
        .single()

      expect(usage).toBeDefined()
      expect(usage.file_id).toBe(fileId)
      expect(usage.project_id).toBe(projectId)
      expect(usage.usage_type).toBe('visualizer')
      expect(usage.usage_context).toEqual({ settings: { tempo: 120 } })
      expect(usage.ended_at).toBeNull()

      // Verify file usage status was updated
      const { data: file } = await testSupabase
        .from('file_metadata')
        .select('usage_status, last_used_at')
        .eq('id', fileId)
        .single()

      expect(file.usage_status).toBe('active')
      expect(file.last_used_at).toBeDefined()
    })

    it('should end usage tracking', async () => {
      // Create test usage record
      const usageId = 'test-usage-1'
      await testSupabase.from('asset_usage').insert({
        id: usageId,
        file_id: 'test-file-1',
        project_id: 'test-project-1',
        usage_type: 'visualizer',
        usage_context: {},
        started_at: new Date().toISOString()
      })

      await assetManager.endUsageTracking(usageId)

      // Verify usage record was updated
      const { data: usage } = await testSupabase
        .from('asset_usage')
        .select('ended_at')
        .eq('id', usageId)
        .single()

      expect(usage.ended_at).toBeDefined()
    })

    it('should update file usage status', async () => {
      const fileId = 'test-file-1'
      await testSupabase.from('file_metadata').insert({
        id: fileId,
        user_id: 'test-user',
        project_id: 'test-project-1',
        file_name: 'test.mid',
        file_type: 'midi',
        mime_type: 'audio/midi',
        file_size: 1024,
        s3_key: 'test-key',
        s3_bucket: 'test-bucket',
        upload_status: 'completed'
      })

      await assetManager.updateFileUsageStatus(fileId, 'referenced')

      const { data: file } = await testSupabase
        .from('file_metadata')
        .select('usage_status, last_used_at')
        .eq('id', fileId)
        .single()

      expect(file.usage_status).toBe('referenced')
      expect(file.last_used_at).toBeDefined()
    })

    it('should get asset usage history', async () => {
      const fileId = 'test-file-1'
      const projectId = 'test-project-1'

      // Create test usage records
      await testSupabase.from('asset_usage').insert([
        {
          file_id: fileId,
          project_id: projectId,
          usage_type: 'visualizer',
          usage_context: { session: 1 },
          started_at: new Date(Date.now() - 1000).toISOString(),
          ended_at: new Date().toISOString()
        },
        {
          file_id: fileId,
          project_id: projectId,
          usage_type: 'composition',
          usage_context: { session: 2 },
          started_at: new Date().toISOString()
        }
      ])

      const usage = await assetManager.getAssetUsage(fileId, projectId)

      expect(usage).toHaveLength(2)
      expect(usage[0].usageType).toBe('composition') // Most recent first
      expect(usage[1].usageType).toBe('visualizer')
    })
  })

  describe('Storage Quota Management', () => {
    it('should get storage quota for project', async () => {
      const projectId = 'test-project-1'

      // Create test quota
      await testSupabase.from('project_storage_quotas').insert({
        project_id: projectId,
        user_subscription_tier: 'free',
        total_limit_bytes: 104857600,
        used_bytes: 52428800,
        file_count_limit: 10,
        file_count_used: 5,
        per_file_size_limit: 52428800
      })

      const quota = await assetManager.getStorageQuota(projectId)

      expect(quota.projectId).toBe(projectId)
      expect(quota.userSubscriptionTier).toBe('free')
      expect(quota.totalLimitBytes).toBe(104857600)
      expect(quota.usedBytes).toBe(52428800)
      expect(quota.fileCountLimit).toBe(10)
      expect(quota.fileCountUsed).toBe(5)
    })

    it('should check storage quota before upload', async () => {
      const projectId = 'test-project-1'

      // Create test quota with limited space
      await testSupabase.from('project_storage_quotas').insert({
        project_id: projectId,
        user_subscription_tier: 'free',
        total_limit_bytes: 104857600, // 100MB
        used_bytes: 94371840, // 90MB used
        file_count_limit: 10,
        file_count_used: 5,
        per_file_size_limit: 52428800
      })

      // Check if 20MB file can be uploaded
      const result = await assetManager.checkStorageQuota(projectId, 20 * 1024 * 1024)

      expect(result.allowed).toBe(false)
      expect(result.reason).toContain('Storage limit exceeded')
    })

    it('should allow upload within quota limits', async () => {
      const projectId = 'test-project-1'

      await testSupabase.from('project_storage_quotas').insert({
        project_id: projectId,
        user_subscription_tier: 'free',
        total_limit_bytes: 104857600,
        used_bytes: 52428800,
        file_count_limit: 10,
        file_count_used: 5,
        per_file_size_limit: 52428800
      })

      const result = await assetManager.checkStorageQuota(projectId, 10 * 1024 * 1024)

      expect(result.allowed).toBe(true)
    })
  })

  describe('Asset Organization', () => {
    it('should create asset folder', async () => {
      const projectId = 'test-project-1'
      await testSupabase.from('projects').insert({
        id: projectId,
        user_id: 'test-user',
        name: 'Test Project'
      })

      const folder = await assetManager.createFolder(
        projectId,
        'Test Folder',
        'Test description'
      )

      expect(folder.projectId).toBe(projectId)
      expect(folder.name).toBe('Test Folder')
      expect(folder.description).toBe('Test description')
      expect(folder.id).toBeDefined()
    })

    it('should get asset folders for project', async () => {
      const projectId = 'test-project-1'
      await testSupabase.from('projects').insert({
        id: projectId,
        user_id: 'test-user',
        name: 'Test Project'
      })

      // Create test folders
      await testSupabase.from('asset_folders').insert([
        {
          project_id: projectId,
          name: 'Folder 1',
          description: 'First folder'
        },
        {
          project_id: projectId,
          name: 'Folder 2',
          description: 'Second folder'
        }
      ])

      const folders = await assetManager.getFolders(projectId)

      expect(folders).toHaveLength(2)
      expect(folders[0].name).toBe('Folder 1')
      expect(folders[1].name).toBe('Folder 2')
    })

    it('should create asset tag', async () => {
      const projectId = 'test-project-1'
      await testSupabase.from('projects').insert({
        id: projectId,
        user_id: 'test-user',
        name: 'Test Project'
      })

      const tag = await assetManager.createTag(
        projectId,
        'Test Tag',
        '#FF0000'
      )

      expect(tag.projectId).toBe(projectId)
      expect(tag.name).toBe('Test Tag')
      expect(tag.color).toBe('#FF0000')
      expect(tag.id).toBeDefined()
    })

    it('should get asset tags for project', async () => {
      const projectId = 'test-project-1'
      await testSupabase.from('projects').insert({
        id: projectId,
        user_id: 'test-user',
        name: 'Test Project'
      })

      // Create test tags
      await testSupabase.from('asset_tags').insert([
        {
          project_id: projectId,
          name: 'Tag 1',
          color: '#FF0000'
        },
        {
          project_id: projectId,
          name: 'Tag 2',
          color: '#00FF00'
        }
      ])

      const tags = await assetManager.getTags(projectId)

      expect(tags).toHaveLength(2)
      expect(tags[0].name).toBe('Tag 1')
      expect(tags[1].name).toBe('Tag 2')
    })

    it('should add and remove tags from files', async () => {
      const fileId = 'test-file-1'
      const tagId = 'test-tag-1'

      // Create test file and tag
      await testSupabase.from('file_metadata').insert({
        id: fileId,
        user_id: 'test-user',
        project_id: 'test-project-1',
        file_name: 'test.mid',
        file_type: 'midi',
        mime_type: 'audio/midi',
        file_size: 1024,
        s3_key: 'test-key',
        s3_bucket: 'test-bucket',
        upload_status: 'completed'
      })

      await testSupabase.from('asset_tags').insert({
        id: tagId,
        project_id: 'test-project-1',
        name: 'Test Tag',
        color: '#FF0000'
      })

      // Add tag to file
      await assetManager.addTagToFile(fileId, tagId)

      let fileTags = await assetManager.getFileTags(fileId)
      expect(fileTags).toHaveLength(1)
      expect(fileTags[0].id).toBe(tagId)

      // Remove tag from file
      await assetManager.removeTagFromFile(fileId, tagId)

      fileTags = await assetManager.getFileTags(fileId)
      expect(fileTags).toHaveLength(0)
    })
  })

  describe('Asset Replacement', () => {
    it('should replace asset while preserving metadata', async () => {
      const oldFileId = 'old-file-1'
      const newFileId = 'new-file-1'
      const tagId = 'test-tag-1'

      // Create test files
      await testSupabase.from('file_metadata').insert([
        {
          id: oldFileId,
          user_id: 'test-user',
          project_id: 'test-project-1',
          file_name: 'old.mid',
          file_type: 'midi',
          mime_type: 'audio/midi',
          file_size: 1024,
          s3_key: 'old-key',
          s3_bucket: 'test-bucket',
          upload_status: 'completed',
          asset_type: 'midi',
          is_primary: true,
          usage_status: 'active',
          folder_id: 'test-folder-1'
        },
        {
          id: newFileId,
          user_id: 'test-user',
          project_id: 'test-project-1',
          file_name: 'new.mid',
          file_type: 'midi',
          mime_type: 'audio/midi',
          file_size: 2048,
          s3_key: 'new-key',
          s3_bucket: 'test-bucket',
          upload_status: 'completed'
        }
      ])

      // Create test tag and add to old file
      await testSupabase.from('asset_tags').insert({
        id: tagId,
        project_id: 'test-project-1',
        name: 'Test Tag',
        color: '#FF0000'
      })

      await testSupabase.from('asset_tag_relationships').insert({
        file_id: oldFileId,
        tag_id: tagId
      })

      // Replace asset
      await assetManager.replaceAsset(oldFileId, newFileId, true)

      // Verify new file has old file's metadata
      const { data: newFile } = await testSupabase
        .from('file_metadata')
        .select('*')
        .eq('id', newFileId)
        .single()

      expect(newFile.asset_type).toBe('midi')
      expect(newFile.is_primary).toBe(true)
      expect(newFile.usage_status).toBe('active')
      expect(newFile.folder_id).toBe('test-folder-1')
      expect(newFile.replacement_history).toContain(oldFileId)

      // Verify new file has the tag
      const newFileTags = await assetManager.getFileTags(newFileId)
      expect(newFileTags).toHaveLength(1)
      expect(newFileTags[0].id).toBe(tagId)

      // Verify old file is marked as unused
      const { data: oldFile } = await testSupabase
        .from('file_metadata')
        .select('usage_status, is_primary')
        .eq('id', oldFileId)
        .single()

      expect(oldFile.usage_status).toBe('unused')
      expect(oldFile.is_primary).toBe(false)
    })
  })
})
</file>

<file path="test/basic.test.ts">
import { describe, it, expect } from 'vitest'

describe('Backend Tests', () => {
  it('should pass basic test', () => {
    expect(1 + 1).toBe(2)
  })

  it('should have Node.js environment', () => {
    expect(typeof process).toBe('object')
    expect(process.version).toBeDefined()
  })
})
</file>

<file path="test/basic.test.ts">
import { describe, it, expect } from 'vitest'

describe('Backend Tests', () => {
  it('should pass basic test', () => {
    expect(1 + 1).toBe(2)
  })

  it('should have Node.js environment', () => {
    expect(typeof process).toBe('object')
    expect(process.version).toBeDefined()
  })
})
</file>

<file path="test/database-schema.test.ts">
import { describe, it, expect } from 'vitest';

describe('Database Schema Validation', () => {
  describe('MIDI Files Table Schema', () => {
    it('should have all required columns for MIDI processing', () => {
      // Test data structure that matches our expected schema
      const sampleMidiFile = {
        id: 'uuid-string',
        user_id: 'user-uuid',
        file_key: 'midi/user-id/123_song.mid',
        original_filename: 'song.mid',
        file_size: 1024,
        duration_seconds: 120.5,
        track_count: 4,
        note_count: 500,
        time_signature: '4/4',
        key_signature: 'C major',
        tempo_bpm: 120,
        parsing_status: 'completed',
        parsed_data: {
          file: {
            name: 'song.mid',
            size: 1024,
            duration: 120.5,
            ticksPerQuarter: 480,
            timeSignature: [4, 4],
            keySignature: 'C major'
          },
          tracks: [],
          tempoChanges: []
        },
        error_message: null,
        created_at: new Date().toISOString(),
        updated_at: new Date().toISOString()
      };

      // Verify all expected fields are present
      expect(sampleMidiFile).toHaveProperty('id');
      expect(sampleMidiFile).toHaveProperty('user_id');
      expect(sampleMidiFile).toHaveProperty('file_key');
      expect(sampleMidiFile).toHaveProperty('original_filename');
      expect(sampleMidiFile).toHaveProperty('file_size');
      expect(sampleMidiFile).toHaveProperty('duration_seconds');
      expect(sampleMidiFile).toHaveProperty('track_count');
      expect(sampleMidiFile).toHaveProperty('note_count');
      expect(sampleMidiFile).toHaveProperty('time_signature');
      expect(sampleMidiFile).toHaveProperty('key_signature');
      expect(sampleMidiFile).toHaveProperty('tempo_bpm');
      expect(sampleMidiFile).toHaveProperty('parsing_status');
      expect(sampleMidiFile).toHaveProperty('parsed_data');
      expect(sampleMidiFile).toHaveProperty('error_message');
      expect(sampleMidiFile).toHaveProperty('created_at');
      expect(sampleMidiFile).toHaveProperty('updated_at');
    });

    it('should validate parsing status enum values', () => {
      const validStatuses = ['pending', 'completed', 'failed'];
      
      validStatuses.forEach(status => {
        expect(['pending', 'completed', 'failed']).toContain(status);
      });
    });

    it('should validate parsed_data structure', () => {
      const sampleParsedData = {
        file: {
          name: 'test.mid',
          size: 1024,
          duration: 60,
          ticksPerQuarter: 480,
          timeSignature: [4, 4],
          keySignature: 'C major'
        },
        tracks: [
          {
            id: 'track-1',
            name: 'Piano',
            instrument: 'Acoustic Grand Piano',
            channel: 0,
            notes: [],
            color: '#84a98c'
          }
        ],
        tempoChanges: [
          {
            tick: 0,
            bpm: 120,
            microsecondsPerQuarter: 500000
          }
        ]
      };

      expect(sampleParsedData.file).toHaveProperty('name');
      expect(sampleParsedData.file).toHaveProperty('duration');
      expect(sampleParsedData.file).toHaveProperty('ticksPerQuarter');
      expect(sampleParsedData).toHaveProperty('tracks');
      expect(sampleParsedData).toHaveProperty('tempoChanges');
      expect(Array.isArray(sampleParsedData.tracks)).toBe(true);
      expect(Array.isArray(sampleParsedData.tempoChanges)).toBe(true);
    });
  });

  describe('Visualization Settings Table Schema', () => {
    it('should have all required columns for visualization preferences', () => {
      const sampleVisualizationSettings = {
        id: 'uuid-string',
        user_id: 'user-uuid',
        midi_file_id: 'midi-file-uuid',
        color_scheme: 'mixed',
        pixels_per_second: 50,
        show_track_labels: true,
        show_velocity: true,
        min_key: 21,
        max_key: 108,
        created_at: new Date().toISOString(),
        updated_at: new Date().toISOString()
      };

      // Verify all expected fields are present
      expect(sampleVisualizationSettings).toHaveProperty('id');
      expect(sampleVisualizationSettings).toHaveProperty('user_id');
      expect(sampleVisualizationSettings).toHaveProperty('midi_file_id');
      expect(sampleVisualizationSettings).toHaveProperty('color_scheme');
      expect(sampleVisualizationSettings).toHaveProperty('pixels_per_second');
      expect(sampleVisualizationSettings).toHaveProperty('show_track_labels');
      expect(sampleVisualizationSettings).toHaveProperty('show_velocity');
      expect(sampleVisualizationSettings).toHaveProperty('min_key');
      expect(sampleVisualizationSettings).toHaveProperty('max_key');
      expect(sampleVisualizationSettings).toHaveProperty('created_at');
      expect(sampleVisualizationSettings).toHaveProperty('updated_at');
    });

    it('should validate color scheme enum values', () => {
      const validColorSchemes = ['sage', 'slate', 'dusty-rose', 'mixed'];
      
      validColorSchemes.forEach(scheme => {
        expect(['sage', 'slate', 'dusty-rose', 'mixed']).toContain(scheme);
      });
    });

    it('should validate pixels per second range', () => {
      const testValues = [
        { value: 10, valid: true },
        { value: 50, valid: true },
        { value: 200, valid: true },
        { value: 5, valid: false },   // Too low
        { value: 250, valid: false }  // Too high
      ];

      testValues.forEach(({ value, valid }) => {
        const isValid = value >= 10 && value <= 200;
        expect(isValid).toBe(valid);
      });
    });

    it('should validate MIDI key range', () => {
      const testKeys = [
        { min: 21, max: 108, valid: true },
        { min: 0, max: 127, valid: true },
        { min: 60, max: 72, valid: true },
        { min: 108, max: 21, valid: false }, // Invalid range
        { min: -1, max: 127, valid: false }, // Below minimum
        { min: 0, max: 128, valid: false }   // Above maximum
      ];

      testKeys.forEach(({ min, max, valid }) => {
        const isValidRange = min >= 0 && max <= 127 && min <= max;
        expect(isValidRange).toBe(valid);
      });
    });
  });

  describe('Data Relationships', () => {
    it('should maintain referential integrity between tables', () => {
      // Sample data showing the relationship
      const midiFile = {
        id: 'midi-file-uuid',
        user_id: 'user-uuid'
      };

      const visualizationSettings = {
        id: 'settings-uuid',
        user_id: 'user-uuid',           // Must match MIDI file user
        midi_file_id: 'midi-file-uuid'  // Must reference existing MIDI file
      };

      // Verify foreign key relationships
      expect(visualizationSettings.user_id).toBe(midiFile.user_id);
      expect(visualizationSettings.midi_file_id).toBe(midiFile.id);
    });

    it('should ensure unique constraint on user/midi_file combination', () => {
      // Only one settings record per user per MIDI file
      const settings1 = {
        user_id: 'user-1',
        midi_file_id: 'midi-1',
        color_scheme: 'sage'
      };

      const settings2 = {
        user_id: 'user-1',
        midi_file_id: 'midi-1',  // Same combination - should be unique constraint violation
        color_scheme: 'slate'
      };

      // In a real database, this would violate the unique constraint
      expect(settings1.user_id).toBe(settings2.user_id);
      expect(settings1.midi_file_id).toBe(settings2.midi_file_id);
    });
  });

  describe('Index Coverage', () => {
    it('should have proper indexes for common query patterns', () => {
      // Verify we have indexes for common queries our API will perform
      const commonQueries = [
        'WHERE user_id = ?',                    // User's files
        'WHERE user_id = ? AND file_key = ?',   // Specific file lookup
        'WHERE parsing_status = ?',             // Status filtering
        'WHERE created_at > ?',                 // Time-based queries
        'WHERE midi_file_id = ?'                // Settings lookup
      ];

      // These represent the indexes we created in our schema
      const expectedIndexes = [
        'idx_midi_files_user_id',
        'idx_midi_files_file_key', 
        'idx_midi_files_parsing_status',
        'idx_midi_files_created_at',
        'idx_midi_files_user_file_key',
        'idx_visualization_settings_user_id',
        'idx_visualization_settings_midi_file_id',
        'idx_visualization_settings_user_midi_file'
      ];

      expect(expectedIndexes.length).toBeGreaterThan(0);
      expect(commonQueries.length).toBeGreaterThan(0);
    });
  });
});
</file>

<file path="test/database-security.test.ts">
import { describe, it, expect, beforeAll, afterAll, beforeEach, afterEach } from 'vitest';
import { supabaseAdmin } from '../lib/supabase';
import type { SupabaseClient } from '@supabase/supabase-js';
import { randomUUID } from 'crypto';

describe('Database Security and RLS Tests', () => {
  let supabase: SupabaseClient;
  let testUser1: any;
  let testUser2: any;
  let testProject: any;
  
  beforeAll(async () => {
    supabase = supabaseAdmin;
    
    // Create test users
    const { data: user1, error: error1 } = await supabase.auth.admin.createUser({
      email: 'test1@example.com',
      password: 'password123',
      user_metadata: { name: 'Test User 1' },
    });
    
    const { data: user2, error: error2 } = await supabase.auth.admin.createUser({
      email: 'test2@example.com',
      password: 'password123',
      user_metadata: { name: 'Test User 2' },
    });
    
    if (error1 || error2) {
      throw new Error(`Failed to create test users: ${error1?.message || error2?.message}`);
    }
    
    testUser1 = user1.user;
    testUser2 = user2.user;
  });

  afterAll(async () => {
    // Clean up test users
    if (testUser1) {
      await supabase.auth.admin.deleteUser(testUser1.id);
    }
    if (testUser2) {
      await supabase.auth.admin.deleteUser(testUser2.id);
    }
  });

  beforeEach(async () => {
    // Create a test project for user1
    const { data: project, error } = await supabase
      .from('projects')
      .insert({
        id: `test_proj_${randomUUID()}`,
        name: 'Test Project',
        user_id: testUser1.id,
        midi_file_path: '/test/midi/file.mid',
        render_configuration: { test: true },
      })
      .select()
      .single();
    
    if (error) {
      throw new Error(`Failed to create test project: ${error.message}`);
    }
    
    testProject = project;
  });

  afterEach(async () => {
    // Clean up test project
    if (testProject) {
      await supabase
        .from('projects')
        .delete()
        .eq('id', testProject.id);
    }
  });

  describe('Row Level Security (RLS) Policies', () => {
    it('should allow users to see only their own projects', async () => {
      // User1 should see their project
      const { data: user1Projects, error: error1 } = await supabase
        .from('projects')
        .select('*')
        .eq('user_id', testUser1.id);

      expect(error1).toBeNull();
      expect(user1Projects).toHaveLength(1);
      expect(user1Projects?.[0].id).toBe(testProject.id);

      // User2 should not see user1's project when querying all projects
      const { data: user2Projects, error: error2 } = await supabase
        .from('projects')
        .select('*');

      expect(error2).toBeNull();
      expect(user2Projects?.find(p => p.id === testProject.id)).toBeUndefined();
    });

    it('should prevent users from accessing other users projects directly', async () => {
      // User2 should not be able to access user1's project directly
      const { data: project, error } = await supabase
        .from('projects')
        .select('*')
        .eq('id', testProject.id)
        .single();

      // This should return null due to RLS filtering
      expect(project).toBeNull();
      expect(error?.code).toBe('PGRST116'); // No rows found
    });

    it('should allow users to create projects only for themselves', async () => {
      const projectId = `test_proj_${randomUUID()}`;
      
      // User2 should be able to create a project for themselves
      const { data: project, error } = await supabase
        .from('projects')
        .insert({
          id: projectId,
          name: 'User2 Project',
          user_id: testUser2.id,
          midi_file_path: '/test/midi/file2.mid',
          render_configuration: { test: true },
        })
        .select()
        .single();

      expect(error).toBeNull();
      expect(project?.user_id).toBe(testUser2.id);

      // Clean up
      await supabase.from('projects').delete().eq('id', projectId);
    });

    it('should prevent users from creating projects for other users', async () => {
      const projectId = `test_proj_${randomUUID()}`;
      
      // User2 should not be able to create a project for user1
      const { data: project, error } = await supabase
        .from('projects')
        .insert({
          id: projectId,
          name: 'Malicious Project',
          user_id: testUser1.id, // Trying to create for another user
          midi_file_path: '/test/midi/malicious.mid',
          render_configuration: { test: true },
        })
        .select()
        .single();

      expect(error).not.toBeNull();
      expect(project).toBeNull();
    });

    it('should allow users to update only their own projects', async () => {
      // User1 should be able to update their own project
      const { data: updatedProject, error: error1 } = await supabase
        .from('projects')
        .update({ name: 'Updated Project Name' })
        .eq('id', testProject.id)
        .select()
        .single();

      expect(error1).toBeNull();
      expect(updatedProject?.name).toBe('Updated Project Name');

      // User2 should not be able to update user1's project
      const { data: maliciousUpdate, error: error2 } = await supabase
        .from('projects')
        .update({ name: 'Malicious Update' })
        .eq('id', testProject.id)
        .select()
        .single();

      expect(maliciousUpdate).toBeNull();
      expect(error2?.code).toBe('PGRST116'); // No rows found/updated
    });

    it('should allow users to delete only their own projects', async () => {
      // Create another project for user1
      const { data: tempProject, error: createError } = await supabase
        .from('projects')
        .insert({
          id: `temp_proj_${randomUUID()}`,
          name: 'Temporary Project',
          user_id: testUser1.id,
          midi_file_path: '/test/midi/temp.mid',
          render_configuration: { test: true },
        })
        .select()
        .single();

      expect(createError).toBeNull();
      expect(tempProject).not.toBeNull();

      // User1 should be able to delete their own project
      const { data: deletedProject, error: deleteError } = await supabase
        .from('projects')
        .delete()
        .eq('id', tempProject.id)
        .select()
        .single();

      expect(deleteError).toBeNull();
      expect(deletedProject?.id).toBe(tempProject.id);

      // User2 should not be able to delete user1's main project
      const { data: maliciousDelete, error: maliciousError } = await supabase
        .from('projects')
        .delete()
        .eq('id', testProject.id)
        .select()
        .single();

      expect(maliciousDelete).toBeNull();
      expect(maliciousError?.code).toBe('PGRST116'); // No rows found/deleted
    });
  });

  describe('User Profile Security', () => {
    it('should allow users to view all user profiles', async () => {
      // Users should be able to view all profiles (for collaboration)
      const { data: profiles, error } = await supabase
        .from('user_profiles')
        .select('*');

      expect(error).toBeNull();
      expect(profiles).toBeInstanceOf(Array);
    });

    it('should allow users to manage only their own profile', async () => {
      // User1 should be able to update their own profile
      const { data: updatedProfile, error: error1 } = await supabase
        .from('user_profiles')
        .update({ display_name: 'Updated Name' })
        .eq('id', testUser1.id)
        .select()
        .single();

      expect(error1).toBeNull();
      expect(updatedProfile?.display_name).toBe('Updated Name');

      // User2 should not be able to update user1's profile
      const { data: maliciousUpdate, error: error2 } = await supabase
        .from('user_profiles')
        .update({ display_name: 'Malicious Update' })
        .eq('id', testUser1.id)
        .select()
        .single();

      expect(maliciousUpdate).toBeNull();
      expect(error2?.code).toBe('PGRST116'); // No rows found/updated
    });
  });

  describe('Project Collaborators Security', () => {
    it('should allow project owners to add collaborators', async () => {
      // User1 (owner) should be able to add user2 as collaborator
      const { data: collaborator, error } = await supabase
        .from('project_collaborators')
        .insert({
          project_id: testProject.id,
          user_id: testUser2.id,
          role: 'viewer',
        })
        .select()
        .single();

      expect(error).toBeNull();
      expect(collaborator?.project_id).toBe(testProject.id);
      expect(collaborator?.user_id).toBe(testUser2.id);
      expect(collaborator?.role).toBe('viewer');

      // Clean up
      await supabase
        .from('project_collaborators')
        .delete()
        .eq('id', collaborator.id);
    });

    it('should allow collaborators to view project details', async () => {
      // Add user2 as collaborator
      const { data: collaborator, error: collabError } = await supabase
        .from('project_collaborators')
        .insert({
          project_id: testProject.id,
          user_id: testUser2.id,
          role: 'viewer',
        })
        .select()
        .single();

      expect(collabError).toBeNull();

      // User2 should now be able to see the project
      const { data: project, error } = await supabase
        .from('projects')
        .select('*')
        .eq('id', testProject.id)
        .single();

      expect(error).toBeNull();
      expect(project?.id).toBe(testProject.id);

      // Clean up
      await supabase
        .from('project_collaborators')
        .delete()
        .eq('id', collaborator.id);
    });
  });

  describe('Audit Logs Security', () => {
    it('should allow users to view only their own audit logs', async () => {
      // Create audit log for user1
      await supabase.rpc('log_audit_event', {
        p_user_id: testUser1.id,
        p_action: 'test.action',
        p_resource_type: 'test',
        p_resource_id: 'test123',
        p_metadata: { test: true },
      });

      // User1 should see their own audit logs
      const { data: user1Logs, error: error1 } = await supabase
        .from('audit_logs')
        .select('*')
        .eq('user_id', testUser1.id);

      expect(error1).toBeNull();
      expect(user1Logs?.length).toBeGreaterThan(0);

      // User2 should not see user1's audit logs
      const { data: user2Logs, error: error2 } = await supabase
        .from('audit_logs')
        .select('*')
        .eq('user_id', testUser1.id);

      expect(error2).toBeNull();
      expect(user2Logs).toHaveLength(0); // RLS should filter out user1's logs
    });

    it('should allow system to insert audit logs', async () => {
      // System should be able to insert audit logs
      const { data: log, error } = await supabase
        .from('audit_logs')
        .insert({
          user_id: testUser1.id,
          action: 'system.test',
          resource_type: 'system',
          resource_id: 'system123',
          metadata: { system: true },
        })
        .select()
        .single();

      expect(error).toBeNull();
      expect(log?.action).toBe('system.test');
    });
  });

  describe('Database Functions', () => {
    it('should correctly identify user access to projects', async () => {
      // User1 should have access to their own project
      const { data: hasAccess1, error: error1 } = await supabase
        .rpc('user_can_access_project', {
          p_project_id: testProject.id,
          p_user_id: testUser1.id,
        });

      expect(error1).toBeNull();
      expect(hasAccess1).toBe(true);

      // User2 should not have access to user1's project
      const { data: hasAccess2, error: error2 } = await supabase
        .rpc('user_can_access_project', {
          p_project_id: testProject.id,
          p_user_id: testUser2.id,
        });

      expect(error2).toBeNull();
      expect(hasAccess2).toBe(false);
    });

    it('should log audit events correctly', async () => {
      const testAction = 'test.database.function';
      const testMetadata = { function: 'test', timestamp: Date.now() };

      // Log audit event
      const { error } = await supabase.rpc('log_audit_event', {
        p_user_id: testUser1.id,
        p_action: testAction,
        p_resource_type: 'test',
        p_resource_id: 'test456',
        p_metadata: testMetadata,
      });

      expect(error).toBeNull();

      // Verify audit log was created
      const { data: logs, error: fetchError } = await supabase
        .from('audit_logs')
        .select('*')
        .eq('user_id', testUser1.id)
        .eq('action', testAction)
        .order('created_at', { ascending: false })
        .limit(1);

      expect(fetchError).toBeNull();
      expect(logs).toHaveLength(1);
      expect(logs?.[0].action).toBe(testAction);
      expect(logs?.[0].metadata).toEqual(testMetadata);
    });
  });
});
</file>

<file path="test/file-upload-integration.test.ts">
import { describe, it, expect, beforeAll, afterAll, vi } from 'vitest'
import { createSupabaseServerClient } from '../lib/supabase'
import { appRouter } from '../routers'

// Mock AWS S3 for testing
vi.mock('../services/s3', () => ({
  generateUploadUrl: vi.fn().mockResolvedValue('https://mock-signed-url.com'),
  generateDownloadUrl: vi.fn().mockResolvedValue('https://mock-download-url.com'),
  deleteFile: vi.fn().mockResolvedValue(undefined),
  generateS3Key: vi.fn().mockReturnValue('mock/test/file_123.mid'),
}))

describe('File Upload Integration', () => {
  let mockUser: any
  let mockSupabase: any

  beforeAll(() => {
    // Mock authenticated user
    mockUser = {
      id: 'test-user-123',
      email: 'test@example.com',
      created_at: new Date().toISOString(),
    }

    // Mock Supabase client
    mockSupabase = {
      from: vi.fn().mockReturnValue({
        insert: vi.fn().mockResolvedValue({ error: null }),
        select: vi.fn().mockReturnValue({
          eq: vi.fn().mockReturnValue({
            single: vi.fn().mockResolvedValue({ 
              data: { id: 'file_123', s3_key: 'test/file.mid' }, 
              error: null 
            })
          })
        }),
        delete: vi.fn().mockResolvedValue({ error: null }),
        update: vi.fn().mockResolvedValue({ error: null }),
      }),
    }
  })

  it('should generate upload URL for valid file', async () => {
    const caller = appRouter.createCaller({
      user: mockUser,
      session: { access_token: 'mock-token' },
      supabase: mockSupabase,
      isGuest: false,
      req: {},
      res: {},
    })

    const result = await caller.file.getUploadUrl({
      fileName: 'test-song.mid',
      fileSize: 1024,
      mimeType: 'audio/midi',
    })

    expect(result).toMatchObject({
      fileId: expect.any(String),
      uploadUrl: expect.any(String),
      s3Key: expect.any(String),
      expiresIn: 3600,
      fileInfo: {
        fileName: 'test-song.mid',
        fileType: 'midi',
        fileSize: 1024,
      },
    })
  })

  it('should reject invalid file types', async () => {
    const caller = appRouter.createCaller({
      user: mockUser,
      session: { access_token: 'mock-token' },
      supabase: mockSupabase,
      isGuest: false,
      req: {},
      res: {},
    })

    await expect(
      caller.file.getUploadUrl({
        fileName: 'test.txt',
        fileSize: 1024,
        mimeType: 'text/plain',
      })
    ).rejects.toThrow('File validation failed')
  })

  it('should reject oversized files', async () => {
    const caller = appRouter.createCaller({
      user: mockUser,
      session: { access_token: 'mock-token' },
      supabase: mockSupabase,
      isGuest: false,
      req: {},
      res: {},
    })

    await expect(
      caller.file.getUploadUrl({
        fileName: 'huge-file.mid',
        fileSize: 10 * 1024 * 1024, // 10MB - exceeds 5MB limit
        mimeType: 'audio/midi',
      })
    ).rejects.toThrow('File size exceeds limit')
  })

  it('should confirm upload completion', async () => {
    const caller = appRouter.createCaller({
      user: mockUser,
      session: { access_token: 'mock-token' },
      supabase: mockSupabase,
      isGuest: false,
      req: {},
      res: {},
    })

    const result = await caller.file.confirmUpload({
      fileId: 'file_123',
      success: true,
    })

    expect(result).toMatchObject({
      success: true,
      fileId: 'file_123',
      status: 'completed',
    })
  })
})
</file>

<file path="test/file-validation.test.ts">
import { describe, it, expect, beforeEach, vi } from 'vitest'
import {
  validateFile,
  validateFileExtension,
  validateMimeType,
  validateFileSize,
  sanitizeFileName,
  isExecutableFile,
  createUploadRateLimit,
  FILE_SIZE_LIMITS,
  type FileUploadInput,
} from '../lib/file-validation'

describe('File Validation', () => {
  beforeEach(() => {
    vi.clearAllMocks()
  })

  describe('validateFileExtension', () => {
    it('should return "midi" for .mid files', () => {
      expect(validateFileExtension('test.mid')).toBe('midi')
      expect(validateFileExtension('TEST.MID')).toBe('midi')
      expect(validateFileExtension('song.Mid')).toBe('midi')
    })

    it('should return "midi" for .midi files', () => {
      expect(validateFileExtension('test.midi')).toBe('midi')
      expect(validateFileExtension('TEST.MIDI')).toBe('midi')
      expect(validateFileExtension('song.Midi')).toBe('midi')
    })

    it('should return "audio" for .mp3 files', () => {
      expect(validateFileExtension('test.mp3')).toBe('audio')
      expect(validateFileExtension('TEST.MP3')).toBe('audio')
      expect(validateFileExtension('song.Mp3')).toBe('audio')
    })

    it('should return "audio" for .wav files', () => {
      expect(validateFileExtension('test.wav')).toBe('audio')
      expect(validateFileExtension('TEST.WAV')).toBe('audio')
      expect(validateFileExtension('song.Wav')).toBe('audio')
    })

    it('should return null for unsupported extensions', () => {
      expect(validateFileExtension('test.txt')).toBeNull()
      expect(validateFileExtension('test.pdf')).toBeNull()
      expect(validateFileExtension('test.exe')).toBeNull()
      expect(validateFileExtension('test')).toBeNull()
    })
  })

  describe('validateMimeType', () => {
    it('should validate MIDI MIME types', () => {
      expect(validateMimeType('audio/midi', 'midi')).toBe(true)
      expect(validateMimeType('audio/x-midi', 'midi')).toBe(true)
      expect(validateMimeType('application/x-midi', 'midi')).toBe(true)
      expect(validateMimeType('audio/mid', 'midi')).toBe(true)
    })

    it('should validate audio MIME types', () => {
      expect(validateMimeType('audio/mpeg', 'audio')).toBe(true)
      expect(validateMimeType('audio/mp3', 'audio')).toBe(true)
      expect(validateMimeType('audio/wav', 'audio')).toBe(true)
      expect(validateMimeType('audio/wave', 'audio')).toBe(true)
      expect(validateMimeType('audio/x-wav', 'audio')).toBe(true)
    })

    it('should reject invalid MIME types', () => {
      expect(validateMimeType('text/plain', 'midi')).toBe(false)
      expect(validateMimeType('application/pdf', 'audio')).toBe(false)
      expect(validateMimeType('audio/mp3', 'midi')).toBe(false)
      expect(validateMimeType('audio/midi', 'audio')).toBe(false)
    })
  })

  describe('validateFileSize', () => {
    it('should validate MIDI file sizes within limit', () => {
      expect(validateFileSize(1000, 'midi')).toBe(true)
      expect(validateFileSize(FILE_SIZE_LIMITS.midi, 'midi')).toBe(true)
      expect(validateFileSize(FILE_SIZE_LIMITS.midi - 1, 'midi')).toBe(true)
    })

    it('should validate audio file sizes within limit', () => {
      expect(validateFileSize(1000, 'audio')).toBe(true)
      expect(validateFileSize(FILE_SIZE_LIMITS.audio, 'audio')).toBe(true)
      expect(validateFileSize(FILE_SIZE_LIMITS.audio - 1, 'audio')).toBe(true)
    })

    it('should reject oversized files', () => {
      expect(validateFileSize(FILE_SIZE_LIMITS.midi + 1, 'midi')).toBe(false)
      expect(validateFileSize(FILE_SIZE_LIMITS.audio + 1, 'audio')).toBe(false)
    })
  })

  describe('validateFile', () => {
    it('should validate a valid MIDI file', () => {
      const input: FileUploadInput = {
        fileName: 'test.mid',
        fileSize: 1000,
        mimeType: 'audio/midi',
      }

      const result = validateFile(input)

      expect(result.isValid).toBe(true)
      expect(result.errors).toHaveLength(0)
      expect(result.fileType).toBe('midi')
    })

    it('should validate a valid audio file', () => {
      const input: FileUploadInput = {
        fileName: 'test.mp3',
        fileSize: 10000,
        mimeType: 'audio/mpeg',
      }

      const result = validateFile(input)

      expect(result.isValid).toBe(true)
      expect(result.errors).toHaveLength(0)
      expect(result.fileType).toBe('audio')
    })

    it('should reject files with invalid extensions', () => {
      const input: FileUploadInput = {
        fileName: 'test.txt',
        fileSize: 1000,
        mimeType: 'text/plain',
      }

      const result = validateFile(input)

      expect(result.isValid).toBe(false)
      expect(result.errors).toContain('Invalid file type. Only .mid, .midi, .mp3, and .wav files are allowed.')
    })

    it('should reject files with invalid MIME types', () => {
      const input: FileUploadInput = {
        fileName: 'test.mid',
        fileSize: 1000,
        mimeType: 'text/plain',
      }

      const result = validateFile(input)

      expect(result.isValid).toBe(false)
      expect(result.errors).toContain('Invalid MIME type for midi file. Allowed types: audio/midi, audio/x-midi, application/x-midi, audio/mid')
    })

    it('should reject oversized files', () => {
      const input: FileUploadInput = {
        fileName: 'test.mid',
        fileSize: FILE_SIZE_LIMITS.midi + 1,
        mimeType: 'audio/midi',
      }

      const result = validateFile(input)

      expect(result.isValid).toBe(false)
      expect(result.errors).toContain('File size exceeds limit. Maximum size for midi files: 5MB')
    })

    it('should reject files with too long names', () => {
      const input: FileUploadInput = {
        fileName: 'a'.repeat(260) + '.mid',
        fileSize: 1000,
        mimeType: 'audio/midi',
      }

      const result = validateFile(input)

      expect(result.isValid).toBe(false)
      expect(result.errors).toContain('File name is too long (maximum 255 characters)')
    })

    it('should accumulate multiple errors for valid file type with multiple issues', () => {
      const input: FileUploadInput = {
        fileName: 'a'.repeat(260) + '.mid', // Too long name
        fileSize: FILE_SIZE_LIMITS.midi + 1, // Too large
        mimeType: 'text/plain', // Wrong MIME type
      }

      const result = validateFile(input)

      expect(result.isValid).toBe(false)
      expect(result.errors.length).toBeGreaterThan(1)
      expect(result.errors).toContain('Invalid MIME type for midi file. Allowed types: audio/midi, audio/x-midi, application/x-midi, audio/mid')
      expect(result.errors).toContain('File size exceeds limit. Maximum size for midi files: 5MB')
      expect(result.errors).toContain('File name is too long (maximum 255 characters)')
    })
  })

  describe('sanitizeFileName', () => {
    it('should preserve valid characters', () => {
      expect(sanitizeFileName('test.mid')).toBe('test.mid')
      expect(sanitizeFileName('Test123-file.mp3')).toBe('Test123-file.mp3')
    })

    it('should replace invalid characters with underscores', () => {
      expect(sanitizeFileName('test file.mid')).toBe('test_file.mid')
      expect(sanitizeFileName('test@#$%file.mid')).toBe('test_file.mid')
      expect(sanitizeFileName('test/\\file.mid')).toBe('test_file.mid')
    })

    it('should handle multiple consecutive invalid characters', () => {
      expect(sanitizeFileName('test   file.mid')).toBe('test_file.mid')
      expect(sanitizeFileName('test!!!file.mid')).toBe('test_file.mid')
    })

    it('should remove leading and trailing underscores', () => {
      expect(sanitizeFileName('_test.mid')).toBe('test.mid')
      expect(sanitizeFileName('test.mid_')).toBe('test.mid')
      expect(sanitizeFileName('_test.mid_')).toBe('test.mid')
    })
  })

  describe('isExecutableFile', () => {
    it('should detect executable files', () => {
      expect(isExecutableFile('test.exe')).toBe(true)
      expect(isExecutableFile('test.bat')).toBe(true)
      expect(isExecutableFile('test.sh')).toBe(true)
      expect(isExecutableFile('test.js')).toBe(true)
      expect(isExecutableFile('test.APP')).toBe(true)
    })

    it('should not flag safe files as executable', () => {
      expect(isExecutableFile('test.mid')).toBe(false)
      expect(isExecutableFile('test.mp3')).toBe(false)
      expect(isExecutableFile('test.txt')).toBe(false)
      expect(isExecutableFile('test.pdf')).toBe(false)
    })
  })

  describe('createUploadRateLimit', () => {
    it('should allow uploads within rate limit', () => {
      const rateLimit = createUploadRateLimit()
      const userId = 'user123'

      // Should allow multiple uploads up to the limit
      for (let i = 0; i < 5; i++) {
        expect(rateLimit.checkRateLimit(userId)).toBe(true)
      }
    })

    it('should track remaining uploads correctly', () => {
      const rateLimit = createUploadRateLimit()
      const userId = 'user123'

      // Initial state
      expect(rateLimit.getRemainingUploads(userId)).toBe(10)

      // After one upload
      rateLimit.checkRateLimit(userId)
      expect(rateLimit.getRemainingUploads(userId)).toBe(9)

      // After multiple uploads
      for (let i = 0; i < 5; i++) {
        rateLimit.checkRateLimit(userId)
      }
      expect(rateLimit.getRemainingUploads(userId)).toBe(4)
    })

    it('should enforce rate limit per user', () => {
      const rateLimit = createUploadRateLimit()
      const user1 = 'user1'
      const user2 = 'user2'

      // User 1 uses some uploads
      for (let i = 0; i < 5; i++) {
        rateLimit.checkRateLimit(user1)
      }

      // User 2 should still have full quota
      expect(rateLimit.getRemainingUploads(user2)).toBe(10)
      expect(rateLimit.getRemainingUploads(user1)).toBe(5)
    })
  })
})
</file>

<file path="test/midi-parser.test.ts">
import { describe, it, expect, beforeEach } from 'vitest';
import { parseMidiFile, validateMidiBuffer } from '../services/midi-parser.js';

describe('MIDI Parser Service', () => {
  describe('validateMidiBuffer', () => {
    it('should validate correct MIDI header', () => {
      // Create a buffer with MIDI header signature
      const buffer = Buffer.from([0x4D, 0x54, 0x68, 0x64, 0x00, 0x00, 0x00, 0x06]);
      expect(validateMidiBuffer(buffer)).toBe(true);
    });

    it('should reject buffer without MIDI header', () => {
      const buffer = Buffer.from([0x00, 0x00, 0x00, 0x00]);
      expect(validateMidiBuffer(buffer)).toBe(false);
    });

    it('should reject empty buffer', () => {
      const buffer = Buffer.alloc(0);
      expect(validateMidiBuffer(buffer)).toBe(false);
    });

    it('should reject buffer that is too short', () => {
      const buffer = Buffer.from([0x4D, 0x54]);
      expect(validateMidiBuffer(buffer)).toBe(false);
    });
  });

  describe('parseMidiFile', () => {
    it('should handle invalid MIDI data gracefully', async () => {
      const invalidBuffer = Buffer.from([0x00, 0x00, 0x00, 0x00]);
      const result = await parseMidiFile(invalidBuffer, 'test.mid');
      
      expect(result.success).toBe(false);
      expect(result.error).toBeDefined();
      expect(result.data).toBeUndefined();
    });

    it('should create minimal MIDI data structure for valid but empty file', async () => {
      // Create minimal valid MIDI file structure
      const midiHeader = Buffer.from([
        0x4D, 0x54, 0x68, 0x64, // "MThd" header
        0x00, 0x00, 0x00, 0x06, // Header length (6 bytes)
        0x00, 0x00,             // Format type 0
        0x00, 0x01,             // Number of tracks (1)
        0x00, 0x60,             // Ticks per quarter note (96)
        
        0x4D, 0x54, 0x72, 0x6B, // "MTrk" track header
        0x00, 0x00, 0x00, 0x04, // Track length (4 bytes)
        0x00, 0xFF, 0x2F, 0x00  // End of track meta event
      ]);

      const result = await parseMidiFile(midiHeader, 'empty.mid');
      
      expect(result.success).toBe(true);
      expect(result.data).toBeDefined();
      
      if (result.data) {
        expect(result.data.file.name).toBe('empty.mid');
        expect(result.data.file.size).toBe(midiHeader.length);
        expect(result.data.file.ticksPerQuarter).toBe(96);
        expect(result.data.tracks).toHaveLength(0); // No notes = no tracks in our implementation
        expect(result.data.tempoChanges).toHaveLength(1); // Default tempo
        expect(result.data.tempoChanges[0].bpm).toBe(120);
      }
    });

    it('should extract basic MIDI information correctly', async () => {
      // This would require a more complex MIDI buffer with actual note events
      // For now, test the error handling path
      const filename = 'test-song.mid';
      const result = await parseMidiFile(Buffer.alloc(0), filename);
      
      expect(result.success).toBe(false);
      expect(result.error).toContain('Invalid MIDI file format');
    });
  });

  describe('MIDI Note Conversion', () => {
    it('should convert MIDI note numbers to correct note names', () => {
      // This tests the internal midiNoteToName function indirectly
      // We'll need to export it or test through the main parsing function
      expect(true).toBe(true); // Placeholder for now
    });
  });

  describe('Color Assignment', () => {
    it('should assign colors from the muted palette', () => {
      // Test that tracks get assigned appropriate colors
      expect(true).toBe(true); // Placeholder for now
    });
  });

  describe('Performance', () => {
    it('should handle large MIDI files efficiently', async () => {
      // Create a larger buffer to test performance
      const largeBuffer = Buffer.alloc(1000000); // 1MB buffer
      const startTime = Date.now();
      
      const result = await parseMidiFile(largeBuffer, 'large.mid');
      const endTime = Date.now();
      
      // Should complete in reasonable time (even if it fails parsing)
      expect(endTime - startTime).toBeLessThan(5000); // 5 seconds max
      expect(result).toBeDefined();
    });
  });
});
</file>

<file path="test/midi-router.test.ts">
import { describe, it, expect, beforeEach, vi } from 'vitest';
import { TRPCError } from '@trpc/server';
import { midiRouter } from '../routers/midi';
import * as r2Storage from '../services/r2-storage';
import * as midiParser from '../services/midi-parser';

// Mock dependencies
vi.mock('../services/r2-storage');
vi.mock('../services/midi-parser');

const mockSupabase = {
  from: vi.fn(() => ({
    select: vi.fn(() => ({
      eq: vi.fn(() => ({
        eq: vi.fn(() => ({
          eq: vi.fn(() => ({
            single: vi.fn()
          })),
          single: vi.fn()
        })),
        single: vi.fn()
      }))
    })),
    upsert: vi.fn(() => ({
      select: vi.fn(() => ({
        single: vi.fn()
      }))
    })),
    order: vi.fn(() => ({
      range: vi.fn()
    }))
  }))
};

const mockContext = {
  user: { id: 'test-user-id' },
  supabase: mockSupabase
};

describe('MIDI Router', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  describe('parseMidiFile', () => {
    it('should parse a MIDI file successfully', async () => {
      // Mock file metadata response
      const fileData = {
        id: 'test-file-id',
        s3_key: 'midi/test-user-id/test.mid',
        file_name: 'test.mid',
        file_size: 1000,
        upload_status: 'completed',
        file_type: 'midi'
      };

      mockSupabase.from().select().eq().eq().eq().single.mockResolvedValueOnce({
        data: fileData,
        error: null
      });

      // Mock no existing MIDI file
      mockSupabase.from().select().eq().eq().single.mockResolvedValueOnce({
        data: null,
        error: null
      });

      // Mock file buffer
      const mockBuffer = Buffer.from([0x4D, 0x54, 0x68, 0x64]); // "MThd"
      vi.mocked(r2Storage.getFileBuffer).mockResolvedValueOnce(mockBuffer);

      // Mock MIDI validation
      vi.mocked(midiParser.validateMidiBuffer).mockReturnValueOnce(true);

      // Mock MIDI parsing
      const mockMidiData = {
        file: {
          name: 'test.mid',
          size: 1000,
          duration: 10.5,
          ticksPerQuarter: 480,
          timeSignature: [4, 4] as [number, number],
          keySignature: 'C major'
        },
        tracks: [{
          id: 'track-1',
          name: 'Track 1',
          instrument: 'Piano',
          channel: 0,
          notes: [],
          color: '#84a98c'
        }],
        tempoChanges: [{
          tick: 0,
          bpm: 120,
          microsecondsPerQuarter: 500000
        }]
      };

      vi.mocked(midiParser.parseMidiFile).mockResolvedValueOnce({
        success: true,
        data: mockMidiData
      });

      // Mock database insert
      const midiRecord = { id: 'midi-record-id' };
      mockSupabase.from().upsert().select().single.mockResolvedValueOnce({
        data: midiRecord,
        error: null
      });

      // Execute the mutation
      const caller = midiRouter.createCaller(mockContext);
      const result = await caller.parseMidiFile({ fileId: 'test-file-id' });

      expect(result.success).toBe(true);
      expect(result.midiFileId).toBe('midi-record-id');
      expect(result.data).toEqual(mockMidiData);
      expect(result.cached).toBe(false);
    });

    it('should return cached data if already parsed', async () => {
      const fileData = {
        id: 'test-file-id',
        s3_key: 'midi/test-user-id/test.mid',
        file_name: 'test.mid',
        upload_status: 'completed',
        file_type: 'midi'
      };

      mockSupabase.from().select().eq().eq().eq().single.mockResolvedValueOnce({
        data: fileData,
        error: null
      });

      // Mock existing MIDI file
      const existingMidi = {
        id: 'existing-midi-id',
        parsing_status: 'completed',
        parsed_data: { test: 'data' }
      };

      mockSupabase.from().select().eq().eq().single.mockResolvedValueOnce({
        data: existingMidi,
        error: null
      });

      const caller = midiRouter.createCaller(mockContext);
      const result = await caller.parseMidiFile({ fileId: 'test-file-id' });

      expect(result.success).toBe(true);
      expect(result.cached).toBe(true);
      expect(result.midiFileId).toBe('existing-midi-id');
    });

    it('should throw error if file not found', async () => {
      mockSupabase.from().select().eq().eq().eq().single.mockResolvedValueOnce({
        data: null,
        error: 'Not found'
      });

      const caller = midiRouter.createCaller(mockContext);
      
      await expect(caller.parseMidiFile({ fileId: 'non-existent' }))
        .rejects
        .toThrow('MIDI file not found or access denied');
    });

    it('should throw error if file upload not complete', async () => {
      const fileData = {
        upload_status: 'uploading',
        file_type: 'midi'
      };

      mockSupabase.from().select().eq().eq().eq().single.mockResolvedValueOnce({
        data: fileData,
        error: null
      });

      const caller = midiRouter.createCaller(mockContext);
      
      await expect(caller.parseMidiFile({ fileId: 'test-file-id' }))
        .rejects
        .toThrow('File upload is not complete');
    });

    it('should throw error for invalid MIDI format', async () => {
      const fileData = {
        upload_status: 'completed',
        file_type: 'midi',
        s3_key: 'test-key'
      };

      mockSupabase.from().select().eq().eq().eq().single.mockResolvedValueOnce({
        data: fileData,
        error: null
      });

      mockSupabase.from().select().eq().eq().single.mockResolvedValueOnce({
        data: null,
        error: null
      });

      const mockBuffer = Buffer.from([0x00, 0x00]); // Invalid MIDI
      vi.mocked(r2Storage.getFileBuffer).mockResolvedValueOnce(mockBuffer);
      vi.mocked(midiParser.validateMidiBuffer).mockReturnValueOnce(false);

      const caller = midiRouter.createCaller(mockContext);
      
      await expect(caller.parseMidiFile({ fileId: 'test-file-id' }))
        .rejects
        .toThrow('Invalid MIDI file format');
    });
  });

  describe('getVisualizationData', () => {
    it('should return visualization data successfully', async () => {
      const midiFile = {
        id: 'midi-file-id',
        parsing_status: 'completed',
        parsed_data: { test: 'midi-data' },
        original_filename: 'test.mid',
        duration_seconds: 10.5,
        track_count: 2,
        note_count: 100,
        time_signature: '4/4',
        key_signature: 'C major',
        tempo_bpm: 120
      };

      mockSupabase.from().select().eq().eq().single.mockResolvedValueOnce({
        data: midiFile,
        error: null
      });

      const settings = {
        color_scheme: 'mixed',
        pixels_per_second: 50
      };

      mockSupabase.from().select().eq().eq().single.mockResolvedValueOnce({
        data: settings,
        error: null
      });

      const caller = midiRouter.createCaller(mockContext);
      const result = await caller.getVisualizationData({ fileId: 'midi-file-id' });

      expect(result.midiData).toEqual({ test: 'midi-data' });
      expect(result.settings).toEqual(settings);
      expect(result.metadata.fileName).toBe('test.mid');
    });

    it('should throw error if MIDI file not parsed', async () => {
      const midiFile = {
        parsing_status: 'pending'
      };

      mockSupabase.from().select().eq().eq().single.mockResolvedValueOnce({
        data: midiFile,
        error: null
      });

      const caller = midiRouter.createCaller(mockContext);
      
      await expect(caller.getVisualizationData({ fileId: 'midi-file-id' }))
        .rejects
        .toThrow('MIDI file has not been parsed yet');
    });
  });

  describe('saveVisualizationSettings', () => {
    it('should save visualization settings successfully', async () => {
      // Mock MIDI file exists
      mockSupabase.from().select().eq().eq().single.mockResolvedValueOnce({
        data: { id: 'midi-file-id' },
        error: null
      });

      // Mock successful upsert
      mockSupabase.from().upsert.mockResolvedValueOnce({
        error: null
      });

      const caller = midiRouter.createCaller(mockContext);
      const result = await caller.saveVisualizationSettings({
        fileId: 'midi-file-id',
        settings: {
          colorScheme: 'sage',
          pixelsPerSecond: 75,
          showTrackLabels: true,
          showVelocity: false,
          minKey: 21,
          maxKey: 108
        }
      });

      expect(result.success).toBe(true);
      expect(result.message).toBe('Visualization settings saved successfully');
    });

    it('should throw error if MIDI file not found', async () => {
      mockSupabase.from().select().eq().eq().single.mockResolvedValueOnce({
        data: null,
        error: 'Not found'
      });

      const caller = midiRouter.createCaller(mockContext);
      
      await expect(caller.saveVisualizationSettings({
        fileId: 'non-existent',
        settings: { colorScheme: 'sage' }
      }))
        .rejects
        .toThrow('MIDI file not found or access denied');
    });
  });

  describe('getUserMidiFiles', () => {
    it('should return user MIDI files successfully', async () => {
      const midiFiles = [
        {
          id: 'file-1',
          original_filename: 'song1.mid',
          file_size: 1000,
          duration_seconds: 60,
          track_count: 2,
          note_count: 500,
          parsing_status: 'completed',
          created_at: '2024-01-01T00:00:00Z',
          error_message: null
        },
        {
          id: 'file-2',
          original_filename: 'song2.mid',
          file_size: 2000,
          duration_seconds: 120,
          track_count: 4,
          note_count: 1000,
          parsing_status: 'completed',
          created_at: '2024-01-02T00:00:00Z',
          error_message: null
        }
      ];

      mockSupabase.from().select().eq().order().range.mockResolvedValueOnce({
        data: midiFiles,
        error: null
      });

      const caller = midiRouter.createCaller(mockContext);
      const result = await caller.getUserMidiFiles({});

      expect(result.files).toHaveLength(2);
      expect(result.files[0].fileName).toBe('song1.mid');
      expect(result.hasMore).toBe(false);
    });

    it('should filter by status', async () => {
      mockSupabase.from().select().eq().order().range.mockImplementationOnce(() => ({
        eq: vi.fn().mockResolvedValueOnce({
          data: [],
          error: null
        })
      }));

      const caller = midiRouter.createCaller(mockContext);
      const result = await caller.getUserMidiFiles({ status: 'failed' });

      expect(result.files).toHaveLength(0);
    });
  });
});
</file>

<file path="test/r2-storage.test.ts">
import { describe, it, expect, vi, beforeEach } from 'vitest'
import { validateR2Config, generateR2Key } from '../services/r2-storage'

// Mock AWS SDK (R2 uses S3-compatible API)
vi.mock('@aws-sdk/client-s3', () => ({
  S3Client: vi.fn().mockImplementation(() => ({
    send: vi.fn(),
  })),
  CreateBucketCommand: vi.fn(),
  PutBucketCorsCommand: vi.fn(),
  HeadBucketCommand: vi.fn(),
  PutObjectCommand: vi.fn(),
  GetObjectCommand: vi.fn(),
  DeleteObjectCommand: vi.fn(),
}))

vi.mock('@aws-sdk/s3-request-presigner', () => ({
  getSignedUrl: vi.fn().mockResolvedValue('https://r2-signed-url.com'),
}))

describe('Cloudflare R2 Storage Service', () => {
  beforeEach(() => {
    vi.clearAllMocks()
    // Clear environment variables
    delete process.env.CLOUDFLARE_ACCOUNT_ID
    delete process.env.CLOUDFLARE_R2_ACCESS_KEY_ID
    delete process.env.CLOUDFLARE_R2_SECRET_ACCESS_KEY
    delete process.env.CLOUDFLARE_R2_BUCKET
  })

  describe('validateR2Config', () => {
    it('should pass when all required environment variables are set', () => {
      process.env.CLOUDFLARE_ACCOUNT_ID = 'test-account-id'
      process.env.CLOUDFLARE_R2_ACCESS_KEY_ID = 'test-access-key'
      process.env.CLOUDFLARE_R2_SECRET_ACCESS_KEY = 'test-secret-key'
      process.env.CLOUDFLARE_R2_BUCKET = 'test-bucket'

      expect(() => validateR2Config()).not.toThrow()
    })

    it('should throw error when CLOUDFLARE_ACCOUNT_ID is missing', () => {
      process.env.CLOUDFLARE_R2_ACCESS_KEY_ID = 'test-access-key'
      process.env.CLOUDFLARE_R2_SECRET_ACCESS_KEY = 'test-secret-key'
      process.env.CLOUDFLARE_R2_BUCKET = 'test-bucket'

      expect(() => validateR2Config()).toThrow(
        'Missing required Cloudflare R2 environment variables: CLOUDFLARE_ACCOUNT_ID'
      )
    })

    it('should throw error when CLOUDFLARE_R2_ACCESS_KEY_ID is missing', () => {
      process.env.CLOUDFLARE_ACCOUNT_ID = 'test-account-id'
      process.env.CLOUDFLARE_R2_SECRET_ACCESS_KEY = 'test-secret-key'
      process.env.CLOUDFLARE_R2_BUCKET = 'test-bucket'

      expect(() => validateR2Config()).toThrow(
        'Missing required Cloudflare R2 environment variables: CLOUDFLARE_R2_ACCESS_KEY_ID'
      )
    })

    it('should throw error when CLOUDFLARE_R2_SECRET_ACCESS_KEY is missing', () => {
      process.env.CLOUDFLARE_ACCOUNT_ID = 'test-account-id'
      process.env.CLOUDFLARE_R2_ACCESS_KEY_ID = 'test-access-key'
      process.env.CLOUDFLARE_R2_BUCKET = 'test-bucket'

      expect(() => validateR2Config()).toThrow(
        'Missing required Cloudflare R2 environment variables: CLOUDFLARE_R2_SECRET_ACCESS_KEY'
      )
    })

    it('should throw error when CLOUDFLARE_R2_BUCKET is missing', () => {
      process.env.CLOUDFLARE_ACCOUNT_ID = 'test-account-id'
      process.env.CLOUDFLARE_R2_ACCESS_KEY_ID = 'test-access-key'
      process.env.CLOUDFLARE_R2_SECRET_ACCESS_KEY = 'test-secret-key'

      expect(() => validateR2Config()).toThrow(
        'Missing required Cloudflare R2 environment variables: CLOUDFLARE_R2_BUCKET'
      )
    })

    it('should throw error when multiple variables are missing', () => {
      expect(() => validateR2Config()).toThrow(
        'Missing required Cloudflare R2 environment variables:'
      )
    })
  })

  describe('generateR2Key', () => {
    it('should generate correct R2 key for MIDI file', () => {
      const userId = 'user123'
      const fileName = 'test-song.mid'
      const fileType = 'midi'

      const key = generateR2Key(userId, fileName, fileType)

      expect(key).toMatch(/^midi\/user123\/\d+_test-song\.mid$/)
    })

    it('should generate correct R2 key for audio file', () => {
      const userId = 'user456'
      const fileName = 'test-audio.mp3'
      const fileType = 'audio'

      const key = generateR2Key(userId, fileName, fileType)

      expect(key).toMatch(/^audio\/user456\/\d+_test-audio\.mp3$/)
    })

    it('should generate correct R2 key for video file', () => {
      const userId = 'user789'
      const fileName = 'test-video.mp4'
      const fileType = 'video'

      const key = generateR2Key(userId, fileName, fileType)

      expect(key).toMatch(/^video\/user789\/\d+_test-video\.mp4$/)
    })

    it('should sanitize file name with special characters', () => {
      const userId = 'user789'
      const fileName = 'test file with spaces & symbols!.midi'
      const fileType = 'midi'

      const key = generateR2Key(userId, fileName, fileType)

      expect(key).toMatch(/^midi\/user789\/\d+_test_file_with_spaces___symbols_\.midi$/)
    })

    it('should include timestamp in the key', () => {
      const userId = 'user123'
      const fileName = 'test.mid'
      const fileType = 'midi'

      const key = generateR2Key(userId, fileName, fileType)
      
      // Should contain timestamp pattern
      expect(key).toMatch(/^midi\/user123\/\d+_test\.mid$/)
      
      // Extract and verify timestamp is recent (within last 5 seconds)
      const timestampMatch = key.match(/\/(\d+)_/)
      expect(timestampMatch).toBeTruthy()
      const timestamp = parseInt(timestampMatch![1])
      const now = Date.now()
      expect(timestamp).toBeGreaterThan(now - 5000) // Within 5 seconds
      expect(timestamp).toBeLessThanOrEqual(now)
    })
  })
})
</file>

<file path="test/supabase-connection.test.ts">
import { describe, it, expect } from 'vitest'

describe('Supabase Server Configuration', () => {
  it('should have required environment variables defined', () => {
    // Mock environment variables for testing
    const mockEnv = {
      NEXT_PUBLIC_SUPABASE_URL: 'https://test.supabase.co',
      NEXT_PUBLIC_SUPABASE_ANON_KEY: 'test-anon-key',
      SUPABASE_SERVICE_ROLE_KEY: 'test-service-role-key'
    }
    
    // Verify the variables are defined
    expect(mockEnv.NEXT_PUBLIC_SUPABASE_URL).toBeDefined()
    expect(mockEnv.NEXT_PUBLIC_SUPABASE_ANON_KEY).toBeDefined()
    expect(mockEnv.SUPABASE_SERVICE_ROLE_KEY).toBeDefined()
  })

  it('should create Supabase admin client successfully', async () => {
    // Mock the Supabase client import
    const mockCreateClient = (url: string, key: string) => ({
      auth: { 
        admin: { 
          listUsers: () => Promise.resolve({ data: { users: [] }, error: null })
        }
      },
      from: (table: string) => ({ select: () => Promise.resolve({ data: [], error: null }) })
    })

    const adminClient = mockCreateClient('https://test.supabase.co', 'test-service-key')
    expect(adminClient).toBeDefined()
    expect(adminClient.auth.admin).toBeDefined()
    expect(adminClient.from).toBeDefined()
  })
})
</file>

<file path="test/supabase-connection.test.ts">
import { describe, it, expect } from 'vitest'

describe('Supabase Server Configuration', () => {
  it('should have required environment variables defined', () => {
    // Mock environment variables for testing
    const mockEnv = {
      NEXT_PUBLIC_SUPABASE_URL: 'https://test.supabase.co',
      NEXT_PUBLIC_SUPABASE_ANON_KEY: 'test-anon-key',
      SUPABASE_SERVICE_ROLE_KEY: 'test-service-role-key'
    }
    
    // Verify the variables are defined
    expect(mockEnv.NEXT_PUBLIC_SUPABASE_URL).toBeDefined()
    expect(mockEnv.NEXT_PUBLIC_SUPABASE_ANON_KEY).toBeDefined()
    expect(mockEnv.SUPABASE_SERVICE_ROLE_KEY).toBeDefined()
  })

  it('should create Supabase admin client successfully', async () => {
    // Mock the Supabase client import
    const mockCreateClient = (url: string, key: string) => ({
      auth: { 
        admin: { 
          listUsers: () => Promise.resolve({ data: { users: [] }, error: null })
        }
      },
      from: (table: string) => ({ select: () => Promise.resolve({ data: [], error: null }) })
    })

    const adminClient = mockCreateClient('https://test.supabase.co', 'test-service-key')
    expect(adminClient).toBeDefined()
    expect(adminClient.auth.admin).toBeDefined()
    expect(adminClient.from).toBeDefined()
  })
})
</file>

<file path="test/trpc-auth.test.ts">
import { describe, it, expect, vi, beforeEach } from 'vitest'
import { createTRPCContext, appRouter } from '../trpc'
import type { CreateExpressContextOptions } from '@trpc/server/adapters/express'

// Mock Supabase
vi.mock('../lib/supabase', () => ({
  createSupabaseServerClient: vi.fn(() => ({
    auth: {
      getUser: vi.fn(),
      getSession: vi.fn(),
    },
  })),
}))

describe('tRPC Authentication Integration', () => {
  beforeEach(() => {
    vi.clearAllMocks()
  })

  describe('createTRPCContext', () => {
    it('should create context without user when no auth header', async () => {
      const mockOpts: CreateExpressContextOptions = {
        req: {
          headers: {},
        } as any,
        res: {} as any,
      }

      const context = await createTRPCContext(mockOpts)

      expect(context.user).toBeNull()
      expect(context.session).toBeNull()
      expect(context.supabase).toBeDefined()
    })

    it('should create context with user when valid auth header', async () => {
      const { createSupabaseServerClient } = await import('../lib/supabase')
      const mockSupabase = {
        auth: {
          getUser: vi.fn().mockResolvedValue({
            data: {
              user: {
                id: 'user-123',
                email: 'test@example.com',
                user_metadata: { name: 'Test User' },
                created_at: '2023-01-01T00:00:00Z',
                updated_at: '2023-01-01T00:00:00Z',
              },
            },
            error: null,
          }),
          getSession: vi.fn().mockResolvedValue({
            data: { session: { access_token: 'test-token' } },
            error: null,
          }),
        },
      }
      ;(createSupabaseServerClient as any).mockReturnValue(mockSupabase)

      const mockOpts: CreateExpressContextOptions = {
        req: {
          headers: {
            authorization: 'Bearer test-token',
          },
        } as any,
        res: {} as any,
      }

      const context = await createTRPCContext(mockOpts)

      expect(context.user).toEqual({
        id: 'user-123',
        email: 'test@example.com',
        name: 'Test User',
        image: undefined,
        created_at: '2023-01-01T00:00:00Z',
        updated_at: '2023-01-01T00:00:00Z',
      })
      expect(context.session).toEqual({ access_token: 'test-token' })
    })
  })

  describe('Public Procedures', () => {
    it('should allow health check without authentication', async () => {
      const caller = appRouter.createCaller({
        req: {},
        res: {},
        supabase: {},
        user: null,
        session: null,
        isGuest: false,
      })

      const result = await caller.health.check()

      expect(result.status).toBe('healthy')
      expect(result.message).toContain('tRPC server is running!')
    })

    it('should allow greeting without authentication', async () => {
      const caller = appRouter.createCaller({
        req: {},
        res: {},
        supabase: {},
        user: null,
        session: null,
        isGuest: false,
      })

      const result = await caller.greeting({ name: 'Test' })

      expect(result.message).toContain('Hello Test from tRPC!')
      expect(result.authenticated).toBe(false)
    })

    it('should return session info for unauthenticated user', async () => {
      const caller = appRouter.createCaller({
        req: {},
        res: {},
        supabase: {},
        user: null,
        session: null,
        isGuest: false,
      })

      const result = await caller.auth.session()

      expect(result.authenticated).toBe(false)
      expect(result.user).toBeNull()
    })
  })

  describe('Protected Procedures', () => {
    it('should reject protected procedures without authentication', async () => {
      const caller = appRouter.createCaller({
        req: {},
        res: {},
        supabase: {},
        user: null,
        session: null,
        isGuest: false,
      })

      await expect(caller.auth.me()).rejects.toThrow('You must be logged in to access this resource')
    })

    it('should allow protected procedures with authentication', async () => {
      const mockUser = {
        id: 'user-123',
        email: 'test@example.com',
        name: 'Test User',
        image: undefined,
        created_at: '2023-01-01T00:00:00Z',
        updated_at: '2023-01-01T00:00:00Z',
      }

      const caller = appRouter.createCaller({
        req: {},
        res: {},
        supabase: {},
        user: mockUser,
        session: { access_token: 'test-token' },
        isGuest: false,
      })

      const result = await caller.auth.me()

      expect(result.user).toEqual(mockUser)
      expect(result.authenticated).toBe(true)
    })

    it('should return user profile for authenticated user', async () => {
      const mockUser = {
        id: 'user-123',
        email: 'test@example.com',
        name: 'Test User',
        image: 'https://example.com/avatar.jpg',
        created_at: '2023-01-01T00:00:00Z',
        updated_at: '2023-01-01T00:00:00Z',
      }

      const caller = appRouter.createCaller({
        req: {},
        res: {},
        supabase: {},
        user: mockUser,
        session: { access_token: 'test-token' },
        isGuest: false,
      })

      const result = await caller.user.profile()

      expect(result.id).toBe('user-123')
      expect(result.display_name).toBeDefined()
      expect(result.avatar_url).toBeDefined()
    })
  })
})
</file>

<file path="test/video-image-validation.test.ts">
import { describe, it, expect, beforeEach, vi } from 'vitest'
import {
  validateFile,
  validateFileExtension,
  validateMimeType,
  validateFileSize,
  FILE_SIZE_LIMITS,
  videoValidation,
  imageValidation,
  type FileUploadInput,
} from '../lib/file-validation'

describe('Video & Image File Validation', () => {
  beforeEach(() => {
    vi.clearAllMocks()
  })

  describe('validateFileExtension - Video Files', () => {
    it('should return "video" for .mp4 files', () => {
      expect(validateFileExtension('video.mp4')).toBe('video')
      expect(validateFileExtension('VIDEO.MP4')).toBe('video')
      expect(validateFileExtension('my-video.Mp4')).toBe('video')
    })

    it('should return "video" for .mov files', () => {
      expect(validateFileExtension('video.mov')).toBe('video')
      expect(validateFileExtension('VIDEO.MOV')).toBe('video')
      expect(validateFileExtension('my-video.Mov')).toBe('video')
    })

    it('should return "video" for .webm files', () => {
      expect(validateFileExtension('video.webm')).toBe('video')
      expect(validateFileExtension('VIDEO.WEBM')).toBe('video')
      expect(validateFileExtension('my-video.Webm')).toBe('video')
    })
  })

  describe('validateFileExtension - Image Files', () => {
    it('should return "image" for .jpg/.jpeg files', () => {
      expect(validateFileExtension('image.jpg')).toBe('image')
      expect(validateFileExtension('image.jpeg')).toBe('image')
      expect(validateFileExtension('IMAGE.JPG')).toBe('image')
      expect(validateFileExtension('IMAGE.JPEG')).toBe('image')
    })

    it('should return "image" for .png files', () => {
      expect(validateFileExtension('image.png')).toBe('image')
      expect(validateFileExtension('IMAGE.PNG')).toBe('image')
      expect(validateFileExtension('my-image.Png')).toBe('image')
    })

    it('should return "image" for .gif files', () => {
      expect(validateFileExtension('image.gif')).toBe('image')
      expect(validateFileExtension('IMAGE.GIF')).toBe('image')
      expect(validateFileExtension('animated.Gif')).toBe('image')
    })

    it('should return "image" for .webp files', () => {
      expect(validateFileExtension('image.webp')).toBe('image')
      expect(validateFileExtension('IMAGE.WEBP')).toBe('image')
      expect(validateFileExtension('my-image.Webp')).toBe('image')
    })
  })

  describe('validateMimeType - Video Files', () => {
    it('should validate video MIME types', () => {
      expect(validateMimeType('video/mp4', 'video')).toBe(true)
      expect(validateMimeType('video/mov', 'video')).toBe(true)
      expect(validateMimeType('video/quicktime', 'video')).toBe(true)
      expect(validateMimeType('video/webm', 'video')).toBe(true)
    })

    it('should reject invalid MIME types for video', () => {
      expect(validateMimeType('image/jpeg', 'video')).toBe(false)
      expect(validateMimeType('audio/mp3', 'video')).toBe(false)
      expect(validateMimeType('text/plain', 'video')).toBe(false)
    })
  })

  describe('validateMimeType - Image Files', () => {
    it('should validate image MIME types', () => {
      expect(validateMimeType('image/jpeg', 'image')).toBe(true)
      expect(validateMimeType('image/jpg', 'image')).toBe(true)
      expect(validateMimeType('image/png', 'image')).toBe(true)
      expect(validateMimeType('image/gif', 'image')).toBe(true)
      expect(validateMimeType('image/webp', 'image')).toBe(true)
    })

    it('should reject invalid MIME types for image', () => {
      expect(validateMimeType('video/mp4', 'image')).toBe(false)
      expect(validateMimeType('audio/mp3', 'image')).toBe(false)
      expect(validateMimeType('text/plain', 'image')).toBe(false)
    })
  })

  describe('validateFileSize - Video Files', () => {
    it('should validate video file sizes within limit', () => {
      expect(validateFileSize(1000000, 'video')).toBe(true) // 1MB
      expect(validateFileSize(FILE_SIZE_LIMITS.video, 'video')).toBe(true) // 500MB
      expect(validateFileSize(FILE_SIZE_LIMITS.video - 1, 'video')).toBe(true)
    })

    it('should reject oversized video files', () => {
      expect(validateFileSize(FILE_SIZE_LIMITS.video + 1, 'video')).toBe(false)
      expect(validateFileSize(600 * 1024 * 1024, 'video')).toBe(false) // 600MB
    })
  })

  describe('validateFileSize - Image Files', () => {
    it('should validate image file sizes within limit', () => {
      expect(validateFileSize(1000000, 'image')).toBe(true) // 1MB
      expect(validateFileSize(FILE_SIZE_LIMITS.image, 'image')).toBe(true) // 25MB
      expect(validateFileSize(FILE_SIZE_LIMITS.image - 1, 'image')).toBe(true)
    })

    it('should reject oversized image files', () => {
      expect(validateFileSize(FILE_SIZE_LIMITS.image + 1, 'image')).toBe(false)
      expect(validateFileSize(30 * 1024 * 1024, 'image')).toBe(false) // 30MB
    })
  })

  describe('validateFile - Video Files', () => {
    it('should validate a valid video file', () => {
      const input: FileUploadInput = {
        fileName: 'video.mp4',
        fileSize: 10 * 1024 * 1024, // 10MB
        mimeType: 'video/mp4',
      }

      const result = validateFile(input)

      expect(result.isValid).toBe(true)
      expect(result.errors).toHaveLength(0)
      expect(result.fileType).toBe('video')
    })

    it('should reject video files with invalid MIME types', () => {
      const input: FileUploadInput = {
        fileName: 'video.mp4',
        fileSize: 10 * 1024 * 1024,
        mimeType: 'image/jpeg',
      }

      const result = validateFile(input)

      expect(result.isValid).toBe(false)
      expect(result.errors).toContain('Invalid MIME type for video file. Allowed types: video/mp4, video/mov, video/quicktime, video/webm')
    })

    it('should reject oversized video files', () => {
      const input: FileUploadInput = {
        fileName: 'video.mp4',
        fileSize: FILE_SIZE_LIMITS.video + 1,
        mimeType: 'video/mp4',
      }

      const result = validateFile(input)

      expect(result.isValid).toBe(false)
      expect(result.errors).toContain('File size exceeds limit. Maximum size for video files: 500MB')
    })
  })

  describe('validateFile - Image Files', () => {
    it('should validate a valid image file', () => {
      const input: FileUploadInput = {
        fileName: 'image.jpg',
        fileSize: 5 * 1024 * 1024, // 5MB
        mimeType: 'image/jpeg',
      }

      const result = validateFile(input)

      expect(result.isValid).toBe(true)
      expect(result.errors).toHaveLength(0)
      expect(result.fileType).toBe('image')
    })

    it('should reject image files with invalid MIME types', () => {
      const input: FileUploadInput = {
        fileName: 'image.jpg',
        fileSize: 5 * 1024 * 1024,
        mimeType: 'video/mp4',
      }

      const result = validateFile(input)

      expect(result.isValid).toBe(false)
      expect(result.errors).toContain('Invalid MIME type for image file. Allowed types: image/jpeg, image/jpg, image/png, image/gif, image/webp')
    })

    it('should reject oversized image files', () => {
      const input: FileUploadInput = {
        fileName: 'image.jpg',
        fileSize: FILE_SIZE_LIMITS.image + 1,
        mimeType: 'image/jpeg',
      }

      const result = validateFile(input)

      expect(result.isValid).toBe(false)
      expect(result.errors).toContain('File size exceeds limit. Maximum size for image files: 25MB')
    })
  })

  describe('Validation Configurations', () => {
    it('should have correct video validation settings', () => {
      expect(videoValidation.maxSize).toBe(500 * 1024 * 1024) // 500MB
      expect(videoValidation.maxDuration).toBe(600) // 10 minutes
      expect(videoValidation.maxResolution.width).toBe(3840) // 4K
      expect(videoValidation.maxResolution.height).toBe(2160)
      expect(videoValidation.allowedTypes).toContain('video/mp4')
      expect(videoValidation.allowedTypes).toContain('video/webm')
    })

    it('should have correct image validation settings', () => {
      expect(imageValidation.maxSize).toBe(25 * 1024 * 1024) // 25MB
      expect(imageValidation.maxResolution.width).toBe(8192) // 8K
      expect(imageValidation.maxResolution.height).toBe(8192)
      expect(imageValidation.allowedTypes).toContain('image/jpeg')
      expect(imageValidation.allowedTypes).toContain('image/png')
      expect(imageValidation.allowedTypes).toContain('image/gif')
    })
  })

  describe('Updated error messages', () => {
    it('should show comprehensive error message for unsupported file types', () => {
      const input: FileUploadInput = {
        fileName: 'document.pdf',
        fileSize: 1000,
        mimeType: 'application/pdf',
      }

      const result = validateFile(input)

      expect(result.isValid).toBe(false)
      expect(result.errors).toContain('Invalid file type. Allowed types: .mid, .midi, .mp3, .wav, .mp4, .mov, .webm, .jpg, .jpeg, .png, .gif, .webp')
    })
  })
})
</file>

<file path="types/fluent-ffmpeg.d.ts">

</file>

<file path="types/guest.ts">
/**
 * Guest User Types for API
 */

export interface GuestUser {
  id: string
  isGuest: true
  sessionId: string
  createdAt: string
  tempData?: {
    projects: any[]
    preferences: Record<string, any>
  }
}

export interface GuestProject {
  id: string
  name: string
  guestUserId: string
  tempData: any
  createdAt: string
  expiresAt: string
}

export interface GuestSession {
  sessionId: string
  createdAt: string
  expiresAt: string
  ipAddress?: string
  userAgent?: string
}

/**
 * Extract guest session from request headers
 */
export function extractGuestSession(req: any): { sessionId: string } | null {
  // Check for guest session in headers
  const guestSessionHeader = req.headers['x-guest-session']
  if (guestSessionHeader && typeof guestSessionHeader === 'string') {
    return { sessionId: guestSessionHeader }
  }

  // Check for guest session in cookies
  const cookies = req.headers.cookie
  if (cookies) {
    const guestSessionMatch = cookies.match(/guest_session_id=([^;]+)/)
    if (guestSessionMatch) {
      return { sessionId: guestSessionMatch[1] }
    }
  }

  return null
}

/**
 * Create guest user from session
 */
export function createGuestUserFromSession(sessionId: string): GuestUser {
  return {
    id: `guest_${sessionId}`,
    isGuest: true,
    sessionId,
    createdAt: new Date().toISOString(),
    tempData: {
      projects: [],
      preferences: {}
    }
  }
}

/**
 * Check if user is a guest user
 */
export function isGuestUser(user: any): user is GuestUser {
  return user && user.isGuest === true
}

/**
 * Validate guest session format
 */
export function isValidGuestSession(sessionId: string): boolean {
  // Basic validation - guest sessions should be in format: timestamp_randomstring
  const parts = sessionId.split('_')
  if (parts.length < 2) return false
  
  // Check if first part is a valid timestamp
  const timestampStr = parts[0]
  if (!timestampStr) return false
  
  const timestamp = parseInt(timestampStr)
  if (isNaN(timestamp) || timestamp <= 0) return false
  
  // Check if session is not too old (7 days)
  const maxAge = 7 * 24 * 60 * 60 * 1000 // 7 days
  const sessionAge = Date.now() - timestamp
  
  return sessionAge <= maxAge
}
</file>

<file path="index.ts">
import dotenv from 'dotenv';
import path from 'path';

// Load environment variables from the root .env file
dotenv.config({ path: path.resolve(__dirname, '../../../.env') });

import express from 'express'
import cors from 'cors'
import helmet from 'helmet'
import * as trpcExpress from '@trpc/server/adapters/express'
import { createTRPCContext } from './trpc'
import { appRouter } from './routers'
import { testConnection } from './db/connection'
import { initializeS3 } from './services/r2-storage'
import { logger } from './lib/logger';

const app = express()
const PORT = process.env.PORT || 3001

// Security middleware
app.use(helmet())

// Content-Type normalization middleware (before body parsing)
app.use((req: any, res: any, next: any) => {
  if (req.headers['content-type'] && req.headers['content-type'].includes('application/json, application/json')) {
    logger.log(' Normalizing duplicate Content-Type header');
    req.headers['content-type'] = 'application/json';
  }
  next();
});

// Raw body logging middleware (before body parsing)
app.use((req: any, res: any, next: any) => {
  if (req.path.startsWith('/api/trpc') && req.method === 'POST') {
    logger.log('=== RAW REQUEST BEFORE PARSING ===');
    logger.log('Content-Type:', req.headers['content-type']);
    logger.log('Content-Length:', req.headers['content-length']);
    logger.log('Raw body available:', !!req.body);
    logger.log('Body before parsing:', req.body);
    logger.log('=== END RAW REQUEST BEFORE PARSING ===');
  }
  next();
});

// Debug middleware to log all requests
app.use((req: any, res: any, next: any) => {
  logger.log(` ${req.method} ${req.path} - Origin: ${req.headers.origin} - Auth: ${req.headers.authorization ? 'present' : 'missing'}`);
  
  // Log raw request details for tRPC requests
  if (req.path.startsWith('/api/trpc') && req.method === 'POST') {
    logger.log('=== RAW REQUEST DEBUG ===');
    logger.log('Content-Type:', req.headers['content-type']);
    logger.log('Raw body:', req.body);
    logger.log('Body type:', typeof req.body);
    logger.log('Body keys:', req.body ? Object.keys(req.body) : 'no body');
    logger.log('=== END RAW REQUEST DEBUG ===');
  }
  
  next();
});

// CORS configuration
const allowedOrigins = process.env.FRONTEND_URL
  ? process.env.FRONTEND_URL.split(',').map(origin => origin.trim())
  : [];

const corsOptions = {
  origin: (origin: string | undefined, callback: (err: Error | null, allow?: boolean) => void) => {
    // Allow requests with no origin (like mobile apps or curl requests)
    if (!origin) {
      return callback(null, true);
    }

    const allowed = process.env.NODE_ENV === 'production'
      ? [
          ...allowedOrigins,
          'https://phonoglyph.rheome.tools',
          'https://www.phonoglyph.rheome.tools',
          'https://phonoglyph.vercel.app',
        ]
      : ['http://localhost:3000', 'http://127.0.0.1:3000'];

    // Check exact matches
    if (allowed.includes(origin)) {
      return callback(null, true);
    }

    // Check Vercel preview URLs pattern
    if (origin.match(/^https:\/\/phonoglyph-.*\.vercel\.app$/)) {
      return callback(null, true);
    }

    // Block but don't throw error - just reject with false
    console.error(`CORS blocked origin: ${origin}`);
    callback(null, false);
  },
  credentials: true,
  methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS', 'PATCH', 'HEAD'],
  allowedHeaders: ['Content-Type', 'Authorization', 'X-Requested-With', 'x-guest-session', 'Accept'],
  exposedHeaders: ['Authorization'],
  preflightContinue: false,
  optionsSuccessStatus: 204,
  maxAge: 86400, // 24 hours
}

// Apply CORS middleware
app.use(cors(corsOptions))

// Handle preflight requests explicitly for all routes
app.options('*', cors(corsOptions))

// Body parsing middleware - EXTENDED for large file uploads
app.use(express.json({ limit: '600mb' }))
app.use(express.urlencoded({ extended: true, limit: '600mb' }))

// Debug middleware to log request bodies
app.use('/api/trpc', (req: any, res: any, next: any) => {
  logger.log('=== REQUEST BODY DEBUG ===');
  logger.log('Method:', req.method);
  logger.log('Path:', req.path);
  logger.log('Content-Type:', req.headers['content-type']);
  logger.log('Body:', JSON.stringify(req.body, null, 2));
  logger.log('=== END REQUEST BODY DEBUG ===');
  next();
});

// tRPC API routes with Supabase authentication context
app.use('/api/trpc', trpcExpress.createExpressMiddleware({
  router: appRouter,
  createContext: createTRPCContext,
  onError: ({ error, req }) => {
    logger.log('=== tRPC ERROR DEBUG ===');
    logger.log('Error code:', error.code);
    logger.log('Error message:', error.message);
    logger.log('Full error:', JSON.stringify(error, null, 2));
    logger.log('Request body:', (req as any).body);
    logger.log('Request headers:', (req as any).headers);
    logger.log('=== END tRPC ERROR DEBUG ===');
  },
}))

// Health check endpoint
app.get('/health', (req: any, res: any) => {
  logger.log(' Health check requested');
  res.status(200).json({ 
    status: 'healthy', 
    timestamp: new Date().toISOString(),
    environment: process.env.NODE_ENV || 'development'
  })
})

// Test endpoint for debugging
app.post('/test', (req: any, res: any) => {
  logger.log(' Test endpoint hit');
  logger.log('Request body:', JSON.stringify(req.body, null, 2));
  res.status(200).json({ 
    message: 'Test endpoint working',
    receivedBody: req.body,
    timestamp: new Date().toISOString()
  })
})

// Basic route
app.get('/', (req: any, res: any) => {
  res.json({ message: 'Phonoglyph API Server is running! ' })
})

// Initialize services (for serverless, this runs on cold start)
const initializeServices = async () => {
  try {
    await testConnection()
    await initializeS3()
  } catch (error) {
    console.error('Service initialization warning:', error)
  }
}

// For serverless deployment (Vercel), initialize on cold start
if (process.env.VERCEL) {
  initializeServices().catch(console.error)
}

// For local development - start the server
if (!process.env.VERCEL) {
  app.listen(PORT, async () => {
    console.log(` Server running on port ${PORT}`)
    console.log(` Environment: ${process.env.NODE_ENV || 'development'}`)
    await initializeServices()
  })
}

// Export the app for both Vercel serverless and potential imports
export default app
</file>

<file path="trpc.ts">
import { initTRPC, TRPCError } from '@trpc/server'
import type { CreateExpressContextOptions } from '@trpc/server/adapters/express'
import { z } from 'zod'
import { createSupabaseServerClient } from './lib/supabase'
import { transformSupabaseUser, type User, type AuthContext } from 'phonoglyph-types'
import { 
  extractGuestSession, 
  createGuestUserFromSession, 
  isValidGuestSession, 
  isGuestUser,
  type GuestUser 
} from './types/guest'
import { logger } from './lib/logger'

// Create tRPC context with Supabase authentication and guest support for Express
export const createTRPCContext = async (opts: CreateExpressContextOptions) => {
  const { req, res } = opts

  // Debug all headers
  logger.debug('Backend - All headers:', (req as any).headers)
  logger.debug('Backend - Authorization header:', (req as any).headers?.authorization)
  logger.debug('Backend - Content-Type header:', (req as any).headers?.['content-type'])

  // Extract authorization header
  const authHeader = (req as any).headers?.authorization
  const accessToken = authHeader?.replace('Bearer ', '')

  logger.auth('Backend - Auth header present:', !!authHeader)
  logger.auth('Backend - Access token present:', !!accessToken)

  // Create Supabase client with user session
  const supabase = createSupabaseServerClient(accessToken)

  let user: User | GuestUser | null = null
  let session: any = null
  let isGuest = false

  // Try to get authenticated user session first
  if (accessToken) {
    try {
      // Try different approaches for getting user data
      let supabaseUser: any = null;
      let error: any = null;
      
      try {
        // Use type assertion to access auth methods
        const authClient = supabase.auth as any;
        if (authClient.getUser) {
          const result = await authClient.getUser();
          supabaseUser = result.data?.user;
          error = result.error;
        } else if (authClient.getSession) {
          const { data: { session } } = await authClient.getSession();
          supabaseUser = session?.user || null;
        }
      } catch (authError) {
        error = authError;
      }
      
      logger.auth('Backend - Supabase user lookup result:', { user: !!supabaseUser, error: !!error })
      
      if (!error && supabaseUser) {
        user = transformSupabaseUser(supabaseUser)
        // For server-side, we create a session object from the user data
        // since getSession() doesn't work the same way on server
        session = {
          user: supabaseUser,
          access_token: accessToken,
          // Add other session properties as needed
        }
        logger.auth('Backend - User authenticated:', user.email)
      }
    } catch (error) {
      logger.error('Error retrieving user session:', error)
    }
  }

  // If no authenticated user, check for guest session
  if (!user) {
    const guestSession = extractGuestSession(req)
    if (guestSession && isValidGuestSession(guestSession.sessionId)) {
      user = createGuestUserFromSession(guestSession.sessionId)
      isGuest = true
      logger.auth('Backend - Guest user created')
    }
  }

  logger.auth('Backend - Final context:', { 
    hasUser: !!user, 
    hasSession: !!session, 
    isGuest 
  })

  return {
    req,
    res,
    supabase,
    user,
    session,
    isGuest,
  } as AuthContext & { req: any; res: any; isGuest: boolean }
}

export type Context = Awaited<ReturnType<typeof createTRPCContext>>

// Initialize tRPC with context
const t = initTRPC.context<Context>().create()

// Export reusable router and procedure helpers
export const router = t.router
export const publicProcedure = t.procedure

// Protected procedure that requires authentication
export const protectedProcedure = t.procedure.use(({ ctx, next }) => {
  if (!ctx.user || !ctx.session || ctx.isGuest) {
    throw new TRPCError({
      code: 'UNAUTHORIZED',
      message: 'You must be logged in to access this resource',
    })
  }
  return next({
    ctx: {
      ...ctx,
      user: ctx.user as User,
      session: ctx.session,
    },
  })
})

// Procedure that works with both authenticated and guest users
export const flexibleProcedure = t.procedure.use(({ ctx, next }) => {
  if (!ctx.user) {
    throw new TRPCError({
      code: 'UNAUTHORIZED',
      message: 'You must have a session (authenticated or guest) to access this resource',
    })
  }
  return next({
    ctx: {
      ...ctx,
      user: ctx.user,
      isGuest: ctx.isGuest,
    },
  })
})

// Guest-friendly procedure (allows access without any user session)
export const guestFriendlyProcedure = t.procedure.use(({ ctx, next }) => {
  return next({
    ctx: {
      ...ctx,
      user: ctx.user || null,
      isGuest: ctx.isGuest || false,
    },
  })
})
</file>

<file path="app/(auth)/login/page.tsx">
import { LoginForm } from "@/components/auth/login-form"
import { PhonoglyphLogo } from "@/components/ui/phonoglyph-logo"

export default function LoginPage() {
  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50 py-12 px-4 sm:px-6 lg:px-8">
      <div className="w-full max-w-md">
        <div className="text-center mb-8">
          <div className="flex justify-center mb-4">
            <PhonoglyphLogo size="lg" className="text-gray-900" />
          </div>
          <p className="mt-2 text-sm text-gray-600">
            Visualize your MIDI files with beautiful animations
          </p>
        </div>
        
        <LoginForm />
      </div>
    </div>
  )
}
</file>

<file path="app/(auth)/signup/page.tsx">
import { SignupForm } from "@/components/auth/signup-form"
import { PhonoglyphLogo } from "@/components/ui/phonoglyph-logo"

export default function SignupPage() {
  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50 py-12 px-4 sm:px-6 lg:px-8">
      <div className="w-full max-w-md">
        <div className="text-center mb-8">
          <div className="flex justify-center mb-4">
            <PhonoglyphLogo size="lg" className="text-gray-900" />
          </div>
          <p className="mt-2 text-sm text-gray-600">
            Create beautiful MIDI visualizations
          </p>
        </div>
        
        <SignupForm />
      </div>
    </div>
  )
}
</file>

<file path="app/audio-analysis-sandbox/page.tsx">
'use client';

import React, { useState, useCallback, useRef, useEffect } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Slider } from '@/components/ui/slider';
import { Badge } from '@/components/ui/badge';
import { Separator } from '@/components/ui/separator';
import { Upload, Play, Pause, Download, Settings, BarChart3, Music, Volume2 } from 'lucide-react';
import { useToast } from '@/hooks/use-toast';
import { AudioAnalysisSandbox } from '@/components/audio-analysis/audio-analysis-sandbox';
import { AnalysisVisualization } from '@/components/audio-analysis/analysis-visualization';
import { AnalysisParameters } from '@/components/audio-analysis/analysis-parameters';
import { AnalysisComparison } from '@/components/audio-analysis/analysis-comparison';
import { AudioAnalysisSandboxService } from '@/services/audio-analysis-sandbox-service';
import { ApiTest } from '@/components/audio-analysis/api-test';
import { AuthStatus } from '@/components/audio-analysis/auth-status';
import { debugLog } from '@/lib/utils';

export default function AudioAnalysisSandboxPage() {
  const [selectedFile, setSelectedFile] = useState<File | null>(null);
  const [audioBuffer, setAudioBuffer] = useState<AudioBuffer | null>(null);
  const [analysisData, setAnalysisData] = useState<any>(null);
  const [cachedAnalysis, setCachedAnalysis] = useState<any>(null);
  const [comparison, setComparison] = useState<any>(null);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [isPlaying, setIsPlaying] = useState(false);
  const [currentTime, setCurrentTime] = useState(0);
  const [duration, setDuration] = useState(0);
  const [isSaving, setIsSaving] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [analysisParams, setAnalysisParams] = useState({
    transientThreshold: 0.3,
    onsetThreshold: 0.2,
    chromaSmoothing: 0.8,
    rmsWindowSize: 1024,
    pitchConfidence: 0.7,
    minNoteDuration: 0.1
  });

  const audioRef = useRef<HTMLAudioElement>(null);
  const { toast } = useToast();

  const handleFileSelect = useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;

    if (!file.type.startsWith('audio/')) {
      toast({
        title: 'Invalid file type',
        description: 'Please select an audio file (MP3, WAV, etc.)',
        variant: 'destructive',
      });
      return;
    }

    if (file.size > 50 * 1024 * 1024) {
      toast({
        title: 'File too large',
        description: 'Please select a file smaller than 50MB',
        variant: 'destructive',
      });
      return;
    }

    setSelectedFile(file);
    setAnalysisData(null);
    setCurrentTime(0);
    setIsPlaying(false);

    // Load audio buffer for analysis
    const reader = new FileReader();
    reader.onload = async (e) => {
      try {
        const arrayBuffer = e.target?.result as ArrayBuffer;
        const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
        const buffer = await audioContext.decodeAudioData(arrayBuffer);
        setAudioBuffer(buffer);
        setDuration(buffer.duration);
      } catch (error) {
        debugLog.error('Error loading audio:', error);
        toast({
          title: 'Error loading audio',
          description: 'Failed to decode audio file',
          variant: 'destructive',
        });
      }
    };
    reader.readAsArrayBuffer(file);
  }, [toast]);

  const handleAnalyze = useCallback(async () => {
    if (!audioBuffer) return;

    setIsAnalyzing(true);
    setAnalysisData(null); // Clear previous analysis
    
    toast({
      title: 'Starting analysis...',
      description: 'Processing audio with new parameters',
    });
  }, [audioBuffer, toast]);

  const handleAnalysisComplete = useCallback((analysis: any) => {
    setAnalysisData(analysis);
    setIsAnalyzing(false);
    
    // Compare with cached analysis if available
    if (cachedAnalysis) {
      const comparisonData = AudioAnalysisSandboxService.compareAnalysis(analysis, cachedAnalysis);
      setComparison(comparisonData);
    }
    
    toast({
      title: 'Analysis complete!',
      description: 'Audio analysis finished successfully',
    });
  }, [cachedAnalysis, toast]);

  const handleSaveToCache = useCallback(async () => {
    if (!analysisData || !selectedFile) return;
    
    setIsSaving(true);
    try {
      // First upload the file if it hasn't been uploaded yet
      let fileId = 'sandbox-file'; // Default for demo
      
      // In a real implementation, you would upload the file first and get a real fileId
      // For now, we'll use a placeholder
      
      const success = await AudioAnalysisSandboxService.saveToCache(analysisData, fileId, 'master');
      if (success) {
        toast({
          title: 'Saved to cache!',
          description: 'Analysis data has been saved to the backend cache',
        });
      } else {
        throw new Error('Failed to save to cache');
      }
    } catch (error) {
      debugLog.error('Save error:', error);
      toast({
        title: 'Save failed',
        description: 'Failed to save analysis to cache',
        variant: 'destructive',
      });
    } finally {
      setIsSaving(false);
    }
  }, [analysisData, selectedFile, toast]);

  const handleLoadFromCache = useCallback(async () => {
    if (!selectedFile) return;
    
    setIsLoading(true);
    try {
      const fileId = 'sandbox-file'; // In real implementation, this would be the actual file ID
      const sandboxData = await AudioAnalysisSandboxService.loadFromCache(fileId, 'master');
      if (sandboxData) {
        setAnalysisData(sandboxData);
        toast({
          title: 'Loaded from cache!',
          description: 'Analysis data has been loaded from the backend cache',
        });
      } else {
        toast({
          title: 'No cached data',
          description: 'No cached analysis found for this file',
          variant: 'destructive',
        });
      }
    } catch (error) {
      debugLog.error('Load error:', error);
      toast({
        title: 'Load failed',
        description: 'Failed to load analysis from cache',
        variant: 'destructive',
      });
    } finally {
      setIsLoading(false);
    }
  }, [selectedFile, toast]);

  const handlePlayPause = useCallback(() => {
    if (!audioRef.current) return;

    if (isPlaying) {
      audioRef.current.pause();
      setIsPlaying(false);
    } else {
      audioRef.current.play();
      setIsPlaying(true);
    }
  }, [isPlaying]);

  const handleSeek = useCallback((time: number) => {
    if (audioRef.current) {
      audioRef.current.currentTime = time;
      setCurrentTime(time);
    }
  }, []);

  const handleTimeUpdate = useCallback(() => {
    if (audioRef.current) {
      setCurrentTime(audioRef.current.currentTime);
    }
  }, []);

  const handleEnded = useCallback(() => {
    setIsPlaying(false);
    setCurrentTime(0);
  }, []);

  return (
    <div className="min-h-screen bg-gradient-to-br from-slate-900 via-purple-900 to-slate-900 p-6">
      <div className="max-w-7xl mx-auto space-y-6">
        {/* Header */}
        <div className="text-center space-y-4">
          <h1 className="text-4xl font-bold text-white">
            Audio Analysis Sandbox
          </h1>
          <p className="text-xl text-slate-300">
            Test transient detection, chroma analysis, and RMS processing
          </p>
          <div className="flex justify-center gap-4">
            <Badge variant="outline" className="text-slate-300 border-slate-600">
              <Music className="w-3 h-3 mr-1" />
              Transient Detection
            </Badge>
            <Badge variant="outline" className="text-slate-300 border-slate-600">
              <BarChart3 className="w-3 h-3 mr-1" />
              Chroma Analysis
            </Badge>
            <Badge variant="outline" className="text-slate-300 border-slate-600">
              <Volume2 className="w-3 h-3 mr-1" />
              RMS Processing
            </Badge>
          </div>
        </div>

        {/* API Connection Test */}
        <ApiTest />

        {/* Authentication Status */}
        <AuthStatus />

        {/* File Upload Section */}
        <Card className="bg-slate-800/50 border-slate-700">
          <CardHeader>
            <CardTitle className="text-white flex items-center gap-2">
              <Upload className="w-5 h-5" />
              Audio File Upload
            </CardTitle>
          </CardHeader>
          <CardContent>
            <div className="space-y-4">
              <input
                type="file"
                accept="audio/*"
                onChange={handleFileSelect}
                className="block w-full text-sm text-slate-300 file:mr-4 file:py-2 file:px-4 file:rounded-lg file:border-0 file:text-sm file:font-semibold file:bg-purple-600 file:text-white hover:file:bg-purple-700"
              />
              
              {selectedFile && (
                <div className="flex items-center justify-between p-4 bg-slate-700/50 rounded-lg">
                  <div className="flex items-center gap-3">
                    <Music className="w-5 h-5 text-purple-400" />
                    <div>
                      <p className="text-white font-medium">{selectedFile.name}</p>
                      <p className="text-sm text-slate-400">
                        {(selectedFile.size / 1024 / 1024).toFixed(2)} MB
                      </p>
                    </div>
                  </div>
                  <div className="flex gap-2">
                    <Button
                      onClick={handleAnalyze}
                      disabled={isAnalyzing || !audioBuffer}
                      className="bg-purple-600 hover:bg-purple-700"
                    >
                      {isAnalyzing ? 'Analyzing...' : 'Analyze'}
                    </Button>
                    <Button
                      onClick={handlePlayPause}
                      disabled={!audioBuffer}
                      variant="outline"
                      className="border-slate-600 text-slate-300 hover:bg-slate-700"
                    >
                      {isPlaying ? <Pause className="w-4 h-4" /> : <Play className="w-4 h-4" />}
                    </Button>
                  </div>
                </div>
              )}

              {/* Hidden audio element for playback */}
              {selectedFile && (
                <audio
                  ref={audioRef}
                  src={URL.createObjectURL(selectedFile)}
                  onTimeUpdate={handleTimeUpdate}
                  onEnded={handleEnded}
                  className="hidden"
                />
              )}
            </div>
          </CardContent>
        </Card>

        {/* Audio Analysis Sandbox Component */}
        {audioBuffer && (
          <AudioAnalysisSandbox
            audioBuffer={audioBuffer}
            params={analysisParams}
            onAnalysisComplete={handleAnalysisComplete}
          />
        )}

        {/* Analysis Parameters */}
        {audioBuffer && (
          <AnalysisParameters
            params={analysisParams}
            onParamsChange={setAnalysisParams}
          />
        )}

        {/* Visualization */}
        {analysisData && (
          <AnalysisVisualization
            analysisData={analysisData}
            currentTime={currentTime}
            duration={duration}
            onSeek={handleSeek}
            isPlaying={isPlaying}
          />
        )}

        {/* Analysis Comparison */}
        {comparison && (
          <AnalysisComparison
            comparison={comparison}
            onSaveToCache={handleSaveToCache}
            onLoadFromCache={handleLoadFromCache}
            isSaving={isSaving}
            isLoading={isLoading}
          />
        )}

        {/* Analysis Results Summary */}
        {analysisData && (
          <Card className="bg-slate-800/50 border-slate-700">
            <CardHeader>
              <CardTitle className="text-white flex items-center gap-2">
                <BarChart3 className="w-5 h-5" />
                Analysis Results
              </CardTitle>
            </CardHeader>
            <CardContent>
              <div className="grid grid-cols-1 md:grid-cols-3 gap-4">
                <div className="text-center p-4 bg-slate-700/50 rounded-lg">
                  <h3 className="text-lg font-semibold text-white">Transients</h3>
                  <p className="text-2xl font-bold text-red-400">
                    {analysisData.transients?.length || 0}
                  </p>
                  <p className="text-sm text-slate-400">Detected onsets</p>
                </div>
                <div className="text-center p-4 bg-slate-700/50 rounded-lg">
                  <h3 className="text-lg font-semibold text-white">Chroma Notes</h3>
                  <p className="text-2xl font-bold text-blue-400">
                    {new Set(analysisData.chroma?.map((c: any) => c.note) || []).size}
                  </p>
                  <p className="text-sm text-slate-400">Unique notes</p>
                </div>
                <div className="text-center p-4 bg-slate-700/50 rounded-lg">
                  <h3 className="text-lg font-semibold text-white">RMS Avg</h3>
                  <p className="text-2xl font-bold text-green-400">
                    {analysisData.rms?.length ? 
                      (analysisData.rms.reduce((sum: number, r: any) => sum + r.value, 0) / analysisData.rms.length).toFixed(3) : 
                      '0.000'
                    }
                  </p>
                  <p className="text-sm text-slate-400">Average amplitude</p>
                </div>
              </div>
            </CardContent>
          </Card>
        )}
      </div>
    </div>
  );
}
</file>

<file path="app/audio-analysis-sandbox/README.md">
# Audio Analysis Sandbox

This sandbox environment allows you to test a new audio analysis pipeline focused on transient detection, chroma analysis, and RMS processing.

## Features

- **Transient Detection**: Spectral flux-based onset detection
- **Chroma Analysis**: YIN pitch detection for MIDI-like note analysis  
- **RMS Processing**: Configurable window-based amplitude analysis
- **Real-time Visualization**: Interactive waveforms with analysis overlays
- **Parameter Tuning**: Adjustable thresholds and settings
- **Cache Integration**: Save/load analysis results to backend

## API Configuration

The sandbox requires the API server to be running. Make sure your environment variables are set:

```bash
# In your .env.local file
NEXT_PUBLIC_API_URL=http://localhost:3001
```

Or for production:
```bash
NEXT_PUBLIC_API_URL=https://api.phonoglyph.rheome.tools
```

## Usage

1. Navigate to `/audio-analysis-sandbox`
2. Upload an audio file (MP3, WAV, etc.)
3. Adjust analysis parameters using the sliders
4. View real-time visualizations
5. Save results to backend cache
6. Compare with existing analysis methods

## API Endpoints

The sandbox uses the following tRPC endpoints:

- `audioAnalysisSandbox.saveSandboxAnalysis` - Save analysis to cache
- `audioAnalysisSandbox.getSandboxAnalysis` - Load analysis from cache
- `audioAnalysisSandbox.compareAnalysis` - Compare analysis methods
- `audioAnalysisSandbox.getSandboxAnalyses` - List all sandbox analyses
- `audioAnalysisSandbox.deleteSandboxAnalysis` - Delete analysis

## Troubleshooting

If you see a 404 error for the API:

1. Ensure the API server is running on the correct port
2. Check your `NEXT_PUBLIC_API_URL` environment variable
3. Verify the tRPC router is properly configured
4. Check browser console for detailed error messages

## Development

To add new analysis features:

1. Update the analysis algorithms in `AudioAnalysisSandbox` component
2. Add new parameters to the `AnalysisParameters` component
3. Update the visualization in `AnalysisVisualization` component
4. Modify the API schema in `audio-analysis-sandbox.ts` router
</file>

<file path="app/auth/callback/route.ts">
import { NextRequest, NextResponse } from 'next/server'
import { supabase } from '@/lib/supabase'
import { debugLog } from '@/lib/utils';

export async function GET(request: NextRequest) {
  const requestUrl = new URL(request.url)
  const code = requestUrl.searchParams.get('code')
  const next = requestUrl.searchParams.get('next') ?? '/'

  // Check if Supabase is properly configured
  if (!process.env.NEXT_PUBLIC_SUPABASE_URL || !process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY) {
    debugLog.error('Supabase not configured properly')
    return NextResponse.redirect(new URL('/auth/error', request.url))
  }

  if (code) {
    try {
      const { error } = await supabase.auth.exchangeCodeForSession(code)
      
      if (error) {
        debugLog.error('OAuth callback error:', error)
        return NextResponse.redirect(new URL('/auth/error', request.url))
      }
    } catch (error) {
      debugLog.error('OAuth callback error:', error)
      return NextResponse.redirect(new URL('/auth/error', request.url))
    }
  }

  // Redirect to the intended page or dashboard
  return NextResponse.redirect(new URL(next, request.url))
}
</file>

<file path="app/auth/error/page.tsx">
import Link from 'next/link'

export default function AuthErrorPage() {
  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50">
      <div className="max-w-md w-full space-y-8">
        <div className="text-center">
          <h2 className="mt-6 text-3xl font-extrabold text-gray-900">
            Authentication Error
          </h2>
          <p className="mt-2 text-sm text-gray-600">
            There was an error signing you in. Please try again.
          </p>
        </div>
        
        <div className="space-y-4">
          <Link
            href="/auth/login"
            className="w-full flex justify-center py-2 px-4 border border-transparent rounded-md shadow-sm text-sm font-medium text-white bg-indigo-600 hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-indigo-500"
          >
            Try Again
          </Link>
          
          <Link
            href="/"
            className="w-full flex justify-center py-2 px-4 border border-gray-300 rounded-md shadow-sm text-sm font-medium text-gray-700 bg-white hover:bg-gray-50 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-indigo-500"
          >
            Go Home
          </Link>
        </div>
      </div>
    </div>
  )
}
</file>

<file path="app/creative-visualizer/page.tsx">
'use client';

import React, { useState, useRef, useEffect, useCallback, Suspense } from 'react';
import { DndProvider } from 'react-dnd';
import { HTML5Backend } from 'react-dnd-html5-backend';
import { useRouter, useSearchParams } from 'next/navigation';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { Play, Pause, RotateCcw, Zap, Palette, Settings2, Eye, EyeOff, Info, Map } from 'lucide-react';
import { ThreeVisualizer } from '@/components/midi/three-visualizer';
import { EffectsLibrarySidebar, EffectUIData } from '@/components/ui/EffectsLibrarySidebar';
import { CollapsibleEffectsSidebar } from '@/components/layout/collapsible-effects-sidebar';
import { FileSelector } from '@/components/midi/file-selector';
import { MIDIData, VisualizationSettings, DEFAULT_VISUALIZATION_SETTINGS } from '@/types/midi';
import { VisualizationPreset, StemVisualizationMapping } from '@/types/stem-visualization';
import { AudioAnalysisData, LiveMIDIData } from '@/types/visualizer';
import { trpc } from '@/lib/trpc';
import { CollapsibleSidebar } from '@/components/layout/collapsible-sidebar';
import { ProjectPickerModal } from '@/components/projects/project-picker-modal';
import { debugLog } from '@/lib/utils';
import { ProjectCreationModal } from '@/components/projects/project-creation-modal';
import { useStemAudioController } from '@/hooks/use-stem-audio-controller';
import { useAudioAnalysis } from '@/hooks/use-audio-analysis';
import { PortalModal } from '@/components/ui/portal-modal';
import { Slider } from '@/components/ui/slider';
import { Label } from '@/components/ui/label';
import { Switch } from '@/components/ui/switch';
import { MappingSourcesPanel } from '@/components/ui/MappingSourcesPanel';
import { DroppableParameter } from '@/components/ui/droppable-parameter';
import { LayerContainer } from '@/components/video-composition/LayerContainer';
import { UnifiedTimeline } from '@/components/video-composition/UnifiedTimeline';
import { TestVideoComposition } from '@/components/video-composition/TestVideoComposition';
import type { Layer } from '@/types/video-composition';
import { useFeatureValue } from '@/hooks/use-feature-value';
import { HudOverlayProvider, useHudOverlayContext } from '@/components/hud/HudOverlayManager';
import { AspectRatioSelector } from '@/components/ui/aspect-ratio-selector';
import { getAspectRatioConfig } from '@/lib/visualizer/aspect-ratios';

// Derived boolean: are stem URLs ready?
// const stemUrlsReady = Object.keys(asyncStemUrlMap).length > 0; // This line was moved

// Wrapper component that provides HUD overlay functionality to the sidebar
const EffectsLibrarySidebarWithHud: React.FC<{
  effects: any[];
  selectedEffects: Record<string, boolean>;
  onEffectToggle: (effectId: string) => void;
  onEffectDoubleClick: (effectId: string) => void;
  isVisible: boolean;
  stemUrlsReady: boolean;
}> = ({ effects, selectedEffects, onEffectToggle, onEffectDoubleClick, isVisible, stemUrlsReady }) => {
  const [isClient, setIsClient] = useState(false);
  
  useEffect(() => {
    setIsClient(true);
  }, []);
  
  const hudContext = useHudOverlayContext();
  
  const handleEffectDoubleClick = (effectId: string) => {
    if (!stemUrlsReady) {
      debugLog.warn('[EffectsLibrarySidebarWithHud] Overlay creation blocked: stem URLs not ready');
      return;
    }
    const effect = effects.find(e => e.id === effectId);
    if (effect && effect.category === 'Overlays' && isClient) {
      // Map effect ID to overlay type
      const overlayTypeMap: Record<string, string> = {
        'waveform': 'waveform',
        'spectrogram': 'spectrogram',
        'peakMeter': 'peakMeter',
        'stereometer': 'stereometer',
        'oscilloscope': 'oscilloscope',
        'spectrumAnalyzer': 'spectrumAnalyzer',
        'midiMeter': 'midiMeter'
      };
      
      const overlayType = overlayTypeMap[effectId];
      if (overlayType) {
        debugLog.log(' Adding HUD overlay:', overlayType);
        hudContext.addOverlay(overlayType);
      }
    }
    onEffectDoubleClick(effectId);
  };
  
  return (
    <EffectsLibrarySidebar
      effects={effects}
      selectedEffects={selectedEffects}
      onEffectToggle={onEffectToggle}
      onEffectDoubleClick={handleEffectDoubleClick}
      isVisible={isVisible}
    />
  );
};

// Sample MIDI data for demonstration
const createSampleMIDIData = (): MIDIData => {
  const notes: any[] = [];
  const melodyPattern = [60, 64, 67, 72, 69, 65, 62, 60, 67, 64, 69, 72, 74, 67, 64, 60];
  for (let i = 0; i < melodyPattern.length; i++) {
    notes.push({
      id: `melody-${i}`,
      start: i * 0.5,
      duration: 0.4,
      pitch: melodyPattern[i],
      velocity: 60 + Math.random() * 40,
      track: 'melody',
      noteName: `Note${melodyPattern[i]}`,
    });
  }
  const chordTimes = [2, 4, 6, 8];
  chordTimes.forEach((time, idx) => {
    const chordNotes = [48, 52, 55];
    chordNotes.forEach((note, noteIdx) => {
      notes.push({
        id: `chord-${idx}-${noteIdx}`,
        start: time,
        duration: 1.5,
        pitch: note,
        velocity: 40 + Math.random() * 30,
        track: 'melody',
        noteName: `Chord${note}`,
      });
    });
  });

  return {
    file: {
      name: 'Creative Demo.mid',
      size: 1024,
      duration: 10.0,
      ticksPerQuarter: 480,
      timeSignature: [4, 4],
      keySignature: 'C Major'
    },
    tracks: [
      { id: 'melody', name: 'Synth Lead', instrument: 'Synthesizer', channel: 1, color: '#84a98c', visible: true, notes: notes },
      { id: 'bass', name: 'Bass Synth', instrument: 'Bass', channel: 2, color: '#6b7c93', visible: true, notes: [
          { id: 'b1', start: 0.0, duration: 1.0, pitch: 36, velocity: 100, track: 'bass', noteName: 'C2' },
          { id: 'b2', start: 1.0, duration: 1.0, pitch: 40, velocity: 95, track: 'bass', noteName: 'E2' },
          { id: 'b3', start: 2.0, duration: 1.0, pitch: 43, velocity: 90, track: 'bass', noteName: 'G2' },
          { id: 'b4', start: 3.0, duration: 1.0, pitch: 48, velocity: 85, track: 'bass', noteName: 'C3' },
          { id: 'b5', start: 4.0, duration: 2.0, pitch: 36, velocity: 100, track: 'bass', noteName: 'C2' },
        ]
      },
      { id: 'drums', name: 'Drums', instrument: 'Drum Kit', channel: 10, color: '#b08a8a', visible: true, notes: [
          { id: 'd1', start: 0.0, duration: 0.1, pitch: 36, velocity: 120, track: 'drums', noteName: 'Kick' },
          { id: 'd2', start: 0.5, duration: 0.1, pitch: 42, velocity: 80, track: 'drums', noteName: 'HiHat' },
          { id: 'd3', start: 1.0, duration: 0.1, pitch: 38, velocity: 100, track: 'drums', noteName: 'Snare' },
          { id: 'd4', start: 1.5, duration: 0.1, pitch: 42, velocity: 70, track: 'drums', noteName: 'HiHat' },
          { id: 'd5', start: 2.0, duration: 0.1, pitch: 36, velocity: 127, track: 'drums', noteName: 'Kick' },
          { id: 'd6', start: 2.5, duration: 0.1, pitch: 42, velocity: 85, track: 'drums', noteName: 'HiHat' },
          { id: 'd7', start: 3.0, duration: 0.1, pitch: 38, velocity: 110, track: 'drums', noteName: 'Snare' },
          { id: 'd8', start: 3.5, duration: 0.1, pitch: 42, velocity: 75, track: 'drums', noteName: 'HiHat' },
        ]
      }
    ],
    tempoChanges: [
      { tick: 0, bpm: 120, microsecondsPerQuarter: 500000 }
    ]
  };
};

// Transform backend MIDI data to frontend format
const transformBackendToFrontendMidiData = (backendData: any): MIDIData => {
  return {
    file: {
      name: backendData.file.name,
      size: backendData.file.size,
      duration: backendData.file.duration,
      ticksPerQuarter: backendData.file.ticksPerQuarter,
      timeSignature: backendData.file.timeSignature,
      keySignature: backendData.file.keySignature
    },
    tracks: backendData.tracks.map((track: any) => ({
      id: String(track.id),
      name: track.name,
      instrument: track.instrument,
      channel: track.channel,
      color: track.color,
      visible: true,
      notes: track.notes.map((note: any) => ({
        id: note.id,
        start: note.startTime, // Backend: startTime -> Frontend: start
        duration: note.duration,
        pitch: note.note,      // Backend: note -> Frontend: pitch
        velocity: note.velocity,
        track: String(track.id), // Backend: track (number) -> Frontend: track (string)
        noteName: note.name,   // Backend: name -> Frontend: noteName
      }))
    })),
    tempoChanges: backendData.tempoChanges
  };
};


function CreativeVisualizerPage() {
  const router = useRouter();
  const searchParams = useSearchParams();
  const [isClient, setIsClient] = useState(false);

  // Ensure we're on the client side to prevent hydration issues
  useEffect(() => {
    setIsClient(true);
  }, []);
  
  const [selectedFileId, setSelectedFileId] = useState<string | null>(null);
  const [useDemoData, setUseDemoData] = useState(false);
  const [currentProjectId, setCurrentProjectId] = useState<string | null>(null);
  const [isInitialized, setIsInitialized] = useState(false);
  
  const [settings, setSettings] = useState<VisualizationSettings>(DEFAULT_VISUALIZATION_SETTINGS);
  const [currentTime, setCurrentTime] = useState(0);
  const [isPlaying, setIsPlaying] = useState(false);
  const [fps, setFps] = useState(60);
  const playbackIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const [isMapMode, setIsMapMode] = useState(false);
  const [currentPreset, setCurrentPreset] = useState<VisualizationPreset>({
    id: 'default',
    name: 'Default',
    description: 'Default visualization preset',
    category: 'custom',
    tags: ['default'],
    mappings: {},
    defaultSettings: {
      masterIntensity: 1.0,
      transitionSpeed: 1.0,
      backgroundAlpha: 0.1,
      particleCount: 100,
      qualityLevel: 'medium'
    },
    createdAt: new Date().toISOString(),
    updatedAt: new Date().toISOString(),
    isDefault: true,
    usageCount: 0
  });

  // Effects timeline state
  const [effectClips, setEffectClips] = useState<Array<{
    id: string;
    effectId: string;
    name: string;
    startTime: number;
    endTime: number;
    parameters: Record<string, any>;
  }>>([]);

  // Video composition state
  const [videoLayers, setVideoLayers] = useState<Layer[]>([]);
  const [selectedLayerId, setSelectedLayerId] = useState<string | null>(null);
  const [showVideoComposition, setShowVideoComposition] = useState(false);

  // Effects carousel state (now for timeline-based effects)
  const [selectedEffects, setSelectedEffects] = useState<Record<string, boolean>>({});

  // Visualizer aspect ratio toggle state - now using modular system
  const [visualizerAspectRatio, setVisualizerAspectRatio] = useState<string>('mobile');

  // Effect parameter modal state
  const [openEffectModals, setOpenEffectModals] = useState<Record<string, boolean>>({
    'metaballs': false,
    'midiHud': false,
    'particleNetwork': false
  });

  // Feature mapping state
  interface FeatureMapping {
    featureId: string | null;
    modulationAmount: number; // 0-1, default 1.0 (100%)
  }
  const [mappings, setMappings] = useState<Record<string, FeatureMapping>>({});
  const [featureNames, setFeatureNames] = useState<Record<string, string>>({});
  const [activeTrackId, setActiveTrackId] = useState<string | null>(null);
  // Base (user-set) parameter values and last modulated values for visualization
  const [baseParameterValues, setBaseParameterValues] = useState<Record<string, number>>({});
  const [modulatedParameterValues, setModulatedParameterValues] = useState<Record<string, number>>({});

  // Real-time sync calibration offset in ms
  const [syncOffsetMs, setSyncOffsetMs] = useState(0);

  // Performance monitoring for sync debugging
  const [syncMetrics, setSyncMetrics] = useState({
    audioLatency: 0,
    visualLatency: 0,
    syncDrift: 0,
    frameTime: 0,
    lastUpdate: 0
  });

  const [sampleMidiData] = useState<MIDIData>(createSampleMIDIData());
  const stemAudio = useStemAudioController();
  const audioAnalysis = useAudioAnalysis();
  
  // Sync performance monitoring
  useEffect(() => {
    if (!isPlaying) return;
    
    const updateSyncMetrics = () => {
      const now = performance.now();
      const audioTime = stemAudio.currentTime;
      const visualTime = currentTime;
      const audioLatency = stemAudio.getAudioLatency ? stemAudio.getAudioLatency() * 1000 : 0;
      const frameTime = now - syncMetrics.lastUpdate;
      
      setSyncMetrics({
        audioLatency,
        visualLatency: frameTime,
        syncDrift: Math.abs(audioTime - visualTime) * 1000, // Convert to ms
        frameTime,
        lastUpdate: now
      });
    };
    
    const interval = setInterval(updateSyncMetrics, 100); // Update every 100ms
    return () => clearInterval(interval);
  }, [isPlaying, stemAudio.currentTime, currentTime, syncMetrics.lastUpdate]);
  
  // Enhanced audio analysis data - This state is no longer needed, data comes from useCachedStemAnalysis
  // const [audioAnalysisData, setAudioAnalysisData] = useState<any>(null);
  
  const [showPicker, setShowPicker] = useState(false);
  const [showCreateModal, setShowCreateModal] = useState(false);
  const isLoadingStemsRef = useRef(false);
  const [isCacheLoaded, setIsCacheLoaded] = useState(false);
  
  // Ref to track current analysis state to avoid stale closures
  const currentAnalysisRef = useRef(audioAnalysis.cachedAnalysis);
  
  // Update ref when analysis changes
  useEffect(() => {
    currentAnalysisRef.current = audioAnalysis.cachedAnalysis;
  }, [audioAnalysis.cachedAnalysis]);

  // Get download URL mutation
  const getDownloadUrlMutation = trpc.file.getDownloadUrl.useMutation();

  // Fetch current project information
  const { 
    data: projectData, 
    isLoading: projectLoading, 
    error: projectError 
  } = trpc.project.get.useQuery(
    { id: currentProjectId! },
    { enabled: !!currentProjectId }
  );

  // Fetch project files to get available stems
  const { 
    data: projectFiles, 
    isLoading: projectFilesLoading 
  } = trpc.file.getUserFiles.useQuery(
    { 
      limit: 20, 
      fileType: 'all',
      projectId: currentProjectId || undefined
    },
    { enabled: !!currentProjectId }
  );

  // Fetch MIDI visualization data
  const { 
    data: fileData, 
    isLoading: fileLoading, 
    error: fileError 
  } = trpc.midi.getVisualizationData.useQuery(
    { fileId: selectedFileId! },
    { enabled: !!selectedFileId && !useDemoData }
  );

  useEffect(() => {
    const fileId = searchParams.get('fileId');
    const projectId = searchParams.get('projectId');
    
    if (projectId) {
      setCurrentProjectId(projectId);
      setUseDemoData(false);
    }
    
    if (fileId) {
      setSelectedFileId(fileId);
      setUseDemoData(false);
    }

    // If no project or file is specified, default to demo mode
    if (!projectId && !fileId) {
      setUseDemoData(true);
    }

    const projectIdFromParams = searchParams.get('projectId');
    if (!projectIdFromParams) {
      setShowPicker(true);
    } else {
      setShowPicker(false);
    }

    // Mark as initialized after processing URL params
    setIsInitialized(true);
  }, [searchParams]);

  // Helper to sort stems: non-master first, master last
  function sortStemsWithMasterLast(stems: any[]) {
    return [...stems].sort((a, b) => {
      if (a.is_master && !b.is_master) return 1;
      if (!a.is_master && b.is_master) return -1;
      return 0;
    });
  }

  // Load stems when project files are available
  useEffect(() => {
    // This effect now correctly handles both initial load and changes to project files
    if (projectFiles?.files && currentProjectId && isInitialized && !audioAnalysis.isLoading) {
      let cancelled = false;
      
      const loadStemsWithUrls = async () => {
        // Prevent re-loading if already in progress
        if (isLoadingStemsRef.current) return;
        isLoadingStemsRef.current = true;

        try {
          const audioFiles = projectFiles.files.filter(file => 
            file.file_type === 'audio' && file.upload_status === 'completed'
          );

          if (audioFiles.length > 0) {
            debugLog.log('Found audio files, preparing to load:', audioFiles.map(f => f.file_name));
            debugLog.log('Master stem info:', audioFiles.map(f => ({ name: f.file_name, is_master: f.is_master })));
            
            // Debug: Log file structure to see what fields are available
            debugLog.log('Audio file structure sample:', audioFiles[0]);
            
            // Sort so master is last
            const sortedAudioFiles = sortStemsWithMasterLast(audioFiles.map(f => ({
              ...f,
              stemType: f.stem_type || getStemTypeFromFileName(f.file_name)
            })));

            const stemsToLoad = await Promise.all(
              sortedAudioFiles.map(async file => {
                // Debug: Check if file.id exists
                if (!file.id) {
                  debugLog.error('File missing ID:', file);
                  throw new Error(`File missing ID: ${file.file_name}`);
                }
                
                debugLog.log('Getting download URL for file:', { id: file.id, name: file.file_name });
                const result = await getDownloadUrlMutation.mutateAsync({ fileId: file.id });
                return {
                  id: file.id,
                  url: result.downloadUrl,
                  label: file.file_name,
                  isMaster: file.is_master || false,
                  stemType: file.stemType
                };
              })
            );

            if (!cancelled) {
              // Process non-master first, then master
              const nonMasterStems = stemsToLoad.filter(s => !s.isMaster);
              const masterStems = stemsToLoad.filter(s => s.isMaster);
              await stemAudio.loadStems(nonMasterStems, (stemId, audioBuffer) => {
                const stem = nonMasterStems.find(s => s.id === stemId);
                // Use ref to get current state to avoid stale closure
                const currentAnalysis = currentAnalysisRef.current;
                const hasAnalysis = currentAnalysis.some(a => a.fileMetadataId === stemId);
                debugLog.log(' Stem loaded callback:', { 
                  stemId, 
                  stemType: stem?.stemType, 
                  hasAnalysis,
                  cachedAnalysisCount: currentAnalysis.length,
                  cachedAnalysisIds: currentAnalysis.map(a => a.fileMetadataId)
                });
                if (stem && !hasAnalysis) {
                  debugLog.log(' Triggering analysis for stem:', stemId, stem.stemType);
                  audioAnalysis.analyzeAudioBuffer(stemId, audioBuffer, stem.stemType);
                } else {
                  debugLog.log(' Skipping analysis for stem:', stemId, 'reason:', !stem ? 'no stem found' : 'analysis already exists');
                }
              });
              if (masterStems.length > 0) {
                await stemAudio.loadStems(masterStems, (stemId, audioBuffer) => {
                  const stem = masterStems.find(s => s.id === stemId);
                  // Use ref to get current state to avoid stale closure
                  const currentAnalysis = currentAnalysisRef.current;
                  const hasAnalysis = currentAnalysis.some(a => a.fileMetadataId === stemId);
                  debugLog.log(' Master stem loaded callback:', { 
                    stemId, 
                    stemType: stem?.stemType, 
                    hasAnalysis,
                    cachedAnalysisCount: currentAnalysis.length,
                    cachedAnalysisIds: currentAnalysis.map(a => a.fileMetadataId)
                  });
                  if (stem && !hasAnalysis) {
                    debugLog.log(' Triggering analysis for master stem:', stemId, stem.stemType);
                    audioAnalysis.analyzeAudioBuffer(stemId, audioBuffer, stem.stemType);
                  } else {
                    debugLog.log(' Skipping analysis for master stem:', stemId, 'reason:', !stem ? 'no stem found' : 'analysis already exists');
                  }
                });
              }
            }
          } else {
            debugLog.log('No completed audio files found in project.');
          }
        } catch (error) {
          if (!cancelled) {
            debugLog.error('Failed to load stems:', error);
          }
        } finally {
          if (!cancelled) {
            isLoadingStemsRef.current = false;
          }
        }
      };
      
      loadStemsWithUrls();
      return () => { 
        cancelled = true; 
        isLoadingStemsRef.current = false;
      };
    }
  }, [projectFiles?.files, currentProjectId, isInitialized, audioAnalysis.isLoading]); // Removed audioAnalysis.cachedAnalysis from dependencies

  

  const availableStems = projectFiles?.files?.filter(file => 
    file.file_type === 'audio' && file.upload_status === 'completed'
  ) || [];

  // Load all analyses when stems are available
  useEffect(() => {
    if (availableStems.length > 0) {
      const stemIds = availableStems.map(stem => stem.id);
      audioAnalysis.loadAnalysis(stemIds);
    }
  }, [availableStems.length]); // Only depend on stem count, not the analysis functions



  const midiData = useDemoData ? sampleMidiData : (fileData?.midiData ? transformBackendToFrontendMidiData(fileData.midiData) : undefined);
  const visualizationSettings = useDemoData ? DEFAULT_VISUALIZATION_SETTINGS : (fileData?.settings || DEFAULT_VISUALIZATION_SETTINGS);

  const handleFileSelected = (fileId: string) => {
    setSelectedFileId(fileId);
    setUseDemoData(false);
    setCurrentTime(0);
    setIsPlaying(false);
    
    const params = new URLSearchParams(searchParams);
    params.set('fileId', fileId);
    router.push(`/creative-visualizer?${params.toString()}`, { scroll: false });
  };

  const handleDemoModeChange = useCallback((demoMode: boolean) => {
    setUseDemoData(demoMode);
    setCurrentTime(0);
    setIsPlaying(false);
    
    if (demoMode) {
      const params = new URLSearchParams(searchParams);
      params.delete('fileId');
      const newUrl = params.toString() ? `/creative-visualizer?${params.toString()}` : '/creative-visualizer';
      router.push(newUrl, { scroll: false });
    }
  }, [searchParams, router]);

  const handlePlayPause = async () => {
    // Control both MIDI visualization and stem audio
    if (isPlaying) {
      stemAudio.pause();
      setIsPlaying(false);
    } else {
      // Only start if we have stems loaded
      if (hasStems) {
        try {
          await stemAudio.play();
          setIsPlaying(true);
        } catch (error) {
          debugLog.error('Failed to start audio playback:', error);
          setIsPlaying(false);
        }
      } else {
        setIsPlaying(true);
      }
    }
  };

  const handleReset = () => {
    stemAudio.stop();
    setIsPlaying(false);
    setCurrentTime(0);
  };

  const handleProjectSelect = (projectId: string) => {
    setCurrentProjectId(projectId);
    setShowPicker(false);
    const params = new URLSearchParams(searchParams);
    params.set('projectId', projectId);
    router.push(`/creative-visualizer?${params.toString()}`);
  };

  const handleCreateNew = () => {
    setShowPicker(false);
    setShowCreateModal(true);
  };

  const handleCloseCreateModal = () => {
    setShowCreateModal(false);
  };

  


  

  // Check if stems are actually loaded in the audio controller, not just available in the project
  const hasStems = availableStems.length > 0 && stemAudio.stemsLoaded;
  
  // Check if we're currently loading stems
  const stemLoadingState = availableStems.length > 0 && !stemAudio.stemsLoaded;

  // Effects data for new sidebar (with categories and rarity)
  const effects: EffectUIData[] = [
    { 
      id: 'metaballs', 
      name: 'Metaballs Effect', 
      description: 'Organic, fluid-like visualizations that respond to audio intensity',
      category: 'Generative',
      rarity: 'Rare',
      image: '/effects/generative/metaballs.png',
      parameters: {} // <-- Added
    },
    { 
      id: 'midiHud', 
      name: 'HUD Effect', 
      description: 'Technical overlay displaying real-time audio analysis and MIDI data',
      category: 'Overlays',
      rarity: 'Common',
      parameters: {} // <-- Added
    },
    { 
      id: 'particleNetwork', 
      name: 'Particle Effect', 
      description: 'Dynamic particle systems that react to rhythm and pitch',
      category: 'Generative',
      rarity: 'Mythic',
      image: '/effects/generative/particles.png',
      parameters: {} // Empty - modal is handled by ThreeVisualizer
    },
    // HUD Overlay Effects
    { 
      id: 'waveform', 
      name: 'Waveform Overlay', 
      description: 'Real-time audio waveform visualization',
      category: 'Overlays',
      rarity: 'Common',
      parameters: {}
    },
    { 
      id: 'spectrogram', 
      name: 'Spectrogram Overlay', 
      description: 'Frequency vs time visualization with color mapping',
      category: 'Overlays',
      rarity: 'Rare',
      parameters: {}
    },
    { 
      id: 'peakMeter', 
      name: 'Peak/LUFS Meter', 
      description: 'Professional audio level metering with peak and LUFS measurements',
      category: 'Overlays',
      rarity: 'Common',
      parameters: {}
    },
    { 
      id: 'stereometer', 
      name: 'Stereometer Overlay', 
      description: 'Stereo field visualization and correlation meter',
      category: 'Overlays',
      rarity: 'Rare',
      parameters: {}
    },
    { 
      id: 'oscilloscope', 
      name: 'Oscilloscope Overlay', 
      description: 'Real-time waveform oscilloscope with pitch tracking',
      category: 'Overlays',
      rarity: 'Mythic',
      parameters: {}
    },
    { 
      id: 'spectrumAnalyzer', 
      name: 'Spectrum Analyzer', 
      description: 'FFT-based frequency spectrum visualization',
      category: 'Overlays',
      rarity: 'Rare',
      parameters: {}
    },
    { 
      id: 'midiMeter', 
      name: 'MIDI Activity Meter', 
      description: 'Real-time MIDI note and velocity visualization',
      category: 'Overlays',
      rarity: 'Common',
      parameters: {}
    },
    { 
      id: 'vuMeter', 
      name: 'VU Meter', 
      description: 'Classic VU meter with needle and bar styles',
      category: 'Overlays',
      rarity: 'Common',
      parameters: {}
    },
    { 
      id: 'chromaWheel', 
      name: 'Chroma Wheel', 
      description: '12-note chroma wheel for pitch class visualization',
      category: 'Overlays',
      rarity: 'Rare',
      parameters: {}
    },
    { 
      id: 'consoleFeed', 
      name: 'Data Feed', 
      description: 'Live data feed for MIDI, LUFS, FFT, and more',
      category: 'Overlays',
      rarity: 'Common',
      parameters: {}
    }
  ];

  const handleSelectEffect = (effectId: string) => {
    // Toggle the effect selection
    setSelectedEffects(prev => ({
      ...prev,
      [effectId]: !prev[effectId]
    }));
    
    // Open the parameter modal for this effect
    setOpenEffectModals(prev => ({
      ...prev,
      [effectId]: true
    }));
  };

  const handleEffectDoubleClick = (effectId: string) => {
    // Open the parameter modal for this effect
    setOpenEffectModals(prev => ({
      ...prev,
      [effectId]: true
    }));
  };

  const handleEffectClipAdd = (effect: any) => {
    const newClip = {
      id: `${effect.id}-${Date.now()}`,
      effectId: effect.id,
      name: effect.name,
      startTime: stemAudio.currentTime,
      endTime: stemAudio.currentTime + 10, // Default 10 second duration
      parameters: effect.parameters || {}
    };
    setEffectClips(prev => [...prev, newClip]);
    
    // Also enable the effect in the visualizer
    setSelectedEffects(prev => ({
      ...prev,
      [effect.id]: true
    }));
    
    debugLog.log('Effect added to timeline:', newClip);
  };

  const handleEffectClipRemove = (clipId: string) => {
    setEffectClips(prev => prev.filter(clip => clip.id !== clipId));
  };

  const handleEffectClipEdit = (clipId: string) => {
    const clip = effectClips.find(c => c.id === clipId);
    if (clip) {
      setOpenEffectModals(prev => ({
        ...prev,
        [clip.effectId]: true
      }));
    }
  };



  const handleCloseEffectModal = (effectId: string) => {
    setOpenEffectModals(prev => ({
      ...prev,
      [effectId]: false
    }));
  };

  // Video composition handlers
  const handleLayerAdd = (layer: Layer) => {
    setVideoLayers(prev => [...prev, layer]);
  };

  const handleLayerUpdate = (layerId: string, updates: Partial<Layer>) => {
    debugLog.log('handleLayerUpdate', layerId, updates);
    setVideoLayers(prev => prev.map(layer => 
      layer.id === layerId ? { ...layer, ...updates } : layer
    ));
  };

  const handleLayerDelete = (layerId: string) => {
    setVideoLayers(prev => prev.filter(layer => layer.id !== layerId));
    if (selectedLayerId === layerId) {
      setSelectedLayerId(null);
    }
  };

  const handleLayerSelect = (layerId: string) => {
    setSelectedLayerId(layerId);
  };





  // Feature mapping handlers
  const handleMapFeature = (parameterId: string, featureId: string) => {
    debugLog.log(' Creating mapping:', {
      parameterId,
      featureId,
      parameterName: parameterId.split('-')[1],
      effectId: parameterId.split('-')[0]
    });
    
    setMappings(prev => ({ 
      ...prev, 
      [parameterId]: { 
        featureId, 
        modulationAmount: 0.5 // Default to 50% (noon)
      } 
    }));
    
    // Store feature name for display
    const featureName = featureId.split('-').map(word => 
      word.charAt(0).toUpperCase() + word.slice(1)
    ).join(' ');
    setFeatureNames(prev => ({ ...prev, [featureId]: featureName }));
    
    debugLog.log(' Mapping created successfully');
  };

  const handleUnmapFeature = (parameterId: string) => {
    debugLog.log(' Removing mapping:', {
      parameterId,
      currentMapping: mappings[parameterId]
    });
    
    setMappings(prev => ({ 
      ...prev, 
      [parameterId]: { 
        featureId: null, 
        modulationAmount: 0.5 
      } 
    }));
    
    debugLog.log(' Mapping removed successfully');
  };

  const handleModulationAmountChange = (parameterId: string, amount: number) => {
    setMappings(prev => ({
      ...prev,
      [parameterId]: {
        ...prev[parameterId],
        modulationAmount: amount
      }
    }));
  };

  // Handler for selecting a stem/track
  const handleStemSelect = (stemId: string) => {
    debugLog.log(' Selecting stem:', {
      stemId,
      previousActiveTrack: activeTrackId,
      availableAnalyses: audioAnalysis.cachedAnalysis?.map(a => ({
        id: a.fileMetadataId,
        stemType: a.stemType,
        hasData: !!a.analysisData,
        features: a.analysisData ? Object.keys(a.analysisData) : []
      })) || []
    });
    
    setActiveTrackId(stemId);
    
    // Log the analysis data for the selected stem
    const selectedAnalysis = audioAnalysis.cachedAnalysis?.find(a => a.fileMetadataId === stemId);
    if (selectedAnalysis) {
      debugLog.log(' Selected stem analysis:', {
        stemId,
        stemType: selectedAnalysis.stemType,
        duration: selectedAnalysis.metadata.duration,
        features: selectedAnalysis.analysisData ? Object.keys(selectedAnalysis.analysisData) : [],
        sampleValues: selectedAnalysis.analysisData ? 
          Object.entries(selectedAnalysis.analysisData).reduce((acc, [feature, data]) => {
            if (Array.isArray(data) && data.length > 0) {
              acc[feature] = {
                length: data.length,
                firstValue: data[0],
                lastValue: data[data.length - 1],
                sampleValues: data.slice(0, 5) // First 5 values
              };
            }
            return acc;
          }, {} as Record<string, any>) : {}
      });
    } else {
      debugLog.warn(' No analysis found for selected stem:', stemId);
    }
  };

  const [activeSliderValues, setActiveSliderValues] = useState<Record<string, number>>({});
  const visualizerRef = useRef<any>(null);
  const animationFrameId = useRef<number>();

  // Function to convert frontend feature names to backend analysis keys
  const getAnalysisKeyFromFeatureId = (featureId: string): string => {
    // Frontend feature IDs are like "drums-rms-volume", "bass-loudness", etc.
    // Backend analysis data has keys like "rms", "loudness", etc.
    const parts = featureId.split('-');
    if (parts.length >= 2) {
      // Remove the stem type prefix and get the feature name
      const featureName = parts.slice(1).join('-');
      
      // Map frontend feature names to backend analysis keys
      const featureMapping: Record<string, string> = {
        'rms-volume': 'rms',
        'loudness': 'loudness',
        'spectral-centroid': 'spectralCentroid',
        'spectral-rolloff': 'spectralRolloff',
        'spectral-flux': 'spectralFlux',
        'mfcc-1': 'mfcc_0', // Meyda uses 0-indexed MFCC
        'mfcc-2': 'mfcc_1',
        'mfcc-3': 'mfcc_2',
        'perceptual-spread': 'perceptualSpread',
        'energy': 'energy',
        'zcr': 'zcr',
        'beat-intensity': 'beatIntensity',
        'rhythm-pattern': 'rhythmPattern',
        'attack-time': 'attackTime',
        'chroma-vector': 'chromaVector',
        'harmonic-content': 'harmonicContent',
        'sub-bass': 'subBass',
        'warmth': 'warmth',
        'spectral-complexity': 'spectralComplexity',
        'texture': 'texture',
        'pitch-height': 'pitchHeight',
        'pitch-movement': 'pitchMovement',
        'melody-complexity': 'melodyComplexity',
        'expression': 'expression'
      };
      
      return featureMapping[featureName] || featureName;
    }
    return featureId; // Fallback to original if no prefix
  };

  // Function to get the stem type from a feature ID
  const getStemTypeFromFeatureId = (featureId: string): string | null => {
    const parts = featureId.split('-');
    if (parts.length >= 2) {
      return parts[0]; // First part is the stem type
    }
    return null;
  };

  // Track when visualizer ref becomes available
  useEffect(() => {
    if (visualizerRef.current) {
      debugLog.log(' Visualizer ref available:', {
        hasRef: !!visualizerRef.current,
        availableEffects: visualizerRef.current?.getAllEffects?.()?.map((e: any) => e.id) || [],
        selectedEffects: Object.keys(selectedEffects).filter(k => selectedEffects[k])
      });
    } else {
      debugLog.log(' Visualizer ref not available yet');
    }
  }, [visualizerRef.current, selectedEffects]);

  // Real-time feature mapping and visualizer update loop
  useEffect(() => {
    let cachedMappings: [string, string][] = [];
    let lastUpdateTime = 0;
    let frameCount = 0;

    const animationLoop = () => {
      if (!isPlaying || !visualizerRef.current) {
        animationFrameId.current = requestAnimationFrame(animationLoop);
        return;
      }
      
      // 30FPS CAP
      const now = performance.now();
      const elapsed = now - lastUpdateTime;
      const targetFrameTime = 1000 / 30;
      
      if (elapsed < targetFrameTime) {
        animationFrameId.current = requestAnimationFrame(animationLoop);
        return;
      }
      
      lastUpdateTime = now;
      frameCount++;
      
      // Get current audio time
      const time = stemAudio.currentTime;
      setCurrentTime(time);
      
      // Sync calculation (keep your existing code)
      const audioContextTime = stemAudio.getAudioContextTime?.() || 0;
      const scheduledStartTime = stemAudio.scheduledStartTimeRef?.current || 0;
      const measuredLatency = stemAudio.getAudioLatency?.() || 0;
      const audioPlaybackTime = Math.max(0, audioContextTime - scheduledStartTime);
      let syncTime = Math.max(0, audioPlaybackTime - measuredLatency + (syncOffsetMs / 1000));
      
      //  FIX: Handle audio looping by wrapping syncTime to analysis duration
      if (audioAnalysis.cachedAnalysis.length > 0) {
        const analysisDuration = audioAnalysis.cachedAnalysis[0]?.metadata?.duration || 1;
        if (analysisDuration > 0) {
          syncTime = syncTime % analysisDuration; // Wrap time to loop within analysis duration
        }
      }

      // Cache mappings
      if (cachedMappings.length !== Object.keys(mappings).length) {
        cachedMappings = Object.entries(mappings)
          .filter(([, mapping]) => mapping.featureId !== null)
          .map(([paramKey, mapping]) => [paramKey, mapping.featureId!]) as [string, string][];
      }

      //  THE FIX: Use enhancedAudioAnalysis instead of cachedStemAnalysis
      if (audioAnalysis.cachedAnalysis && audioAnalysis.cachedAnalysis.length > 0) {
        for (const [paramKey, featureId] of cachedMappings) {
          if (!featureId) continue;

          // Parse feature ID: "drums-rms"
          const featureStemType = getStemTypeFromFeatureId(featureId);
          if (!featureStemType) continue;

          //  CHANGED: Use audioAnalysis.getFeatureValue from consolidated hook
          // Find the analysis for this stem type to get its file ID
          const stemAnalysis = audioAnalysis.cachedAnalysis?.find(
            a => a.stemType === featureStemType
          );
          if (!stemAnalysis) continue;

          // Use the hook's getFeatureValue which properly handles both Float32Arrays and time-indexed arrays
          const rawValue = audioAnalysis.getFeatureValue(
            stemAnalysis.fileMetadataId,
            featureId,
            syncTime,
            featureStemType
          );

          if (rawValue === null || rawValue === undefined) continue;

          // Parse parameter key: "metaballs-glowIntensity"
          const [effectId, ...paramParts] = paramKey.split('-');
          const paramName = paramParts.join('-');
          
          if (!effectId || !paramName) continue;

          // Scale to parameter range with modulation amount attenuation
          const maxValue = getSliderMax(paramName);
          // Bipolar attenuverter: mapping.modulationAmount in [0..1] maps to [-1..+1] around noon
          // Range clamp to 0.5 (50%) so modulation isn't too extreme
          const knobFull = (mappings[paramKey]?.modulationAmount ?? 0.5) * 2 - 1; // -1..+1
          const knob = Math.max(-0.5, Math.min(0.5, knobFull));
          const baseValue = baseParameterValues[paramKey] ?? (activeSliderValues[paramKey] ?? 0);
          const delta = rawValue * knob * maxValue; // modulation contribution
          const scaledValue = Math.max(0, Math.min(maxValue, baseValue + delta));

          // Update visualizer
          visualizerRef.current.updateEffectParameter(effectId, paramName, scaledValue);
          
          // Update React state occasionally
          if (frameCount % 10 === 0) {
            setModulatedParameterValues(prev => ({ ...prev, [paramKey]: scaledValue }));
          }
        }
      }


      animationFrameId.current = requestAnimationFrame(animationLoop);
    };

    animationFrameId.current = requestAnimationFrame(animationLoop);

    return () => {
      if (animationFrameId.current) {
        cancelAnimationFrame(animationFrameId.current);
      }
    };
  }, [
    isPlaying, 
    mappings, 
    audioAnalysis.cachedAnalysis,
    stemAudio, 
    syncOffsetMs
  ]);
  
  const getSliderMax = (paramName: string) => {
    if (paramName === 'base-radius') return 1.0;
    if (paramName === 'animation-speed') return 2.0;
    if (paramName === 'glow-intensity') return 3.0;
    if (paramName === 'hud-opacity') return 1.0;
    if (paramName === 'max-particles') return 200;
    if (paramName === 'connection-distance') return 5.0;
    if (paramName === 'particle-size') return 50;
    return 100; // Default max for other numeric parameters
  };

  const getSliderStep = (paramName: string) => {
    if (paramName === 'base-radius') return 0.1;
    if (paramName === 'animation-speed') return 0.1;
    if (paramName === 'glow-intensity') return 0.1;
    if (paramName === 'hud-opacity') return 0.1;
    if (paramName === 'max-particles') return 10;
    if (paramName === 'connection-distance') return 0.1;
    if (paramName === 'particle-size') return 5;
    return 1; // Default step for other numeric parameters
  };

  const handleParameterChange = (effectId: string, paramName: string, value: any) => {
    const paramKey = `${effectId}-${paramName}`;
    // Slider sets the base value regardless of mapping
    setBaseParameterValues(prev => ({ ...prev, [paramKey]: value }));
    setActiveSliderValues(prev => ({ ...prev, [paramKey]: value }));
    // In a real application, you would update the effect's parameters here
    // For now, we'll just update the state to reflect the current value in the modal
  };

  const effectModals = Object.entries(openEffectModals).map(([effectId, isOpen], index) => {
    if (!isOpen) return null;
    const effectInstance = effects.find(e => e.id === effectId);
    if (!effectInstance) return null;
    const sortedParams = Object.entries(effectInstance.parameters || {}).sort(([, a], [, b]) => {
      if (typeof a === 'boolean' && typeof b !== 'boolean') return -1;
      if (typeof a !== 'boolean' && typeof b === 'boolean') return 1;
      return 0;
    });
    if (sortedParams.length === 0) return null;
    const initialPos = {
      x: 100 + (index * 50),
      y: 100 + (index * 50)
    };
    return (
      <PortalModal
        key={effectId}
        title={effectInstance.name.replace(' Effect', '')}
        isOpen={isOpen}
        onClose={() => handleCloseEffectModal(effectId)}
        initialPosition={initialPos}
        bounds="#editor-bounds"
      >
        <div className="flex flex-col gap-4 max-h-96 overflow-y-auto">
          {sortedParams.map(([paramName, value]) => {
            if (typeof value === 'boolean') {
              return (
                <div key={paramName} className="flex items-center justify-between">
                  <Label className="text-white/80 text-xs font-mono">{paramName}</Label>
                  <Switch
                    checked={value}
                    onCheckedChange={(checked) => handleParameterChange(effectId, paramName, checked)}
                  />
                </div>
              );
            }
            if (typeof value === 'number') {
              const paramKey = `${effectId}-${paramName}`;
              const mapping = mappings[paramKey];
              const mappedFeatureId = mapping?.featureId || null;
              const mappedFeatureName = mappedFeatureId ? featureNames[mappedFeatureId] : undefined;
              const modulationAmount = mapping?.modulationAmount ?? 0.5;
              const baseVal = activeSliderValues[paramKey] ?? value;
              return (
                <DroppableParameter
                  key={paramKey}
                  parameterId={paramKey}
                  label={paramName}
                  mappedFeatureId={mappedFeatureId}
                  mappedFeatureName={mappedFeatureName}
                  modulationAmount={modulationAmount}
                  baseValue={baseParameterValues[paramKey] ?? baseVal}
                  modulatedValue={modulatedParameterValues[paramKey] ?? baseVal}
                  sliderMax={getSliderMax(paramName)}
                  onFeatureDrop={handleMapFeature}
                  onFeatureUnmap={handleUnmapFeature}
                  onModulationAmountChange={handleModulationAmountChange}
                  className="mb-2"
                  dropZoneStyle="inlayed"
                  showTagOnHover
                >
                                            <Slider
                            value={[activeSliderValues[paramKey] ?? value]}
                            onValueChange={([val]) => {
                              setActiveSliderValues(prev => ({ ...prev, [paramKey]: val }));
                              handleParameterChange(effectId, paramName, val);
                            }}
                            min={0}
                            max={getSliderMax(paramName)}
                            step={getSliderStep(paramName)}
                            className="w-full"
                            disabled={!!mappedFeatureId} // Disable manual control when mapped
                          />
                </DroppableParameter>
              );
            }
            if ((paramName === 'highlightColor' || paramName === 'particleColor') && Array.isArray(value)) {
              const displayName = paramName === 'highlightColor' ? 'Highlight Color' : 'Particle Color';
              return (
                <div key={paramName} className="space-y-2">
                  <Label className="text-white/90 text-sm font-medium flex items-center justify-between">
                    {displayName}
                    <span className="ml-2 w-6 h-6 rounded-full border border-white/40 inline-block" style={{ background: `rgb(${value.map((v) => Math.round(v * 255)).join(',')})` }} />
                  </Label>
                  <input
                    type="color"
                    value={`#${value.map((v) => Math.round(v * 255).toString(16).padStart(2, '0')).join('')}`}
                    onChange={e => {
                      const hex = e.target.value;
                      const rgb = [
                        parseInt(hex.slice(1, 3), 16) / 255,
                        parseInt(hex.slice(3, 5), 16) / 255,
                        parseInt(hex.slice(5, 7), 16) / 255
                      ];
                      handleParameterChange(effectId, paramName, rgb);
                    }}
                    className="w-12 h-8 rounded border border-white/30 bg-transparent cursor-pointer"
                  />
                </div>
              );
            }
            return null;
          })}
          {/* Effect Enabled Toggle - Remove border and adjust spacing */}
          <div className="pt-2 mt-2">
            <div className="flex items-center justify-between">
              <Label className="text-white/80 text-xs font-mono">Effect Enabled</Label>
              <Switch 
                checked={selectedEffects[effectId]}
                onCheckedChange={(checked) => {
                  setSelectedEffects(prev => ({
                    ...prev,
                    [effectId]: checked
                  }));
                }}
              />
            </div>
          </div>
        </div>
      </PortalModal>
    );
  });

  // Helper to infer stem type from file name
  const getStemTypeFromFileName = (fileName: string) => {
    const lower = fileName.toLowerCase();
    if (lower.includes('bass')) return 'bass';
    if (lower.includes('drum')) return 'drums';
    if (lower.includes('vocal')) return 'vocals';
    return 'other';
  };

  // Find the selected stem and its type
  const selectedStem = availableStems.find(stem => stem.id === activeTrackId);
  // Use the actual stem_type from the database, fallback to filename inference
  const selectedStemType = selectedStem 
    ? (selectedStem.stem_type || getStemTypeFromFileName(selectedStem.file_name))
    : undefined;

  // Helper to get the master stem (if available)
  const getMasterStem = () => availableStems.find(stem => stem.is_master);

  // Helper to get the correct duration (master audio if available, else fallback)
  const getCurrentDuration = () => {
    if (hasStems && stemAudio.duration && stemAudio.duration > 0) {
      return stemAudio.duration;
    }
    return (midiData || sampleMidiData).file.duration;
  };

  // Update currentTime from stemAudio if stems are loaded
  useEffect(() => {
    if (!isPlaying) return;
    let rafId: number;
    const update = () => {
      if (hasStems) {
        const duration = getCurrentDuration();
        let displayTime = stemAudio.currentTime;
        
        // If looping is enabled, show position within the current loop cycle
        if (stemAudio.isLooping && duration > 0) {
          displayTime = stemAudio.currentTime % duration;
        }
        
        setCurrentTime(displayTime);
      }
      rafId = requestAnimationFrame(update);
    };
    rafId = requestAnimationFrame(update);
    return () => cancelAnimationFrame(rafId);
  }, [isPlaying, hasStems, stemAudio]);


  // In the render, use the sorted stems
  const sortedAvailableStems = sortStemsWithMasterLast(availableStems);

  // Log projectFiles.files before building stemUrlMap
  useEffect(() => {
    debugLog.log('[CreativeVisualizerPage] projectFiles.files:', projectFiles?.files);
  }, [projectFiles?.files]);

  // State for asynchronously built stemUrlMap
  const [asyncStemUrlMap, setAsyncStemUrlMap] = useState<Record<string, string>>({});

  useEffect(() => {
    async function fetchUrls() {
      if (!projectFiles?.files) return;
      const audioFiles = projectFiles.files.filter(f => f.file_type === 'audio' && f.upload_status === 'completed');
      
      // Debug: Log file structure
      debugLog.log('fetchUrls - projectFiles.files:', projectFiles.files);
      debugLog.log('fetchUrls - audioFiles:', audioFiles);
      
      const entries = await Promise.all(audioFiles.map(async f => {
        let url = f.downloadUrl;
        if (!url && getDownloadUrlMutation) {
          try {
            // Debug: Check if f.id exists
            if (!f.id) {
              debugLog.error('fetchUrls - File missing ID:', f);
              return [f.id, null];
            }
            
            debugLog.log('fetchUrls - Getting download URL for file:', { id: f.id, name: f.file_name });
            const result = await getDownloadUrlMutation.mutateAsync({ fileId: f.id });
            url = result.downloadUrl;
          } catch (err) {
            debugLog.error('[CreativeVisualizerPage] Failed to fetch downloadUrl for', f.id, err);
          }
        }
        return [f.id, url];
      }));
      const map = Object.fromEntries(entries.filter(([id, url]) => !!url));
      setAsyncStemUrlMap(map);
      if (Object.keys(map).length > 0) {
        debugLog.log('[CreativeVisualizerPage] asyncStemUrlMap populated:', map);
      } else {
        debugLog.log('[CreativeVisualizerPage] asyncStemUrlMap is empty');
      }
    }
    fetchUrls();
  }, [projectFiles?.files]);

  const stemUrlsReady = Object.keys(asyncStemUrlMap).length > 0;

  // Don't render anything until we're on the client side
  if (!isClient) {
    return (
      <div className="flex h-screen bg-stone-800 text-white items-center justify-center">
        <div className="text-center">
          <div className="animate-spin rounded-full h-8 w-8 border-b-2 border-white mx-auto mb-4"></div>
          <div className="text-sm text-stone-300">Loading...</div>
        </div>
      </div>
    );
  }

  // If no project is selected, show the picker
  if (!currentProjectId && !useDemoData) {
    return (
      <>
        {showPicker && (
          <ProjectPickerModal
            isOpen={showPicker}
            onClose={() => router.push('/dashboard')}
            onSelect={handleProjectSelect}
            onCreateNew={handleCreateNew}
          />
        )}
        {showCreateModal && (
          <ProjectCreationModal
            isOpen={showCreateModal}
            onClose={handleCloseCreateModal}
          />
        )}
        <div className="flex h-screen bg-stone-800 text-white items-center justify-center">
          <div className="text-center">
            <div className="animate-spin rounded-full h-8 w-8 border-b-2 border-white mx-auto mb-4"></div>
            <div className="text-sm text-stone-300">Please create or select a project.</div>
          </div>
        </div>
      </>
    );
  }

  return (
    <HudOverlayProvider 
      cachedAnalysis={audioAnalysis.cachedAnalysis}
      stemAudio={stemAudio}
      stemUrlMap={asyncStemUrlMap}
    >
      {showPicker && (
        <ProjectPickerModal
          isOpen={showPicker}
          onClose={() => router.push('/dashboard')}
          onSelect={handleProjectSelect}
          onCreateNew={handleCreateNew}
        />
      )}
      {showCreateModal && (
        <ProjectCreationModal
          isOpen={showCreateModal}
          onClose={handleCloseCreateModal}
        />
      )}
      <DndProvider backend={HTML5Backend}>
        {/* Main visualizer UI */}
        <div className="flex h-screen bg-stone-800 text-white min-w-0 creative-visualizer-text">
          <CollapsibleSidebar>
            <div className="space-y-4">
              <MappingSourcesPanel 
                activeTrackId={activeTrackId || undefined}
                className="mb-4"
                selectedStemType={selectedStemType}
                currentTime={currentTime}
                cachedAnalysis={audioAnalysis.cachedAnalysis}
                isPlaying={isPlaying}
              />
              <FileSelector 
                onFileSelected={handleFileSelected}
                selectedFileId={selectedFileId || undefined}
                useDemoData={useDemoData}
                onDemoModeChange={handleDemoModeChange}
                projectId={currentProjectId || undefined}
                projectName={projectData?.name}
              />
            </div>
          </CollapsibleSidebar>
          <main className="flex-1 flex overflow-hidden min-w-0">
            {/* Editor bounds container with proper positioning context */}
            <div 
              id="editor-bounds" 
              className="relative flex-1 flex flex-col overflow-hidden min-w-0"
              style={{ 
                height: '100vh',
                position: 'relative',
                contain: 'layout'
              }}
            >
          {/* Top Control Bar */}
          <div className="p-2 bg-stone-900/50 border-b border-white/10">
              <div className="flex items-center justify-between min-w-0">
                <div className="flex items-center gap-2 min-w-0 overflow-hidden">
                <Button 
                  onClick={handlePlayPause} 
                  size="sm" 
                    disabled={stemLoadingState}
                  className={`font-mono text-xs uppercase tracking-wider px-4 py-2 transition-all duration-300 ${
                      stemLoadingState 
                      ? 'bg-stone-600 text-stone-400 cursor-not-allowed' 
                      : 'bg-stone-700 hover:bg-stone-600'
                  }`}
                >
                    {stemLoadingState ? (
                    <>
                      <div className="h-3 w-3 mr-1 animate-spin rounded-full border-2 border-stone-400 border-t-transparent" />
                      LOADING
                    </>
                  ) : (
                    <>
                      {isPlaying ? <Pause className="h-3 w-3 mr-1" /> : <Play className="h-3 w-3 mr-1" />}
                      {isPlaying ? 'PAUSE' : 'PLAY'}
                    </>
                  )}
                </Button>
                <Button 
                  variant="outline" 
                  size="sm" 
                    disabled={stemLoadingState}
                  onClick={() => stemAudio.setLooping(!stemAudio.isLooping)}
                  className={`bg-stone-800 border-stone-600 text-stone-300 hover:bg-stone-700 hover:border-stone-500 font-mono text-xs uppercase tracking-wider px-3 py-1 ${
                      stemLoadingState 
                      ? 'opacity-50 cursor-not-allowed' 
                      : stemAudio.isLooping ? 'bg-emerald-900/20 border-emerald-600 text-emerald-300' : ''
                  }`}
                  style={{ borderRadius: '6px' }}
                >
                   {stemAudio.isLooping ? 'LOOP' : 'LOOP'}
                </Button>
                <Button 
                  variant="outline" 
                    disabled={stemLoadingState}
                  onClick={handleReset} 
                  className={`bg-stone-800 border-stone-600 text-stone-300 hover:bg-stone-700 hover:border-stone-500 px-3 py-1 ${
                      stemLoadingState ? 'opacity-50 cursor-not-allowed' : ''
                  }`}
                >
                  <RotateCcw className="h-3 w-3 mr-1" />
                  RESET
                </Button>
                  
                  {/* Stats Section - Compact layout */}
                  <div className="flex items-center gap-1 overflow-hidden">
                <div className="text-xs font-mono uppercase tracking-wider px-2 py-1 rounded text-stone-300" style={{ background: 'rgba(30, 30, 30, 0.5)', backdropFilter: 'blur(5px)', WebkitBackdropFilter: 'blur(5px)', border: '1px solid rgba(255, 255, 255, 0.1)' }}>
                  <span className="font-creative-mono">{currentTime.toFixed(1)}</span><span className="font-creative-mono">S</span> / <span className="font-creative-mono">{getCurrentDuration().toFixed(1)}</span><span className="font-creative-mono">S</span>
                </div>
                <div className="text-xs font-mono uppercase tracking-wider px-2 py-1 rounded text-stone-300" style={{ background: 'rgba(30, 30, 30, 0.5)', backdropFilter: 'blur(5px)', WebkitBackdropFilter: 'blur(5px)', border: '1px solid rgba(255, 255, 255, 0.1)' }}>
                  FPS: <span className="font-creative-mono">{fps}</span>
                </div>
                <div className="text-xs font-mono uppercase tracking-wider px-2 py-1 rounded text-stone-300" style={{ background: 'rgba(30, 30, 30, 0.5)', backdropFilter: 'blur(5px)', WebkitBackdropFilter: 'blur(5px)', border: '1px solid rgba(255, 255, 255, 0.1)' }}>
                  NOTES: <span className="font-creative-mono">{(midiData || sampleMidiData).tracks.reduce((sum, track) => sum + track.notes.length, 0)}</span>
                </div>
                {hasStems && (
                  <div className="text-xs font-mono uppercase tracking-wider px-2 py-1 rounded text-stone-300" style={{ background: 'rgba(30, 30, 30, 0.5)', backdropFilter: 'blur(5px)', WebkitBackdropFilter: 'blur(5px)', border: '1px solid rgba(255, 255, 255, 0.1)' }}>
                    STEMS: <span className="font-creative-mono">{availableStems.length}</span>
                  </div>
                )}
                
              </div>
                </div>
                <div className="flex items-center gap-2 flex-shrink-0 ml-2">
                <AspectRatioSelector
                  currentAspectRatio={visualizerAspectRatio}
                  onAspectRatioChange={setVisualizerAspectRatio}
                  disabled={stemLoadingState}
                />
                <Button 
                  variant="outline" 
                  size="sm" 
                  onClick={() => setShowVideoComposition(!showVideoComposition)} 
                  className={`bg-stone-800 border-stone-600 text-stone-300 hover:bg-stone-700 hover:border-stone-500 font-mono text-xs uppercase tracking-wider px-2 py-1 ${
                    showVideoComposition ? 'bg-emerald-900/20 border-emerald-600 text-emerald-300' : ''
                  }`}
                  style={{ borderRadius: '6px' }}
                >
                     {showVideoComposition ? 'COMP' : 'VIDEO'}
                </Button>
                
                {/* Test Video Composition Controls */}
                {showVideoComposition && (
                  <TestVideoComposition
                    onAddLayer={handleLayerAdd}
                    className="ml-2"
                  />
                )}
                  
                </div>
              </div>
            </div>
            
            {/* Visualizer Area - Scrollable Layout */}
            <div className="flex-1 flex flex-col overflow-hidden bg-stone-900 relative">
              <div className="flex-1 flex flex-col min-h-0 px-4 overflow-y-auto">
                {/* Visualizer Container - Responsive with aspect ratio */}
                <div className="flex-shrink-0 mb-4">
                  <div 
                    className="relative mx-auto bg-stone-900 rounded-lg overflow-hidden shadow-lg flex items-center justify-center"
                    style={{ 
                      height: 'min(calc(100vh - 400px), 60vh)', // Reduced height to make room for stem panel
                      minHeight: '200px',
                      width: '100%',
                      maxWidth: '100%'
                    }}
                  >
                  <ThreeVisualizer
                      midiData={midiData || sampleMidiData}
                      settings={settings}
                      currentTime={currentTime}
                      isPlaying={isPlaying}
                      layers={videoLayers}
                      selectedLayerId={selectedLayerId}
                      onLayerSelect={handleLayerSelect}
                      onPlayPause={handlePlayPause}
                      onSettingsChange={setSettings}
                      onFpsUpdate={setFps}
                      selectedEffects={selectedEffects}
                      aspectRatio={visualizerAspectRatio}
                          // Modal and mapping props
                          openEffectModals={openEffectModals}
                          onCloseEffectModal={handleCloseEffectModal}
                          mappings={mappings}
                          featureNames={featureNames}
                          onMapFeature={handleMapFeature}
                          onUnmapFeature={handleUnmapFeature}
                          onModulationAmountChange={handleModulationAmountChange}
                          activeSliderValues={activeSliderValues}
                          setActiveSliderValues={setActiveSliderValues}
                      onSelectedEffectsChange={() => {}} // <-- Added no-op
                      visualizerRef={visualizerRef}
                  />

                  {/* Video Composition Layer Container */}
                  {showVideoComposition && (
                    <LayerContainer
                      layers={videoLayers}
                      width={visualizerAspectRatio === 'mobile' ? 400 : 1280}
                      height={visualizerAspectRatio === 'mobile' ? 711 : 720}
                      currentTime={currentTime}
                      isPlaying={isPlaying}
                      audioFeatures={{
                        frequencies: new Array(256).fill(0.5),
                        timeData: new Array(256).fill(0.5),
                        volume: 0.5,
                        bass: 0.5,
                        mid: 0.5,
                        treble: 0.5
                      }}
                      midiData={{
                        activeNotes: [],
                        currentTime: currentTime,
                        tempo: 120,
                        totalNotes: 0,
                        trackActivity: {}
                      }}
                      onLayerUpdate={handleLayerUpdate}
                      onLayerDelete={handleLayerDelete}
                    />
                  )}

                  {/* HUD Overlays positioned relative to visualizer */}
                  <div id="hud-overlays" style={{ position: 'absolute', top: 0, left: 0, width: '100%', height: '100%', pointerEvents: 'none', zIndex: 20 }}>
                    {/* Overlays will be rendered here by the HudOverlayProvider */}
                  </div>

                      {/* Visualizer content only - no modals here */}
                </div>
                </div>
                
                {/* Unified Timeline */}
                <div className="flex-shrink-0 mb-4">
                  <UnifiedTimeline
                    layers={videoLayers}
                    currentTime={currentTime}
                    duration={(midiData || sampleMidiData).file.duration}
                    onLayerAdd={handleLayerAdd}
                    onLayerUpdate={handleLayerUpdate}
                    onLayerDelete={handleLayerDelete}
                    onLayerSelect={handleLayerSelect}
                    selectedLayerId={selectedLayerId || undefined}
                    effectClips={effectClips}
                    onEffectClipAdd={handleEffectClipAdd}
                    onEffectClipRemove={handleEffectClipRemove}
                    onEffectClipEdit={handleEffectClipEdit}
                    stems={sortedAvailableStems}
                    masterStemId={projectFiles?.files?.find(f => f.is_master)?.id ?? null}
                    onStemSelect={handleStemSelect}
                    activeTrackId={activeTrackId}
                    soloedStems={stemAudio.soloedStems}
                    onToggleSolo={stemAudio.toggleStemSolo}
                    analysisProgress={audioAnalysis.analysisProgress}
                    cachedAnalysis={audioAnalysis.cachedAnalysis || []}
                    stemLoadingState={audioAnalysis.isLoading}
                    stemError={audioAnalysis.error}
                    isPlaying={isPlaying}
                    onSeek={setCurrentTime}
                    className="bg-stone-800 border border-gray-700"
                  />
                </div>
            </div>
          </div>

              {/* Effect parameter modals - positioned relative to editor-bounds */}
              {effectModals}
            </div>

            {/* Right Effects Sidebar */}
            <CollapsibleEffectsSidebar>
              <EffectsLibrarySidebarWithHud
                effects={effects}
                selectedEffects={selectedEffects}
                onEffectToggle={handleSelectEffect}
                onEffectDoubleClick={handleEffectDoubleClick}
                isVisible={true}
                stemUrlsReady={stemUrlsReady}
              />
            </CollapsibleEffectsSidebar>



        </main>
      </div>
      </DndProvider>
    </HudOverlayProvider>
  );
}

export default function CreativeVisualizerPageWithSuspense() {
  return (
    <Suspense>
      <CreativeVisualizerPage />
    </Suspense>
  );
}
</file>

<file path="app/dashboard/page.tsx">
'use client'

import React, { useEffect, useState } from 'react'
import { supabase } from '@/lib/supabase'
import { Navigation } from '@/components/navigation'
import { ProjectDashboard } from '@/components/projects/project-dashboard'
import { LoadingSpinner } from '@/components/ui/loading-spinner'

export default function DashboardPage() {
  const [user, setUser] = useState<any>(null)
  const [loading, setLoading] = useState(true)
  const [recentProjects, setRecentProjects] = useState<any[]>([])

  useEffect(() => {
    const checkSession = async () => {
      const { data: { session } } = await supabase.auth.getSession()
      setUser(session?.user || null)
      setLoading(false)
    }
    
    checkSession()

    const { data: { subscription } } = supabase.auth.onAuthStateChange(
      async (event, session) => {
        setUser(session?.user || null)
      }
    )

    return () => subscription.unsubscribe()
  }, [])

  if (loading) {
    return (
      <div className="min-h-screen bg-gradient-to-br from-stone-50 to-stone-100 flex items-center justify-center">
        <div className="text-center">
          <LoadingSpinner size="lg" className="mb-4" />
          <p className="text-stone-600 font-mono">LOADING DASHBOARD...</p>
        </div>
      </div>
    )
  }

  if (!user) {
    return (
      <div className="min-h-screen bg-gradient-to-br from-stone-50 to-stone-100 flex items-center justify-center">
        <div className="text-center">
          <h1 className="text-2xl font-display font-bold text-stone-700 mb-4">
            ACCESS DENIED
          </h1>
          <p className="text-stone-600 font-mono mb-6">
            Please sign in to access the dashboard
          </p>
          <a 
            href="/login" 
            className="inline-block bg-stone-600 text-white px-6 py-3 rounded-md font-sans font-bold uppercase tracking-wider text-sm transition-colors hover:bg-stone-700"
          >
            Sign In
          </a>
        </div>
      </div>
    )
  }

  return (
    <>
      <Navigation 
        user={user} 
        currentPath="/dashboard" 
        recentProjects={recentProjects}
        showBreadcrumbs={true}
      />
      <ProjectDashboard user={user} />
    </>
  )
}
</file>

<file path="app/files/page.tsx">
'use client'

import { useState } from 'react'
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card'
import { Badge } from '@/components/ui/badge'
import { Button } from '@/components/ui/button'
import { 
  FileMusic, 
  Music, 
  Video, 
  Download, 
  Trash2, 
  Upload,
  Search,
  Filter,
  MoreVertical
} from 'lucide-react'
import Link from 'next/link'
import { debugLog } from '@/lib/utils'

// Mock data for now - will be replaced with real data from API
const mockFiles = [
  {
    id: 'file_1',
    fileName: 'beethoven_symphony_5.mid',
    fileType: 'midi' as const,
    fileSize: 1024 * 45, // 45KB
    uploadStatus: 'completed' as const,
    createdAt: new Date('2024-01-15T10:30:00Z'),
    r2Key: 'midi/user123/1642248600000_beethoven_symphony_5.mid'
  },
  {
    id: 'file_2', 
    fileName: 'jazz_piano_recording.mp3',
    fileType: 'audio' as const,
    fileSize: 1024 * 1024 * 8.5, // 8.5MB
    uploadStatus: 'completed' as const,
    createdAt: new Date('2024-01-14T15:45:00Z'),
    r2Key: 'audio/user123/1642162700000_jazz_piano_recording.mp3'
  },
  {
    id: 'file_3',
    fileName: 'concert_video.mp4',
    fileType: 'video' as const,
    fileSize: 1024 * 1024 * 125, // 125MB
    uploadStatus: 'completed' as const,
    createdAt: new Date('2024-01-13T20:15:00Z'),
    r2Key: 'video/user123/1642076100000_concert_video.mp4'
  },
  {
    id: 'file_4',
    fileName: 'new_composition.mid',
    fileType: 'midi' as const,
    fileSize: 1024 * 23, // 23KB
    uploadStatus: 'uploading' as const,
    createdAt: new Date('2024-01-16T08:20:00Z'),
    r2Key: 'midi/user123/1642334400000_new_composition.mid'
  },
  {
    id: 'file_5',
    fileName: 'corrupted_file.mid',
    fileType: 'midi' as const,
    fileSize: 1024 * 5, // 5KB
    uploadStatus: 'failed' as const,
    createdAt: new Date('2024-01-16T09:00:00Z'),
    r2Key: 'midi/user123/1642336800000_corrupted_file.mid'
  }
]

type FileType = 'midi' | 'audio' | 'video'
type UploadStatus = 'uploading' | 'completed' | 'failed'

export default function FilesPage() {
  const [files] = useState(mockFiles)
  const [searchTerm, setSearchTerm] = useState('')
  const [filterType, setFilterType] = useState<FileType | 'all'>('all')
  const [filterStatus, setFilterStatus] = useState<UploadStatus | 'all'>('all')

  // Filter files based on search and filters
  const filteredFiles = files.filter(file => {
    const matchesSearch = file.fileName.toLowerCase().includes(searchTerm.toLowerCase())
    const matchesType = filterType === 'all' || file.fileType === filterType
    const matchesStatus = filterStatus === 'all' || file.uploadStatus === filterStatus
    return matchesSearch && matchesType && matchesStatus
  })

  const getFileIcon = (fileType: FileType) => {
    switch (fileType) {
      case 'midi':
        return <FileMusic className="h-5 w-5 text-blue-600" />
      case 'audio':
        return <Music className="h-5 w-5 text-green-600" />
      case 'video':
        return <Video className="h-5 w-5 text-purple-600" />
      default:
        return <FileMusic className="h-5 w-5" />
    }
  }

  const getStatusBadge = (status: UploadStatus) => {
    switch (status) {
      case 'completed':
        return <Badge variant="default" className="bg-green-100 text-green-800">Completed</Badge>
      case 'uploading':
        return <Badge variant="secondary" className="bg-blue-100 text-blue-800">Uploading</Badge>
      case 'failed':
        return <Badge variant="destructive">Failed</Badge>
      default:
        return <Badge variant="outline">Unknown</Badge>
    }
  }

  const formatFileSize = (bytes: number) => {
    const sizes = ['Bytes', 'KB', 'MB', 'GB']
    if (bytes === 0) return '0 Bytes'
    const i = Math.floor(Math.log(bytes) / Math.log(1024))
    return Math.round(bytes / Math.pow(1024, i) * 100) / 100 + ' ' + sizes[i]
  }

  const formatDate = (date: Date) => {
    return new Intl.DateTimeFormat('en-US', {
      month: 'short',
      day: 'numeric',
      year: 'numeric',
      hour: '2-digit',
      minute: '2-digit'
    }).format(date)
  }

  const handleDownload = (file: typeof mockFiles[0]) => {
    // Note: Download functionality placeholder - tRPC integration pending
    debugLog.log('Downloading file:', file.fileName)
    alert(`Download functionality coming soon for: ${file.fileName}`)
  }

  const handleDelete = (file: typeof mockFiles[0]) => {
    // Note: Delete functionality placeholder - tRPC integration pending
    if (confirm(`Are you sure you want to delete "${file.fileName}"?`)) {
      debugLog.log('Deleting file:', file.fileName)
      alert(`Delete functionality coming soon for: ${file.fileName}`)
    }
  }

  const getFileTypeColor = (fileType: FileType) => {
    switch (fileType) {
      case 'midi': return 'bg-blue-50 border-blue-200'
      case 'audio': return 'bg-green-50 border-green-200'
      case 'video': return 'bg-purple-50 border-purple-200'
      default: return 'bg-gray-50 border-gray-200'
    }
  }

  return (
    <div className="container mx-auto p-6 max-w-6xl">
      {/* Header */}
      <div className="mb-8">
        <div className="flex items-center justify-between">
          <div>
            <h1 className="text-3xl font-bold mb-2">My Files </h1>
            <p className="text-muted-foreground">
              Manage your uploaded MIDI, audio, and video files
            </p>
          </div>
          <Link href="/upload-demo">
            <Button className="flex items-center gap-2">
              <Upload className="h-4 w-4" />
              Upload Files
            </Button>
          </Link>
        </div>
      </div>

      {/* Filters and Search */}
      <Card className="mb-6">
        <CardHeader>
          <CardTitle className="text-lg">Filter & Search</CardTitle>
        </CardHeader>
        <CardContent>
          <div className="flex flex-col sm:flex-row gap-4">
            {/* Search */}
            <div className="flex-1 relative">
              <Search className="absolute left-3 top-3 h-4 w-4 text-gray-400" />
              <input
                type="text"
                placeholder="Search files..."
                value={searchTerm}
                onChange={(e) => setSearchTerm(e.target.value)}
                className="w-full pl-10 pr-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:border-transparent"
              />
            </div>

            {/* File Type Filter */}
            <div className="flex items-center gap-2">
              <Filter className="h-4 w-4 text-gray-500" />
              <select
                value={filterType}
                onChange={(e) => setFilterType(e.target.value as FileType | 'all')}
                className="px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500"
              >
                <option value="all">All Types</option>
                <option value="midi">MIDI</option>
                <option value="audio">Audio</option>
                <option value="video">Video</option>
              </select>
            </div>

            {/* Status Filter */}
            <select
              value={filterStatus}
              onChange={(e) => setFilterStatus(e.target.value as UploadStatus | 'all')}
              className="px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500"
            >
              <option value="all">All Status</option>
              <option value="completed">Completed</option>
              <option value="uploading">Uploading</option>
              <option value="failed">Failed</option>
            </select>
          </div>
        </CardContent>
      </Card>

      {/* Files List */}
      <Card>
        <CardHeader>
          <CardTitle>
            Files ({filteredFiles.length})
          </CardTitle>
          <CardDescription>
            Your uploaded files with download and management options
          </CardDescription>
        </CardHeader>
        <CardContent>
          {filteredFiles.length === 0 ? (
            <div className="text-center py-12">
              <FileMusic className="h-16 w-16 text-gray-300 mx-auto mb-4" />
              <h3 className="text-lg font-medium text-gray-900 mb-2">No files found</h3>
              <p className="text-gray-500 mb-4">
                {searchTerm || filterType !== 'all' || filterStatus !== 'all'
                  ? 'Try adjusting your search or filters'
                  : 'Upload your first file to get started'
                }
              </p>
              <Link href="/upload-demo">
                <Button>
                  <Upload className="h-4 w-4 mr-2" />
                  Upload Files
                </Button>
              </Link>
            </div>
          ) : (
            <div className="space-y-4">
              {filteredFiles.map((file) => (
                <div
                  key={file.id}
                  className={`p-4 rounded-lg border-2 ${getFileTypeColor(file.fileType)} hover:shadow-md transition-shadow`}
                >
                  <div className="flex items-center justify-between">
                    {/* File Info */}
                    <div className="flex items-center gap-4 flex-1">
                      <div className="flex-shrink-0">
                        {getFileIcon(file.fileType)}
                      </div>
                      
                      <div className="flex-1 min-w-0">
                        <h3 className="font-semibold text-gray-900 truncate">
                          {file.fileName}
                        </h3>
                        <div className="flex items-center gap-4 text-sm text-gray-600 mt-1">
                          <span>{formatFileSize(file.fileSize)}</span>
                          <span></span>
                          <span>{formatDate(file.createdAt)}</span>
                          <span></span>
                          <span className="capitalize">{file.fileType}</span>
                        </div>
                      </div>

                      <div className="flex items-center gap-3">
                        {getStatusBadge(file.uploadStatus)}
                      </div>
                    </div>

                    {/* Actions */}
                    <div className="flex items-center gap-2 ml-4">
                      {file.uploadStatus === 'completed' && (
                        <>
                          <Button
                            variant="outline"
                            size="sm"
                            onClick={() => handleDownload(file)}
                            className="flex items-center gap-1"
                          >
                            <Download className="h-3 w-3" />
                            Download
                          </Button>
                          <Button
                            variant="outline"
                            size="sm"
                            onClick={() => handleDelete(file)}
                            className="flex items-center gap-1 text-red-600 hover:text-red-700"
                          >
                            <Trash2 className="h-3 w-3" />
                            Delete
                          </Button>
                        </>
                      )}
                      
                      {file.uploadStatus === 'failed' && (
                        <Button
                          variant="outline"
                          size="sm"
                          onClick={() => handleDelete(file)}
                          className="flex items-center gap-1 text-red-600 hover:text-red-700"
                        >
                          <Trash2 className="h-3 w-3" />
                          Remove
                        </Button>
                      )}

                      <Button variant="ghost" size="sm">
                        <MoreVertical className="h-4 w-4" />
                      </Button>
                    </div>
                  </div>
                </div>
              ))}
            </div>
          )}
        </CardContent>
      </Card>

      {/* Statistics */}
      <div className="grid grid-cols-1 md:grid-cols-4 gap-4 mt-6">
        <Card className="bg-blue-50 border-blue-200">
          <CardContent className="p-4">
            <div className="flex items-center gap-2">
              <FileMusic className="h-5 w-5 text-blue-600" />
              <div>
                <p className="text-sm font-medium text-blue-900">MIDI Files</p>
                <p className="text-lg font-bold text-blue-700">
                  {files.filter(f => f.fileType === 'midi').length}
                </p>
              </div>
            </div>
          </CardContent>
        </Card>

        <Card className="bg-green-50 border-green-200">
          <CardContent className="p-4">
            <div className="flex items-center gap-2">
              <Music className="h-5 w-5 text-green-600" />
              <div>
                <p className="text-sm font-medium text-green-900">Audio Files</p>
                <p className="text-lg font-bold text-green-700">
                  {files.filter(f => f.fileType === 'audio').length}
                </p>
              </div>
            </div>
          </CardContent>
        </Card>

        <Card className="bg-purple-50 border-purple-200">
          <CardContent className="p-4">
            <div className="flex items-center gap-2">
              <Video className="h-5 w-5 text-purple-600" />
              <div>
                <p className="text-sm font-medium text-purple-900">Video Files</p>
                <p className="text-lg font-bold text-purple-700">
                  {files.filter(f => f.fileType === 'video').length}
                </p>
              </div>
            </div>
          </CardContent>
        </Card>

        <Card className="bg-gray-50 border-gray-200">
          <CardContent className="p-4">
            <div className="flex items-center gap-2">
              <div>
                <p className="text-sm font-medium text-gray-900">Total Storage</p>
                <p className="text-lg font-bold text-gray-700">
                  {formatFileSize(files.reduce((total, file) => total + file.fileSize, 0))}
                </p>
              </div>
            </div>
          </CardContent>
        </Card>
      </div>
    </div>
  )
}
</file>

<file path="app/profile/page.tsx">
'use client'

import { Suspense } from 'react'
import { AuthGuard } from '@/components/auth/auth-guard'
import { UserDisplay } from '@/components/auth/profile-menu'

function ProfilePageContent() {
  return (
    <AuthGuard>
      <div className="min-h-screen bg-gray-50">
        <div className="max-w-7xl mx-auto py-6 px-4 sm:px-6 lg:px-8">
          <div className="flex justify-between items-center mb-8">
            <h1 className="text-3xl font-bold text-gray-900">Profile</h1>
            <UserDisplay />
          </div>
          
          <div className="bg-white shadow rounded-lg p-6">
            <h2 className="text-xl font-semibold text-gray-900 mb-4">User Profile</h2>
            <p className="text-gray-600">
              This is a protected route that requires authentication.
              You can only see this page if you're logged in.
            </p>
            
            <div className="mt-6 border-t pt-6">
              <h3 className="text-lg font-medium text-gray-900 mb-4">Account Information</h3>
              <p className="text-sm text-gray-500">
                Your account details are managed through your authentication provider.
              </p>
            </div>
          </div>
        </div>
      </div>
    </AuthGuard>
  )
}

export default function ProfilePage() {
  return (
    <Suspense fallback={
      <div className="min-h-screen flex items-center justify-center bg-gray-50">
        <div className="text-center">
          <div className="animate-spin rounded-full h-32 w-32 border-b-2 border-indigo-600 mx-auto"></div>
          <p className="mt-4 text-lg text-gray-600">Loading profile...</p>
        </div>
      </div>
    }>
      <ProfilePageContent />
    </Suspense>
  )
}
</file>

<file path="app/fonts.css">
/* Custom Fonts for Creative Visualizer */

/* 
  To use your downloaded Google Font:
  1. Place your font files in /public/fonts/
  2. Update the font-family name below
  3. Update the src URLs to match your font file names
  4. Uncomment and customize the @font-face declarations
*/

/* Doto Font - Custom monospace font for creative visualizer */
@font-face {
  font-family: 'Doto';
  src: url('/fonts/Doto-Thin.woff2') format('woff2'),
       url('/fonts/Doto-Thin.woff') format('woff'),
       url('/fonts/Doto-Thin.ttf') format('truetype');
  font-weight: 100;
  font-style: normal;
  font-display: swap;
}
</file>

<file path="app/globals.css">
@import url('https://fonts.googleapis.com/css2?family=VT323&display=swap');
@import './fonts.css';

body, .font-mono {
  font-family: 'VT323', 'Fira Mono', 'Menlo', 'monospace';
  letter-spacing: 0.04em;
}

/* Custom font for creative visualizer numbers */
.font-creative-mono {
  font-family: 'Doto', 'VT323', 'Fira Mono', 'Menlo', 'monospace';
  letter-spacing: 0.04em;
  font-weight: 100;
  color: #fcf803; /* White color for Doto font instances */
  font-size: 1.25em; /* Make Doto font slightly larger to match other fonts */
  line-height: 1; /* Ensure consistent line height */
  vertical-align: baseline; /* Align with the baseline of surrounding text */
  position: relative;
  top: .05em; /* Slightly lower the Doto text to match baseline */
  text-shadow: 
    0 0 3px hsla(59, 70%, 53%, 0.6)
    0 0 6px rgba(255, 255, 255, 0.3),
    0 0 9px rgba(255, 255, 255, 0.1); /* Subtle white glow effect */
}



@tailwind base;
@tailwind components;
@tailwind utilities;

@layer base {
  /* Creative visualizer text scaling - makes text 90% of normal size */
  .creative-visualizer-text {
    font-size: 90%;
  }
  
  :root {
    /* Typography System */
    --font-mono: 'JetBrains Mono', 'Fira Code', 'Monaco', 'Consolas', monospace;
    --font-sans: 'Inter', 'Helvetica Neue', 'Arial', sans-serif;
    --font-display: 'Space Grotesk', 'Inter', sans-serif;
    
    /* Typography Scale */
    --text-xs: 0.75rem;    /* 12px - Metadata, captions */
    --text-sm: 0.875rem;   /* 14px - Body small, labels */
    --text-base: 1rem;     /* 16px - Body text */
    --text-lg: 1.125rem;   /* 18px - Emphasized body */
    --text-xl: 1.25rem;    /* 20px - Small headings */
    --text-2xl: 1.5rem;    /* 24px - Section headings */
    --text-3xl: 1.875rem;  /* 30px - Page headings */
    --text-4xl: 2.25rem;   /* 36px - Display headings */
    --text-5xl: 3rem;      /* 48px - Hero text */
    --text-6xl: 3.75rem;   /* 60px - Large display */

    /* Monochromatic Foundation */
    --color-black: #000000;
    --color-gray-900: #0a0a0a;
    --color-gray-800: #1a1a1a;
    --color-gray-700: #2a2a2a;
    --color-gray-600: #3a3a3a;
    --color-gray-500: #6b7280;
    --color-gray-400: #9ca3af;
    --color-gray-300: #d1d5db;
    --color-gray-200: #e5e7eb;
    --color-gray-100: #f3f4f6;
    --color-white: #ffffff;

    /* Technical Brutalist Stone Palette */
    --stone-50: #fafaf9;       /* Lightest stone */
    --stone-100: #f5f5f4;      /* Very light stone */
    --stone-200: #e7e5e4;      /* Light stone - control backgrounds */
    --stone-300: #d6d3d1;      /* Medium light stone - panels */
    --stone-400: #a8a29e;      /* Medium stone - borders */
    --stone-500: #78716c;      /* Primary stone - backgrounds */
    --stone-600: #57534e;      /* Dark stone - buttons */
    --stone-700: #44403c;      /* Darker stone */
    --stone-800: #292524;      /* Very dark stone */
    --stone-900: #1c1917;      /* Darkest stone */

    /* Sophisticated Muted Accents */
    --color-slate-primary: #475569;   /* Interactive elements */
    --color-slate-light: #64748b;     /* Hover states */
    --color-sage-accent: #84a98c;     /* Success, upload */
    --color-terracotta-accent: #a8756b; /* Errors, delete */
    --color-amber-muted: #b8936d;     /* Warnings, processing */
    --color-lavender-accent: #9b8db5; /* Secondary actions */

    /* Muted Visualization Colors */
    --color-sage-viz: #84a98c;        /* Audio waveforms */
    --color-slate-viz: #6b7c93;       /* MIDI data */
    --color-dusty-rose-viz: #b08a8a;  /* Accent elements */
    --color-warm-gray-viz: #a8a29e;   /* Background elements */
    --color-soft-blue-viz: #8da3b0;   /* Timeline markers */

    /* Glassmorphism Variables */
    --glass-bg: rgba(255, 255, 255, 0.1);
    --glass-bg-strong: rgba(255, 255, 255, 0.2);
    --glass-border: rgba(255, 255, 255, 0.2);
    --glass-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
    --glass-shadow-strong: 0 12px 40px rgba(0, 0, 0, 0.15);

    /* Spacing System */
    --spacing-xs: 0.25rem;    /* 4px */
    --spacing-sm: 0.5rem;     /* 8px */
    --spacing-md: 1rem;       /* 16px */
    --spacing-lg: 1.5rem;     /* 24px */
    --spacing-xl: 2rem;       /* 32px */
    --spacing-2xl: 3rem;      /* 48px */
    --spacing-3xl: 4rem;      /* 64px */

    /* Border Radius */
    --radius-sm: 4px;
    --radius-md: 8px;
    --radius-lg: 12px;
    --radius-xl: 16px;
    --radius-2xl: 20px;
    --radius-3xl: 24px;

    /* Legacy shadcn/ui variables for compatibility */
    --background: 0 0% 100%;
    --foreground: 0 0% 3.9%;
    --card: 0 0% 100%;
    --card-foreground: 0 0% 3.9%;
    --popover: 0 0% 100%;
    --popover-foreground: 0 0% 3.9%;
    --primary: 0 0% 9%;
    --primary-foreground: 0 0% 98%;
    --secondary: 0 0% 96.1%;
    --secondary-foreground: 0 0% 9%;
    --muted: 0 0% 96.1%;
    --muted-foreground: 0 0% 45.1%;
    --accent: 0 0% 96.1%;
    --accent-foreground: 0 0% 9%;
    --destructive: 0 84.2% 60.2%;
    --destructive-foreground: 0 0% 98%;
    --border: 0 0% 89.8%;
    --input: 0 0% 89.8%;
    --ring: 0 0% 3.9%;
    --chart-1: 12 76% 61%;
    --chart-2: 173 58% 39%;
    --chart-3: 197 37% 24%;
    --chart-4: 43 74% 66%;
    --chart-5: 27 87% 67%;
    --radius: 0.5rem;
  }

  .dark {
    --background: 0 0% 3.9%;
    --foreground: 0 0% 98%;
    --card: 0 0% 3.9%;
    --card-foreground: 0 0% 98%;
    --popover: 0 0% 3.9%;
    --popover-foreground: 0 0% 98%;
    --primary: 0 0% 98%;
    --primary-foreground: 0 0% 9%;
    --secondary: 0 0% 14.9%;
    --secondary-foreground: 0 0% 98%;
    --muted: 0 0% 14.9%;
    --muted-foreground: 0 0% 63.9%;
    --accent: 0 0% 14.9%;
    --accent-foreground: 0 0% 98%;
    --destructive: 0 62.8% 30.6%;
    --destructive-foreground: 0 0% 98%;
    --border: 0 0% 14.9%;
    --input: 0 0% 14.9%;
    --ring: 0 0% 83.1%;
    --chart-1: 220 70% 50%;
    --chart-2: 160 60% 45%;
    --chart-3: 30 80% 55%;
    --chart-4: 280 65% 60%;
    --chart-5: 340 75% 55%;
  }
}

@layer base {
  * {
    @apply border-border;
  }
  body {
    @apply bg-background text-foreground;
    font-family: var(--font-sans);
    line-height: 1.6;
    letter-spacing: -0.005em;
  }
}

@layer components {
  /* Glassmorphism Components */
  .glass {
    background: var(--glass-bg);
    backdrop-filter: blur(20px);
    -webkit-backdrop-filter: blur(20px);
    border: 1px solid var(--glass-border);
    border-radius: var(--radius-xl);
    box-shadow: var(--glass-shadow);
  }

  .glass-strong {
    background: var(--glass-bg-strong);
    backdrop-filter: blur(30px);
    -webkit-backdrop-filter: blur(30px);
    border: 1px solid var(--glass-border);
    border-radius: var(--radius-2xl);
    box-shadow: var(--glass-shadow-strong);
  }

  .glass-modal {
    background: rgba(24, 24, 27, 0.85); /* dark glass, matches stone-900 */
    backdrop-filter: blur(40px);
    -webkit-backdrop-filter: blur(40px);
    /* border: 1px solid rgba(255, 255, 255, 0.3); */
    border-radius: var(--radius-3xl);
    box-shadow: 0 20px 60px rgba(0, 0, 0, 0.2);
  }

  .glass-overlay {
    background: rgba(0, 0, 0, 0.4);
    backdrop-filter: blur(8px);
    -webkit-backdrop-filter: blur(8px);
  }

  /* Technical Control Components */
  .technical-display {
    background: rgba(231, 229, 228, 0.9);
    backdrop-filter: blur(10px);
    -webkit-backdrop-filter: blur(10px);
    border: 1px solid rgba(120, 113, 108, 0.3);
    border-radius: var(--radius-md);
    padding: var(--spacing-md) var(--spacing-lg);
    color: var(--stone-600);
    font-family: var(--font-sans);
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 0.05em;
    font-size: var(--text-xs);
  }

  .technical-button-primary {
    background-color: var(--stone-600);
    color: white;
    border: none;
    border-radius: var(--radius-md);
    padding: var(--spacing-sm) var(--spacing-lg);
    font-family: var(--font-sans);
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 0.05em;
    font-size: var(--text-sm);
    transition: all 0.3s ease;
  }

  .technical-button-primary:hover {
    background-color: var(--stone-700);
  }

  .technical-button-primary.active {
    background-color: var(--stone-600);
  }

  .technical-button-secondary {
    background-color: var(--stone-200);
    color: var(--stone-700);
    border: 2px solid var(--stone-400);
    border-radius: var(--radius-md);
    padding: var(--spacing-sm) var(--spacing-lg);
    font-family: var(--font-sans);
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 0.05em;
    font-size: var(--text-sm);
    transition: all 0.3s ease;
  }

  .technical-button-secondary:hover {
    background-color: var(--stone-100);
    border-color: var(--stone-500);
  }

  /* Status Indicators */
  .status-live {
    background-color: rgba(16, 185, 129, 0.8);
    color: white;
    padding: 4px 12px;
    border-radius: 12px;
    font-family: var(--font-sans);
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 0.1em;
    font-size: var(--text-xs);
    display: flex;
    align-items: center;
    gap: 8px;
  }

  .status-live::before {
    content: '';
    width: 8px;
    height: 8px;
    border-radius: 50%;
    background-color: white;
    animation: pulse 2s infinite;
  }

  /* Typography Classes */
  .code-aesthetic {
    font-family: var(--font-mono);
    font-weight: 400;
    letter-spacing: -0.01em;
    line-height: 1.4;
  }

  .technical-heading {
    font-family: var(--font-display);
    font-weight: 700;
    letter-spacing: -0.02em;
    text-transform: uppercase;
    line-height: 1.1;
  }

  .body-technical {
    font-family: var(--font-sans);
    font-weight: 400;
    line-height: 1.6;
    letter-spacing: -0.005em;
  }

  /* Animation Classes */
  .animate-glass-pulse {
    animation: glassPulse 2s ease-in-out infinite;
  }

  .animate-fade-in {
    animation: fadeIn 0.5s ease-in-out;
  }

  .animate-slide-up {
    animation: slideUp 0.3s ease-out;
  }
}

@layer utilities {
  .perspective-1000 {
    perspective: 1000px;
  }
  
  .transform-gpu {
    transform: translate3d(0, 0, 0);
  }
  
  .rotate-y-12 {
    transform: rotateY(12deg);
  }
  
  .rotate-x-3 {
    transform: rotateX(3deg);
  }
}

/* Keyframe Animations */
@keyframes pulse {
  0%, 100% { opacity: 1; }
  50% { opacity: 0.3; }
}

@keyframes glassPulse {
  0%, 100% { 
    background: rgba(255, 255, 255, 0.8);
    opacity: 1; 
  }
  50% { 
    background: rgba(255, 255, 255, 0.6);
    opacity: 0.8; 
  }
}

@keyframes fadeIn {
  from { opacity: 0; }
  to { opacity: 1; }
}

@keyframes slideUp {
  from { 
    opacity: 0;
    transform: translateY(20px);
  }
  to { 
    opacity: 1;
    transform: translateY(0);
  }
}

/* Page Transitions */
.page-enter {
  opacity: 0;
  transform: translateY(20px);
}

.page-enter-active {
  opacity: 1;
  transform: translateY(0);
  transition: all 0.4s ease;
}

.page-exit {
  opacity: 1;
  transform: translateY(0);
}

.page-exit-active {
  opacity: 0;
  transform: translateY(-20px);
  transition: all 0.3s ease;
}

/* Story 1.4.2 Styles - Updated with design system */
.file-list-item {
  background: rgba(231, 229, 228, 0.9);
  backdrop-filter: blur(10px);
  border: 1px solid rgba(120, 113, 108, 0.3);
  border-radius: var(--radius-md);
  padding: var(--spacing-sm) var(--spacing-md);
  margin-bottom: var(--spacing-sm);
  cursor: pointer;
  transition: all 0.2s ease;
}

.file-list-item:hover {
  background: rgba(214, 211, 209, 0.9);
  border-color: var(--stone-500);
}

.file-list-item.selected {
  background: var(--stone-400);
  border-color: var(--stone-600);
}

.file-metadata {
  font-family: var(--font-mono);
  font-size: 0.7rem;
  color: var(--stone-500);
  text-transform: uppercase;
  letter-spacing: 0.05em;
}

.upload-zone-compact {
  border: 2px dashed var(--stone-400);
  background: rgba(231, 229, 228, 0.5);
  border-radius: var(--radius-md);
  padding: var(--spacing-md);
  text-align: center;
  margin-bottom: var(--spacing-md);
  transition: all 0.3s ease;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  height: 100%;
}

.upload-zone-compact:hover {
  border-color: var(--stone-600);
  background: rgba(214, 211, 209, 0.7);
  cursor: pointer;
}

.parsing-status {
  display: inline-flex;
  align-items: center;
  gap: 4px;
  font-family: var(--font-mono);
  font-size: 0.65rem;
  font-weight: 700;
  text-transform: uppercase;
  letter-spacing: 0.05em;
  padding: 2px 6px;
  border-radius: 4px;
}

.parsing-status.completed {
  background: rgba(16, 185, 129, 0.2);
  color: #065f46;
}

.parsing-status.pending {
  background: rgba(245, 158, 11, 0.2);
  color: #b45309;
}

.parsing-status.failed {
  background: rgba(239, 68, 68, 0.2);
  color: #b91c1c;
}
</file>

<file path="app/layout.tsx">
import React from 'react'
import './globals.css'
import { Inter } from 'next/font/google'
import { Toaster } from '@/components/ui/toaster'
import { TRPCProvider } from '@/components/providers/trpc-provider'

const inter = Inter({ subsets: ['latin'] })

export const metadata = {
  title: 'Phonoglyph - MIDI Visualization Platform',
  description: 'Transform MIDI files into stunning visual experiences',
}

export default function RootLayout({
  children,
}: {
  children: React.ReactNode
}) {
  return (
    <html lang="en">
      <body className={inter.className}>
        <TRPCProvider>
          {children}
          <Toaster />
          <div id="modal-portal-root" />
        </TRPCProvider>
      </body>
    </html>
  )
}
</file>

<file path="app/page.tsx">
"use client"

import React, { useEffect, useState } from 'react'
import { supabase } from '@/lib/supabase'
import { Navigation } from '@/components/navigation'
import { LandingPage } from '@/components/landing-page'

export default function HomePage() {
  const [user, setUser] = useState<any>(null)
  const [loading, setLoading] = useState(true)

  useEffect(() => {
    const checkSession = async () => {
      const { data: { session } } = await supabase.auth.getSession()
      setUser(session?.user || null)
      setLoading(false)
    }
    
    checkSession()

    const { data: { subscription } } = supabase.auth.onAuthStateChange(
      async (event, session) => {
        setUser(session?.user || null)
      }
    )

    return () => subscription.unsubscribe()
  }, [])

  if (loading) {
    return (
      <div className="min-h-screen bg-gradient-to-br from-stone-50 to-stone-100 flex items-center justify-center">
        <div className="text-center">
          <div className="animate-spin rounded-full h-12 w-12 border-b-2 border-stone-600 mx-auto mb-4"></div>
          <p className="text-stone-600 font-mono">LOADING...</p>
        </div>
      </div>
    )
  }

  return (
    <>
      <Navigation user={user} currentPath="/" />
      <LandingPage user={user} />
    </>
  )
}
</file>

<file path="components/assets/asset-preview.tsx">
import React from 'react'
import { Card, CardContent } from '@/components/ui/card'
import { Badge } from '@/components/ui/badge'

interface FileMetadata {
  id: string
  file_name: string
  file_type: 'midi' | 'audio' | 'video' | 'image'
  file_size: number
  mime_type: string
  thumbnail_url?: string
  video_metadata?: {
    duration: number
    width: number
    height: number
    frameRate: number
    codec: string
    aspectRatio: string
  }
  image_metadata?: {
    width: number
    height: number
    colorProfile: string
    orientation: number
    hasAlpha: boolean
    fileFormat: string
  }
  processing_status?: 'pending' | 'processing' | 'completed' | 'failed'
  created_at: string
}

interface AssetPreviewProps {
  file: FileMetadata
  onSelect?: (file: FileMetadata) => void
  className?: string
}

const formatFileSize = (bytes: number): string => {
  const sizes = ['B', 'KB', 'MB', 'GB']
  if (bytes === 0) return '0 B'
  const i = Math.floor(Math.log(bytes) / Math.log(1024))
  return `${Math.round(bytes / Math.pow(1024, i) * 100) / 100} ${sizes[i]}`
}

const formatDuration = (seconds: number): string => {
  const mins = Math.floor(seconds / 60)
  const secs = Math.floor(seconds % 60)
  return `${mins}:${secs.toString().padStart(2, '0')}`
}

const getFileTypeIcon = (fileType: string): string => {
  switch (fileType) {
    case 'video': return ''
    case 'image': return ''
    case 'audio': return ''
    case 'midi': return ''
    default: return ''
  }
}

const getFileTypeColor = (fileType: string): string => {
  switch (fileType) {
    case 'video': return 'bg-purple-100 text-purple-800'
    case 'image': return 'bg-green-100 text-green-800'
    case 'audio': return 'bg-blue-100 text-blue-800'
    case 'midi': return 'bg-orange-100 text-orange-800'
    default: return 'bg-gray-100 text-gray-800'
  }
}

export function AssetPreview({ file, onSelect, className }: AssetPreviewProps) {
  const handleClick = () => {
    onSelect?.(file)
  }

  const renderPreview = () => {
    switch (file.file_type) {
      case 'video':
        if (file.thumbnail_url) {
          return (
            <div className="relative aspect-video bg-gray-100 rounded-md overflow-hidden">
              <img 
                src={file.thumbnail_url}
                alt={file.file_name}
                className="w-full h-full object-cover"
              />
              <div className="absolute bottom-2 right-2 bg-black bg-opacity-70 text-white px-2 py-1 rounded text-xs">
                {file.video_metadata?.duration ? formatDuration(file.video_metadata.duration) : ''}
              </div>
              <div className="absolute top-2 left-2">
                <span className="text-2xl"></span>
              </div>
            </div>
          )
        }
        return (
          <div className="aspect-video bg-gray-100 rounded-md flex items-center justify-center">
            <div className="text-center text-gray-500">
              <span className="text-4xl block mb-2"></span>
              <span className="text-sm">
                {file.processing_status === 'pending' ? 'Processing...' : 'Video Preview'}
              </span>
            </div>
          </div>
        )

      case 'image':
        if (file.thumbnail_url) {
          return (
            <div className="aspect-video bg-gray-100 rounded-md overflow-hidden">
              <img 
                src={file.thumbnail_url}
                alt={file.file_name}
                className="w-full h-full object-contain"
              />
            </div>
          )
        }
        return (
          <div className="aspect-video bg-gray-100 rounded-md flex items-center justify-center">
            <div className="text-center text-gray-500">
              <span className="text-4xl block mb-2"></span>
              <span className="text-sm">
                {file.processing_status === 'pending' ? 'Processing...' : 'Image Preview'}
              </span>
            </div>
          </div>
        )

      case 'audio':
        return (
          <div className="aspect-video bg-gray-100 rounded-md flex items-center justify-center">
            <div className="text-center text-gray-500">
              <span className="text-4xl block mb-2"></span>
              <span className="text-sm">Audio File</span>
            </div>
          </div>
        )

      case 'midi':
        return (
          <div className="aspect-video bg-gray-100 rounded-md flex items-center justify-center">
            <div className="text-center text-gray-500">
              <span className="text-4xl block mb-2"></span>
              <span className="text-sm">MIDI File</span>
            </div>
          </div>
        )

      default:
        return (
          <div className="aspect-video bg-gray-100 rounded-md flex items-center justify-center">
            <div className="text-center text-gray-500">
              <span className="text-4xl block mb-2"></span>
              <span className="text-sm">Unknown File</span>
            </div>
          </div>
        )
    }
  }

  const renderMetadata = () => {
    if (file.file_type === 'video' && file.video_metadata) {
      return (
        <div className="space-y-1 text-xs text-gray-600">
          <div className="flex justify-between">
            <span>Resolution:</span>
            <span>{file.video_metadata.width}x{file.video_metadata.height}</span>
          </div>
          <div className="flex justify-between">
            <span>Duration:</span>
            <span>{formatDuration(file.video_metadata.duration)}</span>
          </div>
          <div className="flex justify-between">
            <span>Codec:</span>
            <span>{file.video_metadata.codec}</span>
          </div>
        </div>
      )
    }

    if (file.file_type === 'image' && file.image_metadata) {
      return (
        <div className="space-y-1 text-xs text-gray-600">
          <div className="flex justify-between">
            <span>Dimensions:</span>
            <span>{file.image_metadata.width}x{file.image_metadata.height}</span>
          </div>
          <div className="flex justify-between">
            <span>Format:</span>
            <span>{file.image_metadata.fileFormat}</span>
          </div>
          <div className="flex justify-between">
            <span>Color:</span>
            <span>{file.image_metadata.colorProfile}</span>
          </div>
        </div>
      )
    }

    return (
      <div className="text-xs text-gray-600">
        <div className="flex justify-between">
          <span>Type:</span>
          <span className="capitalize">{file.file_type}</span>
        </div>
      </div>
    )
  }

  return (
    <Card 
      className={`cursor-pointer hover:shadow-md transition-shadow ${className}`}
      onClick={handleClick}
    >
      <CardContent className="p-4">
        {renderPreview()}
        
        <div className="mt-3 space-y-2">
          <div className="flex items-center justify-between">
            <h3 className="font-medium text-sm truncate flex-1" title={file.file_name}>
              {file.file_name}
            </h3>
            <Badge variant="secondary" className={getFileTypeColor(file.file_type)}>
              {getFileTypeIcon(file.file_type)} {file.file_type.toUpperCase()}
            </Badge>
          </div>
          
          <div className="flex items-center justify-between text-xs text-gray-500">
            <span>{formatFileSize(file.file_size)}</span>
            <span>{new Date(file.created_at).toLocaleDateString()}</span>
          </div>

          {renderMetadata()}

          {file.processing_status && file.processing_status !== 'completed' && (
            <div className="mt-2">
              <Badge 
                variant={file.processing_status === 'failed' ? 'destructive' : 'secondary'}
                className="text-xs"
              >
                {file.processing_status === 'pending' && ' Processing...'}
                {file.processing_status === 'processing' && ' Processing...'}
                {file.processing_status === 'failed' && ' Failed'}
              </Badge>
            </div>
          )}
        </div>
      </CardContent>
    </Card>
  )
}
</file>

<file path="components/audio-analysis/analysis-comparison.tsx">
'use client';

import React from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Badge } from '@/components/ui/badge';
import { Button } from '@/components/ui/button';
import { BarChart3, TrendingUp, TrendingDown, Minus } from 'lucide-react';

interface ComparisonData {
  transients: { sandbox: number; cached: number; difference: number };
  chroma: { sandbox: number; cached: number; difference: number };
  rms: { sandbox: number; cached: number; difference: number };
}

interface AnalysisComparisonProps {
  comparison: ComparisonData;
  onSaveToCache?: () => void;
  onLoadFromCache?: () => void;
  isSaving?: boolean;
  isLoading?: boolean;
}

export function AnalysisComparison({
  comparison,
  onSaveToCache,
  onLoadFromCache,
  isSaving = false,
  isLoading = false
}: AnalysisComparisonProps) {
  const getTrendIcon = (difference: number) => {
    if (difference > 0) return <TrendingUp className="w-4 h-4 text-green-400" />;
    if (difference < 0) return <TrendingDown className="w-4 h-4 text-red-400" />;
    return <Minus className="w-4 h-4 text-slate-400" />;
  };

  const getTrendColor = (difference: number) => {
    if (difference > 0) return 'text-green-400';
    if (difference < 0) return 'text-red-400';
    return 'text-slate-400';
  };

  const getTrendBadge = (difference: number) => {
    if (difference > 0) return 'bg-green-600/20 text-green-400 border-green-600';
    if (difference < 0) return 'bg-red-600/20 text-red-400 border-red-600';
    return 'bg-slate-600/20 text-slate-400 border-slate-600';
  };

  return (
    <Card className="bg-slate-800/50 border-slate-700">
      <CardHeader>
        <CardTitle className="text-white flex items-center gap-2">
          <BarChart3 className="w-5 h-5" />
          Analysis Comparison
        </CardTitle>
      </CardHeader>
      <CardContent className="space-y-6">
        {/* Comparison Metrics */}
        <div className="grid grid-cols-1 md:grid-cols-3 gap-4">
          {/* Transients Comparison */}
          <div className="space-y-3">
            <h3 className="text-lg font-semibold text-white">Transients</h3>
            <div className="space-y-2">
              <div className="flex items-center justify-between">
                <span className="text-slate-300">Sandbox</span>
                <Badge variant="outline" className="text-blue-400 border-blue-600">
                  {comparison.transients.sandbox}
                </Badge>
              </div>
              <div className="flex items-center justify-between">
                <span className="text-slate-300">Cached</span>
                <Badge variant="outline" className="text-slate-400 border-slate-600">
                  {comparison.transients.cached}
                </Badge>
              </div>
              <div className="flex items-center justify-between">
                <span className="text-slate-300">Difference</span>
                <div className="flex items-center gap-2">
                  {getTrendIcon(comparison.transients.difference)}
                  <Badge 
                    variant="outline" 
                    className={getTrendBadge(comparison.transients.difference)}
                  >
                    {comparison.transients.difference > 0 ? '+' : ''}{comparison.transients.difference}
                  </Badge>
                </div>
              </div>
            </div>
          </div>

          {/* Chroma Comparison */}
          <div className="space-y-3">
            <h3 className="text-lg font-semibold text-white">Chroma</h3>
            <div className="space-y-2">
              <div className="flex items-center justify-between">
                <span className="text-slate-300">Sandbox</span>
                <Badge variant="outline" className="text-blue-400 border-blue-600">
                  {comparison.chroma.sandbox}
                </Badge>
              </div>
              <div className="flex items-center justify-between">
                <span className="text-slate-300">Cached</span>
                <Badge variant="outline" className="text-slate-400 border-slate-600">
                  {comparison.chroma.cached}
                </Badge>
              </div>
              <div className="flex items-center justify-between">
                <span className="text-slate-300">Difference</span>
                <div className="flex items-center gap-2">
                  {getTrendIcon(comparison.chroma.difference)}
                  <Badge 
                    variant="outline" 
                    className={getTrendBadge(comparison.chroma.difference)}
                  >
                    {comparison.chroma.difference > 0 ? '+' : ''}{comparison.chroma.difference}
                  </Badge>
                </div>
              </div>
            </div>
          </div>

          {/* RMS Comparison */}
          <div className="space-y-3">
            <h3 className="text-lg font-semibold text-white">RMS</h3>
            <div className="space-y-2">
              <div className="flex items-center justify-between">
                <span className="text-slate-300">Sandbox</span>
                <Badge variant="outline" className="text-blue-400 border-blue-600">
                  {comparison.rms.sandbox}
                </Badge>
              </div>
              <div className="flex items-center justify-between">
                <span className="text-slate-300">Cached</span>
                <Badge variant="outline" className="text-slate-400 border-slate-600">
                  {comparison.rms.cached}
                </Badge>
              </div>
              <div className="flex items-center justify-between">
                <span className="text-slate-300">Difference</span>
                <div className="flex items-center gap-2">
                  {getTrendIcon(comparison.rms.difference)}
                  <Badge 
                    variant="outline" 
                    className={getTrendBadge(comparison.rms.difference)}
                  >
                    {comparison.rms.difference > 0 ? '+' : ''}{comparison.rms.difference}
                  </Badge>
                </div>
              </div>
            </div>
          </div>
        </div>

        {/* Summary */}
        <div className="p-4 bg-slate-700/50 rounded-lg">
          <h4 className="text-sm font-semibold text-white mb-2">Summary</h4>
          <div className="text-sm text-slate-300 space-y-1">
            {comparison.transients.difference > 0 && (
              <p> Sandbox detected {comparison.transients.difference} more transients</p>
            )}
            {comparison.transients.difference < 0 && (
              <p> Cached analysis has {Math.abs(comparison.transients.difference)} more transients</p>
            )}
            {comparison.chroma.difference > 0 && (
              <p> Sandbox detected {comparison.chroma.difference} more chroma events</p>
            )}
            {comparison.chroma.difference < 0 && (
              <p> Cached analysis has {Math.abs(comparison.chroma.difference)} more chroma events</p>
            )}
            {comparison.rms.difference > 0 && (
              <p> Sandbox has {comparison.rms.difference} more RMS samples</p>
            )}
            {comparison.rms.difference < 0 && (
              <p> Cached analysis has {Math.abs(comparison.rms.difference)} more RMS samples</p>
            )}
            {comparison.transients.difference === 0 && comparison.chroma.difference === 0 && comparison.rms.difference === 0 && (
              <p> No differences detected between analysis methods</p>
            )}
          </div>
        </div>

        {/* Action Buttons */}
        <div className="flex gap-3">
          <Button
            onClick={onSaveToCache}
            disabled={isSaving}
            className="bg-purple-600 hover:bg-purple-700 text-white"
          >
            {isSaving ? 'Saving...' : 'Save to Cache'}
          </Button>
          <Button
            onClick={onLoadFromCache}
            disabled={isLoading}
            variant="outline"
            className="border-slate-600 text-slate-300 hover:bg-slate-700"
          >
            {isLoading ? 'Loading...' : 'Load from Cache'}
          </Button>
        </div>
      </CardContent>
    </Card>
  );
}
</file>

<file path="components/audio-analysis/analysis-method-controls.tsx">
'use client';

import React from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Slider } from '@/components/ui/slider';
import { Label } from '@/components/ui/label';
import { Badge } from '@/components/ui/badge';
import { Separator } from '@/components/ui/separator';
import { Settings, Zap, Music, Volume2, BarChart3, ToggleLeft, ToggleRight } from 'lucide-react';
import { AnalysisParams, AnalysisMethod } from '@/types/audio-analysis';

interface AnalysisMethodControlsProps {
  analysisMethod: AnalysisMethod;
  analysisParams: AnalysisParams;
  onMethodChange: (method: AnalysisMethod) => void;
  onParamsChange: (params: Partial<AnalysisParams>) => void;
  isAnalyzing?: boolean;
}

export function AnalysisMethodControls({
  analysisMethod,
  analysisParams,
  onMethodChange,
  onParamsChange,
  isAnalyzing = false
}: AnalysisMethodControlsProps) {
  const handleParamChange = (key: keyof AnalysisParams, value: number | number[]) => {
    onParamsChange({
      [key]: Array.isArray(value) ? value[0] : value
    });
  };

  const getMethodIcon = (method: string) => {
    switch (method) {
      case 'original': return <BarChart3 className="w-4 h-4" />;
      case 'enhanced': return <Zap className="w-4 h-4" />;
      case 'both': return <Settings className="w-4 h-4" />;
      default: return <BarChart3 className="w-4 h-4" />;
    }
  };

  const getMethodColor = (method: string) => {
    switch (method) {
      case 'original': return 'bg-blue-600/20 text-blue-400 border-blue-600';
      case 'enhanced': return 'bg-purple-600/20 text-purple-400 border-purple-600';
      case 'both': return 'bg-green-600/20 text-green-400 border-green-600';
      default: return 'bg-slate-600/20 text-slate-400 border-slate-600';
    }
  };

  return (
    <Card className="bg-slate-800/50 border-slate-700">
      <CardHeader className="pb-3">
        <CardTitle className="text-white flex items-center gap-2 text-lg">
          <Settings className="w-5 h-5" />
          Audio Analysis Pipeline
        </CardTitle>
      </CardHeader>
      <CardContent className="space-y-4">
        {/* Analysis Method Selection */}
        <div className="space-y-3">
          <Label className="text-slate-300 text-sm font-medium">Analysis Method</Label>
          <div className="flex gap-2">
            <Button
              variant={analysisMethod === 'original' ? 'default' : 'outline'}
              size="sm"
              onClick={() => onMethodChange('original')}
              disabled={isAnalyzing}
              className="flex-1"
            >
              <BarChart3 className="w-4 h-4 mr-2" />
              Original
            </Button>
            <Button
              variant={analysisMethod === 'enhanced' ? 'default' : 'outline'}
              size="sm"
              onClick={() => onMethodChange('enhanced')}
              disabled={isAnalyzing}
              className="flex-1"
            >
              <Zap className="w-4 h-4 mr-2" />
              Enhanced
            </Button>
            <Button
              variant={analysisMethod === 'both' ? 'default' : 'outline'}
              size="sm"
              onClick={() => onMethodChange('both')}
              disabled={isAnalyzing}
              className="flex-1"
            >
              <Settings className="w-4 h-4 mr-2" />
              Both
            </Button>
          </div>
          <div className="flex items-center gap-2">
            <Badge variant="outline" className={getMethodColor(analysisMethod)}>
              {getMethodIcon(analysisMethod)}
              <span className="ml-1 capitalize">{analysisMethod}</span>
            </Badge>
            {isAnalyzing && (
              <Badge variant="outline" className="bg-yellow-600/20 text-yellow-400 border-yellow-600">
                Analyzing...
              </Badge>
            )}
          </div>
        </div>

        {/* Enhanced Analysis Parameters */}
        {(analysisMethod === 'enhanced' || analysisMethod === 'both') && (
          <>
            <Separator className="bg-slate-600" />
            
            <div className="space-y-4">
              <div className="flex items-center gap-2">
                <Zap className="w-4 h-4 text-purple-400" />
                <h3 className="text-sm font-semibold text-white">Enhanced Analysis Parameters</h3>
              </div>
              
              {/* Transient Detection */}
              <div className="space-y-2">
                <div className="flex items-center gap-2">
                  <Zap className="w-3 h-3 text-red-400" />
                  <Label className="text-xs text-slate-300">Transient Detection</Label>
                </div>
                <div className="space-y-2">
                  <div>
                    <Label className="text-xs text-slate-400">
                      Threshold: {analysisParams.transientThreshold.toFixed(2)}
                    </Label>
                    <Slider
                      value={[analysisParams.transientThreshold]}
                      onValueChange={(value) => handleParamChange('transientThreshold', value)}
                      min={0.1}
                      max={0.9}
                      step={0.05}
                      className="mt-1"
                    />
                  </div>
                  <div>
                    <Label className="text-xs text-slate-400">
                      Onset: {analysisParams.onsetThreshold.toFixed(2)}
                    </Label>
                    <Slider
                      value={[analysisParams.onsetThreshold]}
                      onValueChange={(value) => handleParamChange('onsetThreshold', value)}
                      min={0.05}
                      max={0.5}
                      step={0.025}
                      className="mt-1"
                    />
                  </div>
                </div>
              </div>

              {/* Chroma Analysis */}
              <div className="space-y-2">
                <div className="flex items-center gap-2">
                  <Music className="w-3 h-3 text-blue-400" />
                  <Label className="text-xs text-slate-300">Chroma Analysis</Label>
                </div>
                <div className="space-y-2">
                  <div>
                    <Label className="text-xs text-slate-400">
                      Smoothing: {analysisParams.chromaSmoothing.toFixed(2)}
                    </Label>
                    <Slider
                      value={[analysisParams.chromaSmoothing]}
                      onValueChange={(value) => handleParamChange('chromaSmoothing', value)}
                      min={0.1}
                      max={0.95}
                      step={0.05}
                      className="mt-1"
                    />
                  </div>
                  <div>
                    <Label className="text-xs text-slate-400">
                      Confidence: {analysisParams.pitchConfidence.toFixed(2)}
                    </Label>
                    <Slider
                      value={[analysisParams.pitchConfidence]}
                      onValueChange={(value) => handleParamChange('pitchConfidence', value)}
                      min={0.3}
                      max={0.95}
                      step={0.05}
                      className="mt-1"
                    />
                  </div>
                </div>
              </div>

              {/* RMS Analysis */}
              <div className="space-y-2">
                <div className="flex items-center gap-2">
                  <Volume2 className="w-3 h-3 text-green-400" />
                  <Label className="text-xs text-slate-300">RMS Analysis</Label>
                </div>
                <div>
                  <Label className="text-xs text-slate-400">
                    Window Size: {analysisParams.rmsWindowSize}
                  </Label>
                  <Slider
                    value={[analysisParams.rmsWindowSize]}
                    onValueChange={(value) => handleParamChange('rmsWindowSize', value)}
                    min={256}
                    max={4096}
                    step={128}
                    className="mt-1"
                  />
                </div>
              </div>
            </div>

            {/* Quick Presets */}
            <div className="pt-2">
              <Label className="text-xs text-slate-300 mb-2 block">Quick Presets</Label>
              <div className="flex gap-1">
                <Button
                  size="sm"
                  variant="outline"
                  onClick={() => onParamsChange({
                    transientThreshold: 0.2,
                    onsetThreshold: 0.15,
                    chromaSmoothing: 0.7,
                    rmsWindowSize: 512,
                    pitchConfidence: 0.6,
                    minNoteDuration: 0.08
                  })}
                  className="text-xs px-2 py-1 h-7"
                >
                  Sensitive
                </Button>
                <Button
                  size="sm"
                  variant="outline"
                  onClick={() => onParamsChange({
                    transientThreshold: 0.4,
                    onsetThreshold: 0.25,
                    chromaSmoothing: 0.8,
                    rmsWindowSize: 1024,
                    pitchConfidence: 0.75,
                    minNoteDuration: 0.12
                  })}
                  className="text-xs px-2 py-1 h-7"
                >
                  Balanced
                </Button>
                <Button
                  size="sm"
                  variant="outline"
                  onClick={() => onParamsChange({
                    transientThreshold: 0.6,
                    onsetThreshold: 0.35,
                    chromaSmoothing: 0.9,
                    rmsWindowSize: 2048,
                    pitchConfidence: 0.85,
                    minNoteDuration: 0.2
                  })}
                  className="text-xs px-2 py-1 h-7"
                >
                  Conservative
                </Button>
              </div>
            </div>
          </>
        )}

        {/* Analysis Status */}
        {analysisMethod === 'enhanced' || analysisMethod === 'both' ? (
          <div className="p-3 bg-purple-900/20 border border-purple-600/50 rounded-lg">
            <div className="flex items-center gap-2 mb-2">
              <Zap className="w-4 h-4 text-purple-400" />
              <span className="text-sm font-semibold text-white">Enhanced Analysis</span>
            </div>
            <div className="text-xs text-purple-300 space-y-1">
              <p> Transient detection for onset analysis</p>
              <p> Chroma analysis for pitch detection</p>
              <p> RMS processing for amplitude tracking</p>
              <p> MIDI-like control parameters</p>
            </div>
          </div>
        ) : (
          <div className="p-3 bg-blue-900/20 border border-blue-600/50 rounded-lg">
            <div className="flex items-center gap-2 mb-2">
              <BarChart3 className="w-4 h-4 text-blue-400" />
              <span className="text-sm font-semibold text-white">Original Analysis</span>
            </div>
            <div className="text-xs text-blue-300 space-y-1">
              <p> Standard frequency analysis</p>
              <p> Volume and spectral features</p>
              <p> FFT-based processing</p>
            </div>
          </div>
        )}
      </CardContent>
    </Card>
  );
}
</file>

<file path="components/audio-analysis/analysis-parameters.tsx">
'use client';

import React from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Slider } from '@/components/ui/slider';
import { Label } from '@/components/ui/label';
import { Separator } from '@/components/ui/separator';
import { Settings, Zap, Music, Volume2 } from 'lucide-react';

interface AnalysisParametersProps {
  params: {
    transientThreshold: number;
    onsetThreshold: number;
    chromaSmoothing: number;
    rmsWindowSize: number;
    pitchConfidence: number;
    minNoteDuration: number;
  };
  onParamsChange: (params: any) => void;
}

export function AnalysisParameters({ params, onParamsChange }: AnalysisParametersProps) {
  const handleParamChange = (key: string, value: number | number[]) => {
    onParamsChange({
      ...params,
      [key]: Array.isArray(value) ? value[0] : value
    });
  };

  return (
    <Card className="bg-slate-800/50 border-slate-700">
      <CardHeader>
        <CardTitle className="text-white flex items-center gap-2">
          <Settings className="w-5 h-5" />
          Analysis Parameters
        </CardTitle>
      </CardHeader>
      <CardContent className="space-y-6">
        {/* Transient Detection Parameters */}
        <div className="space-y-4">
          <div className="flex items-center gap-2 mb-3">
            <Zap className="w-4 h-4 text-red-400" />
            <h3 className="text-lg font-semibold text-white">Transient Detection</h3>
          </div>
          
          <div className="space-y-3">
            <div>
              <Label className="text-slate-300">
                Transient Threshold: {params.transientThreshold.toFixed(2)}
              </Label>
              <Slider
                value={[params.transientThreshold]}
                onValueChange={(value) => handleParamChange('transientThreshold', value)}
                min={0.1}
                max={0.9}
                step={0.05}
                className="mt-2"
              />
              <p className="text-xs text-slate-400 mt-1">
                Higher values detect fewer, stronger transients
              </p>
            </div>

            <div>
              <Label className="text-slate-300">
                Onset Threshold: {params.onsetThreshold.toFixed(2)}
              </Label>
              <Slider
                value={[params.onsetThreshold]}
                onValueChange={(value) => handleParamChange('onsetThreshold', value)}
                min={0.05}
                max={0.5}
                step={0.025}
                className="mt-2"
              />
              <p className="text-xs text-slate-400 mt-1">
                Sensitivity for detecting note onsets
              </p>
            </div>
          </div>
        </div>

        <Separator className="bg-slate-600" />

        {/* Chroma/Pitch Detection Parameters */}
        <div className="space-y-4">
          <div className="flex items-center gap-2 mb-3">
            <Music className="w-4 h-4 text-blue-400" />
            <h3 className="text-lg font-semibold text-white">Chroma & Pitch Detection</h3>
          </div>
          
          <div className="space-y-3">
            <div>
              <Label className="text-slate-300">
                Chroma Smoothing: {params.chromaSmoothing.toFixed(2)}
              </Label>
              <Slider
                value={[params.chromaSmoothing]}
                onValueChange={(value) => handleParamChange('chromaSmoothing', value)}
                min={0.1}
                max={0.95}
                step={0.05}
                className="mt-2"
              />
              <p className="text-xs text-slate-400 mt-1">
                Higher values create smoother pitch transitions
              </p>
            </div>

            <div>
              <Label className="text-slate-300">
                Pitch Confidence: {params.pitchConfidence.toFixed(2)}
              </Label>
              <Slider
                value={[params.pitchConfidence]}
                onValueChange={(value) => handleParamChange('pitchConfidence', value)}
                min={0.3}
                max={0.95}
                step={0.05}
                className="mt-2"
              />
              <p className="text-xs text-slate-400 mt-1">
                Minimum confidence for pitch detection
              </p>
            </div>

            <div>
              <Label className="text-slate-300">
                Min Note Duration: {params.minNoteDuration.toFixed(2)}s
              </Label>
              <Slider
                value={[params.minNoteDuration]}
                onValueChange={(value) => handleParamChange('minNoteDuration', value)}
                min={0.05}
                max={0.5}
                step={0.025}
                className="mt-2"
              />
              <p className="text-xs text-slate-400 mt-1">
                Minimum duration for valid notes
              </p>
            </div>
          </div>
        </div>

        <Separator className="bg-slate-600" />

        {/* RMS Analysis Parameters */}
        <div className="space-y-4">
          <div className="flex items-center gap-2 mb-3">
            <Volume2 className="w-4 h-4 text-green-400" />
            <h3 className="text-lg font-semibold text-white">RMS Analysis</h3>
          </div>
          
          <div className="space-y-3">
            <div>
              <Label className="text-slate-300">
                Window Size: {params.rmsWindowSize}
              </Label>
              <Slider
                value={[params.rmsWindowSize]}
                onValueChange={(value) => handleParamChange('rmsWindowSize', value)}
                min={256}
                max={4096}
                step={128}
                className="mt-2"
              />
              <p className="text-xs text-slate-400 mt-1">
                Larger windows = smoother RMS values
              </p>
            </div>
          </div>
        </div>

        {/* Preset Buttons */}
        <div className="pt-4">
          <h4 className="text-sm font-medium text-slate-300 mb-3">Quick Presets</h4>
          <div className="flex gap-2 flex-wrap">
            <button
              onClick={() => onParamsChange({
                transientThreshold: 0.2,
                onsetThreshold: 0.15,
                chromaSmoothing: 0.7,
                rmsWindowSize: 512,
                pitchConfidence: 0.6,
                minNoteDuration: 0.08
              })}
              className="px-3 py-1 text-xs bg-purple-600 hover:bg-purple-700 text-white rounded-md transition-colors"
            >
              Sensitive
            </button>
            <button
              onClick={() => onParamsChange({
                transientThreshold: 0.4,
                onsetThreshold: 0.25,
                chromaSmoothing: 0.8,
                rmsWindowSize: 1024,
                pitchConfidence: 0.75,
                minNoteDuration: 0.12
              })}
              className="px-3 py-1 text-xs bg-blue-600 hover:bg-blue-700 text-white rounded-md transition-colors"
            >
              Balanced
            </button>
            <button
              onClick={() => onParamsChange({
                transientThreshold: 0.6,
                onsetThreshold: 0.35,
                chromaSmoothing: 0.9,
                rmsWindowSize: 2048,
                pitchConfidence: 0.85,
                minNoteDuration: 0.2
              })}
              className="px-3 py-1 text-xs bg-green-600 hover:bg-green-700 text-white rounded-md transition-colors"
            >
              Conservative
            </button>
          </div>
        </div>
      </CardContent>
    </Card>
  );
}
</file>

<file path="components/audio-analysis/analysis-visualization.tsx">
'use client';

import React, { useRef, useEffect, useState, useCallback } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Badge } from '@/components/ui/badge';
import { Button } from '@/components/ui/button';
import { BarChart3, Zap, Music, Volume2, Play, Pause } from 'lucide-react';

interface AnalysisData {
  transients: Array<{
    time: number;
    intensity: number;
    frequency: number;
  }>;
  chroma: Array<{
    time: number;
    pitch: number;
    confidence: number;
    note: string;
  }>;
  rms: Array<{
    time: number;
    value: number;
  }>;
  waveform: number[];
}

interface AnalysisVisualizationProps {
  analysisData: AnalysisData;
  currentTime: number;
  duration: number;
  onSeek: (time: number) => void;
  isPlaying: boolean;
}

const CHROMA_COLORS = [
  '#ef4444', // C - Red
  '#f97316', // C# - Orange
  '#eab308', // D - Yellow
  '#84cc16', // D# - Lime
  '#22c55e', // E - Green
  '#10b981', // F - Emerald
  '#06b6d4', // F# - Cyan
  '#0ea5e9', // G - Sky
  '#3b82f6', // G# - Blue
  '#6366f1', // A - Indigo
  '#8b5cf6', // A# - Violet
  '#d946ef', // B - Fuchsia
];

const NOTE_NAMES = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];

export function AnalysisVisualization({
  analysisData,
  currentTime,
  duration,
  onSeek,
  isPlaying
}: AnalysisVisualizationProps) {
  const waveformCanvasRef = useRef<HTMLCanvasElement>(null);
  const chromaCanvasRef = useRef<HTMLCanvasElement>(null);
  const rmsCanvasRef = useRef<HTMLCanvasElement>(null);
  const [selectedView, setSelectedView] = useState<'waveform' | 'chroma' | 'rms' | 'all'>('all');

  // Draw waveform with transient markers
  const drawWaveform = useCallback(() => {
    const canvas = waveformCanvasRef.current;
    if (!canvas || !analysisData.waveform) return;

    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    const rect = canvas.getBoundingClientRect();
    canvas.width = rect.width * devicePixelRatio;
    canvas.height = rect.height * devicePixelRatio;
    ctx.scale(devicePixelRatio, devicePixelRatio);

    const width = rect.width;
    const height = rect.height;
    const midY = height / 2;

    ctx.clearRect(0, 0, width, height);

    // Draw waveform
    ctx.beginPath();
    ctx.strokeStyle = '#ffffff';
    ctx.lineWidth = 1;
    
    const waveform = analysisData.waveform;
    for (let i = 0; i < waveform.length; i++) {
      const x = (i / (waveform.length - 1)) * width;
      const y = midY - (waveform[i] * midY * 0.8);
      
      if (i === 0) {
        ctx.moveTo(x, y);
      } else {
        ctx.lineTo(x, y);
      }
    }
    ctx.stroke();

    // Draw transient markers
    if (analysisData.transients) {
      analysisData.transients.forEach(transient => {
        const x = (transient.time / duration) * width;
        const intensity = transient.intensity;
        const markerHeight = intensity * height * 0.6;
        
        // Draw vertical line
        ctx.beginPath();
        ctx.strokeStyle = '#ef4444';
        ctx.lineWidth = 2;
        ctx.moveTo(x, midY - markerHeight / 2);
        ctx.lineTo(x, midY + markerHeight / 2);
        ctx.stroke();
        
        // Draw intensity circle
        ctx.beginPath();
        ctx.fillStyle = `rgba(239, 68, 68, ${intensity})`;
        ctx.arc(x, midY, 4, 0, Math.PI * 2);
        ctx.fill();
      });
    }

    // Draw current time indicator
    const currentX = (currentTime / duration) * width;
    ctx.beginPath();
    ctx.strokeStyle = '#fbbf24';
    ctx.lineWidth = 2;
    ctx.moveTo(currentX, 0);
    ctx.lineTo(currentX, height);
    ctx.stroke();
  }, [analysisData, currentTime, duration]);

  // Draw chroma visualization
  const drawChroma = useCallback(() => {
    const canvas = chromaCanvasRef.current;
    if (!canvas || !analysisData.chroma) return;

    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    const rect = canvas.getBoundingClientRect();
    canvas.width = rect.width * devicePixelRatio;
    canvas.height = rect.height * devicePixelRatio;
    ctx.scale(devicePixelRatio, devicePixelRatio);

    const width = rect.width;
    const height = rect.height;
    const noteHeight = height / 12;

    ctx.clearRect(0, 0, width, height);

    // Draw chroma data
    analysisData.chroma.forEach(chroma => {
      const x = (chroma.time / duration) * width;
      const y = (11 - chroma.pitch) * noteHeight; // Invert Y so C is at top
      const noteWidth = 4;
      const alpha = chroma.confidence;
      
      ctx.fillStyle = `${CHROMA_COLORS[chroma.pitch]}${Math.floor(alpha * 255).toString(16).padStart(2, '0')}`;
      ctx.fillRect(x - noteWidth / 2, y, noteWidth, noteHeight);
    });

    // Draw note labels
    ctx.fillStyle = '#ffffff';
    ctx.font = '12px monospace';
    ctx.textAlign = 'right';
    for (let i = 0; i < 12; i++) {
      const y = (11 - i) * noteHeight + noteHeight / 2 + 4;
      ctx.fillText(NOTE_NAMES[i], 30, y);
    }

    // Draw current time indicator
    const currentX = (currentTime / duration) * width;
    ctx.beginPath();
    ctx.strokeStyle = '#fbbf24';
    ctx.lineWidth = 2;
    ctx.moveTo(currentX, 0);
    ctx.lineTo(currentX, height);
    ctx.stroke();
  }, [analysisData, currentTime, duration]);

  // Draw RMS visualization
  const drawRMS = useCallback(() => {
    const canvas = rmsCanvasRef.current;
    if (!canvas || !analysisData.rms) return;

    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    const rect = canvas.getBoundingClientRect();
    canvas.width = rect.width * devicePixelRatio;
    canvas.height = rect.height * devicePixelRatio;
    ctx.scale(devicePixelRatio, devicePixelRatio);

    const width = rect.width;
    const height = rect.height;

    ctx.clearRect(0, 0, width, height);

    // Draw RMS curve
    ctx.beginPath();
    ctx.strokeStyle = '#10b981';
    ctx.lineWidth = 2;
    
    analysisData.rms.forEach((rms, index) => {
      const x = (rms.time / duration) * width;
      const y = height - (rms.value * height);
      
      if (index === 0) {
        ctx.moveTo(x, y);
      } else {
        ctx.lineTo(x, y);
      }
    });
    ctx.stroke();

    // Fill area under curve
    ctx.beginPath();
    ctx.strokeStyle = '#10b981';
    ctx.lineWidth = 2;
    
    analysisData.rms.forEach((rms, index) => {
      const x = (rms.time / duration) * width;
      const y = height - (rms.value * height);
      
      if (index === 0) {
        ctx.moveTo(x, height);
        ctx.lineTo(x, y);
      } else {
        ctx.lineTo(x, y);
      }
    });
    ctx.lineTo(width, height);
    ctx.closePath();
    ctx.fillStyle = 'rgba(16, 185, 129, 0.2)';
    ctx.fill();

    // Draw current time indicator
    const currentX = (currentTime / duration) * width;
    ctx.beginPath();
    ctx.strokeStyle = '#fbbf24';
    ctx.lineWidth = 2;
    ctx.moveTo(currentX, 0);
    ctx.lineTo(currentX, height);
    ctx.stroke();
  }, [analysisData, currentTime, duration]);

  // Handle canvas click for seeking
  const handleCanvasClick = useCallback((e: React.MouseEvent<HTMLCanvasElement>) => {
    const canvas = e.currentTarget;
    const rect = canvas.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const relativePosition = x / rect.width;
    const seekTime = relativePosition * duration;
    onSeek(seekTime);
  }, [duration, onSeek]);

  // Redraw canvases when data changes
  useEffect(() => {
    if (selectedView === 'waveform' || selectedView === 'all') {
      drawWaveform();
    }
    if (selectedView === 'chroma' || selectedView === 'all') {
      drawChroma();
    }
    if (selectedView === 'rms' || selectedView === 'all') {
      drawRMS();
    }
  }, [selectedView, drawWaveform, drawChroma, drawRMS]);

  // Redraw on window resize
  useEffect(() => {
    const handleResize = () => {
      if (selectedView === 'waveform' || selectedView === 'all') {
        drawWaveform();
      }
      if (selectedView === 'chroma' || selectedView === 'all') {
        drawChroma();
      }
      if (selectedView === 'rms' || selectedView === 'all') {
        drawRMS();
      }
    };

    window.addEventListener('resize', handleResize);
    return () => window.removeEventListener('resize', handleResize);
  }, [selectedView, drawWaveform, drawChroma, drawRMS]);

  return (
    <Card className="bg-slate-800/50 border-slate-700">
      <CardHeader>
        <CardTitle className="text-white flex items-center justify-between">
          <div className="flex items-center gap-2">
            <BarChart3 className="w-5 h-5" />
            Analysis Visualization
          </div>
          <div className="flex gap-2">
            <Button
              variant={selectedView === 'all' ? 'default' : 'outline'}
              size="sm"
              onClick={() => setSelectedView('all')}
              className="text-xs"
            >
              All
            </Button>
            <Button
              variant={selectedView === 'waveform' ? 'default' : 'outline'}
              size="sm"
              onClick={() => setSelectedView('waveform')}
              className="text-xs"
            >
              Waveform
            </Button>
            <Button
              variant={selectedView === 'chroma' ? 'default' : 'outline'}
              size="sm"
              onClick={() => setSelectedView('chroma')}
              className="text-xs"
            >
              Chroma
            </Button>
            <Button
              variant={selectedView === 'rms' ? 'default' : 'outline'}
              size="sm"
              onClick={() => setSelectedView('rms')}
              className="text-xs"
            >
              RMS
            </Button>
          </div>
        </CardTitle>
      </CardHeader>
      <CardContent className="space-y-6">
        {/* Waveform Visualization */}
        {(selectedView === 'waveform' || selectedView === 'all') && (
          <div className="space-y-2">
            <div className="flex items-center gap-2">
              <Zap className="w-4 h-4 text-red-400" />
              <h3 className="text-lg font-semibold text-white">Waveform with Transients</h3>
              <Badge variant="outline" className="text-slate-300 border-slate-600">
                {analysisData.transients?.length || 0} transients
              </Badge>
            </div>
            <div className="relative">
              <canvas
                ref={waveformCanvasRef}
                onClick={handleCanvasClick}
                className="w-full h-32 bg-slate-900/50 rounded-lg cursor-pointer"
              />
              <div className="absolute top-2 left-2 text-xs text-slate-400">
                Click to seek  Red markers = transients
              </div>
            </div>
          </div>
        )}

        {/* Chroma Visualization */}
        {(selectedView === 'chroma' || selectedView === 'all') && (
          <div className="space-y-2">
            <div className="flex items-center gap-2">
              <Music className="w-4 h-4 text-blue-400" />
              <h3 className="text-lg font-semibold text-white">Chroma Analysis</h3>
              <Badge variant="outline" className="text-slate-300 border-slate-600">
                {new Set(analysisData.chroma?.map(c => c.note) || []).size} unique notes
              </Badge>
            </div>
            <div className="relative">
              <canvas
                ref={chromaCanvasRef}
                onClick={handleCanvasClick}
                className="w-full h-48 bg-slate-900/50 rounded-lg cursor-pointer"
              />
              <div className="absolute top-2 left-2 text-xs text-slate-400">
                Click to seek  Colors = chroma classes
              </div>
            </div>
          </div>
        )}

        {/* RMS Visualization */}
        {(selectedView === 'rms' || selectedView === 'all') && (
          <div className="space-y-2">
            <div className="flex items-center gap-2">
              <Volume2 className="w-4 h-4 text-green-400" />
              <h3 className="text-lg font-semibold text-white">RMS Analysis</h3>
              <Badge variant="outline" className="text-slate-300 border-slate-600">
                Avg: {analysisData.rms?.length ? 
                  (analysisData.rms.reduce((sum, r) => sum + r.value, 0) / analysisData.rms.length).toFixed(3) : 
                  '0.000'
                }
              </Badge>
            </div>
            <div className="relative">
              <canvas
                ref={rmsCanvasRef}
                onClick={handleCanvasClick}
                className="w-full h-32 bg-slate-900/50 rounded-lg cursor-pointer"
              />
              <div className="absolute top-2 left-2 text-xs text-slate-400">
                Click to seek  Green area = RMS amplitude
              </div>
            </div>
          </div>
        )}

        {/* Legend */}
        <div className="grid grid-cols-1 md:grid-cols-3 gap-4 pt-4 border-t border-slate-600">
          <div className="space-y-2">
            <h4 className="text-sm font-semibold text-white flex items-center gap-2">
              <Zap className="w-4 h-4 text-red-400" />
              Transients
            </h4>
            <div className="space-y-1 text-xs text-slate-400">
              <div className="flex items-center gap-2">
                <div className="w-3 h-3 bg-red-500 rounded-full"></div>
                <span>Onset detection</span>
              </div>
              <div className="flex items-center gap-2">
                <div className="w-3 h-3 bg-red-500/50 rounded-full"></div>
                <span>Intensity = opacity</span>
              </div>
            </div>
          </div>

          <div className="space-y-2">
            <h4 className="text-sm font-semibold text-white flex items-center gap-2">
              <Music className="w-4 h-4 text-blue-400" />
              Chroma
            </h4>
            <div className="space-y-1 text-xs text-slate-400">
              <div className="flex items-center gap-2">
                <div className="w-3 h-3 bg-red-500 rounded"></div>
                <span>C</span>
              </div>
              <div className="flex items-center gap-2">
                <div className="w-3 h-3 bg-blue-500 rounded"></div>
                <span>G</span>
              </div>
              <div className="flex items-center gap-2">
                <div className="w-3 h-3 bg-green-500 rounded"></div>
                <span>E</span>
              </div>
            </div>
          </div>

          <div className="space-y-2">
            <h4 className="text-sm font-semibold text-white flex items-center gap-2">
              <Volume2 className="w-4 h-4 text-green-400" />
              RMS
            </h4>
            <div className="space-y-1 text-xs text-slate-400">
              <div className="flex items-center gap-2">
                <div className="w-3 h-3 bg-green-500 rounded"></div>
                <span>Amplitude curve</span>
              </div>
              <div className="flex items-center gap-2">
                <div className="w-3 h-3 bg-green-500/20 rounded"></div>
                <span>Filled area</span>
              </div>
            </div>
          </div>
        </div>
      </CardContent>
    </Card>
  );
}
</file>

<file path="components/audio-analysis/api-test.tsx">
'use client';

import React, { useState } from 'react';
import { Button } from '@/components/ui/button';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Badge } from '@/components/ui/badge';
import { trpc } from '@/lib/trpc';
import { CheckCircle, XCircle, Loader2 } from 'lucide-react';

export function ApiTest() {
  const [testResults, setTestResults] = useState<{
    health: 'pending' | 'success' | 'error';
    sandboxTest: 'pending' | 'success' | 'error';
    sandboxAuth: 'pending' | 'success' | 'error';
  }>({
    health: 'pending',
    sandboxTest: 'pending',
    sandboxAuth: 'pending',
  });

  const healthQuery = trpc.health.check.useQuery(undefined, {
    retry: false,
    onSuccess: () => {
      setTestResults(prev => ({ ...prev, health: 'success' }));
    },
    onError: () => {
      setTestResults(prev => ({ ...prev, health: 'error' }));
    },
  });

  const sandboxTestQuery = trpc.audioAnalysisSandbox.test.useQuery(undefined, {
    retry: false,
    onSuccess: () => {
      setTestResults(prev => ({ ...prev, sandboxTest: 'success' }));
    },
    onError: () => {
      setTestResults(prev => ({ ...prev, sandboxTest: 'error' }));
    },
  });

  const sandboxAuthQuery = trpc.audioAnalysisSandbox.getSandboxAnalyses.useQuery(
    { limit: 1 },
    {
      retry: false,
      onSuccess: () => {
        setTestResults(prev => ({ ...prev, sandboxAuth: 'success' }));
      },
      onError: () => {
        setTestResults(prev => ({ ...prev, sandboxAuth: 'error' }));
      },
    }
  );

  const getStatusIcon = (status: 'pending' | 'success' | 'error') => {
    switch (status) {
      case 'pending':
        return <Loader2 className="w-4 h-4 animate-spin text-yellow-400" />;
      case 'success':
        return <CheckCircle className="w-4 h-4 text-green-400" />;
      case 'error':
        return <XCircle className="w-4 h-4 text-red-400" />;
    }
  };

  const getStatusBadge = (status: 'pending' | 'success' | 'error') => {
    switch (status) {
      case 'pending':
        return 'bg-yellow-600/20 text-yellow-400 border-yellow-600';
      case 'success':
        return 'bg-green-600/20 text-green-400 border-green-600';
      case 'error':
        return 'bg-red-600/20 text-red-400 border-red-600';
    }
  };

  const getStatusText = (status: 'pending' | 'success' | 'error') => {
    switch (status) {
      case 'pending':
        return 'Testing...';
      case 'success':
        return 'Connected';
      case 'error':
        return 'Failed';
    }
  };

  return (
    <Card className="bg-slate-800/50 border-slate-700">
      <CardHeader>
        <CardTitle className="text-white flex items-center gap-2">
          API Connection Test
        </CardTitle>
      </CardHeader>
      <CardContent className="space-y-4">
        <div className="space-y-3">
          <div className="flex items-center justify-between">
            <div className="flex items-center gap-2">
              {getStatusIcon(testResults.health)}
              <span className="text-slate-300">Health Check</span>
            </div>
            <Badge variant="outline" className={getStatusBadge(testResults.health)}>
              {getStatusText(testResults.health)}
            </Badge>
          </div>

          <div className="flex items-center justify-between">
            <div className="flex items-center gap-2">
              {getStatusIcon(testResults.sandboxTest)}
              <span className="text-slate-300">Sandbox Router</span>
            </div>
            <Badge variant="outline" className={getStatusBadge(testResults.sandboxTest)}>
              {getStatusText(testResults.sandboxTest)}
            </Badge>
          </div>

          <div className="flex items-center justify-between">
            <div className="flex items-center gap-2">
              {getStatusIcon(testResults.sandboxAuth)}
              <span className="text-slate-300">Sandbox Auth</span>
            </div>
            <Badge variant="outline" className={getStatusBadge(testResults.sandboxAuth)}>
              {getStatusText(testResults.sandboxAuth)}
            </Badge>
          </div>
        </div>

        {testResults.health === 'error' && (
          <div className="p-3 bg-red-900/20 border border-red-600/50 rounded-lg">
            <p className="text-sm text-red-400">
              API server is not responding. Please check:
            </p>
            <ul className="text-xs text-red-300 mt-2 space-y-1">
              <li> API server is running on the correct port</li>
              <li> NEXT_PUBLIC_API_URL is set correctly</li>
              <li> No firewall blocking the connection</li>
            </ul>
          </div>
        )}

        {testResults.sandboxTest === 'error' && testResults.health === 'success' && (
          <div className="p-3 bg-red-900/20 border border-red-600/50 rounded-lg">
            <p className="text-sm text-red-400">
              Health check passed but sandbox router failed. Check if the router is properly registered.
            </p>
          </div>
        )}

        {testResults.sandboxAuth === 'error' && testResults.sandboxTest === 'success' && (
          <div className="p-3 bg-yellow-900/20 border border-yellow-600/50 rounded-lg">
            <p className="text-sm text-yellow-400">
              Sandbox router is working but authentication failed. Make sure you're logged in.
            </p>
          </div>
        )}

        {testResults.health === 'success' && testResults.sandboxTest === 'success' && testResults.sandboxAuth === 'success' && (
          <div className="p-3 bg-green-900/20 border border-green-600/50 rounded-lg">
            <p className="text-sm text-green-400">
              All API endpoints are working correctly! The sandbox is ready to use.
            </p>
          </div>
        )}

        <Button
          onClick={() => {
            setTestResults({ health: 'pending', sandboxTest: 'pending', sandboxAuth: 'pending' });
            healthQuery.refetch();
            sandboxTestQuery.refetch();
            sandboxAuthQuery.refetch();
          }}
          variant="outline"
          className="w-full border-slate-600 text-slate-300 hover:bg-slate-700"
        >
          Retry Tests
        </Button>
      </CardContent>
    </Card>
  );
}
</file>

<file path="components/audio-analysis/audio-analysis-sandbox.tsx">
'use client';

import React, { useCallback } from 'react';

interface AudioAnalysisSandboxProps {
  audioBuffer: AudioBuffer;
  params: {
    transientThreshold: number;
    onsetThreshold: number;
    chromaSmoothing: number;
    rmsWindowSize: number;
    pitchConfidence: number;
    minNoteDuration: number;
  };
  onAnalysisComplete: (analysis: any) => void;
}

export function AudioAnalysisSandbox({ 
  audioBuffer, 
  params, 
  onAnalysisComplete 
}: AudioAnalysisSandboxProps) {
  
  // Transient/Onset Detection using Spectral Flux
  const detectTransients = useCallback((channelData: Float32Array, sampleRate: number) => {
    const windowSize = 1024;
    const hopSize = 512;
    const transients: Array<{ time: number; intensity: number; frequency: number }> = [];
    
    // Calculate spectral flux for onset detection
    const spectralFlux = [];
    const fftSize = windowSize;
    
    for (let i = 0; i < channelData.length - windowSize; i += hopSize) {
      const window = channelData.slice(i, i + windowSize);
      
      // Apply Hann window
      const hannWindow = window.map((sample, idx) => 
        sample * (0.5 - 0.5 * Math.cos(2 * Math.PI * idx / (windowSize - 1)))
      );
      
      // Calculate FFT magnitude spectrum
      const fft = performFFT(hannWindow);
      const magnitude = fft.map(complex => Math.sqrt(complex.real * complex.real + complex.imag * complex.imag));
      
      // Calculate spectral flux (difference from previous frame)
      if (spectralFlux.length > 0) {
        let flux = 0;
        for (let j = 0; j < magnitude.length; j++) {
          const diff = magnitude[j] - spectralFlux[spectralFlux.length - 1][j];
          if (diff > 0) flux += diff;
        }
        
        // Detect transients based on threshold
        if (flux > params.transientThreshold) {
          const time = i / sampleRate;
          const intensity = Math.min(flux / 10, 1); // Normalize intensity
          
          // Find dominant frequency
          let maxMag = 0;
          let maxFreq = 0;
          for (let j = 1; j < magnitude.length / 2; j++) {
            if (magnitude[j] > maxMag) {
              maxMag = magnitude[j];
              maxFreq = (j * sampleRate) / fftSize;
            }
          }
          
          transients.push({
            time,
            intensity,
            frequency: maxFreq
          });
        }
      }
      
      spectralFlux.push(magnitude);
    }
    
    return transients;
  }, [params.transientThreshold]);

  // Chroma/Pitch Detection using YIN algorithm
  const detectChroma = useCallback((channelData: Float32Array, sampleRate: number) => {
    const windowSize = 2048;
    const hopSize = 512;
    const chroma: Array<{ time: number; pitch: number; confidence: number; note: string }> = [];
    
    const noteNames = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
    
    for (let i = 0; i < channelData.length - windowSize; i += hopSize) {
      const window = channelData.slice(i, i + windowSize);
      
      // Apply Hann window
      const hannWindow = window.map((sample, idx) => 
        sample * (0.5 - 0.5 * Math.cos(2 * Math.PI * idx / (windowSize - 1)))
      );
      
      // YIN pitch detection
      const pitch = detectPitchYIN(hannWindow, sampleRate);
      
      if (pitch > 0 && pitch < 2000) { // Reasonable frequency range
        // Convert frequency to MIDI note number
        const midiNote = 12 * Math.log2(pitch / 440) + 69;
        const chromaClass = Math.round(midiNote) % 12;
        const confidence = Math.min(pitch / 1000, 1); // Simple confidence based on frequency
        
        if (confidence > params.pitchConfidence) {
          chroma.push({
            time: i / sampleRate,
            pitch: chromaClass,
            confidence,
            note: noteNames[chromaClass]
          });
        }
      }
    }
    
    // Apply smoothing
    return smoothChroma(chroma, params.chromaSmoothing);
  }, [params.pitchConfidence, params.chromaSmoothing]);

  // RMS Analysis
  const analyzeRMS = useCallback((channelData: Float32Array, sampleRate: number) => {
    const windowSize = params.rmsWindowSize;
    const hopSize = windowSize / 2;
    const rms: Array<{ time: number; value: number }> = [];
    
    for (let i = 0; i < channelData.length - windowSize; i += hopSize) {
      const window = channelData.slice(i, i + windowSize);
      
      // Calculate RMS
      let sum = 0;
      for (let j = 0; j < window.length; j++) {
        sum += window[j] * window[j];
      }
      const rmsValue = Math.sqrt(sum / window.length);
      
      rms.push({
        time: i / sampleRate,
        value: rmsValue
      });
    }
    
    return rms;
  }, [params.rmsWindowSize]);

  // Generate waveform data
  const generateWaveform = useCallback((channelData: Float32Array, points: number = 1000) => {
    const step = Math.floor(channelData.length / points);
    const waveform: number[] = [];
    
    for (let i = 0; i < points; i++) {
      const start = i * step;
      const end = Math.min(start + step, channelData.length);
      
      // Calculate RMS for this segment
      let sum = 0;
      for (let j = start; j < end; j++) {
        sum += channelData[j] * channelData[j];
      }
      const rms = Math.sqrt(sum / (end - start));
      waveform.push(rms);
    }
    
    return waveform;
  }, []);

  // Perform analysis
  const performAnalysis = useCallback(async () => {
    const channelData = audioBuffer.getChannelData(0);
    const sampleRate = audioBuffer.sampleRate;
    
    // Run all analyses
    const transients = detectTransients(channelData, sampleRate);
    const chroma = detectChroma(channelData, sampleRate);
    const rms = analyzeRMS(channelData, sampleRate);
    const waveform = generateWaveform(channelData);
    
    const analysis = {
      transients,
      chroma,
      rms,
      waveform,
      metadata: {
        sampleRate,
        duration: audioBuffer.duration,
        bufferSize: audioBuffer.length,
        analysisParams: params
      }
    };
    
    onAnalysisComplete(analysis);
  }, [audioBuffer, params, detectTransients, detectChroma, analyzeRMS, generateWaveform, onAnalysisComplete]);

  // Start analysis when component mounts or parameters change
  React.useEffect(() => {
    performAnalysis();
  }, [performAnalysis, params]);

  return null; // This component doesn't render anything
}

// Helper function: Simple FFT implementation
function performFFT(samples: Float32Array): Array<{ real: number; imag: number }> {
  const N = samples.length;
  const result: Array<{ real: number; imag: number }> = [];
  
  for (let k = 0; k < N; k++) {
    let real = 0;
    let imag = 0;
    
    for (let n = 0; n < N; n++) {
      const angle = -2 * Math.PI * k * n / N;
      real += samples[n] * Math.cos(angle);
      imag += samples[n] * Math.sin(angle);
    }
    
    result.push({ real, imag });
  }
  
  return result;
}

// Helper function: YIN pitch detection algorithm
function detectPitchYIN(samples: Float32Array, sampleRate: number): number {
  const minPeriod = Math.floor(sampleRate / 2000); // Max 2000 Hz
  const maxPeriod = Math.floor(sampleRate / 80);   // Min 80 Hz
  
  let bestPeriod = 0;
  let bestDifference = 1;
  
  for (let period = minPeriod; period < maxPeriod && period < samples.length / 2; period++) {
    let difference = 0;
    let sum = 0;
    
    for (let i = 0; i < samples.length - period; i++) {
      const delta = samples[i] - samples[i + period];
      difference += delta * delta;
      sum += samples[i] * samples[i];
    }
    
    if (sum > 0) {
      difference /= sum;
      
      if (difference < bestDifference) {
        bestDifference = difference;
        bestPeriod = period;
      }
    }
  }
  
  // Convert period to frequency
  return bestPeriod > 0 ? sampleRate / bestPeriod : 0;
}

// Helper function: Smooth chroma data
function smoothChroma(chroma: Array<{ time: number; pitch: number; confidence: number; note: string }>, smoothing: number): Array<{ time: number; pitch: number; confidence: number; note: string }> {
  if (chroma.length === 0) return chroma;
  
  const smoothed = [...chroma];
  const noteNames = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
  
  for (let i = 1; i < smoothed.length - 1; i++) {
    const prev = smoothed[i - 1];
    const curr = smoothed[i];
    const next = smoothed[i + 1];
    
    // Simple moving average for pitch
    const avgPitch = Math.round((prev.pitch + curr.pitch + next.pitch) / 3);
    const avgConfidence = (prev.confidence + curr.confidence + next.confidence) / 3;
    
    if (avgConfidence > curr.confidence * smoothing) {
      smoothed[i] = {
        time: curr.time,
        pitch: avgPitch,
        confidence: avgConfidence,
        note: noteNames[avgPitch]
      };
    }
  }
  
  return smoothed;
}
</file>

<file path="components/audio-analysis/auth-status.tsx">
'use client';

import React from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Badge } from '@/components/ui/badge';
import { trpc } from '@/lib/trpc';
import { CheckCircle, XCircle, Loader2, User, UserCheck } from 'lucide-react';

export function AuthStatus() {
  const sessionQuery = trpc.auth.session.useQuery();
  const meQuery = trpc.auth.me.useQuery(undefined, {
    retry: false,
  });

  const getStatusIcon = (isLoading: boolean, isError: boolean, isSuccess: boolean) => {
    if (isLoading) return <Loader2 className="w-4 h-4 animate-spin text-yellow-400" />;
    if (isError) return <XCircle className="w-4 h-4 text-red-400" />;
    if (isSuccess) return <CheckCircle className="w-4 h-4 text-green-400" />;
    return <User className="w-4 h-4 text-slate-400" />;
  };

  const getStatusBadge = (isLoading: boolean, isError: boolean, isSuccess: boolean) => {
    if (isLoading) return 'bg-yellow-600/20 text-yellow-400 border-yellow-600';
    if (isError) return 'bg-red-600/20 text-red-400 border-red-600';
    if (isSuccess) return 'bg-green-600/20 text-green-400 border-green-600';
    return 'bg-slate-600/20 text-slate-400 border-slate-600';
  };

  const getStatusText = (isLoading: boolean, isError: boolean, isSuccess: boolean) => {
    if (isLoading) return 'Checking...';
    if (isError) return 'Not authenticated';
    if (isSuccess) return 'Authenticated';
    return 'Unknown';
  };

  return (
    <Card className="bg-slate-800/50 border-slate-700">
      <CardHeader>
        <CardTitle className="text-white flex items-center gap-2">
          <UserCheck className="w-5 h-5" />
          Authentication Status
        </CardTitle>
      </CardHeader>
      <CardContent className="space-y-4">
        <div className="space-y-3">
          <div className="flex items-center justify-between">
            <div className="flex items-center gap-2">
              {getStatusIcon(sessionQuery.isLoading, sessionQuery.isError, sessionQuery.isSuccess)}
              <span className="text-slate-300">Session Check</span>
            </div>
            <Badge variant="outline" className={getStatusBadge(sessionQuery.isLoading, sessionQuery.isError, sessionQuery.isSuccess)}>
              {getStatusText(sessionQuery.isLoading, sessionQuery.isError, sessionQuery.isSuccess)}
            </Badge>
          </div>

          <div className="flex items-center justify-between">
            <div className="flex items-center gap-2">
              {getStatusIcon(meQuery.isLoading, meQuery.isError, meQuery.isSuccess)}
              <span className="text-slate-300">Protected Endpoint</span>
            </div>
            <Badge variant="outline" className={getStatusBadge(meQuery.isLoading, meQuery.isError, meQuery.isSuccess)}>
              {getStatusText(meQuery.isLoading, meQuery.isError, meQuery.isSuccess)}
            </Badge>
          </div>
        </div>

        {sessionQuery.data && (
          <div className="p-3 bg-slate-700/50 rounded-lg">
            <h4 className="text-sm font-semibold text-white mb-2">Session Info</h4>
            <div className="text-xs text-slate-300 space-y-1">
              <p>Authenticated: {sessionQuery.data.authenticated ? 'Yes' : 'No'}</p>
              {sessionQuery.data.user && (
                <>
                  <p>User ID: {sessionQuery.data.user.id}</p>
                  <p>Email: {sessionQuery.data.user.email}</p>
                  <p>Name: {sessionQuery.data.user.name}</p>
                </>
              )}
            </div>
          </div>
        )}

        {meQuery.data && (
          <div className="p-3 bg-green-900/20 border border-green-600/50 rounded-lg">
            <h4 className="text-sm font-semibold text-white mb-2">User Details</h4>
            <div className="text-xs text-green-300 space-y-1">
              <p>ID: {meQuery.data.user.id}</p>
              <p>Email: {meQuery.data.user.email}</p>
              <p>Name: {meQuery.data.user.name}</p>
            </div>
          </div>
        )}

        {sessionQuery.isError && (
          <div className="p-3 bg-red-900/20 border border-red-600/50 rounded-lg">
            <p className="text-sm text-red-400">
              Session check failed. This might indicate a connection issue.
            </p>
          </div>
        )}

        {meQuery.isError && sessionQuery.isSuccess && (
          <div className="p-3 bg-yellow-900/20 border border-yellow-600/50 rounded-lg">
            <p className="text-sm text-yellow-400">
              Session exists but protected endpoint failed. This suggests an authentication token issue.
            </p>
            <p className="text-xs text-yellow-300 mt-2">
              Try logging out and logging back in to refresh your authentication token.
            </p>
          </div>
        )}
      </CardContent>
    </Card>
  );
}
</file>

<file path="components/auth/auth-guard.tsx">
"use client"

import { useEffect, useState } from 'react'
import { useRouter, useSearchParams } from 'next/navigation'
import { AuthService } from '@/lib/auth'
import { useAuth } from '@/hooks/use-auth'
import { debugLog } from '@/lib/utils';

interface AuthGuardProps {
  children: React.ReactNode
  requireAuth?: boolean
  redirectTo?: string
  fallback?: React.ReactNode
}

export function AuthGuard({ 
  children, 
  requireAuth = true, 
  redirectTo = '/auth/login',
  fallback 
}: AuthGuardProps) {
  const router = useRouter()
  const searchParams = useSearchParams()
  const { user, loading } = useAuth()
  const [isChecking, setIsChecking] = useState(true)

  useEffect(() => {
    const checkAuth = async () => {
      try {
        // If we don't require auth, just show the content
        if (!requireAuth) {
          setIsChecking(false)
          return
        }

        // If we require auth but user is not logged in
        if (requireAuth && !user && !loading) {
          const currentPath = window.location.pathname
          const redirectUrl = new URL(redirectTo, window.location.origin)
          
          // Preserve the current path for redirect after login
          if (currentPath !== redirectTo) {
            redirectUrl.searchParams.set('redirectTo', currentPath)
          }
          
          router.push(redirectUrl.toString())
          return
        }

        // If we have a user and they're trying to access auth pages, redirect to dashboard
        if (user && (window.location.pathname.startsWith('/auth/login') || 
                     window.location.pathname.startsWith('/auth/signup'))) {
          const redirectTo = searchParams.get('redirectTo') || '/dashboard'
          router.push(redirectTo)
          return
        }

        setIsChecking(false)
      } catch (error) {
        debugLog.error('Auth guard error:', error)
        setIsChecking(false)
      }
    }

    checkAuth()
  }, [user, loading, requireAuth, redirectTo, router, searchParams])

  // Show loading state while checking authentication
  if (loading || isChecking) {
    if (fallback) {
      return <>{fallback}</>
    }
    
    return (
      <div className="min-h-screen flex items-center justify-center">
        <div 
          className="animate-spin rounded-full h-32 w-32 border-b-2 border-gray-900"
          data-testid="auth-loading-spinner"
        ></div>
      </div>
    )
  }

  // If auth is required and user is not authenticated, don't render children
  if (requireAuth && !user) {
    return null
  }

  // If auth is not required or user is authenticated, render children
  return <>{children}</>
}

// Higher-order component for protecting pages
export function withAuthGuard<P extends object>(
  Component: React.ComponentType<P>,
  options: Omit<AuthGuardProps, 'children'> = {}
) {
  return function AuthGuardedComponent(props: P) {
    return (
      <AuthGuard {...options}>
        <Component {...props} />
      </AuthGuard>
    )
  }
}

// Loading component for auth states
export function AuthLoadingSpinner() {
  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50">
      <div className="text-center">
        <div className="animate-spin rounded-full h-32 w-32 border-b-2 border-indigo-600 mx-auto"></div>
        <p className="mt-4 text-lg text-gray-600">Loading...</p>
      </div>
    </div>
  )
}
</file>

<file path="components/auth/login-form.tsx">
"use client"

import { useState } from "react"
import { useForm } from "react-hook-form"
import { zodResolver } from "@hookform/resolvers/zod"
import Link from "next/link"
import { Button } from "@/components/ui/button"
import { Input } from "@/components/ui/input"
import { Label } from "@/components/ui/label"
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from "@/components/ui/card"
import { Separator } from "@/components/ui/separator"
import { AuthService } from "@/lib/auth"
import { loginSchema, type LoginInput } from "@/lib/validations"
import { useToast } from "@/hooks/use-toast"
import { OAuthButtons } from "./oauth-buttons"

interface LoginFormProps {
  redirectTo?: string
}

export function LoginForm({ redirectTo = "/dashboard" }: LoginFormProps) {
  const [isLoading, setIsLoading] = useState(false)
  const { toast } = useToast()

  const {
    register,
    handleSubmit,
    formState: { errors },
  } = useForm<LoginInput>({
    resolver: zodResolver(loginSchema),
  })

  const onSubmit = async (data: LoginInput) => {
    try {
      setIsLoading(true)
      await AuthService.signInWithEmail(data)
      
      toast({
        title: "Success!",
        description: "You have been signed in successfully.",
      })
      
      // Redirect will be handled by auth state change
      window.location.href = redirectTo
    } catch (error) {
      toast({
        title: "Authentication Error",
        description: error instanceof Error ? error.message : "Failed to sign in",
        variant: "destructive",
      })
    } finally {
      setIsLoading(false)
    }
  }

  return (
    <Card className="w-full max-w-md mx-auto">
      <CardHeader>
        <CardTitle>Sign In</CardTitle>
        <CardDescription>
          Enter your email and password to access your account
        </CardDescription>
      </CardHeader>
      
      <CardContent className="space-y-6">
        <OAuthButtons redirectTo={redirectTo} />
        
        <div className="relative">
          <div className="absolute inset-0 flex items-center">
            <Separator className="w-full" />
          </div>
          <div className="relative flex justify-center text-xs uppercase">
            <span className="bg-background px-2 text-muted-foreground">
              Or continue with
            </span>
          </div>
        </div>

        <form onSubmit={handleSubmit(onSubmit)} className="space-y-4">
          <div className="space-y-2">
            <Label htmlFor="email">Email</Label>
            <Input
              id="email"
              type="email"
              placeholder="name@example.com"
              {...register("email")}
              disabled={isLoading}
            />
            {errors.email && (
              <p className="text-sm text-destructive">{errors.email.message}</p>
            )}
          </div>

          <div className="space-y-2">
            <div className="flex items-center justify-between">
              <Label htmlFor="password">Password</Label>
              <Link
                href="/auth/reset-password"
                className="text-sm text-muted-foreground hover:text-primary"
              >
                Forgot password?
              </Link>
            </div>
            <Input
              id="password"
              type="password"
              {...register("password")}
              disabled={isLoading}
            />
            {errors.password && (
              <p className="text-sm text-destructive">{errors.password.message}</p>
            )}
          </div>

          <Button type="submit" className="w-full" disabled={isLoading}>
            {isLoading ? "Signing in..." : "Sign In"}
          </Button>
        </form>
      </CardContent>

      <CardFooter className="flex justify-center">
        <p className="text-sm text-muted-foreground">
          Don't have an account?{" "}
          <Link href="/auth/signup" className="text-primary hover:underline">
            Sign up
          </Link>
        </p>
      </CardFooter>
    </Card>
  )
}
</file>

<file path="components/auth/oauth-buttons.tsx">
"use client"

import { useState } from "react"
import { Button } from "@/components/ui/button"
import { AuthService } from "@/lib/auth"
import { useToast } from "@/hooks/use-toast"

interface OAuthButtonsProps {
  redirectTo?: string
}

export function OAuthButtons({ redirectTo }: OAuthButtonsProps) {
  const [isLoading, setIsLoading] = useState(false)
  const { toast } = useToast()

  const handleGoogleSignIn = async () => {
    try {
      setIsLoading(true)
      await AuthService.signInWithOAuth({
        provider: 'google',
        redirectTo,
      })
    } catch (error) {
      toast({
        title: "Authentication Error",
        description: error instanceof Error ? error.message : "Failed to sign in with Google",
        variant: "destructive",
      })
    } finally {
      setIsLoading(false)
    }
  }

  return (
    <div className="space-y-2">
      <Button
        variant="outline"
        type="button"
        disabled={isLoading}
        onClick={handleGoogleSignIn}
        className="w-full"
      >
        <svg className="mr-2 h-4 w-4" viewBox="0 0 24 24">
          <path
            d="M22.56 12.25c0-.78-.07-1.53-.2-2.25H12v4.26h5.92c-.26 1.37-1.04 2.53-2.21 3.31v2.77h3.57c2.08-1.92 3.28-4.74 3.28-8.09z"
            fill="#4285F4"
          />
          <path
            d="M12 23c2.97 0 5.46-.98 7.28-2.66l-3.57-2.77c-.98.66-2.23 1.06-3.71 1.06-2.86 0-5.29-1.93-6.16-4.53H2.18v2.84C3.99 20.53 7.7 23 12 23z"
            fill="#34A853"
          />
          <path
            d="M5.84 14.09c-.22-.66-.35-1.36-.35-2.09s.13-1.43.35-2.09V7.07H2.18C1.43 8.55 1 10.22 1 12s.43 3.45 1.18 4.93l2.85-2.22.81-.62z"
            fill="#FBBC05"
          />
          <path
            d="M12 5.38c1.62 0 3.06.56 4.21 1.64l3.15-3.15C17.45 2.09 14.97 1 12 1 7.7 1 3.99 3.47 2.18 7.07l3.66 2.84c.87-2.6 3.3-4.53 6.16-4.53z"
            fill="#EA4335"
          />
        </svg>
        {isLoading ? "Signing in..." : "Continue with Google"}
      </Button>
    </div>
  )
}
</file>

<file path="components/auth/profile-menu.tsx">
"use client"

import { useState, useEffect } from "react"
import { Avatar, AvatarFallback, AvatarImage } from "@/components/ui/avatar"
import { Button } from "@/components/ui/button"
import {
  DropdownMenu,
  DropdownMenuContent,
  DropdownMenuItem,
  DropdownMenuLabel,
  DropdownMenuSeparator,
  DropdownMenuTrigger,
} from "@/components/ui/dropdown-menu"
import { AuthService } from "@/lib/auth"
import { useToast } from "@/hooks/use-toast"
import type { User } from "phonoglyph-types"
import { debugLog } from '@/lib/utils';

interface ProfileMenuProps {
  user: User
}

export function ProfileMenu({ user }: ProfileMenuProps) {
  const { toast } = useToast()
  const [isLoading, setIsLoading] = useState(false)

  const handleSignOut = async () => {
    try {
      setIsLoading(true)
      await AuthService.signOut()
      
      toast({
        title: "Signed out",
        description: "You have been signed out successfully.",
      })
      
      // Redirect to home page
      window.location.href = "/"
    } catch (error) {
      toast({
        title: "Error",
        description: error instanceof Error ? error.message : "Failed to sign out",
        variant: "destructive",
      })
    } finally {
      setIsLoading(false)
    }
  }

  // Get user initials for avatar fallback
  const getInitials = (name?: string, email?: string) => {
    if (name) {
      return name
        .split(" ")
        .map((n) => n[0])
        .join("")
        .toUpperCase()
        .slice(0, 2)
    }
    if (email) {
      return email[0].toUpperCase()
    }
    return "U"
  }

  return (
    <DropdownMenu>
      <DropdownMenuTrigger asChild>
        <Button variant="ghost" className="relative h-8 w-8 rounded-full">
          <Avatar className="h-8 w-8">
            <AvatarImage 
              src={user.image} 
              alt={user.name || user.email} 
            />
            <AvatarFallback>
              {getInitials(user.name, user.email)}
            </AvatarFallback>
          </Avatar>
        </Button>
      </DropdownMenuTrigger>
      
      <DropdownMenuContent className="w-56" align="end" forceMount>
        <DropdownMenuLabel className="font-normal">
          <div className="flex flex-col space-y-1">
            <p className="text-sm font-medium leading-none">
              {user.name || "User"}
            </p>
            <p className="text-xs leading-none text-muted-foreground">
              {user.email}
            </p>
          </div>
        </DropdownMenuLabel>
        
        <DropdownMenuSeparator />
        
        <DropdownMenuItem onClick={() => window.location.href = "/dashboard"}>
          Dashboard
        </DropdownMenuItem>
        
        <DropdownMenuItem onClick={() => window.location.href = "/profile"}>
          Profile Settings
        </DropdownMenuItem>
        
        <DropdownMenuSeparator />
        
        <DropdownMenuItem 
          onClick={handleSignOut}
          disabled={isLoading}
          className="text-red-600 focus:text-red-600"
        >
          {isLoading ? "Signing out..." : "Sign out"}
        </DropdownMenuItem>
      </DropdownMenuContent>
    </DropdownMenu>
  )
}

// Simple user display component for loading state
export function UserDisplay() {
  const [user, setUser] = useState<User | null>(null)
  const [isLoading, setIsLoading] = useState(true)

  useEffect(() => {
    const loadUser = async () => {
      try {
        const currentUser = await AuthService.getCurrentUser()
        setUser(currentUser)
      } catch (error) {
        debugLog.error("Failed to load user:", error)
      } finally {
        setIsLoading(false)
      }
    }

    loadUser()
  }, [])

  if (isLoading) {
    return (
      <div className="h-8 w-8 rounded-full bg-muted animate-pulse" />
    )
  }

  if (!user) {
    return (
      <div className="flex items-center space-x-2">
        <Button variant="ghost" size="sm" onClick={() => window.location.href = "/auth/login"}>
          Sign in
        </Button>
        <Button size="sm" onClick={() => window.location.href = "/auth/signup"}>
          Sign up
        </Button>
      </div>
    )
  }

  return <ProfileMenu user={user} />
}
</file>

<file path="components/auth/signup-form.tsx">
"use client"

import { useState } from "react"
import { useForm } from "react-hook-form"
import { zodResolver } from "@hookform/resolvers/zod"
import Link from "next/link"
import { Button } from "@/components/ui/button"
import { Input } from "@/components/ui/input"
import { Label } from "@/components/ui/label"
import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from "@/components/ui/card"
import { Separator } from "@/components/ui/separator"
import { AuthService } from "@/lib/auth"
import { signupSchema, type SignupInput } from "@/lib/validations"
import { useToast } from "@/hooks/use-toast"
import { OAuthButtons } from "./oauth-buttons"

interface SignupFormProps {
  redirectTo?: string
}

export function SignupForm({ redirectTo = "/dashboard" }: SignupFormProps) {
  const [isLoading, setIsLoading] = useState(false)
  const [isSuccess, setIsSuccess] = useState(false)
  const { toast } = useToast()

  const {
    register,
    handleSubmit,
    formState: { errors },
    watch,
  } = useForm<SignupInput>({
    resolver: zodResolver(signupSchema),
  })

  const email = watch("email")

  const onSubmit = async (data: SignupInput) => {
    try {
      setIsLoading(true)
      await AuthService.signUpWithEmail({
        email: data.email,
        password: data.password,
        name: data.name,
      })
      
      setIsSuccess(true)
      toast({
        title: "Account created!",
        description: "Please check your email to verify your account.",
      })
    } catch (error) {
      toast({
        title: "Registration Error",
        description: error instanceof Error ? error.message : "Failed to create account",
        variant: "destructive",
      })
    } finally {
      setIsLoading(false)
    }
  }

  if (isSuccess) {
    return (
      <Card className="w-full max-w-md mx-auto">
        <CardHeader>
          <CardTitle>Check your email</CardTitle>
          <CardDescription>
            We've sent a verification link to {email}
          </CardDescription>
        </CardHeader>
        <CardContent className="space-y-4">
          <div className="text-center space-y-2">
            <div className="mx-auto w-12 h-12 bg-green-100 rounded-full flex items-center justify-center">
              <svg
                className="w-6 h-6 text-green-600"
                fill="none"
                stroke="currentColor"
                viewBox="0 0 24 24"
              >
                <path
                  strokeLinecap="round"
                  strokeLinejoin="round"
                  strokeWidth={2}
                  d="M5 13l4 4L19 7"
                />
              </svg>
            </div>
            <p className="text-sm text-muted-foreground">
              Click the link in the email to verify your account and complete registration.
            </p>
          </div>
          <Button
            variant="outline"
            className="w-full"
            onClick={() => setIsSuccess(false)}
          >
            Back to signup
          </Button>
        </CardContent>
      </Card>
    )
  }

  return (
    <Card className="w-full max-w-md mx-auto">
      <CardHeader>
        <CardTitle>Create Account</CardTitle>
        <CardDescription>
          Enter your information to create a new account
        </CardDescription>
      </CardHeader>
      
      <CardContent className="space-y-6">
        <OAuthButtons redirectTo={redirectTo} />
        
        <div className="relative">
          <div className="absolute inset-0 flex items-center">
            <Separator className="w-full" />
          </div>
          <div className="relative flex justify-center text-xs uppercase">
            <span className="bg-background px-2 text-muted-foreground">
              Or continue with
            </span>
          </div>
        </div>

        <form onSubmit={handleSubmit(onSubmit)} className="space-y-4">
          <div className="space-y-2">
            <Label htmlFor="name">Name (optional)</Label>
            <Input
              id="name"
              type="text"
              placeholder="Your name"
              {...register("name")}
              disabled={isLoading}
            />
            {errors.name && (
              <p className="text-sm text-destructive">{errors.name.message}</p>
            )}
          </div>

          <div className="space-y-2">
            <Label htmlFor="email">Email</Label>
            <Input
              id="email"
              type="email"
              placeholder="name@example.com"
              {...register("email")}
              disabled={isLoading}
            />
            {errors.email && (
              <p className="text-sm text-destructive">{errors.email.message}</p>
            )}
          </div>

          <div className="space-y-2">
            <Label htmlFor="password">Password</Label>
            <Input
              id="password"
              type="password"
              {...register("password")}
              disabled={isLoading}
            />
            {errors.password && (
              <p className="text-sm text-destructive">{errors.password.message}</p>
            )}
          </div>

          <div className="space-y-2">
            <Label htmlFor="confirmPassword">Confirm Password</Label>
            <Input
              id="confirmPassword"
              type="password"
              {...register("confirmPassword")}
              disabled={isLoading}
            />
            {errors.confirmPassword && (
              <p className="text-sm text-destructive">{errors.confirmPassword.message}</p>
            )}
          </div>

          <Button type="submit" className="w-full" disabled={isLoading}>
            {isLoading ? "Creating account..." : "Create Account"}
          </Button>
        </form>
      </CardContent>

      <CardFooter className="flex justify-center">
        <p className="text-sm text-muted-foreground">
          Already have an account?{" "}
          <Link href="/auth/login" className="text-primary hover:underline">
            Sign in
          </Link>
        </p>
      </CardFooter>
    </Card>
  )
}
</file>

<file path="components/auto-save/auto-save-indicator.tsx">
"use client"

import { useState, useEffect } from 'react'
import { CheckCircle, Clock, AlertCircle, Save } from 'lucide-react'
import { cn } from '@/lib/utils'

export interface AutoSaveIndicatorProps {
  isSaving: boolean
  lastSaved: Date | null
  error?: string | null
  className?: string
}

export function AutoSaveIndicator({ 
  isSaving, 
  lastSaved, 
  error, 
  className 
}: AutoSaveIndicatorProps) {
  const [showSaved, setShowSaved] = useState(false)

  // Show "Saved" message briefly when save completes
  useEffect(() => {
    if (lastSaved && !isSaving) {
      setShowSaved(true)
      const timer = setTimeout(() => setShowSaved(false), 2000)
      return () => clearTimeout(timer)
    }
  }, [lastSaved, isSaving])

  const getStatusIcon = () => {
    if (error) {
      return <AlertCircle className="h-4 w-4 text-red-500" />
    }
    if (isSaving) {
      return <Clock className="h-4 w-4 text-yellow-500 animate-pulse" />
    }
    if (showSaved) {
      return <CheckCircle className="h-4 w-4 text-green-500" />
    }
    return <Save className="h-4 w-4 text-gray-400" />
  }

  const getStatusText = () => {
    if (error) {
      return 'Save failed'
    }
    if (isSaving) {
      return 'Saving...'
    }
    if (showSaved) {
      return 'Saved'
    }
    if (lastSaved) {
      return `Last saved ${formatTimeAgo(lastSaved)}`
    }
    return 'Not saved'
  }

  return (
    <div className={cn(
      "flex items-center gap-2 text-sm text-gray-600",
      className
    )}>
      {getStatusIcon()}
      <span className="font-medium">{getStatusText()}</span>
      {error && (
        <span className="text-xs text-red-500 ml-2">
          {error}
        </span>
      )}
    </div>
  )
}

// Helper function to format time ago
function formatTimeAgo(date: Date): string {
  const now = new Date()
  const diffInSeconds = Math.floor((now.getTime() - date.getTime()) / 1000)

  if (diffInSeconds < 60) {
    return 'just now'
  } else if (diffInSeconds < 3600) {
    const minutes = Math.floor(diffInSeconds / 60)
    return `${minutes}m ago`
  } else if (diffInSeconds < 86400) {
    const hours = Math.floor(diffInSeconds / 3600)
    return `${hours}h ago`
  } else {
    const days = Math.floor(diffInSeconds / 86400)
    return `${days}d ago`
  }
}
</file>

<file path="components/auto-save/auto-save-provider.tsx">
"use client"

import React, { createContext, useContext, useEffect, useCallback, useRef } from 'react'
import { useAutoSave } from '@/hooks/use-auto-save'
import { AutoSaveIndicator } from './auto-save-indicator'
import { SaveHistory } from './save-history'
import { AutoSaveSettings } from './auto-save-settings'
import { Button } from '@/components/ui/button'
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card'
import { Badge } from '@/components/ui/badge'
import { Settings, History, Save } from 'lucide-react'
import { cn, debugLog } from '@/lib/utils'

interface AutoSaveContextType {
  saveCurrentState: () => Promise<void>
  restoreState: (stateId: string) => Promise<void>
  getCurrentState: () => Promise<any>
  isSaving: boolean
  lastSaved: Date | null
  config: any
  updateConfig: (config: any) => void
}

const AutoSaveContext = createContext<AutoSaveContextType | null>(null)

export function useAutoSaveContext() {
  const context = useContext(AutoSaveContext)
  if (!context) {
    throw new Error('useAutoSaveContext must be used within AutoSaveProvider')
  }
  return context
}

interface AutoSaveProviderProps {
  projectId: string
  children: React.ReactNode
  className?: string
}

export function AutoSaveProvider({ projectId, children, className }: AutoSaveProviderProps) {
  const [showSettings, setShowSettings] = React.useState(false)
  const [showHistory, setShowHistory] = React.useState(false)
  const [error, setError] = React.useState<string | null>(null)
  
  const autoSave = useAutoSave(projectId)
  const stateRef = useRef<any>(null)

  // Function to capture current visualization state
  const captureCurrentState = useCallback(() => {
    // This function should be implemented to capture the current state
    // from the visualization components. For now, we'll use a placeholder
    const currentState = {
      visualizationParams: {
        // Capture visualization parameters
        effects: [], // Will be populated by child components
        settings: {}, // Will be populated by child components
      },
      stemMappings: {
        // Capture stem mappings
        mappings: [], // Will be populated by child components
      },
      effectSettings: {
        // Capture effect settings
        effects: {}, // Will be populated by child components
      },
      timelineState: {
        // Capture timeline state
        currentTime: 0,
        duration: 0,
        isPlaying: false,
      }
    }

    return currentState
  }, [])

  // Save current state
  const saveCurrentState = useCallback(async () => {
    try {
      setError(null)
      const stateData = captureCurrentState()
      await autoSave.saveState()
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to save state')
      debugLog.error('Auto-save error:', err)
    }
  }, [autoSave, captureCurrentState])

  // Restore state
  const handleRestoreState = useCallback(async (stateId: string) => {
    try {
      setError(null)
      const restoredState = await autoSave.restoreState(stateId)
      
      // Apply the restored state to the visualization
      // This will be implemented to restore the state to child components
      debugLog.log('Restored state:', restoredState)
      
      // Trigger a re-render or state update in child components
      // This is a placeholder - actual implementation will depend on the child components
      
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to restore state')
      debugLog.error('Restore error:', err)
    }
  }, [autoSave])

  // Delete state
  const handleDeleteState = useCallback(async (stateId: string) => {
    try {
      setError(null)
      // Note: The delete functionality is not implemented in the hook yet
      // This is a placeholder for future implementation
      debugLog.log('Delete state:', stateId)
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to delete state')
      debugLog.error('Delete error:', err)
    }
  }, [])

  // Clear history
  const handleClearHistory = useCallback(async () => {
    try {
      setError(null)
      await autoSave.clearHistory()
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to clear history')
      debugLog.error('Clear history error:', err)
    }
  }, [autoSave])

  // Auto-save on state changes
  useEffect(() => {
    const interval = setInterval(() => {
      if (autoSave.config.enabled && stateRef.current) {
        saveCurrentState()
      }
    }, autoSave.config.interval)

    return () => clearInterval(interval)
  }, [autoSave.config.enabled, autoSave.config.interval, saveCurrentState])

  // Load saved state on mount
  useEffect(() => {
    const loadSavedState = async () => {
      try {
        const savedState = await autoSave.getCurrentState()
        if (savedState) {
          // Apply the saved state to the visualization
          // This will be implemented to restore the state to child components
          debugLog.log('Loaded saved state:', savedState)
        }
      } catch (err) {
        debugLog.error('Failed to load saved state:', err)
      }
    }

    loadSavedState()
  }, [autoSave])

  const contextValue: AutoSaveContextType = {
    saveCurrentState,
    restoreState: handleRestoreState,
    getCurrentState: autoSave.getCurrentState,
    isSaving: autoSave.isSaving,
    lastSaved: autoSave.lastSaved,
    config: autoSave.config,
    updateConfig: autoSave.updateConfig,
  }

  return (
    <AutoSaveContext.Provider value={contextValue}>
      <div className={cn("relative", className)}>
        {/* Auto-save controls */}
        <div className="absolute top-4 right-4 z-50 flex items-center gap-2">
          <AutoSaveIndicator
            isSaving={autoSave.isSaving}
            lastSaved={autoSave.lastSaved}
            error={error}
            className="bg-white/90 backdrop-blur-sm px-3 py-2 rounded-lg shadow-lg"
          />
          
          <div className="flex items-center gap-1">
            <Button
              variant="outline"
              size="sm"
              onClick={() => setShowHistory(!showHistory)}
              className="bg-white/90 backdrop-blur-sm"
            >
              <History className="h-4 w-4" />
            </Button>
            
            <Button
              variant="outline"
              size="sm"
              onClick={() => setShowSettings(!showSettings)}
              className="bg-white/90 backdrop-blur-sm"
            >
              <Settings className="h-4 w-4" />
            </Button>
            
            <Button
              variant="outline"
              size="sm"
              onClick={saveCurrentState}
              disabled={autoSave.isSaving}
              className="bg-white/90 backdrop-blur-sm"
            >
              <Save className="h-4 w-4" />
            </Button>
          </div>
        </div>

        {/* Settings Panel */}
        {showSettings && (
          <div className="absolute top-16 right-4 z-50 w-80">
            <AutoSaveSettings
              config={autoSave.config}
              onConfigChange={autoSave.updateConfig}
              onSaveNow={saveCurrentState}
              isSaving={autoSave.isSaving}
            />
          </div>
        )}

        {/* History Panel */}
        {showHistory && (
          <div className="absolute top-16 right-4 z-50 w-96">
            <SaveHistory
              saveHistory={autoSave.saveHistory}
              onRestore={handleRestoreState}
              onDelete={handleDeleteState}
              onClearHistory={handleClearHistory}
              isLoading={autoSave.isSaving}
            />
          </div>
        )}

        {/* Main content */}
        <div className="w-full h-full">
          {children}
        </div>
      </div>
    </AutoSaveContext.Provider>
  )
}

// Hook for child components to register their state
export function useAutoSaveState() {
  const context = useAutoSaveContext()
  const stateRef = useRef<any>(null)

  const registerState = useCallback((state: any) => {
    stateRef.current = state
  }, [])

  const updateState = useCallback((updates: any) => {
    if (stateRef.current) {
      stateRef.current = { ...stateRef.current, ...updates }
    }
  }, [])

  return {
    registerState,
    updateState,
    saveCurrentState: context.saveCurrentState,
    isSaving: context.isSaving,
    lastSaved: context.lastSaved,
  }
}
</file>

<file path="components/auto-save/auto-save-settings.tsx">
"use client"

import { useState } from 'react'
import { Settings, Save, Clock, History, Zap } from 'lucide-react'
import { Button } from '@/components/ui/button'
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card'
import { Label } from '@/components/ui/label'
import { Switch } from '@/components/ui/switch'
import { Input } from '@/components/ui/input'
import { Slider } from '@/components/ui/slider'
import { Badge } from '@/components/ui/badge'
import { cn, debugLog } from '@/lib/utils'
import type { AutoSaveConfig } from '@/hooks/use-auto-save'

export interface AutoSaveSettingsProps {
  config: AutoSaveConfig
  onConfigChange: (config: Partial<AutoSaveConfig>) => void
  onSaveNow: () => Promise<void>
  isSaving?: boolean
  className?: string
}

export function AutoSaveSettings({
  config,
  onConfigChange,
  onSaveNow,
  isSaving = false,
  className
}: AutoSaveSettingsProps) {
  const [isExpanded, setIsExpanded] = useState(false)

  const handleSaveNow = async () => {
    try {
      await onSaveNow()
    } catch (error) {
      debugLog.error('Failed to save now:', error)
    }
  }

  const formatInterval = (ms: number) => {
    if (ms < 1000) return `${ms}ms`
    if (ms < 60000) return `${ms / 1000}s`
    return `${ms / 60000}m`
  }

  const formatDebounce = (ms: number) => {
    if (ms < 1000) return `${ms}ms`
    return `${ms / 1000}s`
  }

  return (
    <Card className={cn("w-full", className)}>
      <CardHeader>
        <div className="flex items-center justify-between">
          <CardTitle className="flex items-center gap-2">
            <Settings className="h-5 w-5" />
            Auto-Save Settings
          </CardTitle>
          <Button
            variant="outline"
            size="sm"
            onClick={() => setIsExpanded(!isExpanded)}
          >
            {isExpanded ? 'Hide' : 'Show'} Details
          </Button>
        </div>
      </CardHeader>
      <CardContent className="space-y-4">
        {/* Basic Settings */}
        <div className="flex items-center justify-between">
          <div className="flex items-center gap-2">
            <Save className="h-4 w-4 text-gray-500" />
            <Label htmlFor="auto-save-enabled">Enable Auto-Save</Label>
          </div>
          <Switch
            id="auto-save-enabled"
            checked={config.enabled}
            onCheckedChange={(enabled) => onConfigChange({ enabled })}
          />
        </div>

        {/* Save Now Button */}
        <div className="flex items-center justify-between">
          <div className="flex items-center gap-2">
            <Zap className="h-4 w-4 text-gray-500" />
            <span className="text-sm">Manual Save</span>
          </div>
          <Button
            size="sm"
            onClick={handleSaveNow}
            disabled={isSaving || !config.enabled}
          >
            {isSaving ? 'Saving...' : 'Save Now'}
          </Button>
        </div>

        {/* Current Settings Summary */}
        <div className="flex flex-wrap gap-2">
          <Badge variant="outline" className="text-xs">
            <Clock className="h-3 w-3 mr-1" />
            {formatInterval(config.interval)}
          </Badge>
          <Badge variant="outline" className="text-xs">
            <History className="h-3 w-3 mr-1" />
            {config.maxHistory} states
          </Badge>
          <Badge variant="outline" className="text-xs">
            Debounce: {formatDebounce(config.debounceTime)}
          </Badge>
        </div>

        {/* Advanced Settings */}
        {isExpanded && (
          <div className="space-y-4 pt-4 border-t">
            <div className="space-y-2">
              <Label className="flex items-center gap-2">
                <Clock className="h-4 w-4" />
                Auto-Save Interval
              </Label>
              <div className="space-y-2">
                <Slider
                  value={[config.interval]}
                  onValueChange={([value]) => onConfigChange({ interval: value })}
                  min={1000}
                  max={30000}
                  step={1000}
                  className="w-full"
                />
                <div className="flex justify-between text-xs text-gray-500">
                  <span>1s</span>
                  <span>{formatInterval(config.interval)}</span>
                  <span>30s</span>
                </div>
              </div>
            </div>

            <div className="space-y-2">
              <Label className="flex items-center gap-2">
                <History className="h-4 w-4" />
                Max History States
              </Label>
              <div className="space-y-2">
                <Slider
                  value={[config.maxHistory]}
                  onValueChange={([value]) => onConfigChange({ maxHistory: value })}
                  min={5}
                  max={50}
                  step={5}
                  className="w-full"
                />
                <div className="flex justify-between text-xs text-gray-500">
                  <span>5</span>
                  <span>{config.maxHistory}</span>
                  <span>50</span>
                </div>
              </div>
            </div>

            <div className="space-y-2">
              <Label className="flex items-center gap-2">
                <Zap className="h-4 w-4" />
                Debounce Time
              </Label>
              <div className="space-y-2">
                <Slider
                  value={[config.debounceTime]}
                  onValueChange={([value]) => onConfigChange({ debounceTime: value })}
                  min={100}
                  max={5000}
                  step={100}
                  className="w-full"
                />
                <div className="flex justify-between text-xs text-gray-500">
                  <span>100ms</span>
                  <span>{formatDebounce(config.debounceTime)}</span>
                  <span>5s</span>
                </div>
              </div>
            </div>

            {/* Preset Configurations */}
            <div className="space-y-2">
              <Label>Quick Presets</Label>
              <div className="flex gap-2">
                <Button
                  variant="outline"
                  size="sm"
                  onClick={() => onConfigChange({
                    interval: 3000,
                    debounceTime: 500,
                    maxHistory: 10
                  })}
                >
                  Frequent
                </Button>
                <Button
                  variant="outline"
                  size="sm"
                  onClick={() => onConfigChange({
                    interval: 10000,
                    debounceTime: 1000,
                    maxHistory: 15
                  })}
                >
                  Balanced
                </Button>
                <Button
                  variant="outline"
                  size="sm"
                  onClick={() => onConfigChange({
                    interval: 30000,
                    debounceTime: 2000,
                    maxHistory: 20
                  })}
                >
                  Conservative
                </Button>
              </div>
            </div>
          </div>
        )}
      </CardContent>
    </Card>
  )
}
</file>

<file path="components/auto-save/creative-visualizer-with-auto-save.tsx">
"use client"

import React from 'react'
import { AutoSaveProvider } from './auto-save-provider'

interface CreativeVisualizerWithAutoSaveProps {
  projectId: string
  children: React.ReactNode
}

export function CreativeVisualizerWithAutoSave({ 
  projectId, 
  children 
}: CreativeVisualizerWithAutoSaveProps) {
  return (
    <AutoSaveProvider projectId={projectId}>
      {children}
    </AutoSaveProvider>
  )
}
</file>

<file path="components/auto-save/index.ts">
export { AutoSaveIndicator } from './auto-save-indicator'
export { SaveHistory } from './save-history'
export { AutoSaveSettings } from './auto-save-settings'
export { AutoSaveProvider, useAutoSaveContext, useAutoSaveState } from './auto-save-provider'

export type { AutoSaveIndicatorProps } from './auto-save-indicator'
export type { SaveHistoryProps } from './save-history'
export type { AutoSaveSettingsProps } from './auto-save-settings'
</file>

<file path="components/auto-save/save-history.tsx">
"use client"

import { useState } from 'react'
import { Clock, RotateCcw, Trash2, Calendar } from 'lucide-react'
import { Button } from '@/components/ui/button'
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card'
import { Badge } from '@/components/ui/badge'
import { cn, debugLog } from '@/lib/utils'
import type { EditState } from '@/hooks/use-auto-save'

export interface SaveHistoryProps {
  saveHistory: EditState[]
  onRestore: (stateId: string) => Promise<void>
  onDelete: (stateId: string) => Promise<void>
  onClearHistory: () => Promise<void>
  isLoading?: boolean
  className?: string
}

export function SaveHistory({
  saveHistory,
  onRestore,
  onDelete,
  onClearHistory,
  isLoading = false,
  className
}: SaveHistoryProps) {
  const [restoringId, setRestoringId] = useState<string | null>(null)
  const [deletingId, setDeletingId] = useState<string | null>(null)

  const handleRestore = async (stateId: string) => {
    try {
      setRestoringId(stateId)
      await onRestore(stateId)
    } catch (error) {
      debugLog.error('Failed to restore state:', error)
    } finally {
      setRestoringId(null)
    }
  }

  const handleDelete = async (stateId: string) => {
    try {
      setDeletingId(stateId)
      await onDelete(stateId)
    } catch (error) {
      debugLog.error('Failed to delete state:', error)
    } finally {
      setDeletingId(null)
    }
  }

  const formatTimestamp = (date: Date) => {
    return new Intl.DateTimeFormat('en-US', {
      month: 'short',
      day: 'numeric',
      hour: '2-digit',
      minute: '2-digit',
      hour12: true
    }).format(date)
  }

  const getStateSize = (data: any) => {
    const size = JSON.stringify(data).length
    if (size < 1024) return `${size} B`
    if (size < 1024 * 1024) return `${(size / 1024).toFixed(1)} KB`
    return `${(size / (1024 * 1024)).toFixed(1)} MB`
  }

  if (saveHistory.length === 0) {
    return (
      <Card className={cn("w-full", className)}>
        <CardHeader>
          <CardTitle className="flex items-center gap-2">
            <Clock className="h-5 w-5" />
            Save History
          </CardTitle>
        </CardHeader>
        <CardContent>
          <div className="text-center py-8 text-gray-500">
            <Clock className="h-12 w-12 mx-auto mb-4 text-gray-300" />
            <p>No saved states yet</p>
            <p className="text-sm">Your changes will be automatically saved as you work</p>
          </div>
        </CardContent>
      </Card>
    )
  }

  return (
    <Card className={cn("w-full", className)}>
      <CardHeader>
        <div className="flex items-center justify-between">
          <CardTitle className="flex items-center gap-2">
            <Clock className="h-5 w-5" />
            Save History
            <Badge variant="secondary">{saveHistory.length}</Badge>
          </CardTitle>
          <Button
            variant="outline"
            size="sm"
            onClick={onClearHistory}
            disabled={isLoading}
          >
            <Trash2 className="h-4 w-4 mr-2" />
            Clear All
          </Button>
        </div>
      </CardHeader>
      <CardContent>
        <div className="space-y-3 max-h-96 overflow-y-auto">
          {saveHistory.map((state) => (
            <div
              key={state.id}
              className={cn(
                "flex items-center justify-between p-3 rounded-lg border",
                state.isCurrent 
                  ? "bg-blue-50 border-blue-200" 
                  : "bg-gray-50 border-gray-200"
              )}
            >
              <div className="flex items-center gap-3 flex-1 min-w-0">
                <div className="flex-shrink-0">
                  <Calendar className="h-4 w-4 text-gray-400" />
                </div>
                <div className="flex-1 min-w-0">
                  <div className="flex items-center gap-2">
                    <p className="text-sm font-medium truncate">
                      {formatTimestamp(state.timestamp)}
                    </p>
                    {state.isCurrent && (
                      <Badge variant="default" className="text-xs">
                        Current
                      </Badge>
                    )}
                    <Badge variant="outline" className="text-xs">
                      v{state.version}
                    </Badge>
                  </div>
                  <p className="text-xs text-gray-500">
                    Size: {getStateSize(state.data)}
                  </p>
                </div>
              </div>
              
              <div className="flex items-center gap-2 flex-shrink-0">
                {!state.isCurrent && (
                  <Button
                    variant="ghost"
                    size="sm"
                    onClick={() => handleRestore(state.id)}
                    disabled={isLoading || restoringId === state.id}
                    className="h-8 w-8 p-0"
                  >
                    <RotateCcw className={cn(
                      "h-4 w-4",
                      restoringId === state.id && "animate-spin"
                    )} />
                  </Button>
                )}
                <Button
                  variant="ghost"
                  size="sm"
                  onClick={() => handleDelete(state.id)}
                  disabled={isLoading || deletingId === state.id}
                  className="h-8 w-8 p-0 text-red-500 hover:text-red-700"
                >
                  <Trash2 className={cn(
                    "h-4 w-4",
                    deletingId === state.id && "animate-spin"
                  )} />
                </Button>
              </div>
            </div>
          ))}
        </div>
      </CardContent>
    </Card>
  )
}
</file>

<file path="components/guest/conversion-prompt.tsx">
"use client"

import { useState } from 'react'
import { X, Star, Shield, Cloud, Zap } from 'lucide-react'
import { Button } from '@/components/ui/button'
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card'
import { useAuth } from '@/hooks/use-auth'
import { useRouter } from 'next/navigation'

interface ConversionPromptProps {
  trigger?: 'project_save' | 'time_based' | 'feature_limit' | 'manual'
  title?: string
  description?: string
  benefits?: string[]
  onDismiss?: () => void
  compact?: boolean
}

export function ConversionPrompt({
  trigger = 'manual',
  title,
  description,
  benefits,
  onDismiss,
  compact = false
}: ConversionPromptProps) {
  const [isVisible, setIsVisible] = useState(true)
  const { isGuest } = useAuth()
  const router = useRouter()

  // Don't show if user is authenticated
  if (!isGuest || !isVisible) {
    return null
  }

  const handleDismiss = () => {
    setIsVisible(false)
    onDismiss?.()
  }

  const handleSignUp = () => {
    router.push('/auth/signup?source=conversion_prompt')
  }

  const handleSignIn = () => {
    router.push('/auth/login?source=conversion_prompt')
  }

  // Default content based on trigger
  const getDefaultContent = () => {
    switch (trigger) {
      case 'project_save':
        return {
          title: 'Save Your Work Forever! ',
          description: 'Your project is only saved locally. Create an account to save it to the cloud and access it from anywhere.',
          benefits: ['Unlimited projects', 'Cloud storage', 'Never lose your work']
        }
      case 'time_based':
        return {
          title: 'Unlock Full Features! ',
          description: "You've been exploring for a while! Sign up to unlock unlimited access and premium features.",
          benefits: ['No limitations', 'Advanced tools', 'Priority support']
        }
      case 'feature_limit':
        return {
          title: 'Upgrade to Continue ',
          description: "You've reached the guest limit for this feature. Sign up to continue with unlimited access.",
          benefits: ['Remove all limits', 'Premium features', 'Enhanced experience']
        }
      default:
        return {
          title: 'Join the Community! ',
          description: 'Create an account to unlock all features and save your work permanently.',
          benefits: ['Unlimited projects', 'Cloud sync', 'Premium features']
        }
    }
  }

  const defaultContent = getDefaultContent()
  const finalTitle = title || defaultContent.title
  const finalDescription = description || defaultContent.description
  const finalBenefits = benefits || defaultContent.benefits

  if (compact) {
    return (
      <div className="bg-gradient-to-r from-indigo-500 to-purple-600 text-white p-4 rounded-lg mb-4">
        <div className="flex items-center justify-between">
          <div className="flex-1">
            <h3 className="font-semibold text-sm">{finalTitle}</h3>
            <p className="text-xs opacity-90 mt-1">{finalDescription}</p>
          </div>
          <div className="flex items-center space-x-2 ml-4">
            <Button 
              size="sm" 
              variant="secondary"
              onClick={handleSignUp}
              className="bg-white text-indigo-600 hover:bg-gray-100"
            >
              Sign Up
            </Button>
            <Button 
              size="sm" 
              variant="ghost" 
              onClick={handleDismiss}
              className="text-white hover:bg-white/20"
            >
              <X className="h-4 w-4" />
            </Button>
          </div>
        </div>
      </div>
    )
  }

  return (
    <Card className="border-2 border-indigo-200 bg-gradient-to-br from-indigo-50 to-purple-50">
      <CardHeader className="pb-4">
        <div className="flex items-center justify-between">
          <CardTitle className="text-xl text-indigo-900 flex items-center">
            <Star className="h-5 w-5 mr-2 text-yellow-500" />
            {finalTitle}
          </CardTitle>
          <Button 
            variant="ghost" 
            size="sm" 
            onClick={handleDismiss}
            className="text-gray-500 hover:text-gray-700"
          >
            <X className="h-4 w-4" />
          </Button>
        </div>
      </CardHeader>
      
      <CardContent className="space-y-4">
        <p className="text-gray-700">{finalDescription}</p>
        
        <div className="grid grid-cols-1 md:grid-cols-3 gap-3">
          {finalBenefits.map((benefit, index) => {
            const icons = [Shield, Cloud, Zap]
            const Icon = icons[index % icons.length]
            
            return (
              <div key={index} className="flex items-center space-x-2 text-sm text-gray-600">
                <Icon className="h-4 w-4 text-indigo-500" />
                <span>{benefit}</span>
              </div>
            )
          })}
        </div>
        
        <div className="flex space-x-3 pt-4">
          <Button onClick={handleSignUp} className="flex-1 bg-indigo-600 hover:bg-indigo-700">
            Create Account
          </Button>
          <Button variant="outline" onClick={handleSignIn} className="flex-1">
            Sign In
          </Button>
        </div>
        
        <p className="text-xs text-gray-500 text-center">
          Takes less than 30 seconds  No credit card required
        </p>
      </CardContent>
    </Card>
  )
}

// Hook for managing conversion prompt state
export function useConversionPrompt() {
  const [dismissed, setDismissed] = useState<string[]>([])
  const { isGuest, shouldShowConversionPrompt } = useAuth()

  const shouldShow = (trigger: string) => {
    return isGuest && shouldShowConversionPrompt && !dismissed.includes(trigger)
  }

  const dismiss = (trigger: string) => {
    setDismissed(prev => [...prev, trigger])
  }

  return {
    shouldShow,
    dismiss,
    isGuest,
    shouldShowConversionPrompt
  }
}
</file>

<file path="components/guest/guest-banner.tsx">
"use client"

import { User, Clock, Database, Zap } from 'lucide-react'
import { Button } from '@/components/ui/button'
import { Card, CardContent } from '@/components/ui/card'
import { Badge } from '@/components/ui/badge'
import { useAuth } from '@/hooks/use-auth'
import { useRouter } from 'next/navigation'

interface GuestBannerProps {
  showLimitations?: boolean
  compact?: boolean
}

export function GuestBanner({ showLimitations = true, compact = false }: GuestBannerProps) {
  const { isGuest, user } = useAuth()
  const router = useRouter()

  // Only show for guest users
  if (!isGuest || !user) {
    return null
  }

  const handleUpgrade = () => {
    router.push('/auth/signup?source=guest_banner')
  }

  if (compact) {
    return (
      <div className="bg-amber-50 border border-amber-200 rounded-lg p-3 mb-4">
        <div className="flex items-center justify-between">
          <div className="flex items-center space-x-2">
            <User className="h-4 w-4 text-amber-600" />
            <span className="text-sm font-medium text-amber-800">Guest Mode</span>
            <Badge variant="secondary" className="text-xs">
              Limited Access
            </Badge>
          </div>
          <Button size="sm" onClick={handleUpgrade} className="bg-amber-600 hover:bg-amber-700">
            Upgrade
          </Button>
        </div>
      </div>
    )
  }

  return (
    <Card className="border-amber-200 bg-gradient-to-r from-amber-50 to-orange-50 mb-6">
      <CardContent className="p-6">
        <div className="flex items-start justify-between">
          <div className="flex-1">
            <div className="flex items-center space-x-2 mb-3">
              <User className="h-5 w-5 text-amber-600" />
              <h3 className="text-lg font-semibold text-amber-900">Guest Mode Active</h3>
              <Badge variant="secondary" className="bg-amber-100 text-amber-800">
                Temporary Session
              </Badge>
            </div>
            
            <p className="text-amber-800 mb-4">
              You're using the app as a guest. Your data is stored locally and will be lost when you clear your browser data.
            </p>

            {showLimitations && (
              <div className="grid grid-cols-1 md:grid-cols-3 gap-4 mb-4">
                <div className="flex items-center space-x-2 text-sm text-amber-700">
                  <Database className="h-4 w-4" />
                  <span>Max 3 projects</span>
                </div>
                <div className="flex items-center space-x-2 text-sm text-amber-700">
                  <Clock className="h-4 w-4" />
                  <span>7 days storage</span>
                </div>
                <div className="flex items-center space-x-2 text-sm text-amber-700">
                  <Zap className="h-4 w-4" />
                  <span>Basic features only</span>
                </div>
              </div>
            )}

            <div className="flex space-x-3">
              <Button onClick={handleUpgrade} className="bg-amber-600 hover:bg-amber-700">
                Create Free Account
              </Button>
              <Button 
                variant="outline" 
                onClick={() => router.push('/auth/login')}
                className="border-amber-300 text-amber-700 hover:bg-amber-100"
              >
                Sign In
              </Button>
            </div>
          </div>
        </div>
        
        <div className="mt-4 pt-4 border-t border-amber-200">
          <p className="text-xs text-amber-600">
             <strong>Why create an account?</strong> Save your work permanently, access it from any device, 
            and unlock advanced features like premium visualizations and unlimited projects.
          </p>
        </div>
      </CardContent>
    </Card>
  )
}

// Simple guest status indicator
export function GuestStatusIndicator() {
  const { isGuest } = useAuth()

  if (!isGuest) {
    return null
  }

  return (
    <div className="flex items-center space-x-1 text-xs text-amber-600 bg-amber-50 px-2 py-1 rounded-full">
      <User className="h-3 w-3" />
      <span>Guest</span>
    </div>
  )
}
</file>

<file path="components/hud/HudOverlay.tsx">
import React, { useRef, useEffect, useState, useCallback } from 'react';
import { debugLog } from '@/lib/utils';

function drawWaveform(ctx: CanvasRenderingContext2D, w: number, h: number) {
  ctx.strokeStyle = '#00ffff';
  ctx.lineWidth = 2;
  ctx.beginPath();
  for (let i = 0; i < w; i++) {
    const y = h / 2 + Math.sin(i / 20) * (h / 4);
    if (i === 0) ctx.moveTo(i, y);
    else ctx.lineTo(i, y);
  }
  ctx.stroke();
}
function drawSpectrogram(ctx: CanvasRenderingContext2D, w: number, h: number) {
  for (let x = 0; x < w; x += 2) {
    for (let y = 0; y < h; y += 2) {
      ctx.fillStyle = `hsl(${(x + y) % 360}, 80%, ${40 + 30 * Math.sin(x / 30)}%)`;
      ctx.fillRect(x, y, 2, 2);
    }
  }
}
function drawPeakMeter(ctx: CanvasRenderingContext2D, w: number, h: number) {
  ctx.fillStyle = '#0f0';
  ctx.fillRect(0, h * 0.7, w, h * 0.2);
  ctx.fillStyle = '#ff0';
  ctx.fillRect(0, h * 0.5, w, h * 0.2);
  ctx.fillStyle = '#f00';
  ctx.fillRect(0, h * 0.3, w, h * 0.2);
}
function drawStereometer(ctx: CanvasRenderingContext2D, w: number, h: number) {
  ctx.strokeStyle = '#ff00ff';
  ctx.beginPath();
  for (let i = 0; i < 360; i += 2) {
    const angle = (i * Math.PI) / 180;
    const r = h / 2 * (0.7 + 0.3 * Math.sin(i / 30));
    const x = w / 2 + r * Math.cos(angle);
    const y = h / 2 + r * Math.sin(angle);
    if (i === 0) ctx.moveTo(x, y);
    else ctx.lineTo(x, y);
  }
  ctx.closePath();
  ctx.stroke();
}
function drawOscilloscope(ctx: CanvasRenderingContext2D, w: number, h: number, settings: any = {}) {
  const { 
    color = '#00ffff', 
    glowIntensity = 0, 
    showGrid = false, 
    gridColor = '#333333',
    amplitude = 1,
    traceWidth = 2,
    cornerRadius = 0
  } = settings;
  // Draw background grid if enabled
  if (showGrid) {
    ctx.save();
    
    // Apply corner radius clipping if set
    if (cornerRadius > 0) {
      ctx.beginPath();
      ctx.roundRect(0, 0, w, h, cornerRadius);
      ctx.clip();
    }
    
    ctx.strokeStyle = gridColor;
    ctx.lineWidth = 0.5;
    // Vertical grid lines
    for (let x = 0; x <= w; x += w / 10) {
      ctx.beginPath();
      ctx.moveTo(x, 0);
      ctx.lineTo(x, h);
      ctx.stroke();
    }
    // Horizontal grid lines
    for (let y = 0; y <= h; y += h / 8) {
      ctx.beginPath();
      ctx.moveTo(0, y);
      ctx.lineTo(w, y);
      ctx.stroke();
    }
    // Center crosshair
    ctx.strokeStyle = gridColor;
    ctx.lineWidth = 1;
    ctx.beginPath();
    ctx.moveTo(w / 2, 0);
    ctx.lineTo(w / 2, h);
    ctx.moveTo(0, h / 2);
    ctx.lineTo(w, h / 2);
    ctx.stroke();
    ctx.restore();
  }
  // Draw soft glow effect if enabled
  if (glowIntensity > 0) {
    ctx.save();
    const glowIntensityValue = glowIntensity * 0.15;
    const step = Math.max(1, Math.floor(w / 100));
    for (let i = 0; i < w; i += step) {
      // Bipolar: center at height/2, scale amplitude both ways
      const y = h / 2 + Math.sin(i / 10) * (h / 3) * Math.sin(i / 60) * amplitude;
      const gradient = ctx.createRadialGradient(i, y, 0, i, y, glowIntensity * 2.5);
      const rgbaColor = color.startsWith('#') 
        ? `rgba(${parseInt(color.slice(1, 3), 16)}, ${parseInt(color.slice(3, 5), 16)}, ${parseInt(color.slice(5, 7), 16)}, ${glowIntensityValue})`
        : color;
      gradient.addColorStop(0, rgbaColor);
      gradient.addColorStop(1, 'transparent');
      ctx.fillStyle = gradient;
      ctx.beginPath();
      ctx.arc(i, y, glowIntensity * 2.5, 0, Math.PI * 2);
      ctx.fill();
    }
    ctx.restore();
  }
  // Draw main oscilloscope trace (bipolar)
  ctx.strokeStyle = color;
  ctx.lineWidth = traceWidth;
  ctx.beginPath();
  for (let i = 0; i < w; i++) {
    // Bipolar: center at height/2, scale amplitude both ways
    const y = h / 2 + Math.sin(i / 10) * (h / 3) * Math.sin(i / 60) * amplitude;
    if (i === 0) ctx.moveTo(i, y);
    else ctx.lineTo(i, y);
  }
  ctx.stroke();
}
function drawSpectrumAnalyzer(ctx: CanvasRenderingContext2D, w: number, h: number) {
  for (let i = 0; i < w; i += 8) {
    const barHeight = h * (0.2 + 0.7 * Math.abs(Math.sin(i / 40)));
    ctx.fillStyle = `hsl(${180 + i % 120}, 90%, 60%)`;
    ctx.fillRect(i, h - barHeight, 6, barHeight);
  }
}
function drawMidiMeter(ctx: CanvasRenderingContext2D, w: number, h: number) {
  ctx.fillStyle = '#fff';
  ctx.font = 'bold 18px monospace';
  ctx.fillText('MIDI', w / 2 - 30, h / 2);
  ctx.strokeStyle = '#0ff';
  ctx.strokeRect(w / 2 - 40, h / 2 - 20, 80, 40);
}

function drawVuMeter(ctx: CanvasRenderingContext2D, w: number, h: number, value: number, settings: any) {
  const color = settings.color || '#00ff55';
  const style = settings.style || 'Needle';
  ctx.save();
  ctx.clearRect(0, 0, w, h);
  if (style === 'Needle') {
    // Draw arc
    ctx.strokeStyle = '#333';
    ctx.lineWidth = 6;
    ctx.beginPath();
    ctx.arc(w/2, h*0.9, h*0.7, Math.PI, 2*Math.PI, false);
    ctx.stroke();
    // Draw needle
    const angle = Math.PI + value * Math.PI;
    ctx.strokeStyle = color;
    ctx.lineWidth = 3;
    ctx.beginPath();
    ctx.moveTo(w/2, h*0.9);
    ctx.lineTo(w/2 + Math.cos(angle)*h*0.7, h*0.9 + Math.sin(angle)*h*0.7);
    ctx.stroke();
  } else {
    // Bar style
    ctx.fillStyle = color;
    ctx.fillRect(w*0.3, h*0.1, w*0.4, h*0.8*value);
    ctx.strokeStyle = '#333';
    ctx.strokeRect(w*0.3, h*0.1, w*0.4, h*0.8);
  }
  ctx.restore();
}

function drawChromaWheel(ctx: CanvasRenderingContext2D, w: number, h: number, chroma: any, settings: any) {
  const colorSchemes = {
    Classic: [
      '#ff0000','#ff8000','#ffff00','#80ff00','#00ff00','#00ff80',
      '#00ffff','#0080ff','#0000ff','#8000ff','#ff00ff','#ff0080'
    ],
    Rainbow: [
      '#ff0000','#ff7f00','#ffff00','#7fff00','#00ff00','#00ff7f',
      '#00ffff','#007fff','#0000ff','#7f00ff','#ff00ff','#ff007f'
    ],
    Viridis: [
      '#440154','#482878','#3e4989','#31688e','#26828e','#1f9e89',
      '#35b779','#6ece58','#b5de2b','#fee825','#fde725','#f9d923'
    ],
    Inferno: [
      '#000004','#1b0c41','#4a0c6b','#781c6d','#a52c60','#cf4446',
      '#ed6925','#fb9b06','#f7d13d','#fcffa4','#fffbb4','#fff7ec'
    ]
  };
  const scheme = colorSchemes[settings.colorScheme as keyof typeof colorSchemes] || colorSchemes.Classic;
  const showNames = settings.showNoteNames;
  ctx.save();
  ctx.clearRect(0, 0, w, h);
  const cx = w/2, cy = h/2, r = Math.min(w,h)*0.45;
  for (let i = 0; i < 12; i++) {
    const start = (i/12)*2*Math.PI - Math.PI/2;
    const end = ((i+1)/12)*2*Math.PI - Math.PI/2;
    ctx.beginPath();
    ctx.moveTo(cx, cy);
    ctx.arc(cx, cy, r, start, end, false);
    ctx.closePath();
    ctx.fillStyle = scheme[i];
    ctx.globalAlpha = chroma && chroma[i] ? Math.max(0.2, chroma[i]) : 0.2;
    ctx.fill();
    ctx.globalAlpha = 1;
    if (showNames) {
      ctx.save();
      ctx.translate(cx, cy);
      ctx.rotate((start+end)/2);
      ctx.textAlign = 'center';
      ctx.textBaseline = 'middle';
      ctx.font = 'bold 10px monospace';
      ctx.fillStyle = '#fff';
      ctx.fillText(['C','C#','D','D#','E','F','F#','G','G#','A','A#','B'][i], r*0.7, 0);
      ctx.restore();
    }
  }
  ctx.restore();
}

const ANCHORS = [
  { key: 'nw', style: { left: 0, top: 0, cursor: 'nwse-resize' }, dx: -1, dy: -1 },
  { key: 'n',  style: { left: '50%', top: 0, transform: 'translateX(-50%)', cursor: 'ns-resize' }, dx: 0, dy: -1 },
  { key: 'ne', style: { right: 0, top: 0, cursor: 'nesw-resize' }, dx: 1, dy: -1 },
  { key: 'e',  style: { right: 0, top: '50%', transform: 'translateY(-50%)', cursor: 'ew-resize' }, dx: 1, dy: 0 },
  { key: 'se', style: { right: 0, bottom: 0, cursor: 'nwse-resize' }, dx: 1, dy: 1 },
  { key: 's',  style: { left: '50%', bottom: 0, transform: 'translateX(-50%)', cursor: 'ns-resize' }, dx: 0, dy: 1 },
  { key: 'sw', style: { left: 0, bottom: 0, cursor: 'nesw-resize' }, dx: -1, dy: 1 },
  { key: 'w',  style: { left: 0, top: '50%', transform: 'translateY(-50%)', cursor: 'ew-resize' }, dx: -1, dy: 0 },
];

const SPECTROGRAM_BUFFER_SIZE = 200; // Number of FFT frames to keep (controls width)

export function HudOverlay({ id, type, position, size, stem, settings, featureData, onOpenModal, onUpdate, isSelected, onSelect }: any) {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [dragging, setDragging] = useState(false);
  const [resizing, setResizing] = useState<string | null>(null); // anchor key
  const [dragStart, setDragStart] = useState<{ x: number; y: number } | null>(null);
  const [resizeStart, setResizeStart] = useState<any>(null);
  const [isHovered, setIsHovered] = useState(false);

  // Rolling buffer for spectrogram
  const spectrogramBufferRef = useRef<Array<Float32Array>>([]);

  // Stable refs for event handlers
  const onMouseMoveRef = useRef<(e: MouseEvent) => void>();
  const onMouseUpRef = useRef<(e: MouseEvent) => void>();

  // Mouse move handler
  const onMouseMove = useCallback((e: MouseEvent) => {
    if (dragging && dragStart) {
      onUpdate({ position: { x: e.clientX - dragStart.x, y: e.clientY - dragStart.y } });
    }
    if (resizing && resizeStart) {
      const anchor = ANCHORS.find(a => a.key === resizing);
      if (!anchor) return;
      let { x, y, width, height } = resizeStart;
      const dx = e.clientX - resizeStart.startX;
      const dy = e.clientY - resizeStart.startY;
      // Corner/side logic
      if (anchor.dx === -1) { width -= dx; x += dx; }
      if (anchor.dx === 1)  { width += dx; }
      if (anchor.dy === -1) { height -= dy; y += dy; }
      if (anchor.dy === 1)  { height += dy; }
      width = Math.max(60, width);
      height = Math.max(40, height);
      onUpdate({ position: { x, y }, size: { width, height } });
    }
  }, [dragging, dragStart, resizing, resizeStart, onUpdate]);

  // Mouse up handler
  const onMouseUp = useCallback(() => {
    setDragging(false);
    setResizing(null);
    setDragStart(null);
    setResizeStart(null);
  }, []);

  // Keep refs up to date
  useEffect(() => {
    onMouseMoveRef.current = onMouseMove;
    onMouseUpRef.current = onMouseUp;
  }, [onMouseMove, onMouseUp]);

  // Attach/detach listeners when dragging or resizing
  useEffect(() => {
    if (dragging || resizing) {
      const move = (e: MouseEvent) => onMouseMoveRef.current && onMouseMoveRef.current(e);
      const up = (e: MouseEvent) => onMouseUpRef.current && onMouseUpRef.current(e);
      window.addEventListener('mousemove', move);
      window.addEventListener('mouseup', up);
      return () => {
        window.removeEventListener('mousemove', move);
        window.removeEventListener('mouseup', up);
      };
    }
  }, [dragging, resizing]);

  useEffect(() => {
    if (!canvasRef.current) return;
    const ctx = canvasRef.current.getContext('2d');
    if (!ctx) return;
    ctx.clearRect(0, 0, size.width, size.height);
    // Draw using featureData if available, else fallback to placeholder
    switch (type) {
      case 'waveform':
        if (Array.isArray(featureData) && featureData.length > 0) {
          // Draw bipolar waveform exactly like stem-waveform component
          const midY = size.height / 2;
          
          // Draw center line
          ctx.beginPath();
          ctx.moveTo(0, midY);
          ctx.lineTo(size.width, midY);
          ctx.strokeStyle = '#444';
          ctx.lineWidth = 1;
          ctx.stroke();
          
          // Draw bipolar waveform
          ctx.beginPath();
          ctx.strokeStyle = settings.color || '#4db3fa'; // Use settings color or fallback to blue
          ctx.lineWidth = 1;
          
          for (let i = 0; i < size.width; i++) {
            const idx = Math.floor(i / size.width * (featureData.length - 1));
            const pointHeight = featureData[idx] * midY * 0.8; // Scale to 80% of height
            const x = i;
            ctx.moveTo(x, midY - pointHeight);
            ctx.lineTo(x, midY + pointHeight);
          }
          ctx.stroke();
        } else {
          drawWaveform(ctx, size.width, size.height);
        }
        break;
      case 'oscilloscope':
        const amplitude = typeof settings.amplitude === 'number' ? settings.amplitude : 1;
        const color = settings.color || '#00ffff';
        const glowIntensity = typeof settings.glowIntensity === 'number' ? settings.glowIntensity : 0;
        const traceWidth = typeof settings.traceWidth === 'number' ? settings.traceWidth : 2;
        const showGrid = !!settings.showGrid;
        const gridColor = settings.gridColor || '#333333';
        if (Array.isArray(featureData) && featureData.length > 0) {
          // Draw background grid if enabled
          if (showGrid) {
            ctx.save();
            
            // Apply corner radius clipping if set
            const cornerRadius = settings.cornerRadius || 0;
            if (cornerRadius > 0) {
              ctx.beginPath();
              ctx.roundRect(0, 0, size.width, size.height, cornerRadius);
              ctx.clip();
            }
            
            ctx.strokeStyle = gridColor;
            ctx.lineWidth = 0.5;
            // Vertical grid lines
            for (let x = 0; x <= size.width; x += size.width / 10) {
              ctx.beginPath();
              ctx.moveTo(x, 0);
              ctx.lineTo(x, size.height);
              ctx.stroke();
            }
            // Horizontal grid lines
            for (let y = 0; y <= size.height; y += size.height / 8) {
              ctx.beginPath();
              ctx.moveTo(0, y);
              ctx.lineTo(size.width, y);
              ctx.stroke();
            }
            // Center crosshair
            ctx.strokeStyle = gridColor;
            ctx.lineWidth = 1;
            ctx.beginPath();
            ctx.moveTo(size.width / 2, 0);
            ctx.lineTo(size.width / 2, size.height);
            ctx.moveTo(0, size.height / 2);
            ctx.lineTo(size.width, size.height / 2);
            ctx.stroke();
            ctx.restore();
          }
          // Draw soft glow effect if enabled
          if (glowIntensity > 0) {
            ctx.save();
            const glowIntensityValue = glowIntensity * 0.15;
            const step = Math.max(1, Math.floor(size.width / 100));
            for (let i = 0; i < size.width; i += step) {
              const idx = Math.floor(i / size.width * (featureData.length - 1));
              const val = featureData[idx];
              // Bipolar: normalize to -1 to 1 range, then center at height/2
              const normalizedVal = (val - 0.5) * 2; // Convert 0-1 to -1 to 1
              const y = size.height / 2 - normalizedVal * (size.height / 2) * amplitude;
              const gradient = ctx.createRadialGradient(i, y, 0, i, y, glowIntensity * 2.5);
              const rgbaColor = color.startsWith('#') 
                ? `rgba(${parseInt(color.slice(1, 3), 16)}, ${parseInt(color.slice(3, 5), 16)}, ${parseInt(color.slice(5, 7), 16)}, ${glowIntensityValue})`
                : color;
              gradient.addColorStop(0, rgbaColor);
              gradient.addColorStop(1, 'transparent');
              ctx.fillStyle = gradient;
              ctx.beginPath();
              ctx.arc(i, y, glowIntensity * 2.5, 0, Math.PI * 2);
              ctx.fill();
            }
            ctx.restore();
          }
          // Draw main oscilloscope trace (bipolar)
          ctx.strokeStyle = color;
          ctx.lineWidth = traceWidth;
          ctx.beginPath();
          for (let i = 0; i < size.width; i++) {
            const idx = Math.floor(i / size.width * (featureData.length - 1));
            const val = featureData[idx];
            // Bipolar: normalize to -1 to 1 range, then center at height/2
            const normalizedVal = (val - 0.5) * 2; // Convert 0-1 to -1 to 1
            const y = size.height / 2 - normalizedVal * (size.height / 2) * amplitude;
            if (i === 0) ctx.moveTo(i, y);
            else ctx.lineTo(i, y);
          }
          ctx.stroke();
        } else {
          drawOscilloscope(ctx, size.width, size.height, { ...settings, amplitude, traceWidth });
        }
        break;
      case 'spectrogram': {
        // Enhanced spectrogram using FFT data
        debugLog.log(' Spectrogram rendering check:', {
          hasFeatureData: !!featureData,
          hasFft: !!(featureData && featureData.fft),
          isArray: !!(featureData && featureData.fft && Array.isArray(featureData.fft)),
          hasBuffer: !!(featureData && featureData.fftBuffer),
          bufferLength: featureData?.fftBuffer?.length || 0,
          fftLength: featureData?.fft?.length || 0
        });
        
        if (featureData && featureData.fft && Array.isArray(featureData.fft)) {
          debugLog.log(' Spectrogram rendering with cached FFT data:', {
            fftLength: featureData.fft.length,
            sampleValues: featureData.fft.slice(0, 5),
            maxValue: Math.max(...featureData.fft),
            minValue: Math.min(...featureData.fft),
            hasBuffer: !!featureData.fftBuffer,
            bufferLength: featureData.fftBuffer?.length || 0
          });
          
          // Use the buffer from the overlay manager (contains time-based variations)
          let buffer = featureData.fftBuffer;
          
          // If no buffer available, create a simple one from current FFT data
          if (!buffer || buffer.length === 0) {
            debugLog.log(' No buffer available, creating simple buffer from FFT data');
            const simpleBuffer = [];
            for (let i = 0; i < 50; i++) {
              simpleBuffer.push(Float32Array.from(featureData.fft));
            }
            buffer = simpleBuffer;
          }
          
          debugLog.log(' Spectrogram buffer state:', {
            bufferLength: buffer.length,
            firstFrameLength: buffer[0]?.length || 0
          });
          
          // Clear canvas
          ctx.clearRect(0, 0, size.width, size.height);
          
          // Draw spectrogram with enhanced visualization
          const width = size.width;
          const height = size.height;
          const frameCount = buffer.length;
          const binCount = buffer[0]?.length || 0;
          
          if (frameCount > 0 && binCount > 0) {
            // Calculate frequency range (assuming 44.1kHz sample rate)
            const sampleRate = 44100;
            const nyquist = sampleRate / 2;
            
            // Use logarithmic frequency scaling for better visualization
            const logFreqScale = (binIndex: number) => {
              const linearFreq = (binIndex / binCount) * nyquist;
              // Map to log scale: 20Hz to 20kHz
              const minFreq = 20;
              const maxFreq = 20000;
              const logMin = Math.log10(minFreq);
              const logMax = Math.log10(maxFreq);
              const logFreq = Math.log10(Math.max(minFreq, linearFreq));
              return (logFreq - logMin) / (logMax - logMin);
            };
            
                         // Enhanced color mapping with multiple color schemes
             const colorMap = settings.colorMap || 'Classic';
             const getColor = (magnitude: number, freqRatio: number) => {
               const normalizedMagnitude = Math.log10(magnitude + 1e-10) / Math.log10(1.1);
               const clamped = Math.max(0, Math.min(1, normalizedMagnitude));
               
               switch (colorMap) {
                 case 'Inferno':
                   // Inferno colormap: black -> red -> yellow -> white
                   if (clamped < 0.25) {
                     const t = clamped / 0.25;
                     return `rgb(${Math.floor(255 * t)}, 0, 0)`;
                   } else if (clamped < 0.5) {
                     const t = (clamped - 0.25) / 0.25;
                     return `rgb(255, ${Math.floor(255 * t)}, 0)`;
                   } else if (clamped < 0.75) {
                     const t = (clamped - 0.5) / 0.25;
                     return `rgb(255, 255, ${Math.floor(255 * t)})`;
                   } else {
                     const t = (clamped - 0.75) / 0.25;
                     return `rgb(255, 255, ${Math.floor(255 * (1 - t))})`;
                   }
                 case 'Viridis':
                   // Viridis colormap: blue -> green -> yellow
                   const viridisHue = 240 - clamped * 120;
                   return `hsl(${viridisHue}, 90%, ${30 + clamped * 50}%)`;
                 case 'Rainbow':
                   // Rainbow colormap
                   const rainbowHue = (freqRatio * 240 + clamped * 60) % 360;
                   return `hsl(${rainbowHue}, 90%, ${30 + clamped * 70}%)`;
                 default: // Classic
                   // Classic spectrogram: blue (low) to red (high)
                   const classicHue = 240 - (freqRatio * 240 + clamped * 60);
                   return `hsl(${classicHue}, 90%, ${30 + clamped * 70}%)`;
               }
             };
            
            // Draw spectrogram with improved resolution and anti-aliasing
            const pixelRatio = window.devicePixelRatio || 1;
            const scaledWidth = width * pixelRatio;
            const scaledHeight = height * pixelRatio;
            
            // Create off-screen canvas for high-resolution rendering
            const offscreenCanvas = document.createElement('canvas');
            offscreenCanvas.width = scaledWidth;
            offscreenCanvas.height = scaledHeight;
            const offscreenCtx = offscreenCanvas.getContext('2d');
            
            if (offscreenCtx) {
              // Scale the offscreen context
              offscreenCtx.scale(pixelRatio, pixelRatio);
              
              // Draw each pixel with proper frequency mapping
              for (let x = 0; x < frameCount; x++) {
                const fftFrame = buffer[x];
                if (!fftFrame) continue;
                
                for (let y = 0; y < height; y++) {
                  // Map screen Y to frequency bin using log scale
                  const freqRatio = 1 - (y / height); // Invert Y axis
                  const binIndex = Math.floor(freqRatio * binCount);
                  
                  if (binIndex >= 0 && binIndex < fftFrame.length) {
                    const magnitude = fftFrame[binIndex];
                    const color = getColor(magnitude, freqRatio);
                    
                    offscreenCtx.fillStyle = color;
                    const px = Math.floor(x * width / frameCount);
                    const colWidth = Math.max(1, Math.floor(width / frameCount));
                    offscreenCtx.fillRect(px, y, colWidth, 1);
                  }
                }
              }
              
              // Draw the high-resolution result back to the main canvas
              ctx.drawImage(offscreenCanvas, 0, 0, width, height);
            } else {
              // Fallback to direct drawing if offscreen canvas not available
              for (let x = 0; x < frameCount; x++) {
                const fftFrame = buffer[x];
                if (!fftFrame) continue;
                
                for (let y = 0; y < height; y++) {
                  const freqRatio = 1 - (y / height);
                  const binIndex = Math.floor(freqRatio * binCount);
                  
                  if (binIndex >= 0 && binIndex < fftFrame.length) {
                    const magnitude = fftFrame[binIndex];
                    const color = getColor(magnitude, freqRatio);
                    
                    ctx.fillStyle = color;
                    const px = Math.floor(x * width / frameCount);
                    const colWidth = Math.max(1, Math.floor(width / frameCount));
                    ctx.fillRect(px, y, colWidth, 1);
                  }
                }
              }
            }
            
            // Add frequency labels if enabled
            if (settings.showFrequencyLabels) {
              ctx.fillStyle = 'rgba(255, 255, 255, 0.7)';
              ctx.font = '10px monospace';
              ctx.textAlign = 'right';
              
              const frequencies = [20, 50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000];
              frequencies.forEach(freq => {
                const freqRatio = 1 - (Math.log10(freq) - Math.log10(20)) / (Math.log10(20000) - Math.log10(20));
                const y = freqRatio * height;
                if (y >= 0 && y < height) {
                  ctx.fillText(`${freq}Hz`, width - 5, y - 5);
                }
              });
            }
          }
        } else {
          drawSpectrogram(ctx, size.width, size.height);
        }
        break;
      }
      case 'spectrumAnalyzer': {
        if (featureData && featureData.fft && Array.isArray(featureData.fft)) {
          // Enhanced FFT-based spectrum analyzer using complex spectrum data
          const fftData = featureData.fft;
          const barColor = settings.barColor || '#00ffff';
          const barCount = Math.min(128, Math.floor(size.width / 4)); // Up to 128 bars, 4px min width
          const minFreq = 20; // Hz
          const maxFreq = 20000; // Hz
          const sampleRate = 44100; // Or get from settings/featureData if available
          const binCount = fftData.length;

          // Clear canvas
          ctx.clearRect(0, 0, size.width, size.height);

          // Enhanced logarithmic frequency scaling with better resolution
          for (let bar = 0; bar < barCount; bar++) {
            // Logarithmic frequency scaling for better low-frequency resolution
            const freqStart = minFreq * Math.pow(maxFreq / minFreq, bar / barCount);
            const freqEnd = minFreq * Math.pow(maxFreq / minFreq, (bar + 1) / barCount);
            
            // Find bins in this frequency range
            let binStart = Math.floor((freqStart / (sampleRate / 2)) * binCount);
            let binEnd = Math.ceil((freqEnd / (sampleRate / 2)) * binCount);
            binStart = Math.max(0, binStart);
            binEnd = Math.min(binCount, binEnd);
            
            // Calculate weighted average magnitude in this range
            let sum = 0, weightSum = 0;
            for (let i = binStart; i < binEnd; i++) {
              const magnitude = fftData[i];
              // Apply frequency weighting (emphasize lower frequencies)
              const freq = (i / binCount) * (sampleRate / 2);
              const weight = 1 / (1 + freq / 1000); // Decay weight with frequency
              sum += magnitude * weight;
              weightSum += weight;
            }
            
            const avgMagnitude = weightSum > 0 ? sum / weightSum : 0;
            
            // Enhanced magnitude scaling with dynamic range compression
            const logMagnitude = Math.log10(avgMagnitude + 1e-10);
            const normalizedMagnitude = Math.max(0, Math.min(1, (logMagnitude + 6) / 4)); // Adjust range as needed
            
            // Draw bar with enhanced styling
            const barWidth = size.width / barCount;
            const barHeight = normalizedMagnitude * size.height * 0.95;
            
            // Create gradient for each bar
            const gradient = ctx.createLinearGradient(
              bar * barWidth, size.height - barHeight,
              bar * barWidth, size.height
            );
            
            // Color gradient based on frequency
            const freqRatio = bar / barCount;
            const lowFreqColor = `hsl(${180 + freqRatio * 60}, 90%, 60%)`; // Blue to cyan
            const highFreqColor = `hsl(${240 + freqRatio * 60}, 90%, 60%)`; // Cyan to blue
            
            gradient.addColorStop(0, lowFreqColor);
            gradient.addColorStop(1, highFreqColor);
            
            ctx.fillStyle = gradient;
            ctx.fillRect(bar * barWidth, size.height - barHeight, barWidth - 1, barHeight);
            
            // Add subtle glow effect
            if (normalizedMagnitude > 0.7) {
              ctx.shadowColor = barColor;
              ctx.shadowBlur = 5;
              ctx.fillRect(bar * barWidth, size.height - barHeight, barWidth - 1, barHeight);
              ctx.shadowBlur = 0;
            }
          }
          
          // Add frequency labels if enabled
          if (settings.showFrequencyLabels) {
            ctx.fillStyle = 'rgba(255, 255, 255, 0.7)';
            ctx.font = '10px monospace';
            ctx.textAlign = 'center';
            
            const frequencies = [20, 50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000];
            frequencies.forEach(freq => {
              const freqRatio = (Math.log10(freq) - Math.log10(minFreq)) / (Math.log10(maxFreq) - Math.log10(minFreq));
              const x = freqRatio * size.width;
              if (x >= 0 && x < size.width) {
                ctx.fillText(`${freq}Hz`, x, size.height - 5);
              }
            });
          }
        } else if (Array.isArray(featureData) && featureData.length > 0) {
          // Draw real spectrum using other features
          const barWidth = size.width / featureData.length;
          for (let i = 0; i < featureData.length; i++) {
            const val = featureData[i];
            const h = Math.max(2, val * size.height * 0.9);
            ctx.fillStyle = `hsl(${180 + i % 120}, 90%, 60%)`;
            ctx.fillRect(i * barWidth, size.height - h, barWidth - 1, h);
          }
        } else {
          drawSpectrumAnalyzer(ctx, size.width, size.height);
        }
        break;
      }
      case 'peakMeter':
        if (typeof featureData === 'number') {
          // Draw real peak meter
          const peak = Math.max(0, Math.min(1, featureData));
          ctx.fillStyle = peak > 0.8 ? '#f00' : peak > 0.5 ? '#ff0' : '#0f0';
          ctx.fillRect(0, size.height * (1 - peak), size.width, size.height * peak);
        } else {
          drawPeakMeter(ctx, size.width, size.height);
        }
        break;
      case 'stereometer': {
        // True Lissajous stereometer using stereoWindow
        let stereoWindow = featureData && featureData.stereoWindow;
        // Reconstruct from flat arrays if needed
        if (!stereoWindow && featureData && featureData.stereoWindow_left && featureData.stereoWindow_right) {
          stereoWindow = {
            left: featureData.stereoWindow_left,
            right: featureData.stereoWindow_right
          };
        }
        if (stereoWindow && stereoWindow.left && stereoWindow.right) {
          // Debug log
          debugLog.log('[stereometer render]', {
            leftLength: stereoWindow.left.length,
            rightLength: stereoWindow.right.length,
            leftSample: stereoWindow.left.slice(0, 5),
            rightSample: stereoWindow.right.slice(0, 5),
            type: typeof stereoWindow.left[0]
          });
          const left = stereoWindow.left;
          const right = stereoWindow.right;
          const N = Math.min(left.length, right.length, 1024);
          ctx.save();
          ctx.globalAlpha = 0.8;
          ctx.strokeStyle = '#00ffff';
          ctx.lineWidth = 1.5;
          ctx.beginPath();
          for (let i = 0; i < N; i++) {
            // Normalize to [-1, 1]
            const lx = left[i];
            const ry = right[i];
            const x = ((lx + 1) / 2) * size.width;
            const y = ((ry + 1) / 2) * size.height;
            if (i === 0) ctx.moveTo(x, y);
            else ctx.lineTo(x, y);
          }
          ctx.stroke();
          // Optionally, draw fading trail/cloud
          ctx.globalAlpha = 0.2;
          for (let i = 0; i < N; i += 4) {
            const lx = left[i];
            const ry = right[i];
            const x = ((lx + 1) / 2) * size.width;
            const y = ((ry + 1) / 2) * size.height;
            ctx.beginPath();
            ctx.arc(x, y, 2, 0, Math.PI * 2);
            ctx.fillStyle = '#00ffff';
            ctx.fill();
          }
          ctx.restore();
        } else {
          drawStereometer(ctx, size.width, size.height);
        }
        break;
      }
      case 'midiMeter':
        if (typeof featureData === 'number') {
          // Draw real MIDI pitch/note
          ctx.fillStyle = '#fff';
          ctx.font = 'bold 18px monospace';
          ctx.fillText('MIDI: ' + featureData, size.width / 2 - 40, size.height / 2);
          ctx.strokeStyle = '#0ff';
          ctx.strokeRect(size.width / 2 - 40, size.height / 2 - 20, 80, 40);
        } else {
          drawMidiMeter(ctx, size.width, size.height);
        }
        break;
      case 'vuMeter': {
        // Use RMS or peak from featureData
        let value = 0;
        if (settings.meterType === 'Peak' && typeof featureData.peak === 'number') value = featureData.peak;
        else if (typeof featureData.rms === 'number') value = featureData.rms;
        drawVuMeter(ctx, size.width, size.height, value, settings);
        break;
      }
      case 'chromaWheel': {
        // featureData.chroma should be an array of 12 values (0-1)
        drawChromaWheel(ctx, size.width, size.height, featureData && featureData.chroma, settings);
        break;
      }
      case 'waveform': {
        if (Array.isArray(featureData) && featureData.length > 0) {
          // Draw bipolar waveform exactly like stem-waveform component
          const midY = size.height / 2;
      
          // Draw center line
          ctx.beginPath();
          ctx.moveTo(0, midY);
          ctx.lineTo(size.width, midY);
          ctx.strokeStyle = '#444';
          ctx.lineWidth = 1;
          ctx.stroke();
      
          // Draw bipolar waveform
          ctx.beginPath();
          ctx.strokeStyle = settings.color || '#4db3fa'; // Use settings color or fallback to blue
          ctx.lineWidth = 1;
      
          for (let i = 0; i < size.width; i++) {
            const idx = Math.floor(i / size.width * (featureData.length - 1));
            // Normalize to [-1, 1] for bipolar display
            const normalizedVal = (featureData[idx] - 0.5) * 2;
            const pointHeight = normalizedVal * (midY * 0.8); // Scale to 80% of height
            const x = i;
            ctx.moveTo(x, midY - pointHeight);
            ctx.lineTo(x, midY + pointHeight);
          }
          ctx.stroke();
        } else {
          drawWaveform(ctx, size.width, size.height);
        }
        // Transient detector
        if (settings.showTransients && Array.isArray(featureData.transients)) {
          ctx.save();
          ctx.strokeStyle = settings.transientColor || '#ff0';
          ctx.lineWidth = 1.5;
          for (const t of featureData.transients) {
            const x = Math.floor(t * size.width);
            ctx.beginPath();
            ctx.moveTo(x, 0);
            ctx.lineTo(x, size.height);
            ctx.stroke();
          }
          ctx.restore();
        }
        break;
      }
      case 'oscilloscope': {
        const amplitude = typeof settings.amplitude === 'number' ? settings.amplitude : 1;
        const color = settings.color || '#00ffff';
        const glowIntensity = typeof settings.glowIntensity === 'number' ? settings.glowIntensity : 0;
        const traceWidth = typeof settings.traceWidth === 'number' ? settings.traceWidth : 2;
        const showGrid = !!settings.showGrid;
        const gridColor = settings.gridColor || '#333333';
        if (Array.isArray(featureData) && featureData.length > 0) {
          // Draw background grid if enabled
          if (showGrid) {
            ctx.save();
            
            // Apply corner radius clipping if set
            const cornerRadius = settings.cornerRadius || 0;
            if (cornerRadius > 0) {
              ctx.beginPath();
              ctx.roundRect(0, 0, size.width, size.height, cornerRadius);
              ctx.clip();
            }
            
            ctx.strokeStyle = gridColor;
            ctx.lineWidth = 0.5;
            // Vertical grid lines
            for (let x = 0; x <= size.width; x += size.width / 10) {
              ctx.beginPath();
              ctx.moveTo(x, 0);
              ctx.lineTo(x, size.height);
              ctx.stroke();
            }
            // Horizontal grid lines
            for (let y = 0; y <= size.height; y += size.height / 8) {
              ctx.beginPath();
              ctx.moveTo(0, y);
              ctx.lineTo(size.width, y);
              ctx.stroke();
            }
            // Center crosshair
            ctx.strokeStyle = gridColor;
            ctx.lineWidth = 1;
            ctx.beginPath();
            ctx.moveTo(size.width / 2, 0);
            ctx.lineTo(size.width / 2, size.height);
            ctx.moveTo(0, size.height / 2);
            ctx.lineTo(size.width, size.height / 2);
            ctx.stroke();
            ctx.restore();
          }
          // Draw soft glow effect if enabled
          if (glowIntensity > 0) {
            ctx.save();
            const glowIntensityValue = glowIntensity * 0.15;
            const step = Math.max(1, Math.floor(size.width / 100));
            for (let i = 0; i < size.width; i += step) {
              const idx = Math.floor(i / size.width * (featureData.length - 1));
              const val = featureData[idx];
              // Bipolar: normalize to -1 to 1 range, then center at height/2
              const normalizedVal = (val - 0.5) * 2; // Convert 0-1 to -1 to 1
              const y = size.height / 2 - normalizedVal * (size.height / 2) * amplitude;
              const gradient = ctx.createRadialGradient(i, y, 0, i, y, glowIntensity * 2.5);
              const rgbaColor = color.startsWith('#') 
                ? `rgba(${parseInt(color.slice(1, 3), 16)}, ${parseInt(color.slice(3, 5), 16)}, ${parseInt(color.slice(5, 7), 16)}, ${glowIntensityValue})`
                : color;
              gradient.addColorStop(0, rgbaColor);
              gradient.addColorStop(1, 'transparent');
              ctx.fillStyle = gradient;
              ctx.beginPath();
              ctx.arc(i, y, glowIntensity * 2.5, 0, Math.PI * 2);
              ctx.fill();
            }
            ctx.restore();
          }
          // Draw main oscilloscope trace (bipolar)
          ctx.strokeStyle = color;
          ctx.lineWidth = traceWidth;
          ctx.beginPath();
          for (let i = 0; i < size.width; i++) {
            const idx = Math.floor(i / size.width * (featureData.length - 1));
            const val = featureData[idx];
            const normalizedVal = (val - 0.5) * 2;
            const y = size.height / 2 - normalizedVal * (size.height / 2) * amplitude;
            if (i === 0) ctx.moveTo(i, y);
            else ctx.lineTo(i, y);
          }
          ctx.stroke();
        } else {
          drawOscilloscope(ctx, size.width, size.height, { ...settings, amplitude, traceWidth });
        }
        break;
      }
      default:
        drawWaveform(ctx, size.width, size.height);
    }
  }, [type, stem, size, settings, featureData]);

  function onMouseDown(e: React.MouseEvent) {
    if ((e.target as HTMLElement).classList.contains('transform-anchor')) return;
    setDragging(true);
    setDragStart({ x: e.clientX - position.x, y: e.clientY - position.y });
  }
  function onAnchorMouseDown(anchorKey: string, e: React.MouseEvent) {
    e.stopPropagation();
    setResizing(anchorKey);
    setResizeStart({
      startX: e.clientX,
      startY: e.clientY,
      x: position.x,
      y: position.y,
      width: size.width,
      height: size.height,
    });
  }

  return (
    <div
      data-overlay-id={id}
      style={{
        position: 'absolute',
        left: position.x,
        top: position.y,
        width: size.width,
        height: size.height,
        pointerEvents: 'auto',
        zIndex: 10,
        borderRadius: settings.cornerRadius !== undefined ? `${settings.cornerRadius}px` : 0,
        background: settings.glass || settings.glassmorphism
          ? 'rgba(20, 40, 60, 0.25)'
          : 'rgba(0,0,0,0.2)',
        userSelect: dragging || resizing ? 'none' : 'auto',
        cursor: dragging ? 'grabbing' : 'grab',
        backdropFilter: settings.glass || settings.glassmorphism ? 'blur(12px)' : undefined,
        WebkitBackdropFilter: settings.glass || settings.glassmorphism ? 'blur(12px)' : undefined,
        border: isSelected ? '1px dashed white' : (
          settings.outline ? `${settings.outlineWidth || 1}px solid ${settings.outlineColor || '#ffffff'}` : undefined
        ),
        boxShadow: isSelected ? '0 0 0 1px rgba(255,255,255,0.2)' : (
          settings.dropShadow ? `0 4px ${settings.shadowBlur || 8}px ${settings.shadowColor || '#000000'}40` : undefined
        ),
        transition: 'background 0.2s',
        isolation: 'isolate',
      }}
      onMouseDown={e => { onMouseDown(e); onSelect && onSelect(); }}
      onDoubleClick={onOpenModal}
      onMouseEnter={() => setIsHovered(true)}
      onMouseLeave={() => setIsHovered(false)}
    >
      <canvas
        ref={canvasRef}
        width={size.width}
        height={size.height}
        style={{ width: '100%', height: '100%', display: 'block', borderRadius: settings.cornerRadius !== undefined ? `${settings.cornerRadius}px` : 0 }}
      />
      {/* Photoshop-style transform anchors - only visible on hover */}
      {isHovered && ANCHORS.map(anchor => (
        <div
          key={anchor.key}
          className="transform-anchor"
          style={{
            position: 'absolute',
      width: 12,
      height: 12,
            background: '#fff',
      border: '1px solid #ccc',
      borderRadius: 2,
      boxShadow: '0 1px 2px rgba(0,0,0,0.08)',
      ...anchor.style,
            zIndex: 20,
      opacity: 0.95,
      transition: 'background 0.2s, box-shadow 0.2s'
          }}
          onMouseDown={e => onAnchorMouseDown(anchor.key, e)}
        />
      ))}
    </div>
  );
}
</file>

<file path="components/hud/HudOverlayManager.tsx">
import React, { useState, useEffect, createContext, useContext, useRef } from 'react';
import { createPortal } from 'react-dom';
import { DndProvider } from 'react-dnd';
import { HTML5Backend } from 'react-dnd-html5-backend';
import { HudOverlay } from './HudOverlay';
import { HudOverlayParameterModal } from './HudOverlayParameterModal';
import { useAudioAnalysis } from '@/hooks/use-audio-analysis';
import { useStemAudioController } from '@/hooks/use-stem-audio-controller';
import { useDrop } from 'react-dnd';
import { debugLog } from '@/lib/utils';

export interface HudOverlayConfig {
  id: string;
  type: string;
  position: { x: number; y: number };
  size: { width: number; height: number };
  stem: any;
  settings: Record<string, any>;
}

interface HudOverlayContextType {
  overlays: HudOverlayConfig[];
  addOverlay: (type: string) => void;
  updateOverlay: (id: string, update: Partial<HudOverlayConfig>) => void;
  removeOverlay: (id: string) => void;
  moveOverlay: (from: number, to: number) => void;
  openOverlayModal: (id: string) => void;
  modalOverlayId: string | null;
  closeOverlayModal: () => void;
  selectedOverlayId: string | null;
  setSelectedOverlayId: (id: string | null) => void;
}

export const HudOverlayContext = createContext<HudOverlayContextType | undefined>(undefined);
export function useHudOverlayContext() {
  const ctx = useContext(HudOverlayContext);
  if (!ctx) throw new Error('useHudOverlayContext must be used within HudOverlayProvider');
  return ctx;
}

const OVERLAY_TYPES = [
  { value: 'waveform', label: 'Waveform' },
  { value: 'spectrogram', label: 'Spectrogram' },
  { value: 'peakMeter', label: 'Peak/LUFS Meter' },
  { value: 'vuMeter', label: 'VU Meter' },
  { value: 'stereometer', label: 'Stereometer' },
  { value: 'oscilloscope', label: 'Oscilloscope' },
  { value: 'spectrumAnalyzer', label: 'Spectrum Analyzer' },
  { value: 'midiMeter', label: 'MIDI Activity Meter' },
  { value: 'chromaWheel', label: 'Chroma Wheel' },
  { value: 'consoleFeed', label: 'Data Feed' },
];

export const HudOverlayProvider: React.FC<{ 
  children?: React.ReactNode;
  cachedAnalysis?: any[];
  stemAudio?: any;
  stemUrlMap?: Record<string, string>;
}> = ({ children, cachedAnalysis = [], stemAudio, stemUrlMap = {} }) => {
  const [overlays, setOverlays] = useState<HudOverlayConfig[]>([]);
  const [modalOverlayId, setModalOverlayId] = useState<string | null>(null);
  const [selectedOverlayId, setSelectedOverlayId] = useState<string | null>(null); // NEW
  const [isClient, setIsClient] = useState(false);

  // Force re-render on every animation frame for real-time overlay updates
  const [frame, setFrame] = useState(0);
  
  // Rolling buffer for spectrogram FFT frames
  const spectrogramFramesRef = useRef<Array<Float32Array>>([]);
  const lastFrameTimeRef = useRef<number>(0);
  
  useEffect(() => {
    let raf: number;
    const loop = () => {
      const now = performance.now();
      const deltaTime = now - lastFrameTimeRef.current;
      lastFrameTimeRef.current = now;
      
      setFrame(f => f + 1);
      raf = requestAnimationFrame(loop);
    };
    raf = requestAnimationFrame(loop);
    return () => cancelAnimationFrame(raf);
  }, []);

  // Use passed props or fallback to hooks
  const audioAnalysisHook = useAudioAnalysis();
  const stemAudioController = useStemAudioController();
  
  // Use passed props if available, otherwise use hooks
  const analysisData = cachedAnalysis.length > 0 ? cachedAnalysis : audioAnalysisHook.cachedAnalysis;
  const audioController = stemAudio || stemAudioController;

  // Debug: log when the hook data changes
  useEffect(() => {
    // debugLog.log(' HudOverlayManager analysis data changed:', {
    //   count: analysisData.length,
    //   ids: analysisData.map(a => a.fileMetadataId),
    //   source: cachedAnalysis.length > 0 ? 'props' : 'hook'
    // });
  }, [analysisData, cachedAnalysis.length]);

  // Debug: log cached analysis state
  useEffect(() => {
    // if (frame % 120 === 0) { // Log every 120 frames
    //   debugLog.log(' HudOverlayManager cached analysis state:', {
    //     count: analysisData.length,
    //     analyses: analysisData.map(a => ({
    //       id: a.fileMetadataId,
    //       stemType: a.stemType,
    //       hasData: !!a.analysisData,
    //       features: a.analysisData ? Object.keys(a.analysisData) : []
    //     })),
    //     source: cachedAnalysis.length > 0 ? 'props' : 'hook'
    //   });
    // }
  }, [analysisData, frame, cachedAnalysis.length]);

  // Helper: find master stem from cached analysis
  function findMasterStem() {
    if (!analysisData || analysisData.length === 0) {
      // debugLog.log(' No cached analysis available for master stem selection');
      return null;
    }
    
    // First, try to find by stemType === 'master'
    let masterStem = analysisData.find(a => a.stemType === 'master');
    
    // If not found, try to find by longest duration (master is usually the longest)
    if (!masterStem && analysisData.length > 0) {
      masterStem = analysisData.reduce((longest, current) => {
        const currentDuration = current.metadata?.duration || 0;
        const longestDuration = longest?.metadata?.duration || 0;
        return currentDuration > longestDuration ? current : longest;
      }, analysisData[0]); // Provide initial value
    }
    
    // Debug log to see what we found
    if (masterStem) {
      // debugLog.log(' Found master stem:', {
      //   id: masterStem.fileMetadataId,
      //   stemType: masterStem.stemType,
      //   duration: masterStem.metadata?.duration,
      //   hasAnalysis: !!masterStem.analysisData,
      //   availableFeatures: masterStem.analysisData ? Object.keys(masterStem.analysisData) : []
      // });
    } else {
      // debugLog.log(' No master stem found, available stems:', analysisData.map(a => ({
      //   id: a.fileMetadataId,
      //   stemType: a.stemType,
      //   duration: a.metadata?.duration,
      //   hasAnalysis: !!a.analysisData
      // })));
    }
    
    return masterStem || analysisData[0]; // Fallback to first available
  }

  // Helper: get feature key for overlay type (using real analysis keys)
  function getFeatureKeyForOverlay(type: string): string[] {
    switch (type) {
      case 'waveform':
      case 'oscilloscope':
        return ['rms', 'loudness']; // Use RMS as closest to waveform
      case 'spectrogram':
      case 'spectrumAnalyzer':
        return ['fft', 'spectralCentroid', 'rms', 'loudness']; // Use FFT data for visualization
      case 'peakMeter':
        return ['rms', 'loudness'];
      case 'stereometer':
        return ['spectralCentroid', 'rms']; // Use spectral centroid for stereo effect
      case 'midiMeter':
        return ['rms', 'loudness']; // Use RMS and loudness for MIDI visualization
      default:
        return ['rms']; // Default fallback
    }
  }

  // Helper: get feature data for overlay at current time
  function getFeatureDataForOverlay(overlay: HudOverlayConfig) {
    if (!overlay.stem || !overlay.stem.id) {
      // If no stem assigned, return null (overlay will show placeholder)
      return null;
    }
    if (!analysisData || analysisData.length === 0) return null;
    
    // Debug: log what we're looking for
    if (frame % 120 === 0) { // Log every 120 frames to avoid spam
      // debugLog.log(' Looking for analysis data:', {
      //   overlayId: overlay.id,
      //   overlayType: overlay.type,
      //   stemId: overlay.stem.id,
      //   availableAnalyses: analysisData.map(a => ({
      //     id: a.fileMetadataId,
      //     stemType: a.stemType,
      //     hasData: !!a.analysisData
      //   }))
      // });
    }
    
    const analysis = analysisData.find(a => a.fileMetadataId === overlay.stem.id);
    if (!analysis || !analysis.analysisData) {
      if (frame % 60 === 0) { // Log every 60 frames to avoid spam
        // debugLog.log(' No analysis found for stem:', overlay.stem.id, 'Available:', analysisData.map(a => ({
        //   id: a.fileMetadataId,
        //   stemType: a.stemType,
        //   hasData: !!a.analysisData
        // })));
      }
      return null;
    }

    // Debug: log available features
    if (frame % 60 === 0) { // Log every 60 frames to avoid spam
      // debugLog.log(' Available features for stem:', overlay.stem.id, Object.keys(analysis.analysisData));
    }

    const featureKeys = getFeatureKeyForOverlay(overlay.type);
    let featureArr = null;
    let featureName = null;

    // For spectrum overlays, collect frequency-related features
    if (overlay.type === 'spectrogram' || overlay.type === 'spectrumAnalyzer') {
      // Debug: log what's in the analysis data
      if (frame % 60 === 0) {
        // debugLog.log(' Analysis data for spectrogram:', {
        //   availableKeys: Object.keys(analysis.analysisData),
        //   hasFft: !!analysis.analysisData.fft,
        //   fftType: typeof analysis.analysisData.fft,
        //   fftIsArray: Array.isArray(analysis.analysisData.fft),
        //   fftLength: analysis.analysisData.fft?.length || 0,
        //   fftSample: analysis.analysisData.fft?.slice?.(0, 5) || 'no slice method'
        // });
      }
      
      // Check if we have FFT data (which comes from complex spectrum processing)
      if (analysis.analysisData.fft && Array.isArray(analysis.analysisData.fft) && analysis.analysisData.fft.length > 0) {
        // Get current time and duration with loop handling
        const duration = analysis.metadata?.duration || 1;
        const rawCurrentTime = audioController?.currentTime || 0;
        const currentTime = audioController?.isLooping ? (rawCurrentTime % duration) : rawCurrentTime;
        
        // Use the cached FFT data directly for spectrogram
        const baseFft = analysis.analysisData.fft;
        
        // Create a time-based window through the cached data
        // For spectrogram, we want to show a time-frequency representation
        // Since we have one FFT frame per analysis, we'll create a sliding window
        const progress = Math.max(0, Math.min(currentTime / duration, 1));
        
        // Create a buffer of FFT frames by sampling the cached data at different time points
        const buffer = [];
        const numFrames = 200; // Number of time frames to show in spectrogram
        
        for (let frameIdx = 0; frameIdx < numFrames; frameIdx++) {
          // Calculate the time position for this frame (sliding window)
          const frameTime = currentTime - (numFrames - frameIdx) * 0.1; // 100ms per frame
          const frameProgress = Math.max(0, Math.min(frameTime / duration, 1));
          
          // Create a frame based on the cached FFT data with time-based variations
          const newFrame = new Float32Array(baseFft.length);
          
          // Add time-based variations to make it dynamic
          const timePhase = frameTime * 2 * Math.PI;
          const frequencyPhase = frameTime * Math.PI;
          
          for (let i = 0; i < baseFft.length; i++) {
            const freqRatio = i / baseFft.length;
            const baseValue = baseFft[i];
            
            // Add variations based on time and frequency
            const amplitudeMod = 1 + 0.3 * Math.sin(timePhase + freqRatio * Math.PI * 4);
            const frequencyMod = 1 + 0.2 * Math.sin(frequencyPhase + freqRatio * Math.PI * 2);
            const noiseMod = 1 + 0.1 * Math.sin(timePhase * 3 + i * 0.1);
            
            // Combine all modulations
            newFrame[i] = Math.max(0, baseValue * amplitudeMod * frequencyMod * noiseMod);
          }
          
          buffer.push(newFrame);
        }
        
        // debugLog.log(' Spectrogram using cached data:', {
        //   bufferLength: buffer.length,
        //   currentTime: currentTime,
        //   progress: progress,
        //   baseFftLength: baseFft.length,
        //   sampleValues: buffer[0]?.slice(0, 5)
        // });
        
        return { 
          fft: buffer[buffer.length - 1], // Current frame
          fftBuffer: buffer // Full buffer for spectrogram
        };
      } else {
        // FFT data is missing or empty, create synthetic FFT data for visualization
        // debugLog.log(' Creating synthetic FFT data for spectrogram');
        
        const duration = analysis.metadata?.duration || 1;
        const rawCurrentTime = audioController?.currentTime || 0;
        const currentTime = audioController?.isLooping ? (rawCurrentTime % duration) : rawCurrentTime;
        
        // Create synthetic FFT data (512 frequency bins)
        const fftSize = 512;
        const baseFft = new Float32Array(fftSize);
        
        // Generate a realistic frequency spectrum
        for (let i = 0; i < fftSize; i++) {
          const freqRatio = i / fftSize;
          // Create a spectrum with bass, mid, and treble components
          const bass = Math.exp(-freqRatio * 3) * 0.8;
          const mid = Math.exp(-Math.pow(freqRatio - 0.3, 2) * 10) * 0.6;
          const treble = Math.exp(-Math.pow(freqRatio - 0.8, 2) * 5) * 0.4;
          baseFft[i] = bass + mid + treble + Math.random() * 0.1;
        }
        
        // Create a buffer of FFT frames with time-based variations
        const buffer = [];
        const numFrames = 200;
        
        for (let frameIdx = 0; frameIdx < numFrames; frameIdx++) {
          const frameTime = currentTime - (numFrames - frameIdx) * 0.1;
          const newFrame = new Float32Array(fftSize);
          
          const timePhase = frameTime * 2 * Math.PI;
          const frequencyPhase = frameTime * Math.PI;
          
          for (let i = 0; i < fftSize; i++) {
            const freqRatio = i / fftSize;
            const baseValue = baseFft[i];
            
            // Add dynamic variations
            const amplitudeMod = 1 + 0.3 * Math.sin(timePhase + freqRatio * Math.PI * 4);
            const frequencyMod = 1 + 0.2 * Math.sin(frequencyPhase + freqRatio * Math.PI * 2);
            const noiseMod = 1 + 0.1 * Math.sin(timePhase * 3 + i * 0.1);
            
            newFrame[i] = Math.max(0, baseValue * amplitudeMod * frequencyMod * noiseMod);
          }
          
          buffer.push(newFrame);
        }
        
        // debugLog.log(' Spectrogram using synthetic data:', {
        //   bufferLength: buffer.length,
        //   currentTime: currentTime,
        //   fftSize: fftSize,
        //   sampleValues: buffer[0]?.slice(0, 5)
        // });
        
        return { 
          fft: buffer[buffer.length - 1],
          fftBuffer: buffer
        };
      }
      
      // Fallback to other spectral features if FFT not available
      const spectrumFeatures = featureKeys.filter(key => analysis.analysisData[key] && key !== 'fft');
      if (spectrumFeatures.length > 0) {
        // Get current time and duration with loop handling
        const duration = analysis.metadata?.duration || 1;
        const rawCurrentTime = audioController?.currentTime || 0;
        
        // Handle looping - if audio is looping, use modulo to get position within loop
        const currentTime = audioController?.isLooping ? (rawCurrentTime % duration) : rawCurrentTime;
        const progress = Math.max(0, Math.min(currentTime / duration, 1));
        const idx = Math.floor(progress * (analysis.analysisData[spectrumFeatures[0]].length - 1));
        
        // Build array of current spectrum values
        const currentSpectrumValues = spectrumFeatures.map(key => analysis.analysisData[key][idx] || 0);
        return currentSpectrumValues;
      }
    }

    // For other overlays, find the first available feature
    for (const key of featureKeys) {
      if (analysis.analysisData[key]) {
        featureArr = analysis.analysisData[key];
        featureName = key;
        break;
      }
    }

    if (!featureArr) {
      // debugLog.log(' No matching features found for overlay type:', overlay.type, 'Available:', Object.keys(analysis.analysisData));
      
      // Fallback: try to find any available feature
      const availableFeatures = Object.keys(analysis.analysisData).filter(key => 
        Array.isArray(analysis.analysisData[key]) && analysis.analysisData[key].length > 0
      );
      
      if (availableFeatures.length > 0) {
        // debugLog.log(' Using fallback feature:', availableFeatures[0]);
        featureArr = analysis.analysisData[availableFeatures[0]];
        featureName = availableFeatures[0];
      } else {
        return null;
      }
    }

    // Get current time and duration with loop handling
    const duration = analysis.metadata?.duration || 1;
    const rawCurrentTime = audioController?.currentTime || 0;
    
    // Handle looping - if audio is looping, use modulo to get position within loop
    const currentTime = audioController?.isLooping ? (rawCurrentTime % duration) : rawCurrentTime;
    const progress = Math.max(0, Math.min(currentTime / duration, 1));
    const idx = Math.floor(progress * (featureArr.length - 1));
    
    const value = featureArr[idx];
    if (frame % 60 === 0) { // Log every 60 frames
      // debugLog.log(' Feature data for overlay:', overlay.type, 'feature:', featureName, 'value:', value, 'time:', currentTime);
    }
    
    // Return different data formats based on overlay type
    if (overlay.type === 'waveform' || overlay.type === 'oscilloscope') {
      // For waveform and oscilloscope overlays, return a window ending at idx (playback index) and extending backward
      // so the right edge matches the current playback index
      const windowSize = 2 * 50; // 100 samples
      const endIdx = idx + 1; // include current playback index
      const startIdx = Math.max(0, endIdx - windowSize);
      const windowValues = featureArr.slice(startIdx, endIdx);
      return windowValues;
    } else if (overlay.type === 'spectrogram' || overlay.type === 'spectrumAnalyzer') {
      // For spectrum overlays, we already handled this case above, so return null here
      return null;
    } else if (overlay.type === 'stereometer') {
      // For stereometer, use real-time stereo window from audio controller if available
      if (audioController && audioController.getStereoWindow && overlay.stem && overlay.stem.id) {
        const stereoWindow = audioController.getStereoWindow(overlay.stem.id, 1024);
        debugLog.log('[stereometer getStereoWindow call]', {
          audioControllerExists: !!audioController,
          getStereoWindowExists: !!audioController.getStereoWindow,
          stemId: overlay.stem.id,
          stereoWindow,
        });
        if (stereoWindow) {
          return { stereoWindow };
        }
      }
      // fallback: return null if not available
      return null;
    } else {
      // For other overlays (peak meter, stereometer, etc.), return single value
      return value;
    }
  }

  // Helper: ensure a stem object has id and url
  function getStemWithUrl(stem: any) {
    if (!stem) return null;
    return {
      ...stem,
      url: stem.url || stemUrlMap[stem.id] || '',
    };
  }

  // Helper: ensure all stems for overlays are loaded into the audio controller
  function ensureStemsLoadedForOverlays(overlays: HudOverlayConfig[]) {
    const stemsToLoad = overlays
      .map(o => getStemWithUrl(o.stem))
      .filter(s => s && s.url);
    if (stemsToLoad.length > 0 && audioController && audioController.loadStems) {
      audioController.loadStems(stemsToLoad);
    }
  }

  // Helper: ensure all stems for overlays have id and url, and collect them for audio loading
  function getAllOverlayStemsWithUrls(overlays: HudOverlayConfig[], stemUrlMap: Record<string, string>) {
    const stems: any[] = [];
    overlays.forEach(overlay => {
      if (overlay.stem && overlay.stem.id) {
        const url = overlay.stem.url || stemUrlMap[overlay.stem.id];
        if (url) {
          stems.push({ ...overlay.stem, url });
        }
      }
    });
    return stems;
  }

  // Patch addOverlay to always attach a stem with id and url
  function addOverlay(type: string, position?: { x: number; y: number }) {
    // Find master stem to default to
    const masterStem = findMasterStem();
    const defaultStem = masterStem ? getStemWithUrl({
      id: masterStem.fileMetadataId,
      name: masterStem.stemType || 'master',
      stemType: masterStem.stemType
    }) : null;

    // If no master stem found, show a warning but still create the overlay
    if (!defaultStem) {
      debugLog.warn(' No master stem available for overlay, creating overlay without audio data');
    }

    setOverlays(prev => {
      const newOverlays = [
        ...prev,
        {
          id: Math.random().toString(36).slice(2),
          type,
          position: position || { x: 100 + prev.length * 40, y: 100 + prev.length * 40 },
          size: { width: 400, height: 120 },
          stem: defaultStem, // Always has id and url
          settings: {},
        },
      ];
      ensureStemsLoadedForOverlays(newOverlays);
      return newOverlays;
    });
  }
  function updateOverlay(id: string, update: Partial<HudOverlayConfig>) {
    setOverlays(prev => prev.map(o => o.id === id ? { ...o, ...update } : o));
  }
  function removeOverlay(id: string) {
    setOverlays(prev => prev.filter(o => o.id !== id));
  }
  function moveOverlay(from: number, to: number) {
    setOverlays(prev => {
      const arr = [...prev];
      const [item] = arr.splice(from, 1);
      arr.splice(to, 0, item);
      return arr;
    });
  }
  function openOverlayModal(id: string) {
    setModalOverlayId(id);
  }
  function closeOverlayModal() {
    setModalOverlayId(null);
  }

  // Listen for Delete key to remove selected overlay
  useEffect(() => {
    function handleKeyDown(e: KeyboardEvent) {
      if ((e.key === 'Delete' || e.key === 'Backspace') && selectedOverlayId) {
        removeOverlay(selectedOverlayId);
        setSelectedOverlayId(null);
      }
    }
    window.addEventListener('keydown', handleKeyDown);
    return () => window.removeEventListener('keydown', handleKeyDown);
  }, [selectedOverlayId]);

  // Ensure we're on the client side before rendering portals
  useEffect(() => {
    setIsClient(true);
  }, []);

  useEffect(() => {
    // Only proceed if stemUrlMap is populated and overlays are ready
    const allStemIds = overlays.map(o => o.stem?.id).filter(Boolean);
    const allUrlsAvailable = allStemIds.every(id => stemUrlMap[id]);
    if (!allUrlsAvailable) {
      debugLog.log('[HudOverlayManager] Waiting for all stem URLs to be available', { allStemIds, stemUrlMap });
      return;
    }
    // Attach URLs to overlays
    overlays.forEach(overlay => {
      if (overlay.stem && overlay.stem.id) {
        overlay.stem.url = stemUrlMap[overlay.stem.id];
      }
    });
    // Load stems into audio controller
    const stemsToLoad = getAllOverlayStemsWithUrls(overlays, stemUrlMap);
    if (audioController && stemsToLoad.length > 0) {
      debugLog.log('[HudOverlayManager] Calling loadStems with', stemsToLoad);
      audioController.loadStems(stemsToLoad);
    }
  }, [overlays, stemUrlMap, audioController]);

  return (
    <HudOverlayContext.Provider value={{ overlays, addOverlay, updateOverlay, removeOverlay, moveOverlay, openOverlayModal, modalOverlayId, closeOverlayModal, selectedOverlayId, setSelectedOverlayId }}>
      {children}
      {/* Render overlays in the visualizer container using portal - only on client */}
      {isClient && typeof window !== 'undefined' && createPortal(
        <DndProvider backend={HTML5Backend}>
          {/* Main overlay canvas drop target */}
          <OverlayCanvasDropTarget addOverlay={addOverlay} setSelectedOverlayId={setSelectedOverlayId}>
            <div id="hud-overlays" style={{ position: 'absolute', top:0, left:0, width:'100%', height:'100%', pointerEvents:'auto', zIndex: 20 }}>
              {overlays.map(overlay => (
                <HudOverlay
                  key={overlay.id}
                  {...overlay}
                  featureData={getFeatureDataForOverlay(overlay)} // <-- pass feature data
                  onOpenModal={() => openOverlayModal(overlay.id)}
                  onUpdate={(update: Partial<HudOverlayConfig>) => updateOverlay(overlay.id, update)}
                  isSelected={selectedOverlayId === overlay.id}
                  onSelect={() => setSelectedOverlayId(overlay.id)}
                />
              ))}
              {modalOverlayId && (
                <HudOverlayParameterModal
                  overlay={overlays.find(o => o.id === modalOverlayId)!}
                  onClose={closeOverlayModal}
                  onUpdate={(update: Partial<HudOverlayConfig>) => updateOverlay(modalOverlayId, update)}
                />
              )}
            </div>
          </OverlayCanvasDropTarget>
        </DndProvider>,
        document.getElementById('hud-overlays') || document.body
      )}
    </HudOverlayContext.Provider>
  );
};

// OverlayCanvasDropTarget component
function OverlayCanvasDropTarget({ addOverlay, setSelectedOverlayId, children }: { 
  addOverlay: (type: string, position?: { x: number; y: number }) => void, 
  setSelectedOverlayId: (id: string | null) => void,
  children: React.ReactNode 
}) {
  const ref = React.useRef<HTMLDivElement>(null);
  const [, drop] = useDrop({
    accept: ['EFFECT_CARD'],
    drop: (item: any, monitor) => {
      if (item.type === 'EFFECT_CARD') {
        // Get mouse position relative to the canvas
        const clientOffset = monitor.getClientOffset();
        if (clientOffset && ref.current) {
          const rect = ref.current.getBoundingClientRect();
          const x = clientOffset.x - rect.left;
          const y = clientOffset.y - rect.top;
          addOverlay(item.id, { x, y });
        } else {
          // Fallback: use default overlay position logic
          addOverlay(item.id, undefined);
        }
      }
    },
  });
  
  const handleCanvasClick = (e: React.MouseEvent) => {
    // Check if clicking on the canvas background or on an overlay
    const target = e.target as HTMLElement;
    const isOverlay = target.closest('[data-overlay-id]');
    const isCanvas = target === ref.current || target.id === 'hud-overlays';
    
    // Only unselect if clicking on the canvas background (not on an overlay)
    if (isCanvas && !isOverlay) {
      setSelectedOverlayId(null);
    }
  };
  
  drop(ref);
  return (
    <div 
      ref={ref} 
      style={{ position: 'absolute', top:0, left:0, width:'100%', height:'100%' }}
      onClick={handleCanvasClick}
    >
      {children}
    </div>
  );
}
</file>

<file path="components/hud/HudOverlayParameterModal.tsx">
import React from 'react';
import { useDrop } from 'react-dnd';
import { PortalModal } from '../ui/portal-modal';
import { DroppableParameter } from '../ui/droppable-parameter';
import { Badge } from '../ui/badge';
import { X } from 'lucide-react';
import { Slider } from '../ui/slider';
import { Label } from '../ui/label';

// Add OverlaySetting type to allow min, max, step

type OverlaySetting = {
  label: string;
  key: string;
  type: string;
  options?: any[];
  min?: number;
  max?: number;
  step?: number;
};

const OVERLAY_SETTINGS: Record<string, OverlaySetting[]> = {
  waveform: [
    { label: 'Color', key: 'color', type: 'color' },
    { label: 'Line Width', key: 'lineWidth', type: 'number' },
    { label: 'Corner Radius', key: 'cornerRadius', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Drop Shadow', key: 'dropShadow', type: 'checkbox' },
    { label: 'Shadow Color', key: 'shadowColor', type: 'color' },
    { label: 'Shadow Blur', key: 'shadowBlur', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Outline', key: 'outline', type: 'checkbox' },
    { label: 'Outline Color', key: 'outlineColor', type: 'color' },
    { label: 'Outline Width', key: 'outlineWidth', type: 'number', min: 1, max: 10, step: 1 },
  ],
  spectrogram: [
    { label: 'Color Map', key: 'colorMap', type: 'select', options: ['Classic', 'Inferno', 'Viridis', 'Rainbow'] },
    { label: 'Show Frequency Labels', key: 'showFrequencyLabels', type: 'checkbox' },
    { label: 'Brightness', key: 'brightness', type: 'number', min: 0, max: 2, step: 0.01 },
    { label: 'Contrast', key: 'contrast', type: 'number', min: 0, max: 2, step: 0.01 },
    { label: 'Scroll Speed', key: 'scrollSpeed', type: 'number', min: 0.1, max: 5, step: 0.1 },
    { label: 'FFT Size', key: 'fftSize', type: 'number', min: 256, max: 4096, step: 256 },
    { label: 'Corner Radius', key: 'cornerRadius', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Drop Shadow', key: 'dropShadow', type: 'checkbox' },
    { label: 'Shadow Color', key: 'shadowColor', type: 'color' },
    { label: 'Shadow Blur', key: 'shadowBlur', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Outline', key: 'outline', type: 'checkbox' },
    { label: 'Outline Color', key: 'outlineColor', type: 'color' },
    { label: 'Outline Width', key: 'outlineWidth', type: 'number', min: 1, max: 10, step: 1 },
  ],
  peakMeter: [
    { label: 'Peak Color', key: 'peakColor', type: 'color' },
    { label: 'Hold Time (ms)', key: 'holdTime', type: 'number' },
    { label: 'Corner Radius', key: 'cornerRadius', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Drop Shadow', key: 'dropShadow', type: 'checkbox' },
    { label: 'Shadow Color', key: 'shadowColor', type: 'color' },
    { label: 'Shadow Blur', key: 'shadowBlur', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Outline', key: 'outline', type: 'checkbox' },
    { label: 'Outline Color', key: 'outlineColor', type: 'color' },
    { label: 'Outline Width', key: 'outlineWidth', type: 'number', min: 1, max: 10, step: 1 },
  ],
  stereometer: [
    { label: 'Trace Color', key: 'traceColor', type: 'color' },
    { label: 'Glow Intensity', key: 'glowIntensity', type: 'number', min: 0, max: 1, step: 0.01 },
    { label: 'Point Size', key: 'pointSize', type: 'number', min: 1, max: 10, step: 1 },
    { label: 'Show Grid', key: 'showGrid', type: 'checkbox' },
    { label: 'Corner Radius', key: 'cornerRadius', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Drop Shadow', key: 'dropShadow', type: 'checkbox' },
    { label: 'Shadow Color', key: 'shadowColor', type: 'color' },
    { label: 'Shadow Blur', key: 'shadowBlur', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Outline', key: 'outline', type: 'checkbox' },
    { label: 'Outline Color', key: 'outlineColor', type: 'color' },
    { label: 'Outline Width', key: 'outlineWidth', type: 'number', min: 1, max: 10, step: 1 },
  ],
  oscilloscope: [
    { label: 'Follow Pitch', key: 'followPitch', type: 'checkbox' },
    { label: 'Color', key: 'color', type: 'color' },
    { label: 'Glow Intensity', key: 'glowIntensity', type: 'slider' },
    { label: 'Amplitude', key: 'amplitude', type: 'slider' },
    { label: 'Trace Width', key: 'traceWidth', type: 'slider', min: 0.5, max: 2, step: 0.1 },
    { label: 'Show Grid', key: 'showGrid', type: 'checkbox' },
    { label: 'Grid Color', key: 'gridColor', type: 'color' },
    { label: 'Corner Radius', key: 'cornerRadius', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Drop Shadow', key: 'dropShadow', type: 'checkbox' },
    { label: 'Shadow Color', key: 'shadowColor', type: 'color' },
    { label: 'Shadow Blur', key: 'shadowBlur', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Outline', key: 'outline', type: 'checkbox' },
    { label: 'Outline Color', key: 'outlineColor', type: 'color' },
    { label: 'Outline Width', key: 'outlineWidth', type: 'number', min: 1, max: 10, step: 1 },
  ],
  spectrumAnalyzer: [
    { label: 'Bar Color', key: 'barColor', type: 'color' },
    { label: 'Show Frequency Labels', key: 'showFrequencyLabels', type: 'checkbox' },
    { label: 'FFT Size', key: 'fftSize', type: 'number' },
    { label: 'Corner Radius', key: 'cornerRadius', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Drop Shadow', key: 'dropShadow', type: 'checkbox' },
    { label: 'Shadow Color', key: 'shadowColor', type: 'color' },
    { label: 'Shadow Blur', key: 'shadowBlur', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Outline', key: 'outline', type: 'checkbox' },
    { label: 'Outline Color', key: 'outlineColor', type: 'color' },
    { label: 'Outline Width', key: 'outlineWidth', type: 'number', min: 1, max: 10, step: 1 },
  ],
  midiMeter: [
    { label: 'Show Note Names', key: 'showNoteNames', type: 'checkbox' },
    { label: 'Color', key: 'color', type: 'color' },
    { label: 'Corner Radius', key: 'cornerRadius', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Drop Shadow', key: 'dropShadow', type: 'checkbox' },
    { label: 'Shadow Color', key: 'shadowColor', type: 'color' },
    { label: 'Shadow Blur', key: 'shadowBlur', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Outline', key: 'outline', type: 'checkbox' },
    { label: 'Outline Color', key: 'outlineColor', type: 'color' },
    { label: 'Outline Width', key: 'outlineWidth', type: 'number', min: 1, max: 10, step: 1 },
  ],
  consoleFeed: [
    { label: 'Data Source', key: 'dataSource', type: 'select', options: ['MIDI', 'LUFS/RMS', 'FFT Summary', 'All'] },
    { label: 'Font Size', key: 'fontSize', type: 'number', min: 8, max: 20, step: 1 },
    { label: 'Font Color', key: 'fontColor', type: 'color' },
    { label: 'Max Lines', key: 'maxLines', type: 'number', min: 10, max: 100, step: 1 },
    { label: 'Scroll Speed', key: 'scrollSpeed', type: 'number', min: 0.1, max: 5, step: 0.1 },
    { label: 'Glassmorphism Background', key: 'glassmorphism', type: 'checkbox' },
    { label: 'Corner Radius', key: 'cornerRadius', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Drop Shadow', key: 'dropShadow', type: 'checkbox' },
    { label: 'Shadow Color', key: 'shadowColor', type: 'color' },
    { label: 'Shadow Blur', key: 'shadowBlur', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Outline', key: 'outline', type: 'checkbox' },
    { label: 'Outline Color', key: 'outlineColor', type: 'color' },
    { label: 'Outline Width', key: 'outlineWidth', type: 'number', min: 1, max: 10, step: 1 },
  ],
  vuMeter: [
    { label: 'Color', key: 'color', type: 'color' },
    { label: 'Style', key: 'style', type: 'select', options: ['Needle', 'Bar'] },
    { label: 'Meter Type', key: 'meterType', type: 'select', options: ['RMS', 'Peak'] },
    { label: 'Glassmorphism Background', key: 'glassmorphism', type: 'checkbox' },
    { label: 'Corner Radius', key: 'cornerRadius', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Drop Shadow', key: 'dropShadow', type: 'checkbox' },
    { label: 'Shadow Color', key: 'shadowColor', type: 'color' },
    { label: 'Shadow Blur', key: 'shadowBlur', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Outline', key: 'outline', type: 'checkbox' },
    { label: 'Outline Color', key: 'outlineColor', type: 'color' },
    { label: 'Outline Width', key: 'outlineWidth', type: 'number', min: 1, max: 10, step: 1 },
  ],
  chromaWheel: [
    { label: 'Color Scheme', key: 'colorScheme', type: 'select', options: ['Classic', 'Rainbow', 'Viridis', 'Inferno'] },
    { label: 'Show Note Names', key: 'showNoteNames', type: 'checkbox' },
    { label: 'Glassmorphism Background', key: 'glassmorphism', type: 'checkbox' },
    { label: 'Corner Radius', key: 'cornerRadius', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Drop Shadow', key: 'dropShadow', type: 'checkbox' },
    { label: 'Shadow Color', key: 'shadowColor', type: 'color' },
    { label: 'Shadow Blur', key: 'shadowBlur', type: 'number', min: 0, max: 50, step: 1 },
    { label: 'Outline', key: 'outline', type: 'checkbox' },
    { label: 'Outline Color', key: 'outlineColor', type: 'color' },
    { label: 'Outline Width', key: 'outlineWidth', type: 'number', min: 1, max: 10, step: 1 },
  ],
};

// Add glassmorphism toggle to all overlays
Object.keys(OVERLAY_SETTINGS).forEach(type => {
  OVERLAY_SETTINGS[type].push({ label: 'Glassmorphism Background', key: 'glassmorphism', type: 'checkbox' });
});

// Add transient detector to waveform
OVERLAY_SETTINGS.waveform.push({ label: 'Show Transient Detector', key: 'showTransients', type: 'checkbox' });
OVERLAY_SETTINGS.waveform.push({ label: 'Transient Color', key: 'transientColor', type: 'color' });
OVERLAY_SETTINGS.waveform.push({ label: 'Transient Sensitivity', key: 'transientSensitivity', type: 'number', min: 0.01, max: 1, step: 0.01 });
// Add Lissajous mode to oscilloscope
OVERLAY_SETTINGS.oscilloscope.push({ label: 'Lissajous Stereo Mode', key: 'lissajous', type: 'checkbox' });

export function HudOverlayParameterModal({ overlay, onClose, onUpdate }: any) {
  const settings = overlay.settings || {};
  const settingsConfig = OVERLAY_SETTINGS[overlay.type] || [];

  function handleSettingChange(key: string, value: any) {
    onUpdate({ settings: { ...settings, [key]: value } });
  }

  // Custom drop area that accepts both features and audio stems
  const [{ isOver, canDrop }, drop] = useDrop({
    accept: ['feature', 'AUDIO_STEM'],
    drop: (item: any) => {
      if (item.type === 'AUDIO_STEM') {
        // Handle audio stem drop
        onUpdate({ stem: { id: item.id, name: item.name, stemType: item.stemType } });
      } else {
        // Handle feature drop (legacy)
        onUpdate({ stem: { id: item.id, name: item.stemType || item.id, stemType: item.stemType } });
      }
    },
    canDrop: () => true,
    collect: (monitor) => ({
      isOver: monitor.isOver(),
      canDrop: monitor.canDrop(),
    }),
  });

  const dropRef = React.useCallback((node: HTMLDivElement | null) => {
    drop(node);
  }, [drop]);

  return (
    <PortalModal title={`${overlay.type.charAt(0).toUpperCase() + overlay.type.slice(1)} Settings`} isOpen={true} onClose={onClose}>
      <div className="space-y-6">
        <div>
          <div className="font-bold text-xs mb-2 text-white/80">Audio Source</div>
          <div className="space-y-2">
            <div className="flex items-center justify-between">
              <label className="text-white/80 text-xs font-mono">Audio Stem</label>
              {/* Custom Drop Zone */}
                             <div
                 ref={dropRef}
                className={`
                  relative flex items-center justify-center w-8 h-6 rounded-full cursor-pointer
                  transition-all duration-200 ease-out
                  ${overlay.stem?.id 
                    ? 'bg-emerald-600/20 border-2 border-emerald-500/50 shadow-lg' 
                    : 'bg-stone-700/50 border-2 border-stone-600/50 shadow-inner'
                  }
                  ${isOver && canDrop 
                    ? 'scale-110 bg-emerald-500/30 border-emerald-400 shadow-lg ring-2 ring-emerald-400/50' 
                    : ''
                  }
                  ${!overlay.stem?.id && !isOver 
                    ? 'hover:bg-stone-600/60 hover:border-stone-500/60' 
                    : ''
                  }
                `}
                style={{
                  boxShadow: overlay.stem?.id 
                    ? `
                      inset 0 1px 0 rgba(255, 255, 255, 0.1),
                      inset 0 -1px 0 rgba(0, 0, 0, 0.2),
                      0 2px 4px rgba(0, 0, 0, 0.3),
                      0 0 8px rgba(16, 185, 129, 0.3)
                    `
                    : `
                      inset 0 1px 0 rgba(255, 255, 255, 0.05),
                      inset 0 -1px 0 rgba(0, 0, 0, 0.3),
                      0 1px 2px rgba(0, 0, 0, 0.2)
                    `,
                  background: overlay.stem?.id
                    ? 'linear-gradient(135deg, rgba(16, 185, 129, 0.2) 0%, rgba(16, 185, 129, 0.1) 100%)'
                    : 'linear-gradient(135deg, rgba(68, 64, 60, 0.5) 0%, rgba(41, 37, 36, 0.5) 100%)'
                }}
              >
                {!overlay.stem?.id && (
                  <div className={`
                    w-2 h-2 rounded-full transition-all duration-200
                    ${isOver && canDrop 
                      ? 'bg-emerald-400 scale-125' 
                      : 'bg-stone-400/50'
                    }
                  `} />
                )}
                {overlay.stem?.id && (
                  <div className="w-2 h-2 rounded-full bg-emerald-400 animate-pulse" />
                )}
              </div>
            </div>
            <div className="relative">
              <div className="text-xs text-white/80">Drop a stem here to drive this overlay</div>
              {/* Mapped Stem Badge */}
              {overlay.stem?.id && overlay.stem?.name && (
                <div className="absolute -top-2 -right-2 z-10">
                  <Badge 
                    className="bg-emerald-600/90 text-emerald-100 text-xs px-2 py-1 border border-emerald-500/50 shadow-lg"
                    style={{
                      boxShadow: '0 2px 4px rgba(0, 0, 0, 0.3), 0 0 8px rgba(16, 185, 129, 0.2)'
                    }}
                  >
                    <span className="mr-1">{overlay.stem.name}</span>
                    <button
                      onClick={(e) => {
                        e.stopPropagation();
                        onUpdate({ stem: null });
                      }}
                      className="ml-1 hover:bg-emerald-500/50 rounded-full p-0.5 transition-colors"
                    >
                      <X className="h-3 w-3" />
                    </button>
                  </Badge>
                </div>
              )}
            </div>
            {/* Drop hint */}
            {isOver && canDrop && !overlay.stem?.id && (
              <div className="text-xs text-emerald-400/80 font-mono animate-pulse">
                Drop to assign stem
              </div>
            )}
          </div>
        </div>
        {settingsConfig.length > 0 && (
          <div>
            <div className="font-bold text-xs mb-2 text-white/80">Overlay Settings</div>
            <div className="space-y-3">
              {settingsConfig.map(setting => (
                <div key={setting.key} className="flex items-center gap-2">
                  <label className="text-xs text-white/70 w-32">{setting.label}</label>
                  {setting.type === 'color' && (
                    <input 
                      type="color" 
                      value={settings[setting.key] ?? (
                        setting.key === 'gridColor' ? '#333333' : 
                        setting.key === 'shadowColor' ? '#000000' :
                        setting.key === 'outlineColor' ? '#ffffff' :
                        '#00ffff'
                      )} 
                      onChange={e => handleSettingChange(setting.key, e.target.value)} 
                    />
                  )}
                  {setting.type === 'number' && (setting.key === 'cornerRadius' || setting.key === 'shadowBlur' || setting.key === 'outlineWidth') && (
                    <div className="flex-1">
                      <Slider
                        value={[settings[setting.key] ?? (setting.key === 'cornerRadius' ? 8 : setting.key === 'shadowBlur' ? 8 : 1)]}
                        onValueChange={([value]) => handleSettingChange(setting.key, value)}
                        min={setting.min || 0}
                        max={setting.max || 50}
                        step={setting.step || 1}
                        className="w-full"
                      />
                      <div className="text-xs text-white/60 mt-1">
                        {settings[setting.key] ?? (setting.key === 'cornerRadius' ? 8 : setting.key === 'shadowBlur' ? 8 : 1)}
                      </div>
                    </div>
                  )}
                  {setting.type === 'number' && !(setting.key === 'cornerRadius' || setting.key === 'shadowBlur' || setting.key === 'outlineWidth') && (
                    <input 
                      type="number" 
                      value={settings[setting.key] ?? ''} 
                      onChange={e => handleSettingChange(setting.key, Number(e.target.value))} 
                      className="w-20 px-1 rounded" 
                    />
                  )}
                  {setting.type === 'slider' && (
                    <div className="flex-1">
                      <Slider
                        value={[settings[setting.key] ?? (setting.key === 'glowIntensity' ? 0 : setting.key === 'amplitude' ? 1 : setting.key === 'traceWidth' ? 2 : 0)]}
                        onValueChange={([value]) => handleSettingChange(setting.key, value)}
                        min={setting.key === 'amplitude' ? 0.1 : setting.key === 'traceWidth' ? 0.5 : 0}
                        max={setting.key === 'amplitude' ? 2 : setting.key === 'traceWidth' ? 2 : 5}
                        step={setting.key === 'amplitude' ? 0.01 : setting.key === 'traceWidth' ? 0.1 : 0.1}
                        className="w-full"
                      />
                      <div className="text-xs text-white/60 mt-1">
                        {settings[setting.key] ?? (setting.key === 'glowIntensity' ? 0 : setting.key === 'amplitude' ? 1 : setting.key === 'traceWidth' ? 2 : 0)}
                      </div>
                    </div>
                  )}
                  {setting.type === 'checkbox' && (
                    <input 
                      type="checkbox" 
                      checked={settings[setting.key] ?? (setting.key === 'showGrid' ? false : false)} 
                      onChange={e => handleSettingChange(setting.key, e.target.checked)} 
                    />
                  )}
                  {setting.type === 'select' && (
                    <select value={settings[setting.key] || setting.options?.[0]} onChange={e => handleSettingChange(setting.key, e.target.value)} className="px-1 rounded">
                      {setting.options?.map(opt => <option key={opt} value={opt}>{opt}</option>)}
                    </select>
                  )}
                </div>
              ))}
            </div>
          </div>
        )}
      </div>
    </PortalModal>
  );
}
</file>

<file path="components/layout/breadcrumb-nav.tsx">
"use client"

import { useEffect } from "react"
import { useRouter, usePathname } from "next/navigation"
import Link from "next/link"
import { cn } from "@/lib/utils"

interface BreadcrumbItem {
  label: string
  href: string
  icon?: string
}

interface BreadcrumbNavProps {
  items?: BreadcrumbItem[]
  className?: string
}

export function BreadcrumbNav({ items = [], className }: BreadcrumbNavProps) {
  const router = useRouter()
  const pathname = usePathname()

  // Auto-generate breadcrumbs from path if not provided
  const generatedItems = generateBreadcrumbs(pathname)
  const breadcrumbItems = items.length > 0 ? items : generatedItems

  // Keyboard shortcuts
  useEffect(() => {
    const handleKeyDown = (event: KeyboardEvent) => {
      if (event.ctrlKey || event.metaKey) {
        switch (event.key) {
          case 'b':
          case 'B':
            event.preventDefault()
            router.push('/dashboard')
            break
          case 'h':
          case 'H':
            event.preventDefault()
            router.push('/')
            break
        }
      }
    }

    window.addEventListener('keydown', handleKeyDown)
    return () => window.removeEventListener('keydown', handleKeyDown)
  }, [router])

  if (breadcrumbItems.length <= 1) {
    return null
  }

  return (
    <nav 
      className={cn("flex items-center space-x-2 text-sm font-mono text-stone-600", className)}
      aria-label="Breadcrumb"
    >
      {breadcrumbItems.map((item, index) => (
        <div key={item.href} className="flex items-center">
          {index > 0 && (
            <span className="mx-2 text-stone-400">/</span>
          )}
          {index === breadcrumbItems.length - 1 ? (
            // Current page - not a link
            <span className="flex items-center text-stone-800 font-medium">
              {item.icon && <span className="mr-1">{item.icon}</span>}
              {item.label}
            </span>
          ) : (
            // Previous pages - links
            <Link
              href={item.href}
              className="flex items-center text-stone-600 hover:text-stone-800 transition-colors"
            >
              {item.icon && <span className="mr-1">{item.icon}</span>}
              {item.label}
            </Link>
          )}
        </div>
      ))}
      
      {/* Keyboard shortcuts hint */}
      <div className="ml-6 text-xs text-stone-400 hidden lg:block">
        <span className="mr-3">B Dashboard</span>
        <span>H Home</span>
      </div>
    </nav>
  )
}

function generateBreadcrumbs(pathname: string): BreadcrumbItem[] {
  const segments = pathname.split('/').filter(Boolean)
  const items: BreadcrumbItem[] = [
    { label: 'Home', href: '/', icon: '' }
  ]

  let currentPath = ''
  
  for (let i = 0; i < segments.length; i++) {
    currentPath += `/${segments[i]}`
    const segment = segments[i]
    
    // Generate appropriate labels and icons based on route
    let label = segment
    let icon = ''
    
    switch (segment) {
      case 'dashboard':
        label = 'Dashboard'
        icon = ''
        break
      case 'projects':
        if (i === segments.length - 1) {
          label = 'Projects'
          icon = ''
        } else {
          // This is a project ID, try to get the actual project name
          const projectId = segments[i + 1]
          label = getProjectName(projectId) || `Project ${projectId.slice(0, 8)}`
          icon = ''
          currentPath += `/${projectId}`
          i++ // Skip the next segment as we've processed it
        }
        break
      case 'settings':
        label = 'Settings'
        icon = ''
        break
      case 'shared':
        label = 'Shared Project'
        icon = ''
        break
      case 'files':
        label = 'Files'
        icon = ''
        break
      case 'upload-demo':
        label = 'Upload Demo'
        icon = ''
        break
      case 'creative-visualizer':
        label = 'Visualizer'
        icon = ''
        break
      case 'profile':
        label = 'Profile'
        icon = ''
        break
      default:
        // Capitalize first letter
        label = segment.charAt(0).toUpperCase() + segment.slice(1)
        break
    }
    
    items.push({
      label,
      href: currentPath,
      icon
    })
  }
  
  return items
}

// Helper function to get project name (could be enhanced with tRPC query)
function getProjectName(projectId: string): string | null {
  // This would ideally be fetched from your project data
  // For now, return null to use the fallback
  return null
}

// Enhanced breadcrumb component with project quick switcher
interface EnhancedBreadcrumbNavProps extends BreadcrumbNavProps {
  currentProject?: any
  recentProjects?: any[]
  onProjectSwitch?: (projectId: string) => void
}

export function EnhancedBreadcrumbNav({ 
  currentProject, 
  recentProjects = [], 
  onProjectSwitch,
  ...props 
}: EnhancedBreadcrumbNavProps) {
  const router = useRouter()

  const handleProjectSwitch = (projectId: string) => {
    if (onProjectSwitch) {
      onProjectSwitch(projectId)
    } else {
      router.push(`/projects/${projectId}`)
    }
  }

  return (
    <div className="flex items-center justify-between">
      <BreadcrumbNav {...props} />
      
      {/* Project Quick Switcher */}
      {currentProject && recentProjects.length > 0 && (
        <div className="flex items-center space-x-2">
          <span className="text-xs font-mono text-stone-500">Quick Switch:</span>
          <select
            value={currentProject.id}
            onChange={(e) => handleProjectSwitch(e.target.value)}
            className="text-xs border border-stone-300 rounded px-2 py-1 bg-white text-stone-700 focus:outline-none focus:ring-1 focus:ring-blue-500"
          >
            <option value={currentProject.id}>{currentProject.name}</option>
            {recentProjects
              .filter(p => p.id !== currentProject.id)
              .slice(0, 5)
              .map(project => (
                <option key={project.id} value={project.id}>
                  {project.name}
                </option>
              ))
            }
          </select>
        </div>
      )}
    </div>
  )
}
</file>

<file path="components/layout/collapsible-effects-sidebar.tsx">
'use client';

import * as React from 'react';
import { ChevronsLeft, ChevronsRight, Palette } from 'lucide-react';
import { cn } from '@/lib/utils';

interface CollapsibleEffectsSidebarProps {
  children: React.ReactNode;
}

export function CollapsibleEffectsSidebar({ children }: CollapsibleEffectsSidebarProps) {
  const [isCollapsed, setIsCollapsed] = React.useState(false);

  const toggleSidebar = () => setIsCollapsed(!isCollapsed);

  return (
    <div
      className={cn(
        "relative bg-stone-900 border-l border-white/10 transition-all duration-300 ease-in-out z-20",
        isCollapsed ? "w-16" : "w-80"
      )}
    >
      <div className="h-full flex flex-col">
        {/* Header */}
        <div className={cn("flex items-center p-4 border-b border-white/10", isCollapsed ? 'justify-center' : 'justify-between')}>
          <div className={cn("flex items-center gap-2", isCollapsed && "hidden")}>
            <Palette className="h-5 w-5 text-white/70" />
            <span className="text-lg font-semibold text-white">Effects Library</span>
          </div>
          {isCollapsed && (
            <Palette className="h-6 w-6 text-white/70" />
          )}
        </div>

        {/* Content */}
        <div className="flex-1 overflow-hidden">
          {isCollapsed ? (
            <div className="flex justify-center items-center p-4 h-full">
              <div className="text-center space-y-3 text-white/50">
                <Palette className="w-8 h-8 mx-auto" />
                <div className="text-xs">Effects</div>
              </div>
            </div>
          ) : (
            children
          )}
        </div>
      </div>
      
      {/* Collapse/Expand Button */}
      <button
        onClick={toggleSidebar}
        className="absolute top-1/2 -translate-y-1/2 -left-4 w-8 h-28 bg-stone-800 hover:bg-stone-700 rounded-l-lg border-y border-l border-white/10 flex items-center justify-center transition-colors"
        aria-label="Toggle effects sidebar"
      >
        {isCollapsed ? <ChevronsLeft className="h-6 w-6 text-white/60" /> : <ChevronsRight className="h-6 w-6 text-white/60" />}
      </button>
    </div>
  );
}
</file>

<file path="components/layout/collapsible-sidebar.tsx">
'use client';

import * as React from 'react';
import { ChevronsLeft, ChevronsRight, Home, Folder, User, UploadCloud } from 'lucide-react';
import { cn } from '@/lib/utils';
import { PhonoglyphLogo } from '@/components/ui/phonoglyph-logo';

interface CollapsibleSidebarProps {
  children: React.ReactNode;
}

const NavLink = ({ href, icon: Icon, label, isCollapsed }: { href: string; icon: React.ElementType; label: string; isCollapsed: boolean }) => (
  <a
    href={href}
    className="flex items-center p-2 text-gray-300 rounded-lg hover:bg-gray-800 group"
  >
    <Icon className="w-6 h-6 text-gray-400 transition duration-75 group-hover:text-gray-200" />
    <span className={cn("ml-3", isCollapsed && "hidden")}>{label}</span>
  </a>
);

export function CollapsibleSidebar({ children }: CollapsibleSidebarProps) {
  const [isCollapsed, setIsCollapsed] = React.useState(false);

  const toggleSidebar = () => setIsCollapsed(!isCollapsed);

  return (
    <div
      className={cn(
        "relative bg-black border-r border-gray-800 transition-all duration-300 ease-in-out z-20",
        isCollapsed ? "w-24" : "w-64"
      )}
    >
      <div className="h-full flex flex-col p-4">
        <div className={cn("flex items-center mb-6", isCollapsed ? 'justify-center' : 'justify-between')}>
          <div className={cn("text-2xl font-semibold text-gray-100", isCollapsed && "hidden")}>
            <PhonoglyphLogo size="md" className="text-gray-100" />
          </div>
        </div>

        <nav className="flex-grow space-y-2">
            <NavLink href="/dashboard" icon={Home} label="Home" isCollapsed={isCollapsed} />
            <NavLink href="/files" icon={Folder} label="Files" isCollapsed={isCollapsed} />
            <NavLink href="/profile" icon={User} label="Profile" isCollapsed={isCollapsed} />
        </nav>

        <div className="flex-shrink-0">
          {isCollapsed ? (
            <div className="flex justify-center items-center p-4">
                <UploadCloud className="w-8 h-8 text-gray-400" />
            </div>
          ) : (
            children
          )}
        </div>
      </div>
      
      <button
        onClick={toggleSidebar}
        className="absolute top-1/2 -translate-y-1/2 -right-4 w-8 h-28 bg-gray-900 hover:bg-gray-800 rounded-r-lg border-y border-r border-gray-700 flex items-center justify-center transition-colors"
        aria-label="Toggle sidebar"
      >
        {isCollapsed ? <ChevronsRight className="h-6 w-6 text-gray-300" /> : <ChevronsLeft className="h-6 w-6 text-gray-300" />}
      </button>
    </div>
  );
}
</file>

<file path="components/midi/file-selector.tsx">
'use client';

import React, { useState } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { Switch } from '@/components/ui/switch';
import { Label } from '@/components/ui/label';
import { 
  FileMusic, 
  Upload, 
  Clock, 
  Music,
  AlertCircle,
  CheckCircle2,
  Loader2,
  Play,
  Users,
  Trash2
} from 'lucide-react';
import { trpc } from '@/lib/trpc';
import { useUpload } from '@/hooks/use-upload';
import { useToast } from '@/hooks/use-toast';
import { ConfirmationModal } from '@/components/ui/confirmation-modal';
import { DraggableFile } from '@/components/video-composition/DraggableFile';

interface FileMetadata {
  id: string;
  file_name: string;
  file_size: number;
  file_type: 'midi' | 'audio' | 'video' | 'image';
  mime_type: string;
  upload_status: 'uploading' | 'completed' | 'failed';
  processing_status?: 'pending' | 'completed' | 'failed';
  created_at: string;
  thumbnail_url?: string | null;
}

interface FileSelectorProps {
  onFileSelected: (fileId: string) => void;
  selectedFileId?: string;
  showUpload?: boolean;
  useDemoData: boolean;
  onDemoModeChange: (useDemoData: boolean) => void;
  projectId?: string;
  projectName?: string;
}

export function FileSelector({ 
  onFileSelected, 
  selectedFileId, 
  showUpload = true,
  useDemoData,
  onDemoModeChange,
  projectId,
  projectName
}: FileSelectorProps) {
  const [uploadExpanded, setUploadExpanded] = useState(false);
  const { toast } = useToast();
  const [deleteFileId, setDeleteFileId] = useState<string | null>(null);
  const [isDeleting, setIsDeleting] = useState(false);

  // Fetch user's files (project-scoped if projectId provided)
  const { 
    data: filesData, 
    isLoading: filesLoading, 
    error: filesError,
    refetch: refetchFiles
  } = trpc.file.getUserFiles.useQuery({
    limit: 20,
    fileType: 'all', // Show all file types, not just MIDI
    projectId: projectId
  });

  // Parse MIDI file mutation
  const parseMidiMutation = trpc.midi.parseMidiFile.useMutation({
    onSuccess: (result) => {
      if (result.success) {
        toast({
          title: "MIDI File Ready",
          description: "File parsed successfully and ready for visualization",
        });
        onFileSelected(result.midiFileId);
        onDemoModeChange(false);
        refetchFiles();
      }
    },
    onError: (error) => {
      toast({
        title: "Parsing Failed", 
        description: error.message,
        variant: "destructive"
      });
    }
  });

  // Upload integration
  const { addAndUploadFiles, files: uploadQueue, clearFiles } = useUpload({
    projectId: projectId, // NEW: Associate uploads with project
    onUploadComplete: (uploadFile) => {
      // Refresh the file list to show the newly uploaded file
      refetchFiles();
      
      // Only parse MIDI files
      if (uploadFile.fileId && !uploadFile.fileId.startsWith('mock_')) {
        // Check if it's a MIDI file before parsing
        const extension = uploadFile.file.name.toLowerCase().split('.').pop();
        if (extension && ['mid', 'midi'].includes(extension)) {
          parseMidiMutation.mutate({ fileId: uploadFile.fileId });
        }
      } else {
        toast({
          title: "Upload Demo",
          description: "File uploaded successfully! This is demo mode - parsing not available yet.",
          variant: "default"
        });
      }
    },
    onUploadError: (uploadFile, error) => {
      toast({
        title: "Upload Failed",
        description: `${uploadFile.file.name}: ${error}`,
        variant: "destructive"
      });
    }
  });

  const deleteFileMutation = trpc.file.deleteFile.useMutation({
    onSuccess: () => {
      toast({ title: 'File deleted', description: 'The file was deleted.' });
      setDeleteFileId(null);
      refetchFiles();
    },
    onError: (error) => {
      toast({ title: 'Delete failed', description: error.message, variant: 'destructive' });
      setDeleteFileId(null);
    },
    onSettled: () => setIsDeleting(false)
  });

  const handleDeleteFile = (fileId: string) => {
    setIsDeleting(true);
    deleteFileMutation.mutate({ fileId });
  };

  const handleFileUpload = async (files: File[]) => {
    const supportedFiles = files.filter((file: File) => {
      const ext = file.name.toLowerCase().split('.').pop();
      const midiExts = ['mid', 'midi'];
      const audioExts = ['mp3', 'wav', 'ogg', 'm4a', 'aac'];
      const videoExts = ['mp4', 'mov', 'avi', 'mkv', 'webm'];
      const imageExts = ['jpg', 'jpeg', 'png', 'gif', 'bmp', 'webp'];
      
      return [...midiExts, ...audioExts, ...videoExts, ...imageExts].includes(ext || '');
    });

    if (supportedFiles.length === 0) {
      toast({
        title: "Invalid Files",
        description: "Please select supported files (MIDI, audio, video, or image files)",
        variant: "destructive"
      });
      return;
    }

    await addAndUploadFiles(supportedFiles);
    setUploadExpanded(false);
  };

  const formatFileSize = (bytes: number) => {
    const sizes = ['B', 'KB', 'MB'];
    if (bytes === 0) return '0 B';
    const i = Math.floor(Math.log(bytes) / Math.log(1024));
    return Math.round(bytes / Math.pow(1024, i) * 100) / 100 + ' ' + sizes[i];
  };

  const formatDuration = (seconds: number | null) => {
    if (!seconds) return 'Unknown';
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  const StatusBadge = ({ file }: { file: FileMetadata }) => {
    let text = 'Uploading';
    let statusClass = 'pending';
    
    if (file.upload_status === 'completed') {
      if (file.file_type === 'midi') {
        if (file.processing_status === 'completed') {
          text = 'Ready';
          statusClass = 'completed';
        } else if (file.processing_status === 'failed') {
          text = 'Parse Failed';
          statusClass = 'failed';
        } else {
          text = 'Processing';
          statusClass = 'pending';
        }
      } else {
        text = 'Ready';
        statusClass = 'completed';
      }
    } else if (file.upload_status === 'failed') {
      text = 'Upload Failed';
      statusClass = 'failed';
    }
    
    return (
      <div className={`parsing-status ${statusClass}`}>
        {statusClass === 'pending' && <Loader2 className="h-3 w-3 animate-spin" />}
        {statusClass === 'completed' && <CheckCircle2 className="h-3 w-3" />}
        {statusClass === 'failed' && <AlertCircle className="h-3 w-3" />}
        {text}
      </div>
    );
  };

  const getFileIcon = (fileType: string) => {
    switch (fileType) {
      case 'midi': return <FileMusic className="h-4 w-4" />;
      case 'audio': return <Music className="h-4 w-4" />;
      case 'video': return <Play className="h-4 w-4" />;
      case 'image': return <Users className="h-4 w-4" />; // Using Users as placeholder for image
      default: return <FileMusic className="h-4 w-4" />;
    }
  };

  const userFiles = filesData?.files || [];

  return (
    <div className="bg-stone-900 border border-stone-700 rounded-none font-mono text-xs flex flex-col min-h-0" style={{ maxHeight: 420, overflow: 'hidden' }}>
      <div className="flex items-center justify-between px-3 py-2 border-b border-stone-700 bg-stone-900 text-stone-100">
        <h3 className="text-xs font-bold tracking-widest uppercase">{projectName ? `${projectName} - Files` : 'File Library'}</h3>
      </div>
      {/* File List with proper scrolling */}
      <div className="flex-1 min-h-0 overflow-y-auto" style={{ maxHeight: 320 }}>
        <div className="space-y-1 p-2">
          {filesError && <p className="text-red-400 text-xs">Error loading files.</p>}
          {!useDemoData && userFiles.length === 0 && !filesLoading && (
            <div className="text-center py-8 text-stone-400">
              <span className="text-2xl"></span>
              <p className="text-xs mt-1">No files uploaded yet</p>
            </div>
          )}
          {!useDemoData && userFiles.map((file: FileMetadata) => (
            <DraggableFile
              key={file.id}
              file={{
                id: file.id,
                name: file.file_name,
                file_type: file.file_type,
                file_size: file.file_size,
                uploading: file.upload_status === 'uploading',
              }}
              isSelected={selectedFileId === file.id}
              onClick={() => file.file_type === 'midi' && onFileSelected(file.id)}
              onDelete={() => setDeleteFileId(file.id)}
            />
          ))}
          {/* Demo data - only show when useDemoData is true */}
          {useDemoData && (
            <div className="flex items-center border border-stone-700 bg-stone-900 text-stone-100 font-mono text-xs h-8 px-2 gap-2 select-none" style={{ borderRadius: 2, minHeight: 32, maxHeight: 32 }}>
              <div className="flex-shrink-0 w-4 h-4 flex items-center justify-center"></div>
              <div className="truncate flex-1 font-bold" title="Creative Demo.mid" style={{ maxWidth: 120 }}>Creative Demo.mid</div>
              <div className="uppercase tracking-widest px-1 border border-stone-700 bg-transparent" style={{ borderRadius: 1 }}>midi</div>
              <div className="text-[10px] text-stone-400 font-mono px-1">1 KB</div>
            </div>
          )}
        </div>
      </div>
      {/* Upload Zone */}
      {!useDemoData && (
        <div className="border-t border-stone-700 p-2 bg-stone-900">
          <div 
            className="w-full border-2 border-dashed border-stone-700 rounded-none text-center cursor-pointer hover:bg-stone-800 hover:text-stone-100 transition-colors py-2"
            onClick={() => document.getElementById('file-upload-input')?.click()}
          >
            <div className="text-lg"></div>
            <div className="font-bold">Upload Files</div>
            <div className="text-[10px]">MIDI, audio, video, or images</div>
            <input
              id="file-upload-input"
              type="file"
              multiple
              accept=".mid,.midi,.mp3,.wav,.ogg,.m4a,.aac,.mp4,.mov,.avi,.mkv,.webm,.jpg,.jpeg,.png,.gif,.bmp,.webp"
              className="hidden"
              onChange={(e) => {
                const files = Array.from(e.target.files || []);
                if (files.length > 0) {
                  handleFileUpload(files);
                }
              }}
            />
          </div>
        </div>
      )}
      <ConfirmationModal
        isOpen={!!deleteFileId}
        onClose={() => setDeleteFileId(null)}
        onConfirm={() => deleteFileId && handleDeleteFile(deleteFileId)}
        title="Delete File?"
        description="Are you sure you want to delete this file? This action cannot be undone."
        confirmText={isDeleting ? 'Deleting...' : 'Delete'}
        confirmVariant="danger"
      />
    </div>
  );
}
</file>

<file path="components/midi/midi-controls.tsx">
'use client';

import React, { useState } from 'react';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { Play, Pause, Square, SkipBack, SkipForward, Settings, ZoomIn, ZoomOut } from 'lucide-react';

interface VisualizationSettings {
  colorScheme: 'sage' | 'slate' | 'dusty-rose' | 'mixed';
  pixelsPerSecond: number;
  showTrackLabels: boolean;
  showVelocity: boolean;
  minKey: number;
  maxKey: number;
}

interface MidiControlsProps {
  isPlaying: boolean;
  currentTime: number;
  duration: number;
  zoom: number;
  settings: VisualizationSettings;
  onPlayPause: () => void;
  onTimeChange: (time: number) => void;
  onZoomChange: (zoom: number) => void;
  onSettingsChange: (settings: VisualizationSettings) => void;
}

export function MidiControls({
  isPlaying,
  currentTime,
  duration,
  zoom,
  settings,
  onPlayPause,
  onTimeChange,
  onZoomChange,
  onSettingsChange
}: MidiControlsProps) {
  const [showSettings, setShowSettings] = useState(false);

  const handleStop = () => {
    onTimeChange(0);
  };

  const handleSkipBack = () => {
    onTimeChange(Math.max(0, currentTime - 10));
  };

  const handleSkipForward = () => {
    onTimeChange(Math.min(duration, currentTime + 10));
  };

  const handleZoomIn = () => {
    onZoomChange(zoom * 1.2);
  };

  const handleZoomOut = () => {
    onZoomChange(zoom / 1.2);
  };

  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  return (
    <div className="midi-controls flex items-center justify-between p-4 h-full">
      {/* Transport Controls */}
      <div className="flex items-center gap-2">
        <Button
          variant="ghost"
          size="sm"
          onClick={handleSkipBack}
          className="h-8 w-8 p-0"
        >
          <SkipBack className="h-4 w-4" />
        </Button>
        
        <Button
          variant="ghost"
          size="sm"
          onClick={onPlayPause}
          className="h-8 w-8 p-0"
        >
          {isPlaying ? (
            <Pause className="h-4 w-4" />
          ) : (
            <Play className="h-4 w-4" />
          )}
        </Button>
        
        <Button
          variant="ghost"
          size="sm"
          onClick={handleStop}
          className="h-8 w-8 p-0"
        >
          <Square className="h-4 w-4" />
        </Button>
        
        <Button
          variant="ghost"
          size="sm"
          onClick={handleSkipForward}
          className="h-8 w-8 p-0"
        >
          <SkipForward className="h-4 w-4" />
        </Button>

        {/* Time Display */}
        <div className="ml-4 font-mono text-sm text-gray-600">
          {formatTime(currentTime)} / {formatTime(duration)}
        </div>
      </div>

      {/* Zoom Controls */}
      <div className="flex items-center gap-2">
        <Button
          variant="ghost"
          size="sm"
          onClick={handleZoomOut}
          className="h-8 w-8 p-0"
        >
          <ZoomOut className="h-4 w-4" />
        </Button>
        
        <Badge variant="secondary" className="font-mono text-xs min-w-[60px] text-center">
          {(zoom * 100).toFixed(0)}%
        </Badge>
        
        <Button
          variant="ghost"
          size="sm"
          onClick={handleZoomIn}
          className="h-8 w-8 p-0"
        >
          <ZoomIn className="h-4 w-4" />
        </Button>

        {/* Settings Button */}
        <Button
          variant="ghost"
          size="sm"
          onClick={() => setShowSettings(!showSettings)}
          className="h-8 w-8 p-0 ml-2"
        >
          <Settings className="h-4 w-4" />
        </Button>
      </div>

      {/* Settings Panel */}
      {showSettings && (
        <div className="absolute top-full right-0 mt-2 w-80 p-4 bg-white/95 backdrop-blur-sm border border-gray-200 rounded-lg shadow-lg z-50">
          <h4 className="font-semibold text-gray-900 mb-3">Visualization Settings</h4>
          
          {/* Color Scheme */}
          <div className="mb-4">
            <label className="block text-sm font-medium text-gray-700 mb-2">
              Color Scheme
            </label>
            <div className="grid grid-cols-2 gap-2">
              {(['sage', 'slate', 'dusty-rose', 'mixed'] as const).map((scheme) => (
                <button
                  key={scheme}
                  onClick={() => onSettingsChange({ ...settings, colorScheme: scheme })}
                  className={`p-2 text-sm rounded border text-left capitalize ${
                    settings.colorScheme === scheme
                      ? 'border-blue-500 bg-blue-50'
                      : 'border-gray-200 hover:bg-gray-50'
                  }`}
                >
                  {scheme}
                </button>
              ))}
            </div>
          </div>

          {/* Pixels Per Second */}
          <div className="mb-4">
            <label className="block text-sm font-medium text-gray-700 mb-2">
              Time Scale: {settings.pixelsPerSecond}px/s
            </label>
            <input
              type="range"
              min={10}
              max={200}
              value={settings.pixelsPerSecond}
              onChange={(e) => onSettingsChange({ 
                ...settings, 
                pixelsPerSecond: parseInt(e.target.value) 
              })}
              className="w-full"
            />
          </div>

          {/* Toggle Options */}
          <div className="space-y-2 mb-4">
            <label className="flex items-center gap-2">
              <input
                type="checkbox"
                checked={settings.showTrackLabels}
                onChange={(e) => onSettingsChange({ 
                  ...settings, 
                  showTrackLabels: e.target.checked 
                })}
                className="rounded"
              />
              <span className="text-sm text-gray-700">Show Track Labels</span>
            </label>
            
            <label className="flex items-center gap-2">
              <input
                type="checkbox"
                checked={settings.showVelocity}
                onChange={(e) => onSettingsChange({ 
                  ...settings, 
                  showVelocity: e.target.checked 
                })}
                className="rounded"
              />
              <span className="text-sm text-gray-700">Show Velocity</span>
            </label>
          </div>

          {/* Key Range */}
          <div className="mb-4">
            <label className="block text-sm font-medium text-gray-700 mb-2">
              Key Range: {settings.minKey} - {settings.maxKey}
            </label>
            <div className="grid grid-cols-2 gap-2">
              <div>
                <label className="block text-xs text-gray-500 mb-1">Min Key</label>
                <input
                  type="number"
                  min={0}
                  max={127}
                  value={settings.minKey}
                  onChange={(e) => onSettingsChange({ 
                    ...settings, 
                    minKey: Math.min(parseInt(e.target.value), settings.maxKey)
                  })}
                  className="w-full p-1 text-sm border border-gray-200 rounded"
                />
              </div>
              <div>
                <label className="block text-xs text-gray-500 mb-1">Max Key</label>
                <input
                  type="number"
                  min={0}
                  max={127}
                  value={settings.maxKey}
                  onChange={(e) => onSettingsChange({ 
                    ...settings, 
                    maxKey: Math.max(parseInt(e.target.value), settings.minKey)
                  })}
                  className="w-full p-1 text-sm border border-gray-200 rounded"
                />
              </div>
            </div>
          </div>

          <Button
            variant="outline"
            size="sm"
            onClick={() => setShowSettings(false)}
            className="w-full"
          >
            Close
          </Button>
        </div>
      )}
    </div>
  );
}
</file>

<file path="components/midi/midi-timeline.tsx">
'use client';

import React, { useRef, useCallback } from 'react';

interface TempoChange {
  tick: number;
  bpm: number;
  microsecondsPerQuarter: number;
}

interface MidiTimelineProps {
  duration: number;
  currentTime: number;
  pixelsPerSecond: number;
  zoom: number;
  tempoChanges: TempoChange[];
  onTimeChange: (time: number) => void;
}

export function MidiTimeline({
  duration,
  currentTime,
  pixelsPerSecond,
  zoom,
  tempoChanges,
  onTimeChange
}: MidiTimelineProps) {
  const timelineRef = useRef<HTMLDivElement>(null);

  const width = Math.max(1200, duration * pixelsPerSecond * zoom);

  // Convert time to X position
  const timeToX = useCallback((time: number) => {
    return time * pixelsPerSecond * zoom;
  }, [pixelsPerSecond, zoom]);

  // Convert X position to time
  const xToTime = useCallback((x: number) => {
    return x / (pixelsPerSecond * zoom);
  }, [pixelsPerSecond, zoom]);

  // Handle timeline click
  const handleTimelineClick = useCallback((event: React.MouseEvent) => {
    if (!timelineRef.current) return;
    
    const rect = timelineRef.current.getBoundingClientRect();
    const x = event.clientX - rect.left;
    const time = xToTime(x);
    
    onTimeChange(Math.max(0, Math.min(duration, time)));
  }, [xToTime, onTimeChange, duration]);

  // Format time for display
  const formatTime = useCallback((seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    const ms = Math.floor((seconds % 1) * 100);
    return `${mins}:${secs.toString().padStart(2, '0')}.${ms.toString().padStart(2, '0')}`;
  }, []);

  // Generate time markers
  const generateTimeMarkers = useCallback(() => {
    const markers = [];
    const interval = zoom > 2 ? 1 : zoom > 1 ? 5 : 10; // Adjust interval based on zoom
    
    for (let time = 0; time <= duration; time += interval) {
      const x = timeToX(time);
      const isMinute = time % 60 === 0;
      
      markers.push({
        time,
        x,
        label: formatTime(time),
        isMajor: isMinute || interval <= 1
      });
    }
    
    return markers;
  }, [duration, zoom, timeToX, formatTime]);

  const timeMarkers = generateTimeMarkers();

  return (
    <div 
      ref={timelineRef}
      className="midi-timeline relative w-full h-full bg-white/80 backdrop-blur-sm overflow-hidden cursor-pointer"
      style={{ width: `${width}px` }}
      onClick={handleTimelineClick}
    >
      {/* Time markers */}
      <div className="absolute inset-0">
        {timeMarkers.map((marker, index) => (
          <div
            key={index}
            className="absolute top-0 flex flex-col items-center"
            style={{ left: `${marker.x}px` }}
          >
            {/* Tick mark */}
            <div
              className={`bg-gray-400 ${
                marker.isMajor ? 'w-0.5 h-4' : 'w-px h-2'
              }`}
            />
            
            {/* Time label */}
            {marker.isMajor && (
              <span className="text-xs text-gray-600 font-mono mt-1 select-none">
                {marker.label}
              </span>
            )}
          </div>
        ))}
      </div>

      {/* Tempo changes */}
      <div className="absolute top-0 w-full h-full">
        {tempoChanges.map((tempoChange, index) => {
          // Convert tick to time (simplified - would need actual conversion)
          const time = (tempoChange.tick / 480) * (60 / 120); // Assuming 480 PPQ and 120 BPM base
          const x = timeToX(time);
          
          return (
            <div
              key={index}
              className="absolute top-0 flex flex-col items-center group"
              style={{ left: `${x}px` }}
            >
              {/* Tempo marker */}
              <div className="w-2 h-2 bg-amber-500 rounded-full mt-1" />
              
              {/* Tempo tooltip */}
              <div className="absolute top-full mt-1 px-2 py-1 bg-gray-900 text-white text-xs rounded opacity-0 group-hover:opacity-100 transition-opacity whitespace-nowrap z-10">
                {tempoChange.bpm} BPM
              </div>
            </div>
          );
        })}
      </div>

      {/* Current time indicator */}
      <div
        className="absolute top-0 w-0.5 h-full bg-red-500 z-20 pointer-events-none"
        style={{ left: `${timeToX(currentTime)}px` }}
      >
        {/* Playhead triangle */}
        <div className="absolute -top-1 -left-1 w-0 h-0 border-l-2 border-r-2 border-b-3 border-transparent border-b-red-500" />
        
        {/* Current time label */}
        <div className="absolute top-5 -left-8 bg-red-500 text-white text-xs px-1 py-0.5 rounded whitespace-nowrap">
          {formatTime(currentTime)}
        </div>
      </div>

      {/* Background grid lines */}
      <div className="absolute inset-0 pointer-events-none">
        {timeMarkers
          .filter(marker => marker.isMajor)
          .map((marker, index) => (
            <div
              key={index}
              className="absolute top-0 w-px h-full bg-gray-200"
              style={{ left: `${marker.x}px` }}
            />
          ))}
      </div>

      {/* Hover time indicator */}
      <div className="absolute inset-0 group">
        <div className="absolute top-0 w-px h-full bg-blue-400 opacity-0 group-hover:opacity-50 transition-opacity pointer-events-none" />
      </div>
    </div>
  );
}
</file>

<file path="components/midi/three-visualizer.tsx">
'use client';

import React, { useRef, useEffect, useState, useCallback } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { Play, Pause, Settings, Maximize, Download } from 'lucide-react';
import { cn, debugLog } from '@/lib/utils';
import { VisualizerManager } from '@/lib/visualizer/core/VisualizerManager';
import { EffectRegistry } from '@/lib/visualizer/effects/EffectRegistry';
import '@/lib/visualizer/effects/EffectDefinitions';
import { MIDIData, VisualizationSettings } from '@/types/midi';
import { VisualizerConfig, LiveMIDIData, AudioAnalysisData, VisualEffect, AspectRatioConfig } from '@/types/visualizer';
import { PortalModal } from '@/components/ui/portal-modal';
import { EffectCarousel } from '@/components/ui/effect-carousel';
import { Slider } from '@/components/ui/slider';
import { Label } from '@/components/ui/label';
import { Switch } from '@/components/ui/switch';
import { DroppableParameter } from '@/components/ui/droppable-parameter';
import { getAspectRatioConfig, calculateCanvasSize } from '@/lib/visualizer/aspect-ratios';
import { Layer } from '@/types/video-composition';

interface ThreeVisualizerProps {
  midiData: MIDIData;
  settings: VisualizationSettings;
  currentTime: number;
  isPlaying: boolean;
  onPlayPause: () => void;
  onSettingsChange: (settings: VisualizationSettings) => void;
  onFpsUpdate?: (fps: number) => void;
  className?: string;
  selectedEffects: Record<string, boolean>;
  onSelectedEffectsChange: (updater: (prev: Record<string, boolean>) => Record<string, boolean>) => void;
  aspectRatio?: string; // Changed from 'mobile' | 'youtube' to string for modularity
  // Modal and mapping props
  openEffectModals: Record<string, boolean>;
  onCloseEffectModal: (effectId: string) => void;
  mappings: Record<string, { featureId: string | null; modulationAmount: number }>;
  featureNames: Record<string, string>;
  onMapFeature: (parameterId: string, featureId: string) => void;
  onUnmapFeature: (parameterId: string) => void;
  onModulationAmountChange?: (parameterId: string, amount: number) => void;
  activeSliderValues: Record<string, number>;
  setActiveSliderValues: React.Dispatch<React.SetStateAction<Record<string, number>>>;
  visualizerRef?: React.RefObject<VisualizerManager> | ((instance: VisualizerManager | null) => void);
  layers: Layer[];
  selectedLayerId?: string | null;
  onLayerSelect?: (layerId: string) => void;
  onLayerUpdate?: (layerId: string, updates: Partial<Layer>) => void;
}

export function ThreeVisualizer({
  midiData,
  settings,
  currentTime,
  isPlaying,
  onPlayPause,
  onSettingsChange,
  onFpsUpdate,
  className,
  selectedEffects,
  onSelectedEffectsChange,
  aspectRatio = 'mobile',
  openEffectModals,
  onCloseEffectModal,
  mappings,
  featureNames,
  onMapFeature,
  onUnmapFeature,
  onModulationAmountChange,
  activeSliderValues,
  setActiveSliderValues,
  visualizerRef: externalVisualizerRef,
  layers,
  selectedLayerId,
  onLayerSelect,
  onLayerUpdate
}: ThreeVisualizerProps) {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const containerRef = useRef<HTMLDivElement>(null);
  const internalVisualizerRef = useRef<VisualizerManager | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [isInitialized, setIsInitialized] = useState(false);
  const [canvasSize, setCanvasSize] = useState({ width: 400, height: 711 });
  const [containerSize, setContainerSize] = useState({ width: 0, height: 0 });
  const effectInstancesRef = useRef<{ [id: string]: VisualEffect }>({});
  
  // Get aspect ratio configuration
  const aspectRatioConfig = getAspectRatioConfig(aspectRatio);
  
  // Resize observer for container size changes
  useEffect(() => {
    if (!containerRef.current) return;
    
    const resizeObserver = new ResizeObserver((entries) => {
      for (const entry of entries) {
        const { width, height } = entry.contentRect;
        setContainerSize({ width, height });
      }
    });
    
    resizeObserver.observe(containerRef.current);
    
    return () => {
      resizeObserver.disconnect();
    };
  }, []);
  
  // Calculate canvas size when container size or aspect ratio changes
  useEffect(() => {
    if (containerSize.width > 0 && containerSize.height > 0) {
      const newCanvasSize = calculateCanvasSize(
        containerSize.width,
        containerSize.height,
        aspectRatioConfig
      );
      setCanvasSize(newCanvasSize);
    }
  }, [containerSize, aspectRatioConfig]);
  
  // Update visualizer when canvas size changes
  useEffect(() => {
    if (internalVisualizerRef.current && canvasSize.width > 0 && canvasSize.height > 0) {
      const visualizer = internalVisualizerRef.current;
      visualizer.handleViewportResize(canvasSize.width, canvasSize.height);
      debugLog.log(' Canvas resized to:', canvasSize.width, 'x', canvasSize.height, 'aspect:', canvasSize.width / canvasSize.height);
    }
  }, [canvasSize]);

  // Initialize visualizer
  useEffect(() => {
    if (!canvasRef.current || isInitialized) return;

    try {
      debugLog.log(' Initializing ThreeVisualizer with aspect ratio:', aspectRatio);
    
    const config: VisualizerConfig = {
      canvas: {
          width: canvasSize.width,
          height: canvasSize.height,
        pixelRatio: Math.min(window.devicePixelRatio, 2)
      },
        aspectRatio: aspectRatioConfig,
      performance: {
          targetFPS: 60,
          enableBloom: true,
          enableShadows: false
      },
      midi: {
        velocitySensitivity: 1.0,
        noteTrailDuration: 2.0,
        trackColorMapping: {}
      }
    };

      internalVisualizerRef.current = new VisualizerManager(canvasRef.current, config);
      

      
      // Enable selected effects
      Object.entries(selectedEffects).forEach(([effectId, enabled]) => {
        if (enabled) {
          internalVisualizerRef.current?.enableEffect(effectId);
        } else {
          internalVisualizerRef.current?.disableEffect(effectId);
        }
      });

      setIsInitialized(true);
      debugLog.log(' ThreeVisualizer initialized successfully');
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'Unknown error occurred';
      setError(errorMessage);
      debugLog.error(' Failed to initialize ThreeVisualizer:', err);
    }
  }, [canvasSize, aspectRatioConfig]);

  // Dynamic scene synchronization
  useEffect(() => {
    if (!internalVisualizerRef.current) return;
    const manager = internalVisualizerRef.current;
    debugLog.log('[ThreeVisualizer] layers prop:', layers, layers.map(l => l.type));
    const effectLayers = layers.filter(l => l.type === 'effect');
    debugLog.log('[ThreeVisualizer] effectLayers:', effectLayers);
    const currentIds = Object.keys(effectInstancesRef.current);
    const newIds = effectLayers.map(l => l.id);

    // Remove effects not in layers
    for (const id of currentIds) {
      if (!newIds.includes(id)) {
        manager.removeEffect(id);
        delete effectInstancesRef.current[id];
        debugLog.log(`[ThreeVisualizer] Removed effect instance: ${id}`);
      }
    }

    // Add new effects from layers using registry system
    for (const layer of effectLayers) {
      if (!effectInstancesRef.current[layer.id]) {
        debugLog.log('[ThreeVisualizer] Creating effect for layer:', layer);
        const effect = EffectRegistry.createEffect(layer.effectType || 'metaballs', layer.settings);
        if (effect) {
          effectInstancesRef.current[layer.id] = effect;
          // Add effect with its internal ID (e.g., 'particleNetwork', 'metaballs')
          manager.addEffect(effect);
          debugLog.log(`[ThreeVisualizer] Added effect instance: ${layer.id} (${layer.effectType}) with effect ID: ${effect.id}`);
        } else {
          debugLog.warn(`[ThreeVisualizer] Failed to create effect: ${layer.effectType} for layer: ${layer.id}`);
        }
      }
    }

    // If no effect layers, remove all effects
    if (effectLayers.length === 0) {
      for (const id of Object.keys(effectInstancesRef.current)) {
        manager.removeEffect(id);
        delete effectInstancesRef.current[id];
        debugLog.log(`[ThreeVisualizer] Removed effect instance (all cleared): ${id}`);
      }
    }
  }, [layers, internalVisualizerRef.current]);

  // Expose visualizer ref to parent
  useEffect(() => {
    if (externalVisualizerRef && internalVisualizerRef.current) {
      if (typeof externalVisualizerRef === 'function') {
        externalVisualizerRef(internalVisualizerRef.current);
      } else if (externalVisualizerRef && 'current' in externalVisualizerRef) {
        (externalVisualizerRef as any).current = internalVisualizerRef.current;
      }
    }
  }, [externalVisualizerRef, isInitialized]);

  // Handle play/pause
  useEffect(() => {
    if (!internalVisualizerRef.current) return;

    if (isPlaying) {
      internalVisualizerRef.current.play();
    } else {
      internalVisualizerRef.current.pause();
    }
  }, [isPlaying]);

  // Update MIDI data
  useEffect(() => {
    if (!internalVisualizerRef.current || !midiData) return;
    
         const liveMidiData: LiveMIDIData = {
       currentTime,
       activeNotes: midiData.tracks.flatMap(track => 
         track.notes.filter(note => 
           note.start <= currentTime && note.start + note.duration >= currentTime
         ).map(note => ({
           note: note.pitch,
           velocity: note.velocity,
           track: track.id,
           startTime: note.start
         }))
       ),
       tempo: 120, // Default tempo
       totalNotes: midiData.tracks.reduce((sum, track) => sum + track.notes.length, 0),
       trackActivity: midiData.tracks.reduce((acc, track) => {
         acc[track.id] = track.notes.filter(note => 
           note.start <= currentTime && note.start + note.duration >= currentTime
         ).length > 0;
         return acc;
       }, {} as Record<string, boolean>)
     };
    
    internalVisualizerRef.current.updateMIDIData(liveMidiData);
  }, [midiData, currentTime]);

  // Update FPS
  useEffect(() => {
    if (!internalVisualizerRef.current || !onFpsUpdate) return;

    const interval = setInterval(() => {
      const fps = internalVisualizerRef.current?.getFPS() || 60;
      onFpsUpdate(fps);
    }, 1000);

    return () => clearInterval(interval);
  }, [onFpsUpdate]);

 

  // Handle effect parameter changes
  const handleParameterChange = (effectId: string, paramName: string, value: any) => {
    if (!internalVisualizerRef.current) return;
    
    internalVisualizerRef.current.updateEffectParameter(effectId, paramName, value);
    
    // Update active slider values
      const paramKey = `${effectId}-${paramName}`;
    setActiveSliderValues(prev => ({ ...prev, [paramKey]: value }));
  };

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      if (internalVisualizerRef.current) {
        internalVisualizerRef.current.dispose();
      }
    };
  }, []);

  if (error) {
    return <ErrorDisplay message={error} />;
  }

  // Helper: is the project truly empty (all layers are empty image lanes)?
  const allLayersEmpty = layers.length === 0 || layers.every(l => l.type === 'image' && !l.src);

  return (
    <div 
      ref={containerRef}
      className={cn(
        "relative w-full h-full flex items-center justify-center",
        className
      )}
      style={{
        minHeight: '200px',
        aspectRatio: `${aspectRatioConfig.width}/${aspectRatioConfig.height}`
      }}
    >
      {/* Canvas container with proper sizing */}
      <div 
        className="relative bg-stone-900 rounded-lg overflow-hidden shadow-lg"
        style={{
          width: `${canvasSize.width}px`,
          height: `${canvasSize.height}px`,
          maxWidth: '100%',
          maxHeight: '100%',
          pointerEvents: 'auto', // Ensure overlays receive pointer events
          zIndex: 10 // Ensure overlays are above the canvas
        }}
        >
        <canvas 
          ref={canvasRef} 
          className="absolute top-0 left-0 w-full h-full"
          style={{
            width: `${canvasSize.width}px`,
            height: `${canvasSize.height}px`,
            pointerEvents: 'none', // Only the canvas ignores pointer events
            zIndex: 1
          }}
        />
        {/* Show prompt if all layers are empty */}
        {allLayersEmpty && (
          <div className="absolute inset-0 flex items-center justify-center z-20 pointer-events-auto">
            <span className="text-white/60 text-sm font-mono text-center select-none">
              Add your first layer
            </span>
          </div>
        )}
        {/* Modals are now rendered within the full-width edit canvas */}
        {Object.entries(openEffectModals).map(([effectId, isOpen], index) => {
          if (!isOpen) return null;
          const effectInstance = internalVisualizerRef.current?.getAllEffects().find((e: any) => e.id === effectId);
          if (!effectInstance) return null;
          const sortedParams = Object.entries(effectInstance.parameters).sort(([, a], [, b]) => {
            if (typeof a === 'boolean' && typeof b !== 'boolean') return -1;
            if (typeof a !== 'boolean' && typeof b === 'boolean') return 1;
            return 0;
          });
          const initialPos = {
            x: 100 + (index * 50),
            y: 100 + (index * 50)
          };
          return (
            <PortalModal
              key={effectId}
              title={effectInstance.name.replace(' Effect', '')}
              isOpen={isOpen}
              onClose={() => onCloseEffectModal(effectId)}
              initialPosition={initialPos}
              bounds="#editor-bounds"
            >
              <div className="space-y-4">
                <div className="text-sm text-white/80 mb-4">{effectInstance.description}</div>
                {sortedParams.length === 0 ? (
                  <div className="text-white/60 text-xs font-mono text-center py-4">No configurable parameters.</div>
                ) : (
                  sortedParams.map(([paramName, value]) => {
                    if (typeof value === 'boolean') {
                      return (
                        <div key={paramName} className="flex items-center justify-between">
                          <Label className="text-white/80 text-xs font-mono">{paramName}</Label>
                          <Switch
                            checked={value}
                            onCheckedChange={(checked) => handleParameterChange(effectId, paramName, checked)}
                          />
                        </div>
                      );
                    }
                    if (typeof value === 'number') {
                      const paramKey = `${effectId}-${paramName}`;
                      const mapping = mappings[paramKey];
                      const mappedFeatureId = mapping?.featureId || null;
                      const mappedFeatureName = mappedFeatureId ? featureNames[mappedFeatureId] : undefined;
                      const modulationAmount = mapping?.modulationAmount || 1.0;
                      return (
                        <DroppableParameter
                          key={paramKey}
                          parameterId={paramKey}
                          label={paramName}
                          mappedFeatureId={mappedFeatureId}
                          mappedFeatureName={mappedFeatureName}
                          modulationAmount={modulationAmount}
                          onFeatureDrop={onMapFeature}
                          onFeatureUnmap={onUnmapFeature}
                          onModulationAmountChange={onModulationAmountChange}
                          className="mb-2"
                          dropZoneStyle="inlayed"
                          showTagOnHover
                        >
                          <Slider
                            value={[activeSliderValues[paramKey] ?? value]}
                            onValueChange={([val]) => {
                              setActiveSliderValues(prev => ({ ...prev, [paramKey]: val }));
                              handleParameterChange(effectId, paramName, val);
                            }}
                            min={0}
                            max={getSliderMax(paramName)}
                            step={getSliderStep(paramName)}
                            className="w-full"
                          />
                        </DroppableParameter>
                      );
                    }
                    if ((paramName === 'highlightColor' || paramName === 'particleColor') && Array.isArray(value)) {
                      const displayName = paramName === 'highlightColor' ? 'Highlight Color' : 'Particle Color';
                      return (
                        <div key={paramName} className="space-y-2">
                          <Label className="text-white/90 text-sm font-medium flex items-center justify-between">
                            {displayName}
                            <span className="ml-2 w-6 h-6 rounded-full border border-white/40 inline-block" style={{ background: `rgb(${value.map((v) => Math.round(v * 255)).join(',')})` }} />
                          </Label>
                          <input
                            type="color"
                            value={`#${value.map((v) => Math.round(v * 255).toString(16).padStart(2, '0')).join('')}`}
                            onChange={e => {
                              const hex = e.target.value;
                              const rgb = [
                                parseInt(hex.slice(1, 3), 16) / 255,
                                parseInt(hex.slice(3, 5), 16) / 255,
                                parseInt(hex.slice(5, 7), 16) / 255
                              ];
                              handleParameterChange(effectId, paramName, rgb);
                            }}
                            className="w-12 h-8 rounded border border-white/30 bg-transparent cursor-pointer"
                          />
                        </div>
                      );
                    }
                    return null;
                  })
                )}
                <div className="pt-4 border-t border-white/20">
                  <div className="flex items-center justify-between">
                    <Label className="text-white/80 text-xs font-mono">Effect Enabled</Label>
                    <Switch 
                      checked={selectedEffects[effectId]}
                      onCheckedChange={(checked) => {
                        onSelectedEffectsChange(prev => ({
                          ...prev,
                          [effectId]: checked
                        }));
                      }}
                    />
                  </div>
                </div>
              </div>
            </PortalModal>
          );
        })}
      </div>
    </div>
  );
}

// Custom hook to force re-render
const useForceUpdate = () => {
  const [, setValue] = useState(0);
  return () => setValue(value => value + 1); 
};

function ErrorDisplay({ message }: { message: string }) {
  return (
    <div className="absolute inset-0 flex items-center justify-center bg-red-900/50 z-50">
      <Card className="bg-red-800/80 text-white p-4 max-w-md">
      <h3 className="text-lg font-semibold">An Error Occurred</h3>
      <p className="text-sm">{message}</p>
      <Button onClick={() => window.location.reload()} variant="secondary" className="mt-4">
        Refresh Page
      </Button>
      </Card>
    </div>
  );
}

function MainContent({ children, onMouseEnter, onMouseLeave }: { children: React.ReactNode, onMouseEnter: () => void, onMouseLeave: () => void }) {
  return (
    <div 
      className="relative aspect-[9/16] max-w-sm mx-auto bg-stone-900 rounded-lg overflow-hidden shadow-2xl" // removed border
      onMouseEnter={onMouseEnter}
      onMouseLeave={onMouseLeave}
    >
      {children}
    </div>
  );
}

function Canvas({ canvasRef }: { canvasRef: React.RefObject<HTMLCanvasElement> }) {
  return <canvas ref={canvasRef} className="absolute top-0 left-0 w-full h-full" />;
}

// Utility: getSliderMax for effect parameter sliders
function getSliderMax(paramName: string) {
  switch (paramName) {
    case 'animationSpeed': return 5.0;
    case 'noiseIntensity': return 2.0;
    case 'glowIntensity': return 2.0;
    case 'strength': return 2.0;
    case 'radius': return 2.0;
    case 'threshold': return 1.0;
    case 'particleLifetime': return 10;
    case 'particleSize': return 50;
    case 'glowSoftness': return 5;
    case 'particleSpawning': return 1.0;
    case 'spawnThreshold': return 1.0;
    case 'audioSpawnThreshold': return 1.0;
    case 'audioSpawnRate': return 1.0;
    case 'audioSpawnCooldown': return 1.0;
    case 'audioParticleSize': return 50;
    case 'audioSpawnIntensity': return 2.0;
    default: return 1;
  }
}

// Utility: getSliderStep for effect parameter sliders
function getSliderStep(paramName: string) {
  switch (paramName) {
    case 'animationSpeed': return 0.05;
    case 'noiseIntensity': return 0.1;
    case 'glowIntensity': return 0.1;
    case 'strength': return 0.1;
    case 'radius': return 0.05;
    case 'threshold': return 0.01;
    case 'glowSoftness': return 0.1;
    case 'particleSpawning': return 0.01;
    case 'spawnThreshold': return 0.01;
    case 'audioSpawnThreshold': return 0.01;
    case 'audioSpawnRate': return 0.01;
    case 'audioSpawnCooldown': return 0.01;
    case 'audioParticleSize': return 0.1;
    case 'audioSpawnIntensity': return 0.01;
    default: return 0.01;
  }
}
</file>

<file path="components/projects/project-creation-modal.tsx">
"use client"

import { useState } from "react"
import { useForm } from "react-hook-form"
import { zodResolver } from "@hookform/resolvers/zod"
import { Button } from "@/components/ui/button"
import { Input } from "@/components/ui/input"
import { Label } from "@/components/ui/label"
import { GlassModal } from "@/components/ui/glass-modal"
import { LoadingSpinner } from "@/components/ui/loading-spinner"
import { Badge } from "@/components/ui/badge"
import { createProjectSchema, type CreateProjectInput } from "@/lib/validations"
import { useToast } from "@/hooks/use-toast"
import { useUpload } from "@/hooks/use-upload"
import { useRouter } from "next/navigation"
import { trpc } from "@/lib/trpc"
import { 
  Music, 
  FileAudio, 
  FileMusic, 
  Upload, 
  Zap, 
  Clock, 
  DollarSign, 
  Target,
  ArrowRight,
  CheckCircle,
  XCircle,
  Minus
} from "lucide-react"
import { cn } from "@/lib/utils"
import { StatBar } from "@/components/ui/stat-bar"
import React from "react"
import { debugLog } from '@/lib/utils';

interface ProjectCreationModalProps {
  isOpen: boolean
  onClose: () => void
  defaultMidiFilePath?: string
}

type UploadMethod = 'single-audio' | 'stems'

interface UploadOption {
  id: UploadMethod
  title: string
  description: string
  icon: React.ReactNode
  stats: {
    complexity: number
    speed: number
    control: number
  }
  usesCredits: boolean
  color: string
  gradient: string
}

const uploadOptions: UploadOption[] = [
  {
    id: 'single-audio',
    title: 'Single Audio File',
    description: 'AI separates your audio into stems',
    icon: <Music className="h-6 w-6" />,
    stats: {
      complexity: 1,
      speed: 1,
      control: 1,
    },
    usesCredits: true,
    color: 'bg-emerald-600',
    gradient: 'from-emerald-600 to-emerald-700'
  },
  {
    id: 'stems',
    title: 'Stems',
    description: 'Upload pre-separated audio and/or MIDI stems for max control',
    icon: <FileAudio className="h-6 w-6" />,
    stats: {
      complexity: 3,
      speed: 5,
      control: 5,
    },
    usesCredits: false,
    color: 'bg-emerald-600',
    gradient: 'from-emerald-600 to-emerald-700'
  }
]

function StemsUpload({ 
  isLoading, 
  errors, 
  onFilesChange 
}: { 
  isLoading: boolean; 
  errors: any; 
  onFilesChange: (files: File[], masterFileName: string | null, stemTypes: Record<string, string>) => void;
}) {
  const [files, setFiles] = React.useState<File[]>([]);
  const [masterFileName, setMasterFileName] = React.useState<string | null>(null);
  const [stemTypes, setStemTypes] = React.useState<Record<string, string>>({});
  const fileInputRef = React.useRef<HTMLInputElement>(null);
  const [isDragActive, setIsDragActive] = React.useState(false);

  const stemTypeOptions = [
    { value: 'drums', label: 'Drums' },
    { value: 'bass', label: 'Bass' },
    { value: 'vocals', label: 'Vocals' },
    { value: 'melody', label: 'Melody' },
  ];

  const handleFileChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    if (e.target.files) {
      const newFiles = Array.from(e.target.files);
      setFiles(newFiles);
      // Auto-select master if only one file
      if (newFiles.length === 1) setMasterFileName(newFiles[0].name);
      // Reset stem types for new files
      const newStemTypes: Record<string, string> = {};
      newFiles.forEach(f => {
        // Try to guess stem type from file name
        const lower = f.name.toLowerCase();
        if (lower.includes('drum')) newStemTypes[f.name] = 'drums';
        else if (lower.includes('bass')) newStemTypes[f.name] = 'bass';
        else if (lower.includes('vocal')) newStemTypes[f.name] = 'vocals';
        else newStemTypes[f.name] = 'melody';
      });
      setStemTypes(newStemTypes);
      onFilesChange(newFiles, masterFileName, newStemTypes);
    }
  };

  const handleDrop = (e: React.DragEvent<HTMLDivElement>) => {
    e.preventDefault();
    setIsDragActive(false);
    if (e.dataTransfer.files && e.dataTransfer.files.length > 0) {
      const newFiles = Array.from(e.dataTransfer.files);
      setFiles(newFiles);
      // Auto-select master if only one file
      if (newFiles.length === 1) setMasterFileName(newFiles[0].name);
      // Reset stem types for new files
      const newStemTypes: Record<string, string> = {};
      newFiles.forEach(f => {
        const lower = f.name.toLowerCase();
        if (lower.includes('drum')) newStemTypes[f.name] = 'drums';
        else if (lower.includes('bass')) newStemTypes[f.name] = 'bass';
        else if (lower.includes('vocal')) newStemTypes[f.name] = 'vocals';
        else newStemTypes[f.name] = 'melody';
      });
      setStemTypes(newStemTypes);
      onFilesChange(newFiles, masterFileName, newStemTypes);
    }
  };

  const handleDragOver = (e: React.DragEvent<HTMLDivElement>) => {
    e.preventDefault();
    setIsDragActive(true);
  };

  const handleDragLeave = (e: React.DragEvent<HTMLDivElement>) => {
    e.preventDefault();
    setIsDragActive(false);
  };

  const handleBrowseClick = () => {
    fileInputRef.current?.click();
  };

  // When masterFileName or stemTypes change, notify parent
  React.useEffect(() => {
    onFilesChange(files, masterFileName, stemTypes);
  }, [files, masterFileName, stemTypes]);

  const handleStemTypeChange = (fileName: string, type: string) => {
    setStemTypes(prev => ({ ...prev, [fileName]: type }));
  };

  return (
    <div className="space-y-2">
      <Label htmlFor="stems-files" className="text-stone-200 font-medium">
        Stems (Audio and/or MIDI)
      </Label>
      <div
        className={cn(
          "flex flex-col items-center justify-center border-2 border-dashed rounded-lg p-6 transition-colors cursor-pointer bg-stone-800",
          isDragActive ? "border-emerald-400 bg-stone-700/80" : "border-stone-600 hover:border-emerald-400 hover:bg-stone-700/60"
        )}
        onClick={handleBrowseClick}
        onDrop={handleDrop}
        onDragOver={handleDragOver}
        onDragLeave={handleDragLeave}
        tabIndex={0}
        role="button"
        aria-label="File upload dropzone"
      >
        <div className="text-stone-300 text-sm mb-2 select-none">
          Drag and drop files here, or
        </div>
        <button
          type="button"
          className="px-4 py-2 bg-emerald-400 text-stone-900 font-bold rounded shadow hover:bg-emerald-300 focus:outline-none focus:ring-2 focus:ring-emerald-400"
          onClick={e => { e.stopPropagation(); handleBrowseClick(); }}
          disabled={isLoading}
        >
          Browse
        </button>
        <input
          id="stems-files"
          ref={fileInputRef}
          type="file"
          accept="audio/*,.mid,.midi"
          multiple
          disabled={isLoading}
          onChange={handleFileChange}
          className="hidden"
        />
      </div>
      <ul className="mt-2 space-y-1">
        {files.map((file) => (
          <li key={file.name} className="flex items-center gap-2 text-sm">
            <input
              type="radio"
              name="master-file"
              checked={masterFileName === file.name}
              onChange={() => setMasterFileName(file.name)}
              className="accent-emerald-500"
              disabled={isLoading}
            />
            <span className={masterFileName === file.name ? 'font-bold text-emerald-400' : ''}>
              {file.type.startsWith('audio/') ? '' : (file.name.endsWith('.mid') || file.name.endsWith('.midi')) ? '' : ''}
              {file.name}
              {masterFileName === file.name && <span className="ml-2 px-2 py-0.5 bg-emerald-600 text-xs rounded text-white">MASTER</span>}
            </span>
            {masterFileName !== file.name && (
              <>
                <select
                  value={stemTypes[file.name] || 'melody'}
                  onChange={e => handleStemTypeChange(file.name, e.target.value)}
                  className="ml-2 px-2 py-1 rounded border border-stone-600 bg-stone-900 text-stone-200 text-xs focus:outline-none focus:ring-emerald-400"
                  disabled={isLoading}
                >
                  {stemTypeOptions.map(opt => (
                    <option key={opt.value} value={opt.value}>{opt.label}</option>
                  ))}
                </select>
                <span className="ml-1 text-xs text-stone-400">{stemTypes[file.name] ? stemTypeOptions.find(o => o.value === stemTypes[file.name])?.label : 'Melody'}</span>
              </>
            )}
          </li>
        ))}
      </ul>
      <p className="text-xs text-stone-400">You can upload audio stems, MIDI stems, or both.</p>
      <p className="text-xs text-stone-400">
        <span className="font-bold text-emerald-400">Step 1:</span> Select the master track with the radio button. <br/>
        <span className="font-bold text-emerald-400">Step 2:</span> Categorize all other files as stems.
      </p>
      {errors && errors["stems-files"] && (
        <p className="text-sm text-red-600">{errors["stems-files"].message}</p>
      )}
      {!masterFileName && files.length > 0 && (
        <p className="text-sm text-red-500">Please select a master track.</p>
      )}
      {Object.values(stemTypes).filter(Boolean).length !== files.length && files.length > 0 && (
        <p className="text-sm text-red-500">Please tag each file with a stem type.</p>
      )}
    </div>
  );
}

function SingleAudioUpload({ isLoading, onFileChange }: { isLoading: boolean; onFileChange: (file: File | null) => void }) {
  const fileInputRef = React.useRef<HTMLInputElement>(null);
  const [isDragActive, setIsDragActive] = React.useState(false);
  const [selectedFile, setSelectedFile] = React.useState<File | null>(null);

  const handleFileChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    if (e.target.files && e.target.files[0]) {
      setSelectedFile(e.target.files[0]);
      onFileChange(e.target.files[0]);
    }
  };

  const handleDrop = (e: React.DragEvent<HTMLDivElement>) => {
    e.preventDefault();
    setIsDragActive(false);
    if (e.dataTransfer.files && e.dataTransfer.files[0]) {
      setSelectedFile(e.dataTransfer.files[0]);
      onFileChange(e.dataTransfer.files[0]);
    }
  };

  const handleDragOver = (e: React.DragEvent<HTMLDivElement>) => {
    e.preventDefault();
    setIsDragActive(true);
  };

  const handleDragLeave = (e: React.DragEvent<HTMLDivElement>) => {
    e.preventDefault();
    setIsDragActive(false);
  };

  const handleBrowseClick = () => {
    fileInputRef.current?.click();
  };

  return (
    <div className="space-y-2">
      <Label htmlFor="audio-file" className="text-stone-200 font-medium">
        Audio File
      </Label>
      <div
        className={cn(
          "flex flex-col items-center justify-center border-2 border-dashed rounded-lg p-6 transition-colors cursor-pointer bg-stone-800",
          isDragActive ? "border-emerald-400 bg-stone-700/80" : "border-stone-600 hover:border-emerald-400 hover:bg-stone-700/60"
        )}
        onClick={handleBrowseClick}
        onDrop={handleDrop}
        onDragOver={handleDragOver}
        onDragLeave={handleDragLeave}
        tabIndex={0}
        role="button"
        aria-label="File upload dropzone"
      >
        <div className="text-stone-300 text-sm mb-2 select-none">
          Drag and drop your audio file here, or
        </div>
        <button
          type="button"
          className="px-4 py-2 bg-emerald-400 text-stone-900 font-bold rounded shadow hover:bg-emerald-300 focus:outline-none focus:ring-2 focus:ring-emerald-400"
          onClick={e => { e.stopPropagation(); handleBrowseClick(); }}
          disabled={isLoading}
        >
          Browse
        </button>
        <input
          id="audio-file"
          ref={fileInputRef}
          type="file"
          accept="audio/*"
          disabled={isLoading}
          onChange={handleFileChange}
          className="hidden"
        />
      </div>
      {selectedFile && (
        <div className="mt-2 text-sm text-stone-200 flex items-center gap-2">
           {selectedFile.name}
        </div>
      )}
      <p className="text-xs text-stone-400">This will use credits. Only one audio file allowed.</p>
    </div>
  );
}

export function ProjectCreationModal({ isOpen, onClose, defaultMidiFilePath }: ProjectCreationModalProps) {
  const [selectedMethod, setSelectedMethod] = useState<UploadMethod | null>(null)
  const [isLoading, setIsLoading] = useState(false)
  const [showProjectForm, setShowProjectForm] = useState(false)
  const [selectedFiles, setSelectedFiles] = useState<File[]>([])
  const [masterFileName, setMasterFileName] = useState<string | null>(null)
  const [stemTypes, setStemTypes] = useState<Record<string, string>>({})
  const { toast } = useToast()
  const router = useRouter()
  const { addAndUploadFiles } = useUpload()

  const {
    register,
    handleSubmit,
    formState: { errors },
    reset,
    setValue,
    watch
  } = useForm({
    resolver: zodResolver(createProjectSchema),
    defaultValues: {
      privacy_setting: 'private' as const,
      midi_file_path: defaultMidiFilePath || '',
    }
  })

  const createProjectMutation = trpc.project.create.useMutation({
    onSuccess: (project) => {
      toast({
        title: "Project Created! ",
        description: `"${project.name}" is ready for your creative vision.`,
      })
      reset()
      onClose()
      // Navigate to creative visualizer with the new project loaded
      router.push(`/creative-visualizer?projectId=${project.id}`)
    },
    onError: (error) => {
      toast({
        title: "Creation Failed",
        description: error.message || "Failed to create project. Please try again.",
        variant: "destructive",
      })
    },
    onSettled: () => {
      setIsLoading(false)
    }
  })

  const uploadFileMutation = trpc.file.uploadFile.useMutation({
    onSuccess: (result) => {
      debugLog.log('File uploaded successfully:', result.fileId)
    },
    onError: (error) => {
      debugLog.error('Upload error:', error)
      throw error
    }
  })

  // Get tRPC utils for query invalidation
  const utils = trpc.useUtils()

  const onSubmit = async (data: any) => {
    if (selectedMethod === 'stems' && (!masterFileName || selectedFiles.length < 2 || Object.values(stemTypes).filter(Boolean).length !== selectedFiles.length)) {
      toast({
        title: "Missing Tags",
        description: "You must select a master track, upload at least two files, and tag each file with a stem type.",
        variant: "destructive",
      });
      return;
    }
    try {
      setIsLoading(true)
      debugLog.log('Form submission data:', data)
      
      // Use the actual form data
      const projectData = {
        name: data.name,
        description: data.description || '',
        privacy_setting: data.privacy_setting || 'private',
        render_configuration: data.render_configuration || {}
      };
      
      // Debug: Log the exact payload being sent
      debugLog.log('=== DEBUG PROJECT CREATION ===');
      debugLog.log('projectData to send:', JSON.stringify(projectData, null, 2));
      debugLog.log('projectData.name:', projectData.name);
      debugLog.log('projectData.name type:', typeof projectData.name);
      debugLog.log('=== END DEBUG ===');
      
      const project = await createProjectMutation.mutateAsync(projectData as CreateProjectInput)
      debugLog.log('Project created:', project.id)
      
      // Upload files if stems method is selected
      if (selectedMethod === 'stems' && selectedFiles.length > 0) {
        // Upload files using tRPC mutation with project ID
        const uploadPromises = selectedFiles.map(async (file) => {
          // Convert file to base64
          const base64Data = await new Promise<string>((resolve, reject) => {
            const reader = new FileReader()
            reader.onload = () => {
              const result = reader.result as string
              // Remove the data URL prefix
              const base64 = result.split(',')[1]
              resolve(base64)
            }
            reader.onerror = reject
            reader.readAsDataURL(file)
          })
          
          // Determine file type
          const extension = file.name.toLowerCase().split('.').pop()
          let fileType: 'midi' | 'audio' | 'video' | 'image'
          
          if (['mid', 'midi'].includes(extension || '')) {
            fileType = 'midi'
          } else if (['mp3', 'wav', 'ogg', 'm4a', 'aac'].includes(extension || '')) {
            fileType = 'audio'
          } else if (['mp4', 'mov', 'avi', 'mkv', 'webm'].includes(extension || '')) {
            fileType = 'video'
          } else if (['jpg', 'jpeg', 'png', 'gif', 'bmp', 'webp'].includes(extension || '')) {
            fileType = 'image'
          } else {
            throw new Error(`Unsupported file type: ${extension}`)
          }
          
          return uploadFileMutation.mutateAsync({
            fileName: file.name,
            fileType,
            mimeType: file.type || 'application/octet-stream',
            fileSize: file.size,
            fileData: base64Data,
            projectId: project.id, // Pass the project ID
            isMaster: file.name === masterFileName, // Tag master file
            stemType: file.name === masterFileName ? 'master' : (stemTypes[file.name] || 'melody') // Master files get 'master' type, others get their assigned type
          })
        })

        try {
          const uploadResults = await Promise.all(uploadPromises)
          const fileIds = uploadResults.map(result => result.fileId)
          
          // Invalidate file queries to refresh the sidebar
          utils.file.getUserFiles.invalidate()
          
        } catch (uploadError) {
          debugLog.error('Upload error:', uploadError)
          toast({
            title: "Upload Failed",
            description: "Some files failed to upload. Please try again.",
            variant: "destructive",
          })
          return
        }
      }
      
    } catch (error) {
      debugLog.error('Form submission error:', error)
      toast({
        title: "Upload Failed",
        description: error instanceof Error ? error.message : "Failed to upload files or create project.",
        variant: "destructive",
      })
    }
  }

  const handleClose = () => {
    if (!isLoading) {
      reset()
      setSelectedMethod(null)
      setShowProjectForm(false)
      onClose()
    }
  }

  const handleMethodSelect = (method: UploadMethod) => {
    setSelectedMethod(method)
    setShowProjectForm(true)
  }

  const getStatIcon = (stat: string) => {
    switch (stat) {
      case 'Easy':
      case 'Fast':
      case 'Free':
      case 'Maximum':
        return <CheckCircle className="h-4 w-4 text-green-500" />
      case 'Medium':
        return <Minus className="h-4 w-4 text-yellow-500" />
      case 'Hard':
      case 'Slow':
      case 'Credits':
      case 'Basic':
        return <XCircle className="h-4 w-4 text-red-500" />
      default:
        return null
    }
  }

  const getStatColor = (stat: string) => {
    switch (stat) {
      case 'Easy':
      case 'Fast':
      case 'Free':
      case 'Maximum':
        return 'text-green-600'
      case 'Medium':
        return 'text-yellow-600'
      case 'Hard':
      case 'Slow':
      case 'Credits':
      case 'Basic':
        return 'text-red-600'
      default:
        return 'text-gray-600'
    }
  }

  if (showProjectForm) {
    return (
      <GlassModal isOpen={isOpen} onClose={handleClose} sizeClassName="max-w-2xl min-h-[600px]">
        <div className="w-full h-full bg-stone-900 text-stone-200 font-mono border border-stone-700 rounded-xl max-h-[90vh] overflow-y-auto p-4 min-w-[340px]">
          <div className="space-y-6">
            <div>
              <div className="flex items-center gap-3 mb-2">
                <button
                  onClick={() => {
                    setShowProjectForm(false)
                    setSelectedMethod(null)
                  }}
                  className="p-1 hover:bg-gray-100 rounded-full transition-colors"
                >
                  <ArrowRight className="h-5 w-5 rotate-180" />
                </button>
                <h2 className="text-2xl font-bold mb-2 text-stone-100">Project Details</h2>
              </div>
              <p className="text-gray-600">
                Configure your {selectedMethod === 'single-audio' ? 'audio' : 'stems'} visualization project.
              </p>
            </div>
            <form onSubmit={handleSubmit(onSubmit)} className="space-y-6">
              {/* Validation Error Summary */}
              {Object.keys(errors).length > 0 && (
                <div className="p-3 bg-red-50 border border-red-200 rounded-md">
                  <p className="text-sm text-red-600 font-medium">Please fix the following errors:</p>
                  <ul className="mt-1 text-sm text-red-600 list-disc list-inside">
                    {Object.entries(errors).map(([field, error]) => (
                      <li key={field}>{error?.message?.toString() || 'Validation error'}</li>
                    ))}
                  </ul>
                </div>
              )}

              {/* Project Name */}
              <div className="space-y-2">
                <Label htmlFor="name" className="text-stone-200 font-medium">
                  Project Name *
                </Label>
                <Input
                  id="name"
                  placeholder="My Amazing Song"
                  {...register("name")}
                  disabled={isLoading}
                  className="bg-gray-50 border-gray-300 text-gray-900 placeholder:text-gray-500 focus:ring-blue-500 focus:border-blue-500"
                />
                {errors.name && (
                  <p className="text-sm text-red-600">{errors.name.message}</p>
                )}
              </div>

              {/* Description */}
              <div className="space-y-2">
                <Label htmlFor="description" className="text-stone-200 font-medium">
                  Description
                </Label>
                <textarea
                  id="description"
                  placeholder="Describe your project, inspiration, or creative vision..."
                  {...register("description")}
                  disabled={isLoading}
                  rows={3}
                  className="w-full px-3 py-2 bg-gray-50 border border-gray-300 rounded-md text-gray-900 placeholder:text-gray-500 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-blue-500 resize-none"
                />
                {errors.description && (
                  <p className="text-sm text-red-600">{errors.description.message}</p>
                )}
              </div>

              {/* Privacy Setting */}
              <div className="space-y-3">
                <Label className="text-stone-200 font-medium">Privacy Setting</Label>
                <div className="space-y-3">
                  <div className="flex items-start space-x-3">
                    <input
                      type="radio"
                      id="private"
                      value="private"
                      {...register("privacy_setting")}
                      disabled={isLoading}
                      className="mt-1 w-4 h-4 text-blue-600 border-gray-300 focus:ring-blue-500 focus:ring-2"
                    />
                    <div className="flex flex-col">
                      <Label htmlFor="private" className="text-stone-200 font-medium cursor-pointer">
                        Private
                      </Label>
                      <span className="text-sm text-gray-600">Only you can see this project</span>
                    </div>
                  </div>
                  <div className="flex items-start space-x-3">
                    <input
                      type="radio"
                      id="unlisted"
                      value="unlisted"
                      {...register("privacy_setting")}
                      disabled={isLoading}
                      className="mt-1 w-4 h-4 text-blue-600 border-gray-300 focus:ring-blue-500 focus:ring-2"
                    />
                    <div className="flex flex-col">
                      <Label htmlFor="unlisted" className="text-stone-200 font-medium cursor-pointer">
                        Unlisted
                      </Label>
                      <span className="text-sm text-gray-600">Accessible via direct link only</span>
                    </div>
                  </div>
                  <div className="flex items-start space-x-3">
                    <input
                      type="radio"
                      id="public"
                      value="public"
                      {...register("privacy_setting")}
                      disabled={isLoading}
                      className="mt-1 w-4 h-4 text-blue-600 border-gray-300 focus:ring-blue-500 focus:ring-2"
                    />
                    <div className="flex flex-col">
                      <Label htmlFor="public" className="text-stone-200 font-medium cursor-pointer">
                        Public
                      </Label>
                      <span className="text-sm text-gray-600">Visible to everyone in the community</span>
                    </div>
                  </div>
                </div>
                {errors.privacy_setting && (
                  <p className="text-sm text-red-600">{errors.privacy_setting.message}</p>
                )}
              </div>

              {/* Context-specific upload */}
              {selectedMethod === 'single-audio' && (
                <SingleAudioUpload isLoading={isLoading} onFileChange={() => {}} />
              )}
                              {selectedMethod === 'stems' && (
                <StemsUpload 
                  isLoading={isLoading} 
                  errors={errors} 
                  onFilesChange={(files, master, types) => {
                    setSelectedFiles(files);
                    setMasterFileName(master);
                    setStemTypes(types);
                  }} 
                />
              )}

              {/* Form Actions */}
              <div className="flex gap-3 pt-4">
                <Button
                  type="button"
                  variant="outline"
                  onClick={handleClose}
                  disabled={isLoading}
                  className="flex-1 bg-white border-gray-300 text-gray-700 hover:bg-gray-50 hover:border-gray-400"
                >
                  Cancel
                </Button>
                <Button
                  type="submit"
                  disabled={isLoading}
                  className="flex-1 bg-blue-600 hover:bg-blue-700 text-white border-none"
                >
                  {isLoading ? (
                    <div className="flex items-center gap-2">
                      <LoadingSpinner size="sm" />
                      Creating...
                    </div>
                  ) : (
                    "Create Project"
                  )}
                </Button>
              </div>
            </form>
          </div>
        </div>
      </GlassModal>
    )
  }

  return (
    <GlassModal isOpen={isOpen} onClose={handleClose} sizeClassName="max-w-md min-h-[300px]">
      <div className="w-full h-full bg-stone-900 text-stone-200 font-mono border border-stone-700 rounded-xl max-h-[90vh] overflow-y-auto p-4 min-w-[340px]">
        <div className="mb-2">
          <h2 className="text-xl font-bold text-stone-200 mb-1 tracking-widest uppercase">Choose Upload Method</h2>
          <p className="text-stone-400 text-xs mb-2">Select how you want to create your music visualization project.</p>
        </div>
        <div className="flex flex-col gap-3">
          {uploadOptions.map((option) => (
            <div
              key={option.id}
              className={cn(
                "flex items-center gap-4 p-3 rounded-lg border border-stone-700 bg-stone-800 cursor-pointer transition-all duration-150",
                "hover:bg-stone-700",
              )}
              onClick={() => handleMethodSelect(option.id)}
            >
              <div className={cn("flex-shrink-0 p-2 rounded-lg border border-stone-700", option.color)}>
                {option.icon}
              </div>
              <div className="flex-1 min-w-0">
                <h3 className="text-base font-bold text-stone-200 uppercase tracking-widest mb-1">{option.title}</h3>
                <p className="text-xs text-stone-400 mb-2 truncate">{option.description}</p>
                <div className="space-y-1">
                  <StatBar label="Complexity" value={option.stats.complexity} max={5} color="bg-emerald-400" />
                  <StatBar label="Speed" value={option.stats.speed} max={5} color="bg-emerald-400" />
                  <StatBar label="Control" value={option.stats.control} max={5} color="bg-emerald-400" />
                </div>
              </div>
              <div className="flex flex-col items-end gap-2">
                {option.usesCredits && (
                  <Badge variant="secondary" className="bg-emerald-900/80 text-emerald-200 border border-emerald-700 font-mono text-[10px] px-2 py-1 uppercase tracking-widest">Uses Credits</Badge>
                )}
                <Button
                  size="sm"
                  className="bg-emerald-400 text-stone-900 border border-emerald-400 font-mono text-xs px-3 py-1 rounded-md shadow-none hover:bg-emerald-300 hover:text-stone-900"
                >
                  Select
                  <ArrowRight className="h-3 w-3 ml-1" />
                </Button>
              </div>
            </div>
          ))}
        </div>
        <div className="pt-3 flex gap-2 justify-end">
          <Button
            type="button"
            variant="outline"
            onClick={handleClose}
            className="bg-stone-900 border border-stone-700 text-stone-200 font-mono text-xs px-4 py-1 rounded-md hover:bg-stone-800 hover:text-stone-200"
          >
            Cancel
          </Button>
        </div>
      </div>
    </GlassModal>
  )
}
</file>

<file path="components/projects/project-dashboard.tsx">
"use client"

import * as React from "react"
import { motion } from "framer-motion"
import { GlassCard } from "@/components/ui/glass-card"
import { TechnicalButton } from "@/components/ui/technical-button"
import { StatusIndicator } from "@/components/ui/status-indicator"
import { LoadingSpinner } from "@/components/ui/loading-spinner"
import { ProjectCreationModal } from "./project-creation-modal"
import { trpc } from "@/lib/trpc"
import { useToast } from "@/hooks/use-toast"
import { cn } from "@/lib/utils"
import { useRouter } from "next/navigation"
import { Trash2 } from 'lucide-react'
import { ConfirmationModal } from '@/components/ui/confirmation-modal'
import { debugLog } from '@/lib/utils';

export interface ProjectDashboardProps {
  user: any
}

const ProjectDashboard = React.forwardRef<HTMLDivElement, ProjectDashboardProps>(
  ({ user }, ref) => {
    const [isCreationModalOpen, setIsCreationModalOpen] = React.useState(false)
    const [searchQuery, setSearchQuery] = React.useState("")
    const { toast } = useToast()
    const router = useRouter()
    const [deleteProjectId, setDeleteProjectId] = React.useState<string | null>(null)
    const [isDeleting, setIsDeleting] = React.useState(false)

    // Fetch projects
    const { data: projects = [], isLoading, refetch } = trpc.project.list.useQuery()

    // Search projects - only when there's actually a search query or genre filter
    const hasSearchCriteria = !!(searchQuery?.trim())
    const { data: searchResults, isLoading: isSearching } = trpc.project.search.useQuery(
      {
        query: searchQuery?.trim() || '',
        sort_by: 'updated_at',
        sort_order: 'desc'
      },
      {
        enabled: hasSearchCriteria,
      }
    )

    const displayProjects = hasSearchCriteria ? searchResults || [] : projects

    // Debug logging
    debugLog.log(' ProjectDashboard State:', {
      searchQuery: `"${searchQuery}"`,
      hasSearchCriteria,
      isLoading,
      isSearching,
      projectsLength: projects?.length,
      searchResultsLength: searchResults?.length,
      displayProjectsLength: displayProjects?.length
    })

    const handleProjectClick = (projectId: string) => {
      router.push(`/creative-visualizer?projectId=${projectId}`)
    }

    const openCreationModal = () => {
      setIsCreationModalOpen(true)
    }

    const deleteProjectMutation = trpc.project.delete.useMutation({
      onSuccess: () => {
        toast({ title: 'Project deleted', description: 'The project was deleted.' })
        setDeleteProjectId(null)
        refetch()
      },
      onError: (error) => {
        toast({ title: 'Delete failed', description: error.message, variant: 'destructive' })
        setDeleteProjectId(null)
      },
      onSettled: () => setIsDeleting(false)
    })

    const handleDeleteProject = (projectId: string) => {
      setIsDeleting(true)
      deleteProjectMutation.mutate({ id: projectId })
    }

    return (
      <div ref={ref} className="min-h-screen bg-gradient-to-br from-stone-50 to-stone-100">
        <div className="container mx-auto px-4 lg:px-8 py-8">
          {/* Header */}
          <motion.div
            className="mb-8"
            initial={{ opacity: 0, y: 20 }}
            animate={{ opacity: 1, y: 0 }}
            transition={{ duration: 0.5 }}
          >
            <div className="flex flex-col lg:flex-row justify-between items-start lg:items-center gap-4">
              <div>
                <h1 className="text-3xl lg:text-4xl font-display font-bold text-stone-800">
                  PROJECTS
                </h1>
                <p className="text-lg font-mono text-stone-600">
                  Welcome back, {user?.user_metadata?.name || user?.email}
                </p>
              </div>
              <div className="flex items-center gap-4">
                <StatusIndicator status="live">
                  SYSTEM ONLINE
                </StatusIndicator>
                <motion.div
                  whileHover={{ scale: 1.02 }}
                  whileTap={{ scale: 0.98 }}
                >
                  <TechnicalButton 
                    variant="primary" 
                    size="lg"
                    onClick={openCreationModal}
                  >
                    + Create New Project
                  </TechnicalButton>
                </motion.div>
              </div>
            </div>
          </motion.div>

          <div className="grid grid-cols-1 lg:grid-cols-4 gap-8">
            {/* Sidebar */}
            <motion.aside
              className="lg:col-span-1 space-y-6"
              initial={{ opacity: 0, x: -20 }}
              animate={{ opacity: 1, x: 0 }}
              transition={{ duration: 0.5, delay: 0.1 }}
            >
              {/* Search & Filter Panel */}
              <GlassCard variant="panel" className="p-6">
                <h3 className="text-lg font-display font-bold text-stone-700 mb-4">
                  SEARCH & FILTER
                </h3>
                
                {/* Search Input */}
                <div className="mb-4">
                  <label className="block text-sm font-mono text-stone-600 mb-2">
                    SEARCH PROJECTS
                  </label>
                  <input
                    type="text"
                    placeholder="Search by name..."
                    value={searchQuery}
                    onChange={(e) => setSearchQuery(e.target.value)}
                    className="w-full px-3 py-2 border border-stone-300 rounded-md text-stone-700 placeholder:text-stone-400 focus:outline-none focus:ring-2 focus:ring-blue-500"
                  />
                </div>

                {/* Clear Filters */}
                {searchQuery && (
                  <TechnicalButton
                    variant="secondary"
                    size="sm"
                    className="w-full"
                    onClick={() => {
                      setSearchQuery("")
                    }}
                  >
                    Clear Filters
                  </TechnicalButton>
                )}
              </GlassCard>

              {/* Project Stats Panel */}
              <GlassCard variant="panel" className="p-6">
                <h3 className="text-lg font-display font-bold text-stone-700 mb-4">
                  STATS
                </h3>
                <div className="space-y-3">
                  <div className="flex justify-between">
                    <span className="text-sm font-mono text-stone-600">TOTAL PROJECTS</span>
                    <span className="text-sm font-mono font-bold text-stone-700">{projects.length}</span>
                  </div>
                  <div className="flex justify-between">
                    <span className="text-sm font-mono text-stone-600">ACTIVE</span>
                    <span className="text-sm font-mono font-bold text-green-600">{projects.length}</span>
                  </div>
                  <div className="flex justify-between">
                    <span className="text-sm font-mono text-stone-600">LAST UPDATED</span>
                    <span className="text-xs font-mono text-stone-500">
                      {projects[0]?.updated_at ? new Date(projects[0].updated_at).toLocaleDateString() : 'N/A'}
                    </span>
                  </div>
                </div>
              </GlassCard>
            </motion.aside>

            {/* Main Content */}
            <motion.main
              className="lg:col-span-3"
              initial={{ opacity: 0, x: 20 }}
              animate={{ opacity: 1, x: 0 }}
              transition={{ duration: 0.5, delay: 0.2 }}
            >
              <GlassCard className="p-8 min-h-[600px]">
                {(isLoading || (hasSearchCriteria && isSearching)) ? (
                  <div className="flex flex-col items-center justify-center h-full">
                    <LoadingSpinner size="lg" className="mb-4" />
                    <p className="text-lg font-mono text-stone-600">
                      {hasSearchCriteria && isSearching ? 'SEARCHING PROJECTS...' : 'LOADING PROJECTS...'}
                    </p>
                  </div>
                ) : displayProjects.length > 0 ? (
                  <div>
                    <div className="flex justify-between items-center mb-6">
                      <h2 className="text-2xl font-display font-bold text-stone-700">
                        {searchQuery ? 'Search Results' : 'Your Projects'}
                      </h2>
                      <StatusIndicator status="completed">
                        {displayProjects.length} PROJECT{displayProjects.length !== 1 ? 'S' : ''}
                      </StatusIndicator>
                    </div>
                    
                    {/* Project Grid */}
                    <div className="grid grid-cols-1 md:grid-cols-2 xl:grid-cols-3 gap-6">
                      {displayProjects.map((project: any, index: number) => (
                        <motion.div
                          key={project.id}
                          initial={{ opacity: 0, y: 20 }}
                          animate={{ opacity: 1, y: 0 }}
                          transition={{ duration: 0.4, delay: index * 0.1 }}
                          whileHover={{ y: -4 }}
                          className="cursor-pointer"
                          onClick={() => handleProjectClick(project.id)}
                        >
                          <div className="bg-white/80 backdrop-blur-sm border border-white/20 rounded-xl p-6 shadow-lg hover:shadow-xl transition-all duration-300 relative group">
                            {/* Project Thumbnail */}
                            <div className="w-full h-32 bg-gradient-to-br from-blue-100 to-purple-100 rounded-lg mb-4 flex items-center justify-center">
                              {project.thumbnail_url ? (
                                <img 
                                  src={project.thumbnail_url} 
                                  alt={project.name}
                                  className="w-full h-full object-cover rounded-lg"
                                />
                              ) : (
                                <div className="text-4xl"></div>
                              )}
                            </div>

                            {/* Project Info */}
                            <div className="space-y-2 pb-8">
                              <h3 className="font-display font-bold text-stone-800 truncate">
                                {project.name}
                              </h3>
                              {project.description && (
                                <p className="text-sm text-stone-600 line-clamp-2">
                                  {project.description}
                                </p>
                              )}
                              <div className="flex items-center justify-between text-xs font-mono text-stone-500 mb-1">
                                <span>{new Date(project.updated_at).toLocaleDateString()}</span>
                                <span>{project.file_count || 0} files</span>
                              </div>
                              <span className={cn(
                                "px-2 py-1 rounded text-xs font-mono uppercase",
                                project.privacy_setting === 'private' && "bg-red-100 text-red-700",
                                project.privacy_setting === 'unlisted' && "bg-yellow-100 text-yellow-700",
                                project.privacy_setting === 'public' && "bg-green-100 text-green-700"
                              )}>
                                {project.privacy_setting}
                              </span>
                            </div>

                            {/* Delete Button - bottom right, only on hover */}
                            <button
                              onClick={e => { e.stopPropagation(); setDeleteProjectId(project.id); }}
                              className="absolute bottom-4 right-4 bg-white border border-stone-200 rounded-full p-2 shadow-md text-red-500 hover:text-white hover:bg-red-500 transition-opacity opacity-0 group-hover:opacity-100 focus:opacity-100 focus:outline-none"
                              title="Delete project"
                            >
                              <Trash2 size={18} />
                            </button>
                          </div>
                        </motion.div>
                      ))}
                    </div>
                  </div>
                ) : (
                  <div className="flex flex-col items-center justify-center h-full text-center">
                    <div className="text-6xl mb-6"></div>
                    <h2 className="text-2xl font-display font-bold text-stone-700 mb-4">
                      {searchQuery ? 'No Matching Projects' : 'No Projects Yet'}
                    </h2>
                    <p className="text-lg font-mono text-stone-600 mb-6 max-w-md">
                      {searchQuery 
                        ? 'Try adjusting your search criteria or create a new project.'
                        : 'Create your first music visualization project to get started.'
                      }
                    </p>
                    <motion.div
                      whileHover={{ scale: 1.02 }}
                      whileTap={{ scale: 0.98 }}
                    >
                      <TechnicalButton 
                        variant="primary" 
                        size="lg"
                        onClick={openCreationModal}
                      >
                        Create First Project
                      </TechnicalButton>
                    </motion.div>
                  </div>
                )}
              </GlassCard>
            </motion.main>
          </div>
        </div>

        {/* Project Creation Modal */}
        <ProjectCreationModal
          isOpen={isCreationModalOpen}
          onClose={() => setIsCreationModalOpen(false)}
        />

        <ConfirmationModal
          isOpen={!!deleteProjectId}
          onClose={() => setDeleteProjectId(null)}
          onConfirm={() => deleteProjectId && handleDeleteProject(deleteProjectId)}
          title="Delete Project?"
          description="Are you sure you want to delete this project and all its files? This action cannot be undone."
          confirmText={isDeleting ? 'Deleting...' : 'Delete'}
          confirmVariant="danger"
        />
      </div>
    )
  }
)

ProjectDashboard.displayName = "ProjectDashboard"

export { ProjectDashboard }
</file>

<file path="components/projects/project-picker-modal.tsx">
import React, { useState } from "react";
import { GlassModal } from "@/components/ui/glass-modal";
import { LoadingSpinner } from "@/components/ui/loading-spinner";
import { TechnicalButton } from "@/components/ui/technical-button";
import { trpc } from "@/lib/trpc";

interface ProjectPickerModalProps {
  isOpen: boolean;
  onClose: () => void;
  onSelect: (projectId: string) => void;
  onCreateNew?: () => void;
}

export const ProjectPickerModal: React.FC<ProjectPickerModalProps> = ({ isOpen, onClose, onSelect, onCreateNew }) => {
  const [search, setSearch] = useState("");
  const { data: projects = [], isLoading } = trpc.project.list.useQuery();

  const filteredProjects = projects.filter((p: any) =>
    p.name.toLowerCase().includes(search.toLowerCase())
  );

  return (
    <GlassModal isOpen={isOpen} onClose={onClose} sizeClassName="max-w-md min-h-[300px]">
      <div className="w-full h-full bg-stone-900 text-stone-200 font-mono border border-stone-700 rounded-xl max-h-[90vh] overflow-y-auto p-4 min-w-[340px]">
        <h2 className="text-xl font-bold text-stone-200 mb-1 tracking-widest uppercase">Select a Project</h2>
        <p className="text-stone-400 text-xs mb-2">Choose a project to open in the visualizer, or create a new one.</p>
        <input
          type="text"
          placeholder="Search projects..."
          value={search}
          onChange={e => setSearch(e.target.value)}
          className="w-full px-3 py-2 mb-4 border border-stone-700 rounded-md text-stone-200 bg-stone-800 placeholder:text-stone-400 focus:outline-none focus:ring-2 focus:ring-emerald-400"
        />
        <div className="max-h-64 overflow-y-auto mb-4">
          {isLoading ? (
            <div className="flex justify-center py-8"><LoadingSpinner /></div>
          ) : filteredProjects.length === 0 ? (
            <div className="text-stone-500 text-center py-8">No projects found.</div>
          ) : (
            <ul>
              {filteredProjects.map((project: any) => (
                <li key={project.id}>
                  <button
                    className="w-full text-left px-4 py-3 rounded hover:bg-stone-700 transition flex flex-col mb-1 border border-transparent hover:border-emerald-400"
                    onClick={() => { onSelect(project.id); }}
                  >
                    <span className="font-bold text-stone-200">{project.name}</span>
                    <span className="text-xs text-stone-400">{project.description || "No description"}</span>
                  </button>
                </li>
              ))}
            </ul>
          )}
        </div>
        <TechnicalButton variant="primary" size="lg" className="w-full bg-emerald-400 text-stone-900 font-bold mt-2" onClick={onCreateNew}>
          + Create New Project
        </TechnicalButton>
      </div>
    </GlassModal>
  );
};
</file>

<file path="components/projects/project-settings.tsx">
"use client"

import { useState } from "react"
import { useForm } from "react-hook-form"
import { zodResolver } from "@hookform/resolvers/zod"
import { Button } from "@/components/ui/button"
import { Input } from "@/components/ui/input"
import { Label } from "@/components/ui/label"
import { GlassCard } from "@/components/ui/glass-card"
import { TechnicalButton } from "@/components/ui/technical-button"
import { LoadingSpinner } from "@/components/ui/loading-spinner"
import { updateProjectSchema, type UpdateProjectInput } from "@/lib/validations"
import { useToast } from "@/hooks/use-toast"
import { trpc } from "@/lib/trpc"
import { useRouter } from "next/navigation"
import { cn } from "@/lib/utils"

interface ProjectSettingsProps {
  project: any
  onClose?: () => void
}

type TabId = 'general' | 'privacy' | 'sharing' | 'danger'

export function ProjectSettings({ project, onClose }: ProjectSettingsProps) {
  const [activeTab, setActiveTab] = useState<TabId>('general')
  const [isLoading, setIsLoading] = useState(false)
  const [shareToken, setShareToken] = useState<string>('')
  const { toast } = useToast()
  const router = useRouter()

  const {
    register,
    handleSubmit,
    formState: { errors },
  } = useForm({
    resolver: zodResolver(updateProjectSchema),
    defaultValues: {
      name: project.name,
      description: project.description || '',
      privacy_setting: project.privacy_setting,
      thumbnail_url: project.thumbnail_url || '',
    }
  })

  // Update project mutation
  const updateProjectMutation = trpc.project.update.useMutation({
    onSuccess: () => {
      toast({
        title: "Project Updated! ",
        description: "Your changes have been saved successfully.",
      })
      setIsLoading(false)
    },
    onError: (error) => {
      toast({
        title: "Update Failed",
        description: error.message || "Failed to update project. Please try again.",
        variant: "destructive",
      })
      setIsLoading(false)
    }
  })

  // Share project mutation
  const shareProjectMutation = trpc.project.share.useMutation({
    onSuccess: (share) => {
      setShareToken(share.share_token)
      toast({
        title: "Share Link Created! ",
        description: "Your project share link is ready to use.",
      })
    },
    onError: (error) => {
      toast({
        title: "Share Failed",
        description: error.message || "Failed to create share link.",
        variant: "destructive",
      })
    }
  })

  // Duplicate project mutation
  const duplicateProjectMutation = trpc.project.duplicate.useMutation({
    onSuccess: (newProject) => {
      toast({
        title: "Project Duplicated! ",
        description: `"${newProject.name}" has been created successfully.`,
      })
      router.push(`/projects/${newProject.id}`)
    },
    onError: (error) => {
      toast({
        title: "Duplication Failed",
        description: error.message || "Failed to duplicate project.",
        variant: "destructive",
      })
    }
  })

  // Delete project mutation
  const deleteProjectMutation = trpc.project.delete.useMutation({
    onSuccess: () => {
      toast({
        title: "Project Deleted",
        description: "The project has been permanently removed.",
      })
      router.push('/dashboard')
    },
    onError: (error) => {
      toast({
        title: "Deletion Failed",
        description: error.message || "Failed to delete project.",
        variant: "destructive",
      })
    }
  })

  const onSubmit = async (data: any) => {
    try {
      setIsLoading(true)
      await updateProjectMutation.mutateAsync({
        id: project.id,
        ...data,
      } as UpdateProjectInput & { id: string })
    } catch (error) {
      // Error handled in mutation
    }
  }

  const handleCreateShareLink = async () => {
    try {
      await shareProjectMutation.mutateAsync({
        project_id: project.id,
        access_type: 'view',
      })
    } catch (error) {
      // Error handled in mutation
    }
  }

  const handleDuplicate = async () => {
    const newName = prompt('Enter a name for the duplicate project:', `${project.name} (Copy)`)
    if (newName && newName.trim()) {
      try {
        await duplicateProjectMutation.mutateAsync({
          project_id: project.id,
          new_name: newName.trim(),
          copy_files: true,
        })
      } catch (error) {
        // Error handled in mutation
      }
    }
  }

  const handleDelete = async () => {
    const confirmation = prompt(
      `Type "${project.name}" to confirm deletion. This action cannot be undone.`
    )
    if (confirmation === project.name) {
      try {
        await deleteProjectMutation.mutateAsync({ id: project.id })
      } catch (error) {
        // Error handled in mutation
      }
    } else if (confirmation !== null) {
      toast({
        title: "Deletion Cancelled",
        description: "Project name didn't match. Deletion cancelled for safety.",
        variant: "destructive",
      })
    }
  }

  const copyShareLink = () => {
    const shareUrl = `${window.location.origin}/shared/${shareToken}`
    navigator.clipboard.writeText(shareUrl)
    toast({
      title: "Link Copied! ",
      description: "Share link has been copied to your clipboard.",
    })
  }

  const tabs = [
    { id: 'general' as const, label: 'General', icon: '' },
    { id: 'privacy' as const, label: 'Privacy', icon: '' },
    { id: 'sharing' as const, label: 'Sharing', icon: '' },
    { id: 'danger' as const, label: 'Danger Zone', icon: '' },
  ]

  return (
    <div className="min-h-screen bg-gradient-to-br from-stone-50 to-stone-100 p-8">
      <div className="max-w-4xl mx-auto">
        {/* Header */}
        <div className="mb-8">
          <div className="flex items-center justify-between">
            <div>
              <h1 className="text-3xl font-display font-bold text-stone-800">
                Project Settings
              </h1>
              <p className="text-lg font-mono text-stone-600">
                {project.name}
              </p>
            </div>
            {onClose && (
              <TechnicalButton variant="secondary" onClick={onClose}>
                Back to Project
              </TechnicalButton>
            )}
          </div>
        </div>

        <div className="grid grid-cols-1 lg:grid-cols-4 gap-8">
          {/* Tab Navigation */}
          <div className="lg:col-span-1">
            <GlassCard variant="panel" className="p-6">
              <h3 className="text-lg font-display font-bold text-stone-700 mb-4">
                Settings
              </h3>
              <nav className="space-y-2">
                {tabs.map((tab) => (
                  <button
                    key={tab.id}
                    onClick={() => setActiveTab(tab.id)}
                    className={cn(
                      "w-full text-left px-3 py-2 rounded-md text-sm font-medium transition-colors",
                      activeTab === tab.id
                        ? "bg-blue-100 text-blue-700 border border-blue-200"
                        : "text-stone-600 hover:bg-stone-100"
                    )}
                  >
                    <span className="mr-2">{tab.icon}</span>
                    {tab.label}
                  </button>
                ))}
              </nav>
            </GlassCard>
          </div>

          {/* Tab Content */}
          <div className="lg:col-span-3">
            <GlassCard className="p-8">
              {activeTab === 'general' && (
                <div>
                  <h2 className="text-2xl font-display font-bold text-stone-700 mb-6">
                    General Settings
                  </h2>
                  <form onSubmit={handleSubmit(onSubmit)} className="space-y-6">
                    {/* Project Name */}
                    <div className="space-y-2">
                      <Label htmlFor="name">Project Name</Label>
                      <Input
                        id="name"
                        {...register("name")}
                        disabled={isLoading}
                      />
                      {errors.name && (
                        <p className="text-sm text-red-600">{errors.name.message}</p>
                      )}
                    </div>

                    {/* Description */}
                    <div className="space-y-2">
                      <Label htmlFor="description">Description</Label>
                      <textarea
                        id="description"
                        {...register("description")}
                        disabled={isLoading}
                        rows={4}
                        className="w-full px-3 py-2 border border-stone-300 rounded-md text-stone-700 placeholder:text-stone-400 focus:outline-none focus:ring-2 focus:ring-blue-500 resize-none"
                        placeholder="Describe your project..."
                      />
                      {errors.description && (
                        <p className="text-sm text-red-600">{errors.description.message}</p>
                      )}
                    </div>

                    {/* Thumbnail URL */}
                    <div className="space-y-2">
                      <Label htmlFor="thumbnail_url">Thumbnail URL</Label>
                      <Input
                        id="thumbnail_url"
                        type="url"
                        placeholder="https://example.com/thumbnail.jpg"
                        {...register("thumbnail_url")}
                        disabled={isLoading}
                      />
                      {errors.thumbnail_url && (
                        <p className="text-sm text-red-600">{errors.thumbnail_url.message}</p>
                      )}
                    </div>

                    <div className="flex justify-end">
                      <TechnicalButton
                        type="submit"
                        variant="primary"
                        disabled={isLoading}
                      >
                        {isLoading ? (
                          <>
                            <LoadingSpinner className="mr-2 h-4 w-4" />
                            Saving...
                          </>
                        ) : (
                          'Save Changes'
                        )}
                      </TechnicalButton>
                    </div>
                  </form>
                </div>
              )}

              {activeTab === 'privacy' && (
                <div>
                  <h2 className="text-2xl font-display font-bold text-stone-700 mb-6">
                    Privacy Settings
                  </h2>
                  <form onSubmit={handleSubmit(onSubmit)} className="space-y-6">
                    <div className="space-y-4">
                      <div className="flex items-center space-x-3">
                        <input
                          type="radio"
                          id="private"
                          value="private"
                          {...register("privacy_setting")}
                          disabled={isLoading}
                        />
                        <div>
                          <Label htmlFor="private" className="font-medium">
                            Private
                          </Label>
                          <p className="text-sm text-stone-600">
                            Only you can see this project
                          </p>
                        </div>
                      </div>
                      <div className="flex items-center space-x-3">
                        <input
                          type="radio"
                          id="unlisted"
                          value="unlisted"
                          {...register("privacy_setting")}
                          disabled={isLoading}
                        />
                        <div>
                          <Label htmlFor="unlisted" className="font-medium">
                            Unlisted
                          </Label>
                          <p className="text-sm text-stone-600">
                            Accessible via direct link only
                          </p>
                        </div>
                      </div>
                      <div className="flex items-center space-x-3">
                        <input
                          type="radio"
                          id="public"
                          value="public"
                          {...register("privacy_setting")}
                          disabled={isLoading}
                        />
                        <div>
                          <Label htmlFor="public" className="font-medium">
                            Public
                          </Label>
                          <p className="text-sm text-stone-600">
                            Visible to everyone
                          </p>
                        </div>
                      </div>
                    </div>

                    <div className="flex justify-end">
                      <TechnicalButton
                        type="submit"
                        variant="primary"
                        disabled={isLoading}
                      >
                        Update Privacy
                      </TechnicalButton>
                    </div>
                  </form>
                </div>
              )}

              {activeTab === 'sharing' && (
                <div>
                  <h2 className="text-2xl font-display font-bold text-stone-700 mb-6">
                    Project Sharing
                  </h2>
                  <div className="space-y-6">
                    <div>
                      <h3 className="text-lg font-medium text-stone-700 mb-2">
                        Share Link
                      </h3>
                      <p className="text-sm text-stone-600 mb-4">
                        Create a shareable link for others to view your project.
                      </p>
                      
                      {shareToken ? (
                        <div className="space-y-4">
                          <div className="flex items-center space-x-2">
                            <Input
                              value={`${window.location.origin}/shared/${shareToken}`}
                              readOnly
                              className="flex-1"
                            />
                            <TechnicalButton
                              variant="secondary"
                              onClick={copyShareLink}
                            >
                              Copy
                            </TechnicalButton>
                          </div>
                          <p className="text-xs text-stone-500">
                            This link allows view-only access to your project.
                          </p>
                        </div>
                      ) : (
                        <TechnicalButton
                          variant="primary"
                          onClick={handleCreateShareLink}
                          disabled={shareProjectMutation.isLoading}
                        >
                          {shareProjectMutation.isLoading ? (
                            <>
                              <LoadingSpinner className="mr-2 h-4 w-4" />
                              Creating...
                            </>
                          ) : (
                            'Create Share Link'
                          )}
                        </TechnicalButton>
                      )}
                    </div>
                  </div>
                </div>
              )}

              {activeTab === 'danger' && (
                <div>
                  <h2 className="text-2xl font-display font-bold text-red-700 mb-6">
                    Danger Zone
                  </h2>
                  <div className="space-y-6">
                    {/* Duplicate Project */}
                    <div className="border border-orange-200 rounded-lg p-6 bg-orange-50">
                      <h3 className="text-lg font-medium text-orange-800 mb-2">
                        Duplicate Project
                      </h3>
                      <p className="text-sm text-orange-700 mb-4">
                        Create a copy of this project with all its settings and files.
                      </p>
                      <TechnicalButton
                        variant="secondary"
                        onClick={handleDuplicate}
                        disabled={duplicateProjectMutation.isLoading}
                      >
                        {duplicateProjectMutation.isLoading ? (
                          <>
                            <LoadingSpinner className="mr-2 h-4 w-4" />
                            Duplicating...
                          </>
                        ) : (
                          'Duplicate Project'
                        )}
                      </TechnicalButton>
                    </div>

                    {/* Delete Project */}
                    <div className="border border-red-200 rounded-lg p-6 bg-red-50">
                      <h3 className="text-lg font-medium text-red-800 mb-2">
                        Delete Project
                      </h3>
                      <p className="text-sm text-red-700 mb-4">
                        Permanently delete this project and all associated files. This action cannot be undone.
                      </p>
                      <Button
                        variant="destructive"
                        onClick={handleDelete}
                        disabled={deleteProjectMutation.isLoading}
                      >
                        {deleteProjectMutation.isLoading ? (
                          <>
                            <LoadingSpinner className="mr-2 h-4 w-4" />
                            Deleting...
                          </>
                        ) : (
                          'Delete Project'
                        )}
                      </Button>
                    </div>
                  </div>
                </div>
              )}
            </GlassCard>
          </div>
        </div>
      </div>
    </div>
  )
}
</file>

<file path="components/providers/trpc-provider.tsx">
'use client';

import { useState } from 'react';
import { QueryClient, QueryClientProvider } from '@tanstack/react-query';
import { trpc, trpcClient } from '@/lib/trpc';

interface TRPCProviderProps {
  children: React.ReactNode;
}

export function TRPCProvider({ children }: TRPCProviderProps) {
  const [queryClient] = useState(() => new QueryClient());

  return (
    <trpc.Provider client={trpcClient} queryClient={queryClient}>
      <QueryClientProvider client={queryClient}>
        {children}
      </QueryClientProvider>
    </trpc.Provider>
  );
}
</file>

<file path="components/stem-separation/audio-stems-upload.tsx">
'use client';

import React, { useState, useCallback } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { Progress } from '@/components/ui/progress';
import { 
  Upload, 
  FileAudio, 
  AlertCircle,
  CheckCircle2,
  Loader2,
  Music,
  X,
  Play
} from 'lucide-react';
import { useToast } from '@/hooks/use-toast';
import { cn } from '@/lib/utils';
import { debugLog } from '@/lib/utils';

interface AudioStemsUploadProps {
  onStemsReady?: (stems: Record<string, File>) => void;
  onComplete?: (fileIds: string[]) => void;
  className?: string;
}

interface StemFile {
  type: 'vocals' | 'drums' | 'bass' | 'other';
  file: File;
  preview?: string;
}

export function AudioStemsUpload({ onStemsReady, onComplete, className }: AudioStemsUploadProps) {
  const [stemFiles, setStemFiles] = useState<StemFile[]>([]);
  const [isUploading, setIsUploading] = useState(false);
  const [uploadProgress, setUploadProgress] = useState(0);

  const { toast } = useToast();

  const expectedStems = ['vocals', 'drums', 'bass', 'other'];

  const handleFileSelect = useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const files = Array.from(event.target.files || []);
    
    files.forEach(file => {
      // Validate file type
      if (!file.type.startsWith('audio/')) {
        toast({
          title: 'Invalid file type',
          description: `${file.name} is not an audio file`,
          variant: 'destructive',
        });
        return;
      }

      // Validate file size (max 50MB)
      if (file.size > 50 * 1024 * 1024) {
        toast({
          title: 'File too large',
          description: `${file.name} is larger than 50MB`,
          variant: 'destructive',
        });
        return;
      }

      // Try to determine stem type from filename
      const fileName = file.name.toLowerCase();
      let stemType: 'vocals' | 'drums' | 'bass' | 'other' = 'other';
      
      if (fileName.includes('vocal') || fileName.includes('voice') || fileName.includes('sing')) {
        stemType = 'vocals';
      } else if (fileName.includes('drum') || fileName.includes('beat') || fileName.includes('percussion')) {
        stemType = 'drums';
      } else if (fileName.includes('bass') || fileName.includes('low')) {
        stemType = 'bass';
      }

      // Check if we already have this stem type
      const existingIndex = stemFiles.findIndex(s => s.type === stemType);
      
      if (existingIndex >= 0) {
        // Replace existing file
        setStemFiles(prev => prev.map((stem, index) => 
          index === existingIndex ? { ...stem, file } : stem
        ));
      } else {
        // Add new file
        setStemFiles(prev => [...prev, { type: stemType, file }]);
      }
    });
  }, [stemFiles, toast]);

  const removeStem = useCallback((type: string) => {
    setStemFiles(prev => prev.filter(stem => stem.type !== type));
  }, []);

  const handleUpload = useCallback(async () => {
    if (stemFiles.length === 0) return;

    setIsUploading(true);
    setUploadProgress(0);
    
    try {
      const uploadedFileIds: string[] = [];
      const totalFiles = stemFiles.length;
      
      for (let i = 0; i < stemFiles.length; i++) {
        const stem = stemFiles[i];
        
        // Update progress
        setUploadProgress((i / totalFiles) * 100);
        
        // Upload file
        const formData = new FormData();
        formData.append('file', stem.file);
        
        const response = await fetch('/api/upload', {
          method: 'POST',
          body: formData,
        });

        if (!response.ok) {
          throw new Error(`Failed to upload ${stem.file.name}`);
        }

        const { fileId } = await response.json();
        uploadedFileIds.push(fileId);
      }
      
      setUploadProgress(100);
      
      toast({
        title: 'Upload complete!',
        description: `Successfully uploaded ${stemFiles.length} stem files.`,
      });

      onComplete?.(uploadedFileIds);

    } catch (error) {
      debugLog.error('Upload error:', error);
      toast({
        title: 'Upload failed',
        description: error instanceof Error ? error.message : 'Unknown error',
        variant: 'destructive',
      });
    } finally {
      setIsUploading(false);
      setUploadProgress(0);
    }
  }, [stemFiles, toast, onComplete]);

  const getStemIcon = (type: string) => {
    switch (type) {
      case 'vocals':
        return <Music className="h-4 w-4" />;
      case 'drums':
        return <FileAudio className="h-4 w-4" />;
      case 'bass':
        return <FileAudio className="h-4 w-4" />;
      case 'other':
        return <FileAudio className="h-4 w-4" />;
      default:
        return <FileAudio className="h-4 w-4" />;
    }
  };

  const getStemColor = (type: string) => {
    switch (type) {
      case 'vocals':
        return 'bg-pink-100 text-pink-800 border-pink-200';
      case 'drums':
        return 'bg-orange-100 text-orange-800 border-orange-200';
      case 'bass':
        return 'bg-blue-100 text-blue-800 border-blue-200';
      case 'other':
        return 'bg-gray-100 text-gray-800 border-gray-200';
      default:
        return 'bg-gray-100 text-gray-800 border-gray-200';
    }
  };

  return (
    <Card className={cn('w-full', className)}>
      <CardHeader>
        <CardTitle className="flex items-center gap-2">
          <FileAudio className="h-5 w-5" />
          Audio Stems Upload
        </CardTitle>
      </CardHeader>
      <CardContent className="space-y-6">
        {/* File Upload Section */}
        <div className="space-y-4">
          <div className="flex items-center gap-2">
            <span className="text-sm font-medium">Audio Stems</span>
            <Badge variant="secondary" className="text-xs">
              {stemFiles.length} files selected
            </Badge>
          </div>
          
          <div 
            className="border-2 border-dashed border-gray-300 rounded-lg p-6 text-center cursor-pointer hover:border-gray-400 transition-colors"
            onClick={() => document.getElementById('audio-stems-upload')?.click()}
          >
            <Upload className="h-8 w-8 mx-auto text-gray-400 mb-2" />
            <p className="text-sm text-gray-600">
              Click to select audio stem files
            </p>
            <p className="text-xs text-gray-500 mt-1">
              Supports MP3, WAV, M4A (max 50MB each)
            </p>
          </div>
          
          <input
            id="audio-stems-upload"
            type="file"
            accept="audio/*"
            multiple
            className="hidden"
            onChange={handleFileSelect}
          />
        </div>

        {/* Selected Files */}
        {stemFiles.length > 0 && (
          <div className="space-y-3">
            <h4 className="font-medium text-gray-900">Selected Stems:</h4>
            <div className="grid gap-2">
              {stemFiles.map((stem) => (
                <div
                  key={stem.type}
                  className={cn(
                    "flex items-center justify-between p-3 rounded-lg border",
                    getStemColor(stem.type)
                  )}
                >
                  <div className="flex items-center gap-3">
                    {getStemIcon(stem.type)}
                    <div>
                      <p className="font-medium capitalize">{stem.type}</p>
                      <p className="text-sm opacity-75">{stem.file.name}</p>
                    </div>
                  </div>
                  <button
                    onClick={() => removeStem(stem.type)}
                    className="p-1 hover:bg-black/10 rounded-full transition-colors"
                  >
                    <X className="h-4 w-4" />
                  </button>
                </div>
              ))}
            </div>
          </div>
        )}

        {/* Missing Stems */}
        {stemFiles.length > 0 && (
          <div className="space-y-2">
            <h4 className="font-medium text-gray-900">Missing Stems:</h4>
            <div className="grid grid-cols-2 gap-2">
              {expectedStems
                .filter(type => !stemFiles.find(stem => stem.type === type))
                .map(type => (
                  <div
                    key={type}
                    className="flex items-center gap-2 p-2 bg-gray-50 rounded-lg border border-dashed border-gray-300"
                  >
                    {getStemIcon(type)}
                    <span className="text-sm text-gray-600 capitalize">{type}</span>
                  </div>
                ))}
            </div>
          </div>
        )}

        {/* Upload Progress */}
        {isUploading && (
          <div className="space-y-2">
            <div className="flex items-center justify-between text-sm">
              <span>Uploading stems...</span>
              <span>{Math.round(uploadProgress)}%</span>
            </div>
            <Progress value={uploadProgress} className="w-full" />
          </div>
        )}

        {/* Upload Button */}
        <Button
          onClick={handleUpload}
          disabled={stemFiles.length === 0 || isUploading}
          className="w-full"
        >
          {isUploading ? (
            <>
              <Loader2 className="h-4 w-4 mr-2 animate-spin" />
              Uploading...
            </>
          ) : (
            <>
              <Upload className="h-4 w-4 mr-2" />
              Upload {stemFiles.length} Stem{stemFiles.length !== 1 ? 's' : ''}
            </>
          )}
        </Button>

        {/* Info Section */}
        <div className="p-4 bg-green-50 rounded-lg">
          <div className="flex items-start gap-3">
            <CheckCircle2 className="h-5 w-5 text-green-600 mt-0.5" />
            <div className="space-y-2">
              <h4 className="font-medium text-green-900">Why upload stems?</h4>
              <ul className="text-sm text-green-800 space-y-1">
                <li> Faster processing - no AI separation needed</li>
                <li> Free to use - no credits required</li>
                <li> Better quality control - you control the separation</li>
                <li> More precise visualization mapping</li>
              </ul>
            </div>
          </div>
        </div>

        {/* Tips */}
        <div className="p-4 bg-blue-50 rounded-lg">
          <div className="flex items-start gap-3">
            <AlertCircle className="h-5 w-5 text-blue-600 mt-0.5" />
            <div>
              <h4 className="font-medium text-blue-900">Tips for best results:</h4>
              <ul className="text-sm text-blue-800 space-y-1 mt-2">
                <li> Ensure all stems are the same length and sample rate</li>
                <li> Use descriptive filenames (e.g., "vocals.wav", "drums.mp3")</li>
                <li> Upload at least vocals and drums for good visualization</li>
                <li> WAV format recommended for best quality</li>
              </ul>
            </div>
          </div>
        </div>
      </CardContent>
    </Card>
  );
}
</file>

<file path="components/stem-separation/midi-stems-upload.tsx">
'use client';

import React, { useState, useCallback } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { Progress } from '@/components/ui/progress';
import { Switch } from '@/components/ui/switch';
import { Label } from '@/components/ui/label';
import { 
  Upload, 
  FileMusic, 
  AlertCircle,
  CheckCircle2,
  Loader2,
  Music,
  X,
  Settings,
  Target,
  Zap
} from 'lucide-react';
import { useToast } from '@/hooks/use-toast';
import { cn } from '@/lib/utils';
import { debugLog } from '@/lib/utils';

interface MidiStemsUploadProps {
  onStemsReady?: (stems: Record<string, File>) => void;
  onComplete?: (fileIds: string[]) => void;
  className?: string;
}

interface MidiFile {
  type: 'vocals' | 'drums' | 'bass' | 'melody' | 'chords' | 'other';
  file: File;
  trackCount?: number;
  noteCount?: number;
  duration?: number;
}

export function MidiStemsUpload({ onStemsReady, onComplete, className }: MidiStemsUploadProps) {
  const [midiFiles, setMidiFiles] = useState<MidiFile[]>([]);
  const [isUploading, setIsUploading] = useState(false);
  const [uploadProgress, setUploadProgress] = useState(0);
  const [showAdvanced, setShowAdvanced] = useState(false);
  const [autoLengthMatch, setAutoLengthMatch] = useState(true);
  const [normalizeTempo, setNormalizeTempo] = useState(true);

  const { toast } = useToast();

  const expectedMidiTypes = ['vocals', 'drums', 'bass', 'melody', 'chords', 'other'];

  const handleFileSelect = useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const files = Array.from(event.target.files || []);
    
    files.forEach(file => {
      // Validate file type
      if (!file.name.toLowerCase().endsWith('.mid') && !file.name.toLowerCase().endsWith('.midi')) {
        toast({
          title: 'Invalid file type',
          description: `${file.name} is not a MIDI file`,
          variant: 'destructive',
        });
        return;
      }

      // Validate file size (max 10MB for MIDI)
      if (file.size > 10 * 1024 * 1024) {
        toast({
          title: 'File too large',
          description: `${file.name} is larger than 10MB`,
          variant: 'destructive',
        });
        return;
      }

      // Try to determine MIDI type from filename
      const fileName = file.name.toLowerCase();
      let midiType: 'vocals' | 'drums' | 'bass' | 'melody' | 'chords' | 'other' = 'other';
      
      if (fileName.includes('vocal') || fileName.includes('voice') || fileName.includes('sing')) {
        midiType = 'vocals';
      } else if (fileName.includes('drum') || fileName.includes('beat') || fileName.includes('percussion')) {
        midiType = 'drums';
      } else if (fileName.includes('bass') || fileName.includes('low')) {
        midiType = 'bass';
      } else if (fileName.includes('melody') || fileName.includes('lead')) {
        midiType = 'melody';
      } else if (fileName.includes('chord') || fileName.includes('harmony')) {
        midiType = 'chords';
      }

      // Check if we already have this MIDI type
      const existingIndex = midiFiles.findIndex(m => m.type === midiType);
      
      if (existingIndex >= 0) {
        // Replace existing file
        setMidiFiles(prev => prev.map((midi, index) => 
          index === existingIndex ? { ...midi, file } : midi
        ));
      } else {
        // Add new file
        setMidiFiles(prev => [...prev, { type: midiType, file }]);
      }
    });
  }, [midiFiles, toast]);

  const removeMidi = useCallback((type: string) => {
    setMidiFiles(prev => prev.filter(midi => midi.type !== type));
  }, []);

  const handleUpload = useCallback(async () => {
    if (midiFiles.length === 0) return;

    setIsUploading(true);
    setUploadProgress(0);
    
    try {
      const uploadedFileIds: string[] = [];
      const totalFiles = midiFiles.length;
      
      for (let i = 0; i < midiFiles.length; i++) {
        const midi = midiFiles[i];
        
        // Update progress
        setUploadProgress((i / totalFiles) * 100);
        
        // Upload file
        const formData = new FormData();
        formData.append('file', midi.file);
        
        const response = await fetch('/api/upload', {
          method: 'POST',
          body: formData,
        });

        if (!response.ok) {
          throw new Error(`Failed to upload ${midi.file.name}`);
        }

        const { fileId } = await response.json();
        uploadedFileIds.push(fileId);
      }
      
      setUploadProgress(100);
      
      toast({
        title: 'Upload complete!',
        description: `Successfully uploaded ${midiFiles.length} MIDI files.`,
      });

      onComplete?.(uploadedFileIds);

    } catch (error) {
      debugLog.error('Upload error:', error);
      toast({
        title: 'Upload failed',
        description: error instanceof Error ? error.message : 'Unknown error',
        variant: 'destructive',
      });
    } finally {
      setIsUploading(false);
      setUploadProgress(0);
    }
  }, [midiFiles, toast, onComplete]);

  const getMidiIcon = (type: string) => {
    switch (type) {
      case 'vocals':
        return <Music className="h-4 w-4" />;
      case 'drums':
        return <FileMusic className="h-4 w-4" />;
      case 'bass':
        return <FileMusic className="h-4 w-4" />;
      case 'melody':
        return <FileMusic className="h-4 w-4" />;
      case 'chords':
        return <FileMusic className="h-4 w-4" />;
      case 'other':
        return <FileMusic className="h-4 w-4" />;
      default:
        return <FileMusic className="h-4 w-4" />;
    }
  };

  const getMidiColor = (type: string) => {
    switch (type) {
      case 'vocals':
        return 'bg-pink-100 text-pink-800 border-pink-200';
      case 'drums':
        return 'bg-orange-100 text-orange-800 border-orange-200';
      case 'bass':
        return 'bg-blue-100 text-blue-800 border-blue-200';
      case 'melody':
        return 'bg-purple-100 text-purple-800 border-purple-200';
      case 'chords':
        return 'bg-green-100 text-green-800 border-green-200';
      case 'other':
        return 'bg-gray-100 text-gray-800 border-gray-200';
      default:
        return 'bg-gray-100 text-gray-800 border-gray-200';
    }
  };

  return (
    <Card className={cn('w-full', className)}>
      <CardHeader>
        <CardTitle className="flex items-center gap-2">
          <FileMusic className="h-5 w-5" />
          MIDI Stems Upload
        </CardTitle>
      </CardHeader>
      <CardContent className="space-y-6">
        {/* File Upload Section */}
        <div className="space-y-4">
          <div className="flex items-center gap-2">
            <span className="text-sm font-medium">MIDI Files</span>
            <Badge variant="secondary" className="text-xs">
              {midiFiles.length} files selected
            </Badge>
          </div>
          
          <div 
            className="border-2 border-dashed border-gray-300 rounded-lg p-6 text-center cursor-pointer hover:border-gray-400 transition-colors"
            onClick={() => document.getElementById('midi-stems-upload')?.click()}
          >
            <Upload className="h-8 w-8 mx-auto text-gray-400 mb-2" />
            <p className="text-sm text-gray-600">
              Click to select MIDI files
            </p>
            <p className="text-xs text-gray-500 mt-1">
              Supports .mid and .midi files (max 10MB each)
            </p>
          </div>
          
          <input
            id="midi-stems-upload"
            type="file"
            accept=".mid,.midi"
            multiple
            className="hidden"
            onChange={handleFileSelect}
          />
        </div>

        {/* Advanced Settings */}
        <div className="space-y-4">
          <button
            onClick={() => setShowAdvanced(!showAdvanced)}
            className="flex items-center gap-2 text-sm font-medium text-gray-700 hover:text-gray-900"
          >
            <Settings className="h-4 w-4" />
            Advanced Settings
            <span className={cn("transition-transform", showAdvanced ? "rotate-180" : "")}>
              
            </span>
          </button>
          
          {showAdvanced && (
            <div className="space-y-4 p-4 bg-gray-50 rounded-lg">
              <div className="flex items-center justify-between">
                <div className="space-y-1">
                  <Label className="text-sm font-medium">Auto Length Matching</Label>
                  <p className="text-xs text-gray-600">
                    Automatically match all MIDI files to the same length
                  </p>
                </div>
                <Switch
                  checked={autoLengthMatch}
                  onCheckedChange={setAutoLengthMatch}
                />
              </div>
              
              <div className="flex items-center justify-between">
                <div className="space-y-1">
                  <Label className="text-sm font-medium">Normalize Tempo</Label>
                  <p className="text-xs text-gray-600">
                    Adjust tempo to match the main audio file
                  </p>
                </div>
                <Switch
                  checked={normalizeTempo}
                  onCheckedChange={setNormalizeTempo}
                />
              </div>
            </div>
          )}
        </div>

        {/* Selected Files */}
        {midiFiles.length > 0 && (
          <div className="space-y-3">
            <h4 className="font-medium text-gray-900">Selected MIDI Files:</h4>
            <div className="grid gap-2">
              {midiFiles.map((midi) => (
                <div
                  key={midi.type}
                  className={cn(
                    "flex items-center justify-between p-3 rounded-lg border",
                    getMidiColor(midi.type)
                  )}
                >
                  <div className="flex items-center gap-3">
                    {getMidiIcon(midi.type)}
                    <div>
                      <p className="font-medium capitalize">{midi.type}</p>
                      <p className="text-sm opacity-75">{midi.file.name}</p>
                      {midi.trackCount && (
                        <p className="text-xs opacity-60">{midi.trackCount} tracks</p>
                      )}
                    </div>
                  </div>
                  <button
                    onClick={() => removeMidi(midi.type)}
                    className="p-1 hover:bg-black/10 rounded-full transition-colors"
                  >
                    <X className="h-4 w-4" />
                  </button>
                </div>
              ))}
            </div>
          </div>
        )}

        {/* Missing Types */}
        {midiFiles.length > 0 && (
          <div className="space-y-2">
            <h4 className="font-medium text-gray-900">Recommended MIDI Types:</h4>
            <div className="grid grid-cols-2 gap-2">
              {expectedMidiTypes
                .filter(type => !midiFiles.find(midi => midi.type === type))
                .map(type => (
                  <div
                    key={type}
                    className="flex items-center gap-2 p-2 bg-gray-50 rounded-lg border border-dashed border-gray-300"
                  >
                    {getMidiIcon(type)}
                    <span className="text-sm text-gray-600 capitalize">{type}</span>
                  </div>
                ))}
            </div>
          </div>
        )}

        {/* Upload Progress */}
        {isUploading && (
          <div className="space-y-2">
            <div className="flex items-center justify-between text-sm">
              <span>Uploading MIDI files...</span>
              <span>{Math.round(uploadProgress)}%</span>
            </div>
            <Progress value={uploadProgress} className="w-full" />
          </div>
        )}

        {/* Upload Button */}
        <Button
          onClick={handleUpload}
          disabled={midiFiles.length === 0 || isUploading}
          className="w-full"
        >
          {isUploading ? (
            <>
              <Loader2 className="h-4 w-4 mr-2 animate-spin" />
              Uploading...
            </>
          ) : (
            <>
              <Upload className="h-4 w-4 mr-2" />
              Upload {midiFiles.length} MIDI File{midiFiles.length !== 1 ? 's' : ''}
            </>
          )}
        </Button>

        {/* Info Section */}
        <div className="p-4 bg-purple-50 rounded-lg">
          <div className="flex items-start gap-3">
            <Target className="h-5 w-5 text-purple-600 mt-0.5" />
            <div className="space-y-2">
              <h4 className="font-medium text-purple-900">Maximum Control</h4>
              <ul className="text-sm text-purple-800 space-y-1">
                <li> Precise note-by-note visualization control</li>
                <li> Individual track mapping and effects</li>
                <li> Real-time parameter automation</li>
                <li> Professional-grade visualization quality</li>
              </ul>
            </div>
          </div>
        </div>

        {/* Advanced Tips */}
        <div className="p-4 bg-blue-50 rounded-lg">
          <div className="flex items-start gap-3">
            <AlertCircle className="h-5 w-5 text-blue-600 mt-0.5" />
            <div>
              <h4 className="font-medium text-blue-900">Advanced Setup Tips:</h4>
              <ul className="text-sm text-blue-800 space-y-1 mt-2">
                <li> Export each instrument as a separate MIDI file</li>
                <li> Ensure all files have the same tempo and time signature</li>
                <li> Use descriptive filenames (e.g., "drums.mid", "vocals.mid")</li>
                <li> Consider using a DAW for precise MIDI export</li>
                <li> Match MIDI length to your main audio file</li>
              </ul>
            </div>
          </div>
        </div>

        {/* Complexity Warning */}
        <div className="p-4 bg-red-50 rounded-lg">
          <div className="flex items-start gap-3">
            <AlertCircle className="h-5 w-5 text-red-600 mt-0.5" />
            <div>
              <h4 className="font-medium text-red-900">Advanced Complexity</h4>
              <p className="text-sm text-red-800">
                This method requires manual MIDI file preparation. Each instrument needs to be exported as a separate MIDI file with matching length and tempo.
              </p>
            </div>
          </div>
        </div>
      </CardContent>
    </Card>
  );
}
</file>

<file path="components/stem-separation/single-audio-upload.tsx">
'use client';

import React, { useState, useCallback } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { Progress } from '@/components/ui/progress';
import { 
  Upload, 
  Music, 
  AlertCircle,
  CheckCircle2,
  Loader2,
  FileAudio,
  Clock,
  DollarSign
} from 'lucide-react';
import { trpc } from '@/lib/trpc';
import { useToast } from '@/hooks/use-toast';
import { cn } from '@/lib/utils';
import { debugLog } from '@/lib/utils';

interface SingleAudioUploadProps {
  onStemsReady?: (stems: Record<string, string>) => void;
  onComplete?: (fileId: string) => void;
  className?: string;
}

export function SingleAudioUpload({ onStemsReady, onComplete, className }: SingleAudioUploadProps) {
  const [selectedFile, setSelectedFile] = useState<File | null>(null);
  const [jobId, setJobId] = useState<string | null>(null);
  const [isUploading, setIsUploading] = useState(false);
  const [uploadProgress, setUploadProgress] = useState(0);

  const { toast } = useToast();

  // tRPC mutations and queries
  const createJobMutation = trpc.stem.createSeparationJob.useMutation({
    onSuccess: (data) => {
      setJobId(data.jobId);
      toast({
        title: 'Stem separation started',
        description: 'Your audio is being processed. This may take a few minutes.',
      });
    },
    onError: (error) => {
      toast({
        title: 'Error',
        description: error.message,
        variant: 'destructive',
      });
    },
  });

  const { data: jobStatus, isLoading: isLoadingStatus } = trpc.stem.getJobStatus.useQuery(
    { jobId: jobId! },
    { 
      enabled: !!jobId,
      refetchInterval: (data) => {
        if (data?.status === 'completed' || data?.status === 'failed') {
          return false;
        }
        return 2000; // Poll every 2 seconds
      },
    }
  );

  const handleFileSelect = useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      // Validate file type
      if (!file.type.startsWith('audio/')) {
        toast({
          title: 'Invalid file type',
          description: 'Please select an audio file (MP3, WAV, etc.)',
          variant: 'destructive',
        });
        return;
      }

      // Validate file size (max 50MB)
      if (file.size > 50 * 1024 * 1024) {
        toast({
          title: 'File too large',
          description: 'Please select a file smaller than 50MB',
          variant: 'destructive',
        });
        return;
      }

      setSelectedFile(file);
    }
  }, [toast]);

  const handleUpload = useCallback(async () => {
    if (!selectedFile) return;

    setIsUploading(true);
    setUploadProgress(0);
    
    try {
      // Simulate upload progress
      const progressInterval = setInterval(() => {
        setUploadProgress(prev => {
          if (prev >= 90) {
            clearInterval(progressInterval);
            return 90;
          }
          return prev + 10;
        });
      }, 200);

      // First upload the file using the existing file upload system
      const formData = new FormData();
      formData.append('file', selectedFile);
      
      const response = await fetch('/api/upload', {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) {
        throw new Error('Failed to upload file');
      }

      const { fileId } = await response.json();
      
      clearInterval(progressInterval);
      setUploadProgress(100);

      // Create stem separation job with default config
      await createJobMutation.mutateAsync({
        fileId,
        config: {
          model: 'spleeter',
          modelVariant: '4stems',
          stems: {
            drums: true,
            bass: true,
            vocals: true,
            other: true,
          },
          quality: {
            sampleRate: '44100',
            outputFormat: 'wav',
          },
        },
      });

      onComplete?.(fileId);

    } catch (error) {
      debugLog.error('Upload error:', error);
      toast({
        title: 'Upload failed',
        description: error instanceof Error ? error.message : 'Unknown error',
        variant: 'destructive',
      });
    } finally {
      setIsUploading(false);
      setUploadProgress(0);
    }
  }, [selectedFile, createJobMutation, toast, onComplete]);

  // Handle job completion
  React.useEffect(() => {
    if (jobStatus?.status === 'completed' && jobStatus.results?.stems) {
      toast({
        title: 'Stem separation complete!',
        description: 'Your audio has been separated into stems.',
      });
      onStemsReady?.(jobStatus.results.stems);
    } else if (jobStatus?.status === 'failed') {
      toast({
        title: 'Stem separation failed',
        description: jobStatus.error || 'Unknown error occurred',
        variant: 'destructive',
      });
    }
  }, [jobStatus, onStemsReady, toast]);

  const getStatusIcon = () => {
    if (!jobStatus) return null;
    
    switch (jobStatus.status) {
      case 'queued':
        return <Loader2 className="h-4 w-4 animate-spin" />;
      case 'processing':
        return <Loader2 className="h-4 w-4 animate-spin" />;
      case 'completed':
        return <CheckCircle2 className="h-4 w-4 text-green-500" />;
      case 'failed':
        return <AlertCircle className="h-4 w-4 text-red-500" />;
      default:
        return null;
    }
  };

  const getStatusText = () => {
    if (!jobStatus) return '';
    
    switch (jobStatus.status) {
      case 'queued':
        return 'Queued for processing';
      case 'processing':
        return `Processing... ${jobStatus.progress}%`;
      case 'completed':
        return 'Separation complete';
      case 'failed':
        return 'Separation failed';
      default:
        return '';
    }
  };

  return (
    <Card className={cn('w-full', className)}>
      <CardHeader>
        <CardTitle className="flex items-center gap-2">
          <Music className="h-5 w-5" />
          Single Audio Upload
        </CardTitle>
      </CardHeader>
      <CardContent className="space-y-6">
        {/* File Upload Section */}
        <div className="space-y-4">
          <div className="flex items-center gap-2">
            <span className="text-sm font-medium">Audio File</span>
            {selectedFile && (
              <Badge variant="secondary" className="text-xs">
                {selectedFile.name}
              </Badge>
            )}
          </div>
          
          <div 
            className="border-2 border-dashed border-gray-300 rounded-lg p-6 text-center cursor-pointer hover:border-gray-400 transition-colors"
            onClick={() => document.getElementById('single-audio-upload')?.click()}
          >
            <Upload className="h-8 w-8 mx-auto text-gray-400 mb-2" />
            <p className="text-sm text-gray-600">
              {selectedFile ? selectedFile.name : 'Click to select audio file'}
            </p>
            <p className="text-xs text-gray-500 mt-1">
              Supports MP3, WAV, M4A (max 50MB)
            </p>
          </div>
          
          <input
            id="single-audio-upload"
            type="file"
            accept="audio/*"
            className="hidden"
            onChange={handleFileSelect}
          />
        </div>

        {/* Upload Progress */}
        {isUploading && (
          <div className="space-y-2">
            <div className="flex items-center justify-between text-sm">
              <span>Uploading file...</span>
              <span>{uploadProgress}%</span>
            </div>
            <Progress value={uploadProgress} className="w-full" />
          </div>
        )}

        {/* Job Status */}
        {jobStatus && (
          <div className="space-y-3 p-4 bg-gray-50 rounded-lg">
            <div className="flex items-center gap-2">
              {getStatusIcon()}
              <span className="font-medium">{getStatusText()}</span>
            </div>
            
            {jobStatus.status === 'processing' && (
              <Progress value={jobStatus.progress || 0} className="w-full" />
            )}
            
            {jobStatus.status === 'completed' && jobStatus.results?.stems && (
              <div className="space-y-2">
                <p className="text-sm font-medium text-green-600">Available Stems:</p>
                <div className="grid grid-cols-2 gap-2">
                  {Object.keys(jobStatus.results.stems).map((stem) => (
                    <div key={stem} className="flex items-center gap-2 text-sm">
                      <FileAudio className="h-3 w-3" />
                      <span className="capitalize">{stem}</span>
                    </div>
                  ))}
                </div>
              </div>
            )}
            
            {jobStatus.status === 'failed' && (
              <p className="text-sm text-red-600">
                Error: {jobStatus.error || 'Unknown error'}
              </p>
            )}
          </div>
        )}

        {/* Upload Button */}
        <Button
          onClick={handleUpload}
          disabled={!selectedFile || isUploading || createJobMutation.isLoading}
          className="w-full"
        >
          {isUploading || createJobMutation.isLoading ? (
            <>
              <Loader2 className="h-4 w-4 mr-2 animate-spin" />
              Processing...
            </>
          ) : (
            <>
              <Upload className="h-4 w-4 mr-2" />
              Upload & Separate Stems
            </>
          )}
        </Button>

        {/* Info Section */}
        <div className="p-4 bg-blue-50 rounded-lg">
          <div className="flex items-start gap-3">
            <Clock className="h-5 w-5 text-blue-600 mt-0.5" />
            <div className="space-y-2">
              <h4 className="font-medium text-blue-900">What happens next?</h4>
              <ul className="text-sm text-blue-800 space-y-1">
                <li> Your audio file will be uploaded to our secure servers</li>
                <li> AI will automatically separate it into 4 stems (vocals, drums, bass, other)</li>
                <li> Processing typically takes 2-5 minutes for a 3-minute song</li>
                <li> You'll be notified when separation is complete</li>
              </ul>
            </div>
          </div>
        </div>

        {/* Cost Warning */}
        <div className="p-4 bg-yellow-50 rounded-lg">
          <div className="flex items-start gap-3">
            <DollarSign className="h-5 w-5 text-yellow-600 mt-0.5" />
            <div>
              <h4 className="font-medium text-yellow-900">Credit Usage</h4>
              <p className="text-sm text-yellow-800">
                This operation will use 1 credit from your account. Credits are used for AI-powered stem separation.
              </p>
            </div>
          </div>
        </div>
      </CardContent>
    </Card>
  );
}
</file>

<file path="components/stem-separation/stem-separation-upload.tsx">
'use client';

import React, { useState, useCallback } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { Switch } from '@/components/ui/switch';
import { Label } from '@/components/ui/label';
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@/components/ui/select';
import { Progress } from '@/components/ui/progress';
import { 
  Upload, 
  Music, 
  Settings, 
  Play,
  Pause,
  Download,
  AlertCircle,
  CheckCircle2,
  Loader2,
  FileAudio
} from 'lucide-react';
import { trpc } from '@/lib/trpc';
import { useToast } from '@/hooks/use-toast';
import { cn } from '@/lib/utils';
import { debugLog } from '@/lib/utils';

interface StemSeparationUploadProps {
  onStemsReady?: (stems: Record<string, string>) => void;
  className?: string;
}

interface StemConfig {
  model: 'spleeter';
  modelVariant: '2stems' | '4stems' | '5stems';
  stems: {
    drums?: boolean;
    bass?: boolean;
    vocals: boolean;
    other: boolean;
    piano?: boolean;
  };
  quality: {
    sampleRate: '44100' | '48000';
    outputFormat: 'wav' | 'mp3';
    bitrate?: number;
  };
}

export function StemSeparationUpload({ onStemsReady, className }: StemSeparationUploadProps) {
  const [selectedFile, setSelectedFile] = useState<File | null>(null);
  const [config, setConfig] = useState<StemConfig>({
    model: 'spleeter',
    modelVariant: '4stems',
    stems: {
      drums: true,
      bass: true,
      vocals: true,
      other: true,
    },
    quality: {
      sampleRate: '44100',
      outputFormat: 'wav',
    },
  });
  const [jobId, setJobId] = useState<string | null>(null);
  const [isUploading, setIsUploading] = useState(false);

  const { toast } = useToast();

  // tRPC mutations and queries
  const createJobMutation = trpc.stem.createSeparationJob.useMutation({
    onSuccess: (data) => {
      setJobId(data.jobId);
      toast({
        title: 'Stem separation started',
        description: 'Your audio is being processed. This may take a few minutes.',
      });
    },
    onError: (error) => {
      toast({
        title: 'Error',
        description: error.message,
        variant: 'destructive',
      });
    },
  });

  const { data: jobStatus, isLoading: isLoadingStatus } = trpc.stem.getJobStatus.useQuery(
    { jobId: jobId! },
    { 
      enabled: !!jobId,
      refetchInterval: (data) => {
        if (data?.status === 'completed' || data?.status === 'failed') {
          return false;
        }
        return 2000; // Poll every 2 seconds
      },
    }
  );

  const handleFileSelect = useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      // Validate file type
      if (!file.type.startsWith('audio/')) {
        toast({
          title: 'Invalid file type',
          description: 'Please select an audio file (MP3, WAV, etc.)',
          variant: 'destructive',
        });
        return;
      }

      // Validate file size (max 50MB)
      if (file.size > 50 * 1024 * 1024) {
        toast({
          title: 'File too large',
          description: 'Please select a file smaller than 50MB',
          variant: 'destructive',
        });
        return;
      }

      setSelectedFile(file);
    }
  }, [toast]);

  const handleUpload = useCallback(async () => {
    if (!selectedFile) return;

    setIsUploading(true);
    try {
      // First upload the file using the existing file upload system
      const formData = new FormData();
      formData.append('file', selectedFile);
      
      const response = await fetch('/api/upload', {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) {
        throw new Error('Failed to upload file');
      }

      const { fileId } = await response.json();

      // Create stem separation job
      await createJobMutation.mutateAsync({
        fileId,
        config,
      });

    } catch (error) {
      debugLog.error('Upload error:', error);
      toast({
        title: 'Upload failed',
        description: error instanceof Error ? error.message : 'Unknown error',
        variant: 'destructive',
      });
    } finally {
      setIsUploading(false);
    }
  }, [selectedFile, config, createJobMutation, toast]);

  const handleConfigChange = useCallback((key: string, value: any) => {
    setConfig(prev => ({
      ...prev,
      [key]: value,
    }));
  }, []);

  const handleStemToggle = useCallback((stem: string, enabled: boolean) => {
    setConfig(prev => ({
      ...prev,
      stems: {
        ...prev.stems,
        [stem]: enabled,
      },
    }));
  }, []);

  // Update model variant based on selected stems
  const updateModelVariant = useCallback(() => {
    const { stems } = config;
    const stemCount = Object.values(stems).filter(Boolean).length;
    
    let variant: '2stems' | '4stems' | '5stems' = '4stems';
    if (stemCount <= 2) variant = '2stems';
    else if (stemCount >= 5) variant = '5stems';
    
    setConfig(prev => ({
      ...prev,
      modelVariant: variant,
    }));
  }, [config.stems]);

  React.useEffect(() => {
    updateModelVariant();
  }, [config.stems, updateModelVariant]);

  // Handle job completion
  React.useEffect(() => {
    if (jobStatus?.status === 'completed' && jobStatus.results?.stems) {
      toast({
        title: 'Stem separation complete!',
        description: 'Your audio has been separated into stems.',
      });
      onStemsReady?.(jobStatus.results.stems);
    } else if (jobStatus?.status === 'failed') {
      toast({
        title: 'Stem separation failed',
        description: jobStatus.error || 'Unknown error occurred',
        variant: 'destructive',
      });
    }
  }, [jobStatus, onStemsReady, toast]);

  const getStatusIcon = () => {
    if (!jobStatus) return null;
    
    switch (jobStatus.status) {
      case 'queued':
        return <Loader2 className="h-4 w-4 animate-spin" />;
      case 'processing':
        return <Loader2 className="h-4 w-4 animate-spin" />;
      case 'completed':
        return <CheckCircle2 className="h-4 w-4 text-green-500" />;
      case 'failed':
        return <AlertCircle className="h-4 w-4 text-red-500" />;
      default:
        return null;
    }
  };

  const getStatusText = () => {
    if (!jobStatus) return '';
    
    switch (jobStatus.status) {
      case 'queued':
        return 'Queued for processing';
      case 'processing':
        return `Processing... ${jobStatus.progress}%`;
      case 'completed':
        return 'Separation complete';
      case 'failed':
        return 'Separation failed';
      default:
        return '';
    }
  };

  return (
    <Card className={cn('w-full max-w-2xl', className)}>
      <CardHeader>
        <CardTitle className="flex items-center gap-2">
          <Music className="h-5 w-5" />
          Stem Separation
        </CardTitle>
      </CardHeader>
      <CardContent className="space-y-6">
        {/* File Upload Section */}
        <div className="space-y-4">
          <div className="flex items-center gap-2">
            <Label htmlFor="audio-upload">Audio File</Label>
            {selectedFile && (
              <Badge variant="secondary" className="text-xs">
                {selectedFile.name}
              </Badge>
            )}
          </div>
          
          <div 
            className="border-2 border-dashed border-gray-300 rounded-lg p-6 text-center cursor-pointer hover:border-gray-400 transition-colors"
            onClick={() => document.getElementById('audio-upload')?.click()}
          >
            <Upload className="h-8 w-8 mx-auto text-gray-400 mb-2" />
            <p className="text-sm text-gray-600">
              {selectedFile ? selectedFile.name : 'Click to select audio file'}
            </p>
            <p className="text-xs text-gray-500 mt-1">
              Supports MP3, WAV, M4A (max 50MB)
            </p>
          </div>
          
          <input
            id="audio-upload"
            type="file"
            accept="audio/*"
            className="hidden"
            onChange={handleFileSelect}
          />
        </div>

        {/* Configuration Section */}
        <div className="space-y-4">
          <div className="flex items-center gap-2">
            <Settings className="h-4 w-4" />
            <Label>Separation Settings</Label>
          </div>

          {/* Model Configuration */}
          <div className="grid grid-cols-2 gap-4">
            <div>
              <Label htmlFor="model-variant">Model</Label>
              <Select
                value={config.modelVariant}
                onValueChange={(value: '2stems' | '4stems' | '5stems') => 
                  handleConfigChange('modelVariant', value)
                }
              >
                <SelectTrigger>
                  <SelectValue />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="2stems">2 Stems (Vocals + Other)</SelectItem>
                  <SelectItem value="4stems">4 Stems (Vocals, Drums, Bass, Other)</SelectItem>
                  <SelectItem value="5stems">5 Stems (Vocals, Drums, Bass, Piano, Other)</SelectItem>
                </SelectContent>
              </Select>
            </div>

            <div>
              <Label htmlFor="output-format">Output Format</Label>
              <Select
                value={config.quality.outputFormat}
                onValueChange={(value: 'wav' | 'mp3') => 
                  handleConfigChange('quality', { ...config.quality, outputFormat: value })
                }
              >
                <SelectTrigger>
                  <SelectValue />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="wav">WAV (Lossless)</SelectItem>
                  <SelectItem value="mp3">MP3 (Compressed)</SelectItem>
                </SelectContent>
              </Select>
            </div>
          </div>

          {/* Stem Selection */}
          <div>
            <Label>Stems to Extract</Label>
            <div className="grid grid-cols-2 gap-3 mt-2">
              {Object.entries(config.stems).map(([stem, enabled]) => (
                <div key={stem} className="flex items-center space-x-2">
                  <Switch
                    id={`stem-${stem}`}
                    checked={enabled}
                    onCheckedChange={(checked) => handleStemToggle(stem, checked)}
                  />
                  <Label htmlFor={`stem-${stem}`} className="capitalize">
                    {stem}
                  </Label>
                </div>
              ))}
            </div>
          </div>
        </div>

        {/* Upload Button */}
        <Button
          onClick={handleUpload}
          disabled={!selectedFile || isUploading || createJobMutation.isLoading}
          className="w-full"
        >
          {isUploading || createJobMutation.isLoading ? (
            <>
              <Loader2 className="h-4 w-4 mr-2 animate-spin" />
              Processing...
            </>
          ) : (
            <>
              <Upload className="h-4 w-4 mr-2" />
              Start Stem Separation
            </>
          )}
        </Button>

        {/* Job Status */}
        {jobStatus && (
          <div className="space-y-3 p-4 bg-gray-50 rounded-lg">
            <div className="flex items-center gap-2">
              {getStatusIcon()}
              <span className="font-medium">{getStatusText()}</span>
            </div>
            
            {jobStatus.status === 'processing' && (
              <Progress value={jobStatus.progress || 0} className="w-full" />
            )}
            
            {jobStatus.status === 'completed' && jobStatus.results?.stems && (
              <div className="space-y-2">
                <p className="text-sm font-medium text-green-600">Available Stems:</p>
                <div className="grid grid-cols-2 gap-2">
                  {Object.keys(jobStatus.results.stems).map((stem) => (
                    <div key={stem} className="flex items-center gap-2 text-sm">
                      <FileAudio className="h-3 w-3" />
                      <span className="capitalize">{stem}</span>
                    </div>
                  ))}
                </div>
              </div>
            )}
            
            {jobStatus.status === 'failed' && (
              <p className="text-sm text-red-600">
                Error: {jobStatus.error || 'Unknown error'}
              </p>
            )}
          </div>
        )}
      </CardContent>
    </Card>
  );
}
</file>

<file path="components/stem-visualization/stem-waveform.tsx">
'use client';

import React, { useRef, useEffect, useState, useCallback } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Badge } from '@/components/ui/badge';
import { Button } from '@/components/ui/button';
import { Play, Pause, Volume2, VolumeX } from 'lucide-react';
import { cn } from '@/lib/utils';

export interface FeatureMarker {
  time: number;
  type: 'beat' | 'onset' | 'peak' | 'drop';
  intensity: number;
  frequency?: number;
}

export interface WaveformData {
  points: number[];
  duration: number;
  sampleRate: number;
  markers: FeatureMarker[];
}

export interface StemWaveformProps {
  waveformData: WaveformData | null;
  duration: number;
  currentTime: number;
  onSeek?: (time: number) => void;
  isPlaying: boolean;
  isLoading?: boolean;
}

const MARKER_COLORS = {
  beat: '#ef4444',      // red
  onset: '#3b82f6',     // blue
  peak: '#10b981',      // green
  drop: '#8b5cf6',      // purple
};

const MARKER_LABELS = {
  beat: 'Beat',
  onset: 'Onset',
  peak: 'Peak',
  drop: 'Drop',
};

const WaveformVisualizer: React.FC<StemWaveformProps> = ({
  waveformData,
  duration,
  currentTime,
  onSeek,
  isPlaying,
  isLoading,
}) => {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const containerRef = useRef<HTMLDivElement>(null);

  useEffect(() => {
    if (!canvasRef.current || !waveformData) return;

    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;
    
    const { width, height } = canvas.getBoundingClientRect();
    canvas.width = width;
    canvas.height = height;
    
    const points = waveformData.points;
    const numPoints = points.length;

    ctx.clearRect(0, 0, width, height);

    // Draw midline
    ctx.beginPath();
    ctx.moveTo(0, height / 2);
    ctx.lineTo(width, height / 2);
    ctx.strokeStyle = '#444';
    ctx.lineWidth = 1;
    ctx.stroke();

    // Draw bipolar waveform
    ctx.beginPath();
    const midY = height / 2;
    ctx.strokeStyle = '#ffffff'; // white
    ctx.lineWidth = 1;

    for (let i = 0; i < numPoints; i++) {
      const x = (i / (numPoints - 1)) * width;
      const pointHeight = points[i] * midY;
      ctx.moveTo(x, midY - pointHeight);
      ctx.lineTo(x, midY + pointHeight);
    }
    ctx.stroke();

  }, [waveformData]);

  const handleSeek = (e: React.MouseEvent<HTMLDivElement>) => {
    if (!onSeek || !containerRef.current) return;
    const rect = containerRef.current.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const relativePosition = x / rect.width;
    onSeek(relativePosition * duration);
  };
  
  if (isLoading) {
    return (
      <div className="h-[32px] flex items-center justify-center bg-stone-800/20">
        <p className="text-xs text-stone-400">Analyzing...</p>
      </div>
    );
  }

  if (!waveformData) {
    return (
      <div className="h-[32px] flex items-center justify-center bg-stone-800/20">
        <p className="text-xs text-stone-500">No analysis data available</p>
      </div>
    );
  }
  
  const progress = duration > 0 ? (currentTime / duration) * 100 : 0;

  return (
    <div 
      ref={containerRef}
      className="relative h-[32px] w-full cursor-pointer"
      onClick={handleSeek}
    >
      <canvas ref={canvasRef} className="absolute inset-0 w-full h-full" />
      <div 
        className="absolute top-0 left-0 h-full bg-white/20"
        style={{ width: `${progress}%` }}
      />
      <div 
        className="absolute top-0 w-px h-full bg-red-500"
        style={{ left: `${progress}%` }}
      />
    </div>
  );
};

export const StemWaveform = React.memo(WaveformVisualizer);
</file>

<file path="components/ui/aspect-ratio-selector.tsx">
'use client';

import React from 'react';
import { Button } from '@/components/ui/button';
import { DropdownMenu, DropdownMenuContent, DropdownMenuItem, DropdownMenuTrigger } from '@/components/ui/dropdown-menu';
import { ChevronDown, Monitor, Smartphone, Youtube, Instagram, Video } from 'lucide-react';
import { ASPECT_RATIOS } from '@/lib/visualizer/aspect-ratios';

interface AspectRatioSelectorProps {
  currentAspectRatio: string;
  onAspectRatioChange: (aspectRatio: string) => void;
  disabled?: boolean;
  className?: string;
}

const aspectRatioIcons: Record<string, React.ReactNode> = {
  mobile: <Smartphone className="h-3 w-3" />,
  youtube: <Youtube className="h-3 w-3" />,
  instagram: <Instagram className="h-3 w-3" />,
  tiktok: <Video className="h-3 w-3" />,
  landscape: <Monitor className="h-3 w-3" />
};

const aspectRatioLabels: Record<string, string> = {
  mobile: 'MOB',
  youtube: 'YT',
  instagram: 'IG',
  tiktok: 'TT',
  landscape: 'LS'
};

export function AspectRatioSelector({
  currentAspectRatio,
  onAspectRatioChange,
  disabled = false,
  className
}: AspectRatioSelectorProps) {
  const currentConfig = ASPECT_RATIOS[currentAspectRatio] || ASPECT_RATIOS.mobile;
  const currentIcon = aspectRatioIcons[currentAspectRatio] || aspectRatioIcons.mobile;
  const currentLabel = aspectRatioLabels[currentAspectRatio] || 'MOB';

  return (
    <DropdownMenu>
      <DropdownMenuTrigger asChild>
        <Button 
          variant="outline" 
          size="sm" 
          disabled={disabled}
          className={`bg-stone-800 border-stone-600 text-stone-300 hover:bg-stone-700 hover:border-stone-500 font-mono text-xs uppercase tracking-wider px-2 py-1 ${className}`}
          style={{ borderRadius: '6px' }}
        >
          {currentIcon} {currentLabel}
          <ChevronDown className="h-3 w-3 ml-1" />
        </Button>
      </DropdownMenuTrigger>
      <DropdownMenuContent 
        align="end" 
        className="bg-stone-800 border-stone-600 text-stone-300"
      >
        {Object.entries(ASPECT_RATIOS).map(([id, config]) => (
          <DropdownMenuItem
            key={id}
            onClick={() => onAspectRatioChange(id)}
            className={`text-xs font-mono uppercase tracking-wider hover:bg-stone-700 ${
              currentAspectRatio === id ? 'bg-stone-700 text-white' : 'text-stone-300'
            }`}
          >
            <span className="flex items-center gap-2">
              {aspectRatioIcons[id]}
              {config.name}
              <span className="text-stone-500 ml-auto">
                {config.width}:{config.height}
              </span>
            </span>
          </DropdownMenuItem>
        ))}
      </DropdownMenuContent>
    </DropdownMenu>
  );
}
</file>

<file path="components/ui/avatar.tsx">
"use client"

import * as React from "react"
import * as AvatarPrimitive from "@radix-ui/react-avatar"

import { cn } from "@/lib/utils"

const Avatar = React.forwardRef<
  React.ElementRef<typeof AvatarPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof AvatarPrimitive.Root>
>(({ className, ...props }, ref) => (
  <AvatarPrimitive.Root
    ref={ref}
    className={cn(
      "relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full",
      className
    )}
    {...props}
  />
))
Avatar.displayName = AvatarPrimitive.Root.displayName

const AvatarImage = React.forwardRef<
  React.ElementRef<typeof AvatarPrimitive.Image>,
  React.ComponentPropsWithoutRef<typeof AvatarPrimitive.Image>
>(({ className, ...props }, ref) => (
  <AvatarPrimitive.Image
    ref={ref}
    className={cn("aspect-square h-full w-full", className)}
    {...props}
  />
))
AvatarImage.displayName = AvatarPrimitive.Image.displayName

const AvatarFallback = React.forwardRef<
  React.ElementRef<typeof AvatarPrimitive.Fallback>,
  React.ComponentPropsWithoutRef<typeof AvatarPrimitive.Fallback>
>(({ className, ...props }, ref) => (
  <AvatarPrimitive.Fallback
    ref={ref}
    className={cn(
      "flex h-full w-full items-center justify-center rounded-full bg-muted",
      className
    )}
    {...props}
  />
))
AvatarFallback.displayName = AvatarPrimitive.Fallback.displayName

export { Avatar, AvatarImage, AvatarFallback }
</file>

<file path="components/ui/badge.tsx">
import * as React from "react"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const badgeVariants = cva(
  "inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2",
  {
    variants: {
      variant: {
        default:
          "border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80",
        secondary:
          "border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80",
        destructive:
          "border-transparent bg-destructive text-destructive-foreground shadow hover:bg-destructive/80",
        outline: "text-foreground",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  }
)

export interface BadgeProps
  extends React.HTMLAttributes<HTMLDivElement>,
    VariantProps<typeof badgeVariants> {}

function Badge({ className, variant, ...props }: BadgeProps) {
  return (
    <div className={cn(badgeVariants({ variant }), className)} {...props} />
  )
}

export { Badge, badgeVariants }
</file>

<file path="components/ui/button.tsx">
import * as React from "react"
import { Slot } from "@radix-ui/react-slot"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const buttonVariants = cva(
  "inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0",
  {
    variants: {
      variant: {
        default:
          "bg-primary text-primary-foreground shadow hover:bg-primary/90",
        destructive:
          "bg-destructive text-destructive-foreground shadow-sm hover:bg-destructive/90",
        outline:
          "border border-input bg-background shadow-sm hover:bg-accent hover:text-accent-foreground",
        secondary:
          "bg-secondary text-secondary-foreground shadow-sm hover:bg-secondary/80",
        ghost: "hover:bg-accent hover:text-accent-foreground",
        link: "text-primary underline-offset-4 hover:underline",
      },
      size: {
        default: "h-9 px-4 py-2",
        sm: "h-8 rounded-md px-3 text-xs",
        lg: "h-10 rounded-md px-8",
        icon: "h-9 w-9",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "default",
    },
  }
)

export interface ButtonProps
  extends React.ButtonHTMLAttributes<HTMLButtonElement>,
    VariantProps<typeof buttonVariants> {
  asChild?: boolean
}

const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(
  ({ className, variant, size, asChild = false, ...props }, ref) => {
    const Comp = asChild ? Slot : "button"
    return (
      <Comp
        className={cn(buttonVariants({ variant, size, className }))}
        ref={ref}
        {...props}
      />
    )
  }
)
Button.displayName = "Button"

export { Button, buttonVariants }
</file>

<file path="components/ui/card.tsx">
import * as React from "react"

import { cn } from "@/lib/utils"

const Card = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn(
      "rounded-xl border bg-card text-card-foreground shadow",
      className
    )}
    {...props}
  />
))
Card.displayName = "Card"

const CardHeader = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("flex flex-col space-y-1.5 p-6", className)}
    {...props}
  />
))
CardHeader.displayName = "CardHeader"

const CardTitle = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("font-semibold leading-none tracking-tight", className)}
    {...props}
  />
))
CardTitle.displayName = "CardTitle"

const CardDescription = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("text-sm text-muted-foreground", className)}
    {...props}
  />
))
CardDescription.displayName = "CardDescription"

const CardContent = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div ref={ref} className={cn("p-6 pt-0", className)} {...props} />
))
CardContent.displayName = "CardContent"

const CardFooter = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("flex items-center p-6 pt-0", className)}
    {...props}
  />
))
CardFooter.displayName = "CardFooter"

export { Card, CardHeader, CardFooter, CardTitle, CardDescription, CardContent }
</file>

<file path="components/ui/confirmation-modal.tsx">
import React from "react";
import { GlassModal } from "./glass-modal";
import { TechnicalButton } from "./technical-button";

interface ConfirmationModalProps {
  isOpen: boolean;
  onClose: () => void;
  onConfirm: () => void;
  title: string;
  description?: string;
  confirmText?: string;
  confirmVariant?: "primary" | "danger";
}

export const ConfirmationModal: React.FC<ConfirmationModalProps> = ({
  isOpen,
  onClose,
  onConfirm,
  title,
  description,
  confirmText = "Confirm",
  confirmVariant = "danger",
}) => (
  <GlassModal isOpen={isOpen} onClose={onClose} className="max-w-lg w-auto min-w-[320px] px-6 py-8 flex flex-col items-center justify-center">
    <h2 className="text-xl font-bold text-stone-100 mb-2 text-center w-full">{title}</h2>
    {description && <p className="text-stone-300 mb-6 text-center w-full">{description}</p>}
    <div className="flex justify-end gap-4 mt-6 w-full">
      <TechnicalButton variant="secondary" onClick={onClose}>
        Cancel
      </TechnicalButton>
      <TechnicalButton variant={confirmVariant === 'danger' ? 'primary' : confirmVariant} onClick={onConfirm}>
        {confirmText}
      </TechnicalButton>
    </div>
  </GlassModal>
);
</file>

<file path="components/ui/dropdown-menu.tsx">
"use client"

import * as React from "react"
import * as DropdownMenuPrimitive from "@radix-ui/react-dropdown-menu"
import { Check, ChevronRight, Circle } from "lucide-react"

import { cn } from "@/lib/utils"

const DropdownMenu = DropdownMenuPrimitive.Root

const DropdownMenuTrigger = DropdownMenuPrimitive.Trigger

const DropdownMenuGroup = DropdownMenuPrimitive.Group

const DropdownMenuPortal = DropdownMenuPrimitive.Portal

const DropdownMenuSub = DropdownMenuPrimitive.Sub

const DropdownMenuRadioGroup = DropdownMenuPrimitive.RadioGroup

const DropdownMenuSubTrigger = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.SubTrigger>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.SubTrigger> & {
    inset?: boolean
  }
>(({ className, inset, children, ...props }, ref) => (
  <DropdownMenuPrimitive.SubTrigger
    ref={ref}
    className={cn(
      "flex cursor-default select-none items-center gap-2 rounded-sm px-2 py-1.5 text-sm outline-none focus:bg-accent data-[state=open]:bg-accent [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0",
      inset && "pl-8",
      className
    )}
    {...props}
  >
    {children}
    <ChevronRight className="ml-auto" />
  </DropdownMenuPrimitive.SubTrigger>
))
DropdownMenuSubTrigger.displayName =
  DropdownMenuPrimitive.SubTrigger.displayName

const DropdownMenuSubContent = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.SubContent>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.SubContent>
>(({ className, ...props }, ref) => (
  <DropdownMenuPrimitive.SubContent
    ref={ref}
    className={cn(
      "z-50 min-w-[8rem] overflow-hidden rounded-md border bg-popover p-1 text-popover-foreground shadow-lg data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 origin-[--radix-dropdown-menu-content-transform-origin]",
      className
    )}
    {...props}
  />
))
DropdownMenuSubContent.displayName =
  DropdownMenuPrimitive.SubContent.displayName

const DropdownMenuContent = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Content>
>(({ className, sideOffset = 4, ...props }, ref) => (
  <DropdownMenuPrimitive.Portal>
    <DropdownMenuPrimitive.Content
      ref={ref}
      sideOffset={sideOffset}
      className={cn(
        "z-50 max-h-[var(--radix-dropdown-menu-content-available-height)] min-w-[8rem] overflow-y-auto overflow-x-hidden rounded-md border bg-popover p-1 text-popover-foreground shadow-md",
        "data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 origin-[--radix-dropdown-menu-content-transform-origin]",
        className
      )}
      {...props}
    />
  </DropdownMenuPrimitive.Portal>
))
DropdownMenuContent.displayName = DropdownMenuPrimitive.Content.displayName

const DropdownMenuItem = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.Item>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Item> & {
    inset?: boolean
  }
>(({ className, inset, ...props }, ref) => (
  <DropdownMenuPrimitive.Item
    ref={ref}
    className={cn(
      "relative flex cursor-default select-none items-center gap-2 rounded-sm px-2 py-1.5 text-sm outline-none transition-colors focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50 [&>svg]:size-4 [&>svg]:shrink-0",
      inset && "pl-8",
      className
    )}
    {...props}
  />
))
DropdownMenuItem.displayName = DropdownMenuPrimitive.Item.displayName

const DropdownMenuCheckboxItem = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.CheckboxItem>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.CheckboxItem>
>(({ className, children, checked, ...props }, ref) => (
  <DropdownMenuPrimitive.CheckboxItem
    ref={ref}
    className={cn(
      "relative flex cursor-default select-none items-center rounded-sm py-1.5 pl-8 pr-2 text-sm outline-none transition-colors focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50",
      className
    )}
    checked={checked}
    {...props}
  >
    <span className="absolute left-2 flex h-3.5 w-3.5 items-center justify-center">
      <DropdownMenuPrimitive.ItemIndicator>
        <Check className="h-4 w-4" />
      </DropdownMenuPrimitive.ItemIndicator>
    </span>
    {children}
  </DropdownMenuPrimitive.CheckboxItem>
))
DropdownMenuCheckboxItem.displayName =
  DropdownMenuPrimitive.CheckboxItem.displayName

const DropdownMenuRadioItem = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.RadioItem>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.RadioItem>
>(({ className, children, ...props }, ref) => (
  <DropdownMenuPrimitive.RadioItem
    ref={ref}
    className={cn(
      "relative flex cursor-default select-none items-center rounded-sm py-1.5 pl-8 pr-2 text-sm outline-none transition-colors focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50",
      className
    )}
    {...props}
  >
    <span className="absolute left-2 flex h-3.5 w-3.5 items-center justify-center">
      <DropdownMenuPrimitive.ItemIndicator>
        <Circle className="h-2 w-2 fill-current" />
      </DropdownMenuPrimitive.ItemIndicator>
    </span>
    {children}
  </DropdownMenuPrimitive.RadioItem>
))
DropdownMenuRadioItem.displayName = DropdownMenuPrimitive.RadioItem.displayName

const DropdownMenuLabel = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.Label>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Label> & {
    inset?: boolean
  }
>(({ className, inset, ...props }, ref) => (
  <DropdownMenuPrimitive.Label
    ref={ref}
    className={cn(
      "px-2 py-1.5 text-sm font-semibold",
      inset && "pl-8",
      className
    )}
    {...props}
  />
))
DropdownMenuLabel.displayName = DropdownMenuPrimitive.Label.displayName

const DropdownMenuSeparator = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.Separator>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Separator>
>(({ className, ...props }, ref) => (
  <DropdownMenuPrimitive.Separator
    ref={ref}
    className={cn("-mx-1 my-1 h-px bg-muted", className)}
    {...props}
  />
))
DropdownMenuSeparator.displayName = DropdownMenuPrimitive.Separator.displayName

const DropdownMenuShortcut = ({
  className,
  ...props
}: React.HTMLAttributes<HTMLSpanElement>) => {
  return (
    <span
      className={cn("ml-auto text-xs tracking-widest opacity-60", className)}
      {...props}
    />
  )
}
DropdownMenuShortcut.displayName = "DropdownMenuShortcut"

export {
  DropdownMenu,
  DropdownMenuTrigger,
  DropdownMenuContent,
  DropdownMenuItem,
  DropdownMenuCheckboxItem,
  DropdownMenuRadioItem,
  DropdownMenuLabel,
  DropdownMenuSeparator,
  DropdownMenuShortcut,
  DropdownMenuGroup,
  DropdownMenuPortal,
  DropdownMenuSub,
  DropdownMenuSubContent,
  DropdownMenuSubTrigger,
  DropdownMenuRadioGroup,
}
</file>

<file path="components/ui/droppable-parameter.tsx">
'use client';

import React from 'react';
import { useDrop } from 'react-dnd';
import { Badge } from '@/components/ui/badge';
import { X } from 'lucide-react';
import { ModulationAttenuator } from '@/components/ui/modulation-attenuator';
import { debugLog } from '@/lib/utils';

export interface DraggableFeatureItem {
  id: string;
  name: string;
  stemType?: string;
}

export interface DroppableParameterProps {
  parameterId: string;
  label: string;
  children: React.ReactNode;
  mappedFeatureId?: string | null;
  mappedFeatureName?: string;
  modulationAmount?: number;
  // For visualization of modulation along the slider
  baseValue?: number;
  modulatedValue?: number;
  sliderMax?: number;
  onFeatureDrop: (parameterId: string, featureId: string, stemType?: string) => void;
  onFeatureUnmap: (parameterId: string) => void;
  onModulationAmountChange?: (parameterId: string, amount: number) => void;
  className?: string;
  dropZoneStyle?: string;
  showTagOnHover?: boolean;
}

export const DroppableParameter: React.FC<DroppableParameterProps> = ({
  parameterId,
  label,
  children,
  mappedFeatureId,
  mappedFeatureName,
  modulationAmount = 1.0,
  baseValue,
  modulatedValue,
  sliderMax,
  onFeatureDrop,
  onFeatureUnmap,
  onModulationAmountChange,
  className = '',
  dropZoneStyle = '',
  showTagOnHover = false
}) => {
  // Wrap useDrop in try-catch to handle context errors
  let dropState = { isOver: false, canDrop: false };
  let dropRef: React.RefCallback<HTMLDivElement> = () => {};
  
  try {
    const dropResult = useDrop({
      accept: 'feature',
      drop: (item: DraggableFeatureItem) => {
        onFeatureDrop(parameterId, item.id, item.stemType);
      },
      canDrop: () => true,
      collect: (monitor) => ({
        isOver: monitor.isOver(),
        canDrop: monitor.canDrop(),
      }),
    });
    
    dropState = dropResult[0];
    const drop = dropResult[1];
    
    dropRef = React.useCallback((node: HTMLDivElement | null) => {
      drop(node);
    }, [drop]);
  } catch (error) {
    // If drop context is not available, just use a no-op
    debugLog.warn('Drop context not available for DroppableParameter:', error);
  }

  // For hover badge
  const [hovered, setHovered] = React.useState(false);
  const hideTimeoutRef = React.useRef<number | null>(null);

  const keepBadgeVisible = () => {
    if (hideTimeoutRef.current !== null) {
      window.clearTimeout(hideTimeoutRef.current);
      hideTimeoutRef.current = null;
    }
    setHovered(true);
  };

  const scheduleHideBadge = () => {
    if (hideTimeoutRef.current !== null) {
      window.clearTimeout(hideTimeoutRef.current);
    }
    hideTimeoutRef.current = window.setTimeout(() => {
      setHovered(false);
      hideTimeoutRef.current = null;
    }, 400);
  };

  React.useEffect(() => {
    return () => {
      if (hideTimeoutRef.current !== null) window.clearTimeout(hideTimeoutRef.current);
    };
  }, []);

  return (
    <div className={`space-y-2 ${className}`}>
      <div className="flex items-center justify-between">
        <label className="text-white/80 text-xs font-mono">{label}</label>
        <div className="flex items-center gap-2">
          {/* Modulation Attenuator - only show when feature is mapped, positioned to the left */}
          {mappedFeatureId && onModulationAmountChange && (
            <div 
              className="pointer-events-auto"
              onMouseEnter={(e) => e.stopPropagation()}
              onMouseLeave={(e) => e.stopPropagation()}
            >
              <ModulationAttenuator
                value={modulationAmount}
                onChange={(amount) => onModulationAmountChange(parameterId, amount)}
                size="sm"
              />
            </div>
          )}
          
          {/* Drop Zone - Embossed Pill */}
          <div
            ref={dropRef}
            className={`
              relative flex items-center justify-center w-8 h-6 rounded-full cursor-pointer
              transition-all duration-200 ease-out
              ${mappedFeatureId 
                ? 'bg-emerald-600/20 border-2 border-emerald-500/50 shadow-lg' 
                : 'bg-stone-700/50 border-2 border-stone-600/50 shadow-inner'
              }
              ${dropState.isOver && dropState.canDrop 
                ? 'scale-110 bg-emerald-500/30 border-emerald-400 shadow-lg ring-2 ring-emerald-400/50' 
                : ''
              }
              ${!mappedFeatureId && !dropState.isOver 
                ? 'hover:bg-stone-600/60 hover:border-stone-500/60' 
                : ''
              }
              ${dropZoneStyle === 'inlayed' ? 'ring-2 ring-stone-900/80 shadow-[inset_0_2px_8px_rgba(0,0,0,0.7),0_2px_8px_rgba(16,185,129,0.15)]' : ''}
            `}
            style={{
              // Embossed effect with multiple shadows
              boxShadow: mappedFeatureId 
                ? `
                  inset 0 1px 0 rgba(255, 255, 255, 0.1),
                  inset 0 -1px 0 rgba(0, 0, 0, 0.2),
                  0 2px 4px rgba(0, 0, 0, 0.3),
                  0 0 8px rgba(16, 185, 129, 0.3),
                  ${dropZoneStyle === 'inlayed' ? 'inset 0 4px 12px rgba(0,0,0,0.7)' : ''}
                `
                : `
                  inset 0 1px 0 rgba(255, 255, 255, 0.05),
                  inset 0 -1px 0 rgba(0, 0, 0, 0.3),
                  0 1px 2px rgba(0, 0, 0, 0.2),
                  ${dropZoneStyle === 'inlayed' ? 'inset 0 4px 12px rgba(0,0,0,0.7)' : ''}
                `,
              // Subtle gradient for depth
              background: mappedFeatureId
                ? 'linear-gradient(135deg, rgba(16, 185, 129, 0.2) 0%, rgba(16, 185, 129, 0.1) 100%)'
                : 'linear-gradient(135deg, rgba(68, 64, 60, 0.5) 0%, rgba(41, 37, 36, 0.5) 100%)'
            }}
            onMouseEnter={keepBadgeVisible}
            onMouseLeave={scheduleHideBadge}
          >
            {/* Drop indicator */}
            {!mappedFeatureId && (
              <div className={`
                w-2 h-2 rounded-full transition-all duration-200
                ${dropState.isOver && dropState.canDrop 
                  ? 'bg-emerald-400 scale-125' 
                  : 'bg-stone-400/50'
                }
              `} />
            )}
            {/* Mapped feature indicator */}
            {mappedFeatureId && (
              <div className="w-2 h-2 rounded-full bg-emerald-400 animate-pulse" />
            )}
          </div>
        </div>
      </div>
      {/* Parameter Control */}
      <div className="relative">
        <div className="relative">
          {children}
          {/* Modulation overlay bar (lay over slider track/value) - positioned after children for proper z-index */}
          {typeof baseValue === 'number' && typeof modulatedValue === 'number' && typeof sliderMax === 'number' && sliderMax > 0 && (
            <div className="absolute inset-0 pointer-events-none z-10">
              {(() => {
                const baseN = Math.max(0, Math.min(1, baseValue / sliderMax));
                const modN = Math.max(0, Math.min(1, modulatedValue / sliderMax));
                const left = Math.min(baseN, modN) * 100;
                const width = Math.abs(modN - baseN) * 100;
                return (
                  <div
                    className="absolute top-1/2 -translate-y-1/2 h-[6px] bg-emerald-400/60 rounded-sm shadow-lg"
                    style={{ 
                      left: `${left}%`, 
                      width: `${width}%`,
                      boxShadow: '0 0 8px rgba(16, 185, 129, 0.6), inset 0 1px 2px rgba(255, 255, 255, 0.3)',
                      border: '1px solid rgba(16, 185, 129, 0.4)'
                    }}
                  />
                );
              })()}
            </div>
          )}
        </div>
        {/* Mapped Feature Badge */}
        {mappedFeatureId && mappedFeatureName && (!showTagOnHover || hovered) && (
          <div className="absolute -top-2 -right-2 z-10" onMouseEnter={keepBadgeVisible} onMouseLeave={scheduleHideBadge}>
            <Badge 
              className="bg-emerald-600/90 text-emerald-100 text-xs px-2 py-1 border border-emerald-500/50 shadow-lg"
              style={{
                boxShadow: '0 2px 4px rgba(0, 0, 0, 0.3), 0 0 8px rgba(16, 185, 129, 0.2)'
              }}
            >
              <span className="mr-1">{mappedFeatureName}</span>
              <button
                onClick={(e) => {
                  e.stopPropagation();
                  onFeatureUnmap(parameterId);
                }}
                className="ml-1 hover:bg-emerald-500/50 rounded-full p-0.5 transition-colors"
              >
                <X className="h-3 w-3" />
              </button>
            </Badge>
          </div>
        )}
      </div>
      {/* Drop hint */}
      {dropState.isOver && dropState.canDrop && !mappedFeatureId && (
        <div className="text-xs text-emerald-400/80 font-mono animate-pulse">
          Drop to map feature
        </div>
      )}
    </div>
  );
};
</file>

<file path="components/ui/DroppableSlider.tsx">
'use client';

import React from 'react';
import { useDrop } from 'react-dnd';
import { Slider } from './slider';
import { Label } from './label';
import { Button } from './button';
import { X, Zap } from 'lucide-react';
import { cn } from '@/lib/utils';
import { debugLog } from '@/lib/utils';

interface DroppableSliderProps {
  parameterId: string;
  label: string;
  value: number;
  onValueChange: (value: number) => void;
  onMapFeature: (parameterId: string, featureId: string) => void;
  onUnmapFeature: (parameterId: string) => void;
  mappedFeatureName?: string;
  className?: string;
  min?: number;
  max?: number;
  step?: number;
  disabled?: boolean;
}

export function DroppableSlider({
  parameterId,
  label,
  value,
  onValueChange,
  onMapFeature,
  onUnmapFeature,
  mappedFeatureName,
  className,
  min = 0,
  max = 1,
  step = 0.01,
  disabled = false,
}: DroppableSliderProps) {
  // Wrap useDrop in try-catch to handle context errors
  let dropState = { isOver: false, canDrop: false };
  let dropRef: React.RefCallback<HTMLDivElement> = () => {};
  
  try {
    const dropResult = useDrop({
      accept: 'FEATURE_NODE',
      drop: (item: { id: string; name: string }) => {
        onMapFeature(parameterId, item.id);
      },
      collect: (monitor) => ({
        isOver: monitor.isOver(),
        canDrop: monitor.canDrop(),
      }),
    });
    
    dropState = dropResult[0];
    const drop = dropResult[1];
    
    const dropFunction = drop;
    dropRef = React.useCallback((node: HTMLDivElement | null) => {
      dropFunction(node);
    }, [dropFunction]);
  } catch (error) {
    // If drop context is not available, just use a no-op
    debugLog.warn('Drop context not available for DroppableSlider:', error);
  }

  const isMapped = !!mappedFeatureName;
  const isDragOver = dropState.isOver && dropState.canDrop;

  return (
    <div
      ref={dropRef}
      className={cn(
        "space-y-2 p-3 rounded-lg border transition-all duration-200",
        isMapped 
          ? "bg-blue-500/10 border-blue-500/30" 
          : "bg-stone-800/50 border-stone-700",
        isDragOver && "bg-blue-500/20 border-blue-500/50 scale-105",
        className
      )}
    >
      <div className="flex items-center justify-between">
        <Label className="text-xs font-medium text-stone-300">
          {label}
        </Label>
        {isMapped && (
          <div className="flex items-center gap-2">
            <div className="flex items-center gap-1 px-2 py-1 bg-blue-500/20 rounded text-xs text-blue-300">
              <Zap className="h-3 w-3" />
              {mappedFeatureName}
            </div>
            <Button
              size="sm"
              variant="ghost"
              onClick={() => onUnmapFeature(parameterId)}
              className="h-6 w-6 p-0 text-stone-400 hover:text-stone-200"
            >
              <X className="h-3 w-3" />
            </Button>
          </div>
        )}
      </div>
      
      <Slider
        value={[value]}
        onValueChange={([newValue]) => onValueChange(newValue)}
        min={min}
        max={max}
        step={step}
        disabled={disabled || isMapped}
        className={cn(
          isMapped && "opacity-60",
          isDragOver && "ring-2 ring-blue-500/50"
        )}
      />
      
      {isDragOver && !isMapped && (
        <div className="text-xs text-blue-300 text-center py-1">
          Drop to map feature
        </div>
      )}
    </div>
  );
}
</file>

<file path="components/ui/effect-carousel.tsx">
import React, { useState, useEffect, useCallback } from 'react';
import useEmblaCarousel from 'embla-carousel-react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { ChevronDown, ChevronUp } from 'lucide-react';
import { cn } from '@/lib/utils';

interface EffectCarouselProps {
  effects: { id: string; name: string; description: string }[];
  selectedEffects: Record<string, boolean>;
  onSelectEffect: (id: string) => void;
  className?: string;
}

export function EffectCarousel({
  effects,
  selectedEffects,
  onSelectEffect,
  className
}: EffectCarouselProps) {
  const [emblaRef, emblaApi] = useEmblaCarousel({
    align: 'start',
    containScroll: 'trimSnaps',
    dragFree: true,
    slidesToScroll: 1,
    skipSnaps: false,
  });

  const [isCollapsed, setIsCollapsed] = useState(false);

  // Handle wheel scrolling for horizontal scroll
  const handleWheel = useCallback((event: WheelEvent) => {
    if (!emblaApi) return;
    
    // Prevent default vertical scrolling
    event.preventDefault();
    
    // Convert vertical scroll to horizontal scroll
    const scrollAmount = event.deltaY > 0 ? 1 : -1;
    emblaApi.scrollTo(emblaApi.selectedScrollSnap() + scrollAmount);
  }, [emblaApi]);

  // Add wheel event listener when embla is ready
  useEffect(() => {
    if (!emblaApi) return;

    const emblaContainer = emblaApi.containerNode();
    if (!emblaContainer) return;

    emblaContainer.addEventListener('wheel', handleWheel, { passive: false });
    
    return () => {
      emblaContainer.removeEventListener('wheel', handleWheel);
    };
  }, [emblaApi, handleWheel]);

  // Unified soft grey-beige color scheme for all cards
  const getCardStyle = (index: number, isActive: boolean) => {
    const cardTypes = [
      { 
        name: 'Mythic Rare',
        background: 'bg-gradient-to-b from-zinc-500 via-stone-600 to-neutral-700',
        border: 'border-zinc-400',
        glow: 'shadow-zinc-400/50',
        textColor: 'text-white',
        frameColor: 'bg-gradient-to-b from-zinc-300 to-stone-400'
      },
      { 
        name: 'Rare',
        background: 'bg-gradient-to-b from-zinc-500 via-stone-600 to-neutral-700',
        border: 'border-zinc-400',
        glow: 'shadow-zinc-400/50',
        textColor: 'text-white',
        frameColor: 'bg-gradient-to-b from-zinc-300 to-stone-400'
      },
      { 
        name: 'Uncommon',
        background: 'bg-gradient-to-b from-zinc-500 via-stone-600 to-neutral-700',
        border: 'border-zinc-400',
        glow: 'shadow-zinc-400/50',
        textColor: 'text-white',
        frameColor: 'bg-gradient-to-b from-zinc-300 to-stone-400'
      }
    ];
    
    return cardTypes[index % cardTypes.length];
  };

  return (
    <div className={cn("w-full relative", className)}>
      {/* Show/Hide Toggle - Positioned to overlap with canvas */}
      <div className="absolute top-0 right-0 z-10" style={{ transform: 'translateY(-50px)' }}>
        <Button
          variant="outline"
          size="sm"
          onClick={() => setIsCollapsed(!isCollapsed)}
          className="bg-stone-200 border-stone-400 text-stone-700 hover:bg-stone-100 hover:border-stone-500 font-sans text-xs uppercase tracking-wide"
        >
          {isCollapsed ? <ChevronDown className="h-4 w-4 mr-1" /> : <ChevronUp className="h-4 w-4 mr-1" />}
          {isCollapsed ? 'Show' : 'Hide'} Effects
        </Button>
      </div>

      {/* Collapsible Carousel Container */}
      <div 
        className={cn(
          "overflow-hidden border-t-2 border-b-2 border-stone-400 bg-gradient-to-r from-stone-400 via-stone-300 to-stone-400 transition-all duration-500 ease-in-out",
          isCollapsed ? "max-h-0 py-0 opacity-0" : "max-h-[500px] py-8 opacity-100"
        )}
        ref={emblaRef}
      >
          <div className="flex gap-8 px-8">
            {effects.map((effect, index) => {
              const cardStyle = getCardStyle(index, selectedEffects[effect.id]);
              
              return (
                <div 
                  key={effect.id} 
                  className="flex-shrink-0 w-64 group perspective-1000"
                >
                  <Card
                    className={cn(
                      "h-96 cursor-pointer transition-all duration-500 ease-out border-4 relative overflow-hidden p-0",
                      "transform-gpu hover:scale-105 rounded-xl",
                      "group-hover:rotate-y-12 group-hover:rotate-x-3",
                      cardStyle.background,
                      cardStyle.border,
                      selectedEffects[effect.id]
                        ? `${cardStyle.glow} shadow-2xl ring-4 ring-white/30`
                        : "hover:shadow-xl"
                    )}
                    style={{ 
                      transformStyle: 'preserve-3d',
                    }}
                    onClick={() => onSelectEffect(effect.id)}
                    onMouseMove={(e) => {
                      const card = e.currentTarget;
                      const rect = card.getBoundingClientRect();
                      const x = e.clientX - rect.left;
                      const y = e.clientY - rect.top;
                      const centerX = rect.width / 2;
                      const centerY = rect.height / 2;
                      const rotateX = (y - centerY) / 15;
                      const rotateY = (centerX - x) / 15;
                      
                      card.style.transform = `perspective(1000px) rotateX(${rotateX}deg) rotateY(${rotateY}deg) scale(1.05)`;
                    }}
                    onMouseLeave={(e) => {
                      e.currentTarget.style.transform = 'perspective(1000px) rotateX(0deg) rotateY(0deg) scale(1)';
                    }}
                  >
                    {/* MTG-style card frame overlay */}
                    <div className="absolute inset-0 bg-gradient-to-b from-black/20 via-transparent to-black/40 rounded-xl" />
                    
                    {/* Ornate frame border */}
                    <div className={cn("absolute inset-2 border-2 rounded-lg", cardStyle.frameColor)} />
                    
                    {/* Mana cost indicator (top right) */}
                    <div className={cn("absolute top-3 right-3 w-8 h-8 rounded-full border-2 flex items-center justify-center", cardStyle.frameColor, "border-white/60")}>
                      <span className="text-black font-bold text-sm">{index + 1}</span>
                    </div>

                    <CardHeader className="relative z-10 pb-2">
                      <CardTitle className="flex items-center gap-2 font-serif text-sm font-bold tracking-wide text-black">
                        <div 
                          className="w-3 h-3 rounded-full flex-shrink-0 border-2 border-white/60"
                          style={{ 
                            backgroundColor: '#71717a'
                          }}
                        />
                        {effect.name.toUpperCase().replace(' EFFECT', '')}
                      </CardTitle>
                      
                      {/* Card type line */}
                      <div className="text-xs font-mono uppercase tracking-wider text-black opacity-70">
                        {cardStyle.name}  Visual
                      </div>
                    </CardHeader>
                    
                    <CardContent className="relative z-10 p-4 flex-1 flex flex-col">
                      {/* Card art area - larger like MTG */}
                      <div className="h-36 mb-2 rounded-lg bg-gradient-to-b from-slate-800 to-slate-900 border-2 border-slate-600 flex items-center justify-center relative overflow-hidden">
                        <div className="absolute inset-0 bg-gradient-to-b from-transparent to-black/30" />
                        <div className="text-center relative z-10">
                          <div className="text-3xl mb-1 drop-shadow-lg">
                            {index === 0 ? '' : index === 1 ? '' : ''}
                          </div>
                          <div className="text-xs font-mono text-slate-300 uppercase tracking-wider">
                            ART
                          </div>
                        </div>
                      </div>
                      
                      {/* Card text - extends to bottom with matching spacing */}
                      <div className="bg-gradient-to-b from-slate-100 to-slate-200 rounded-lg p-3 pr-6 pb-4 border border-slate-400 flex-1 -mb-6 relative">
                        <p className="text-xs text-slate-900 font-serif leading-relaxed">
                          {effect.description.replace(/effect/gi, '').replace(/visual/gi, 'visual')}
                        </p>
                        
                        {/* Active status - MTG power/toughness style overlay */}
                        {selectedEffects[effect.id] && (
                          <div className="absolute -bottom-1 -right-1 z-20">
                            <div className="bg-slate-200 text-slate-900 text-xs font-bold px-2 py-1 rounded-md border-2 border-slate-600 shadow-lg">
                              
                            </div>
                          </div>
                        )}
                      </div>
                    </CardContent>
                  </Card>
                </div>
              );
            })}
            
            {/* Placeholder MTG-style cards */}
            {Array.from({ length: 3 }).map((_, index) => (
              <div 
                key={`placeholder-${index}`} 
                className="flex-shrink-0 w-64 group perspective-1000"
              >
                <Card
                  className="h-96 border-4 border-dashed border-stone-500 bg-gradient-to-b from-stone-700 to-stone-800 opacity-60 rounded-xl relative overflow-hidden"
                >
                  <div className="absolute inset-0 bg-gradient-to-b from-transparent via-black/10 to-black/30 rounded-xl" />
                  
                  <CardHeader className="relative z-10 pb-3">
                    <CardTitle className="text-stone-300 flex items-center gap-3 font-serif text-lg font-bold tracking-wide">
                      <div className="w-3 h-3 rounded-full bg-stone-500 border-2 border-stone-400" />
                      Coming Soon
                    </CardTitle>
                    <div className="text-xs font-mono uppercase tracking-wider text-stone-400">
                      Future  Visual Effect
                    </div>
                  </CardHeader>
                  
                  <CardContent className="relative z-10 p-4">
                    <div className="h-32 mb-4 rounded-lg bg-black/50 border border-stone-600 flex items-center justify-center">
                      <div className="text-center">
                        <div className="text-2xl mb-2 text-stone-400"></div>
                        <div className="text-xs font-mono text-stone-300 uppercase tracking-wider">
                          UNKNOWN
                        </div>
                      </div>
                    </div>
                    
                    <div className="bg-stone-600/50 rounded-lg p-3">
                      <p className="text-xs text-stone-300 font-serif leading-relaxed">
                        More visual effects will be added here as the library expands.
                      </p>
                    </div>
                  </CardContent>
                </Card>
              </div>
            ))}
          </div>
      </div>

      {/* Title bar at bottom */}
      <div className="mt-4">
        <h2 className="font-sans text-lg font-bold text-gray-900 uppercase tracking-wider mb-2">
          Visual Effects Library
        </h2>
        <p className="font-sans text-xs text-gray-600 uppercase tracking-wide">
           Drag or scroll to explore effects  Select effects to configure and activate
        </p>
      </div>
    </div>
  );
}
</file>

<file path="components/ui/EffectsLibrarySidebar.README.md">
# EffectsLibrarySidebar Component

## Overview

The `EffectsLibrarySidebar` component is a refactored version of the horizontal `EffectCarousel` component, designed as a vertical, searchable, and categorized sidebar for effect selection.

## Key Features

- **Vertical Layout**: Replaces horizontal scrolling with vertical scrolling
- **Search Functionality**: Filter effects by name, description, category, or rarity
- **Categorization**: Effects are grouped into collapsible categories
- **Two-Column Grid**: Responsive grid layout for effect cards
- **MTG-Style Cards**: Preserves the Magic: The Gathering card styling with 3D hover effects
- **Rarity-Based Styling**: Different color schemes for Common, Rare, and Mythic effects

## Interface Changes

### New EffectUIData Interface

```typescript
export interface EffectUIData {
  id: string;
  name: string;
  description: string;
  category: 'Generative' | 'Overlays' | 'Post-Processing';
  rarity: 'Common' | 'Rare' | 'Mythic';
}
```

### Component Props

```typescript
interface EffectsLibrarySidebarProps {
  effects: EffectUIData[];
  selectedEffects: Record<string, boolean>;
  onEffectToggle: (effectId: string) => void;
  isVisible: boolean;
  className?: string;
}
```

## Usage Example

```typescript
import { EffectsLibrarySidebar } from './components/ui/EffectsLibrarySidebar';

// Transform existing effect data to include category and rarity
const enhancedEffects: EffectUIData[] = [
  {
    id: 'metaballs',
    name: 'Metaballs Effect',
    description: 'Organic, fluid-like visualizations that respond to audio intensity',
    category: 'Generative',
    rarity: 'Rare'
  },
  {
    id: 'midiHud',
    name: 'HUD Effect',
    description: 'Technical overlay displaying real-time audio analysis and MIDI data',
    category: 'Overlays',
    rarity: 'Common'
  },
  {
    id: 'particleNetwork',
    name: 'Particle Effect',
    description: 'Dynamic particle systems that react to rhythm and pitch',
    category: 'Generative',
    rarity: 'Mythic'
  }
];

function MyComponent() {
  const [selectedEffects, setSelectedEffects] = useState<Record<string, boolean>>({
    'metaballs': true,
    'midiHud': false,
    'particleNetwork': true
  });
  const [isLibraryVisible, setIsLibraryVisible] = useState(true);

  const handleEffectToggle = (effectId: string) => {
    setSelectedEffects(prev => ({
      ...prev,
      [effectId]: !prev[effectId]
    }));
  };

  return (
    <div className="flex h-screen">
      {/* Main content */}
      <div className="flex-1">
        {/* Your main content here */}
      </div>
      
      {/* Right sidebar */}
      <div className="w-96">
        <EffectsLibrarySidebar
          effects={enhancedEffects}
          selectedEffects={selectedEffects}
          onEffectToggle={handleEffectToggle}
          isVisible={isLibraryVisible}
        />
      </div>
    </div>
  );
}
```

## Migration from EffectCarousel

### Removed Dependencies

- `embla-carousel-react` - No longer needed for horizontal scrolling
- All carousel-related event handlers and state

### Added Dependencies

- Standard React hooks (`useState`, `useMemo`)
- Lucide React icons (`ChevronDown`, `ChevronRight`, `Search`, `X`)

### Layout Changes

1. **Container Structure**: 
   - Horizontal  Vertical layout
   - Embla carousel wrapper  Standard flex container
   - Fixed height with scrollable content area

2. **Card Layout**:
   - Single row  Two-column grid
   - Flex horizontal layout  CSS Grid
   - Maintains card aspect ratio and styling

3. **Search and Categories**:
   - Added search input with clear functionality
   - Collapsible category sections
   - Effect count per category

### Styling Updates

- **Rarity Colors**: 
  - Common: Zinc/Stone gradients (original style)
  - Rare: Blue gradients
  - Mythic: Orange/Amber gradients
- **Responsive Design**: Adapts to narrow screens with single-column layout
- **3D Effects**: Reduced rotation intensity for tighter grid layout

## Technical Notes

### Performance Considerations

- Uses `useMemo` for expensive filtering and categorization operations
- Efficient re-rendering only when `effects` or `searchQuery` changes
- Conditional rendering based on `isVisible` prop

### Accessibility

- Keyboard navigation for category toggles
- Screen reader friendly search input
- Semantic HTML structure with proper ARIA labels

### Browser Support

- CSS Grid (IE11+ with autoprefixer)
- CSS Custom Properties (IE11+ with polyfill)
- Modern JavaScript features (ES2018+)

## Future Enhancements

1. **Drag & Drop**: Reorder effects within categories
2. **Favorites**: Star/favorite effects for quick access
3. **Import/Export**: Save and load effect collections
4. **Filtering**: Advanced filters by rarity, category, etc.
5. **Preview**: Inline effect previews on hover
</file>

<file path="components/ui/EffectsLibrarySidebar.tsx">
import React, { useState, useMemo } from 'react';
import { useDrag } from 'react-dnd';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { ChevronDown, ChevronRight, Search, X } from 'lucide-react';
import { cn } from '@/lib/utils';

// Extended interface to support categorization and rarity for the UI
export interface EffectUIData {
  id: string;
  name: string;
  description: string;
  category: 'Generative' | 'Overlays' | 'Post-Processing';
  rarity: 'Common' | 'Rare' | 'Mythic';
  parameters?: Record<string, any>; // <-- Added optional parameters property
  image?: string; // <-- Added optional image property
}

interface EffectsLibrarySidebarProps {
  effects: EffectUIData[];
  selectedEffects: Record<string, boolean>;
  onEffectToggle: (effectId: string) => void;
  onEffectDoubleClick: (effectId: string) => void; // New prop for double-click
  isVisible: boolean;
  className?: string;
}

// Draggable Effect Card Component
const DraggableEffectCard: React.FC<{
  effect: EffectUIData;
  cardStyle: any;
  onDoubleClick: () => void;
}> = ({ effect, cardStyle, onDoubleClick }) => {
  const [{ isDragging }, drag] = useDrag({
    type: 'EFFECT_CARD',
    item: {
      type: 'EFFECT_CARD',
      id: effect.id,
      name: effect.name,
      category: effect.category,
      rarity: effect.rarity,
      parameters: effect.parameters
    },
    collect: (monitor) => ({
      isDragging: monitor.isDragging(),
    }),
  });

  return (
    <div 
      ref={drag as any}
      className="cursor-grab"
    >
      <div
        className={cn(
          "cursor-grab active:cursor-grabbing transition-all duration-200 border relative overflow-hidden p-2 rounded-md flex flex-col",
          "hover:bg-gray-800",
          cardStyle.background,
          cardStyle.border,
          isDragging ? "opacity-50" : ""
        )}
        onDoubleClick={onDoubleClick}
      >
        {/* Rarity indicator (top right) */}
        <div className={cn("absolute top-1 right-1 w-4 h-4 border flex items-center justify-center", cardStyle.frameColor, "border-gray-600")}>
          <span className="text-black font-bold text-xs">
            {effect.rarity === 'Common' ? 'C' : effect.rarity === 'Rare' ? 'R' : 'M'}
          </span>
        </div>

        {/* Title - fixed height */}
        <div className="relative z-10 mb-1">
          <div className="flex items-center gap-1 font-mono text-[10px] font-bold tracking-wide text-white">
            <div 
              className="w-1 h-1 flex-shrink-0 border border-gray-600"
              style={{ 
                backgroundColor: '#71717a'
              }}
            />
            {effect.name.toUpperCase().replace(' EFFECT', '')}
          </div>
        </div>
        
        {/* Card art area - square and fills width */}
        <div className="relative z-10 w-full aspect-square bg-neutral-800 border border-gray-600 overflow-hidden rounded p-1">
          {effect.image ? (
            <img 
              src={effect.image} 
              alt={effect.name}
              className="absolute inset-0 w-full h-full object-cover"
            />
          ) : (
            <div className="absolute inset-0 flex items-center justify-center">
              <div className="text-center">
                <div className="text-xs">
                  {effect.category === 'Generative' ? '' : effect.category === 'Overlays' ? '' : ''}
                </div>
                <div className="text-xs font-mono text-gray-300 uppercase tracking-wider">
                  {effect.category.slice(0, 3)}
                </div>
              </div>
            </div>
          )}
        </div>
        
        {/* Drag indicator */}
        <div className="absolute bottom-1 right-1 z-20">
          <div className="bg-gray-600 text-gray-900 text-xs font-bold px-1 py-0.5 border border-gray-700">
            
          </div>
        </div>
      </div>
    </div>
  );
};

export function EffectsLibrarySidebar({
  effects,
  selectedEffects,
  onEffectToggle,
  onEffectDoubleClick,
  isVisible,
  className
}: EffectsLibrarySidebarProps) {
  const [searchQuery, setSearchQuery] = useState('');
  const [expandedCategories, setExpandedCategories] = useState<Record<string, boolean>>({
    'Generative': true,
    'Overlays': true,
    'Post-Processing': true
  });

  // Filter effects based on search query
  const filteredEffects = useMemo(() => {
    if (!searchQuery.trim()) return effects;
    
    const query = searchQuery.toLowerCase();
    return effects.filter(effect => 
      effect.name.toLowerCase().includes(query) ||
      effect.description.toLowerCase().includes(query) ||
      effect.category.toLowerCase().includes(query) ||
      effect.rarity.toLowerCase().includes(query)
    );
  }, [effects, searchQuery]);

  // Group filtered effects by category
  const categorizedEffects = useMemo(() => {
    const categories: Record<string, EffectUIData[]> = {
      'Generative': [],
      'Overlays': [],
      'Post-Processing': []
    };

    filteredEffects.forEach(effect => {
      if (categories[effect.category]) {
        categories[effect.category].push(effect);
      }
    });

    return categories;
  }, [filteredEffects]);

  // Get card styling - all cards are now grey
  const getCardStyle = (rarity: string, isActive: boolean) => {
    // All cards use the same grey styling regardless of rarity
    return {
      name: rarity,
      background: 'bg-neutral-700',
      border: 'border-neutral-600',
      glow: 'shadow-gray-600/50',
      textColor: 'text-white',
      frameColor: 'bg-gray-500'
    };
  };

  const toggleCategory = (category: string) => {
    setExpandedCategories(prev => ({
      ...prev,
      [category]: !prev[category]
    }));
  };

  const clearSearch = () => {
    setSearchQuery('');
  };

  if (!isVisible) {
    return null;
  }

  return (
    <div className={cn("h-full flex flex-col bg-black border-l border-gray-800", className)}>
      {/* Header */}
      <div className="p-3 border-b border-gray-800">
        <h2 className="font-mono text-sm font-bold text-gray-100 uppercase tracking-wider mb-2">
          Effects Library
        </h2>
        
        {/* Search Input */}
        <div className="relative">
          <Search className="absolute left-2 top-1/2 transform -translate-y-1/2 h-3 w-3 text-gray-400" />
          <input
            type="text"
            placeholder="Search effects..."
            value={searchQuery}
            onChange={(e) => setSearchQuery(e.target.value)}
            className="w-full pl-7 pr-7 py-1.5 bg-gray-900 border border-gray-700 text-xs text-white placeholder-gray-500 focus:outline-none focus:ring-1 focus:ring-gray-600 focus:border-transparent"
          />
          {searchQuery && (
            <button
              onClick={clearSearch}
              className="absolute right-2 top-1/2 transform -translate-y-1/2 text-gray-400 hover:text-white"
            >
              <X className="h-3 w-3" />
            </button>
          )}
        </div>
      </div>

      {/* Scrollable Content */}
      <div className="flex-1 overflow-y-auto p-3 space-y-3">
        {Object.entries(categorizedEffects).map(([category, categoryEffects]) => {
          if (categoryEffects.length === 0) return null;
          
          const isExpanded = expandedCategories[category];
          
          return (
            <div key={category} className="space-y-1.5">
              {/* Category Header */}
              <button
                onClick={() => toggleCategory(category)}
                className="w-full flex items-center justify-between p-2 bg-gray-900 border border-gray-700 hover:bg-gray-800 transition-colors"
              >
                <span className="font-mono text-xs font-semibold text-gray-300 uppercase tracking-wide">
                  {category}
                </span>
                <div className="flex items-center gap-2">
                  <span className="text-xs text-gray-500">
                    {categoryEffects.length}
                  </span>
                  {isExpanded ? (
                    <ChevronDown className="h-3 w-3 text-gray-400" />
                  ) : (
                    <ChevronRight className="h-3 w-3 text-gray-400" />
                  )}
                </div>
              </button>

              {/* Category Effects Grid */}
              {isExpanded && (
                <div className="grid grid-cols-2 gap-1.5 w-full">
                  {categoryEffects.map((effect, index) => {
                    const cardStyle = getCardStyle(effect.rarity, selectedEffects[effect.id]);
                    
                    return (
                      <DraggableEffectCard
                        key={effect.id}
                        effect={effect}
                        cardStyle={cardStyle}
                        onDoubleClick={() => onEffectDoubleClick(effect.id)}
                      />
                    );
                  })}
                </div>
              )}
            </div>
          );
        })}

        {/* No results message */}
        {filteredEffects.length === 0 && (
          <div className="text-center py-4">
            <div className="text-gray-500 text-xs">
              No effects found matching "{searchQuery}"
            </div>
            <Button 
              variant="outline" 
              size="sm" 
              onClick={clearSearch}
              className="mt-2 text-xs text-gray-400 border-gray-700 hover:bg-gray-800"
            >
              Clear search
            </Button>
          </div>
        )}
      </div>
    </div>
  );
}
</file>

<file path="components/ui/FeatureNode.tsx">
'use client';

import React from 'react';
import { useDrag, ConnectDragSource } from 'react-dnd';
import { Badge } from '@/components/ui/badge';
import { cn } from '@/lib/utils';
import { debugLog } from '@/lib/utils';

interface AudioFeature {
  id: string;
  name: string;
  description: string;
  category: 'rhythm' | 'pitch' | 'intensity' | 'timbre';
  stemType?: string;
}

interface FeatureNodeProps {
  feature: AudioFeature;
  category: string;
}

const categoryColors = {
  rhythm: 'bg-red-500/20 text-red-300 border-red-500/30 hover:bg-red-500/30',
  pitch: 'bg-blue-500/20 text-blue-300 border-blue-500/30 hover:bg-blue-500/30',
  intensity: 'bg-yellow-500/20 text-yellow-300 border-yellow-500/30 hover:bg-yellow-500/30',
  timbre: 'bg-purple-500/20 text-purple-300 border-purple-500/30 hover:bg-purple-500/30',
};

export function FeatureNode({ feature, category }: FeatureNodeProps) {
  // Wrap useDrag in try-catch to handle context errors
  let dragState = { isDragging: false };
  let dragRef: React.RefCallback<HTMLDivElement> = () => {};
  
  try {
    const dragResult = useDrag({
      type: 'FEATURE_NODE',
      item: {
        id: feature.id,
        name: feature.name,
        description: feature.description,
        category: feature.category,
        stemType: feature.stemType,
      },
      collect: (monitor) => ({
        isDragging: monitor.isDragging(),
      }),
    });
    
    dragState = dragResult[0];
    const drag = dragResult[1];
    
    dragRef = React.useCallback((node: HTMLDivElement | null) => {
      drag(node);
    }, [drag]);
  } catch (error) {
    // If drag context is not available, just use a no-op
    debugLog.warn('Drag context not available for FeatureNode:', error);
  }

  const colorClass = categoryColors[category as keyof typeof categoryColors];

  return (
    <div
      ref={dragRef}
      className={cn(
        "cursor-grab active:cursor-grabbing transition-all duration-200",
        dragState.isDragging && "opacity-50 scale-95"
      )}
      title={feature.description}
    >
      <Badge 
        variant="outline" 
        className={cn(
          "w-full text-left px-2 py-1 text-xs font-medium border rounded-md",
          colorClass,
          dragState.isDragging && "shadow-lg"
        )}
      >
        <div className="flex items-center justify-between w-full">
          <span className="truncate">{feature.name}</span>
          {feature.stemType && (
            <span className="text-xs opacity-70 ml-1">
              {feature.stemType}
            </span>
          )}
        </div>
      </Badge>
    </div>
  );
}
</file>

<file path="components/ui/form.tsx">
"use client"

import * as React from "react"
import * as LabelPrimitive from "@radix-ui/react-label"
import { Slot } from "@radix-ui/react-slot"
import {
  Controller,
  FormProvider,
  useFormContext,
  type ControllerProps,
  type FieldPath,
  type FieldValues,
} from "react-hook-form"

import { cn } from "@/lib/utils"
import { Label } from "@/components/ui/label"

const Form = FormProvider

type FormFieldContextValue<
  TFieldValues extends FieldValues = FieldValues,
  TName extends FieldPath<TFieldValues> = FieldPath<TFieldValues>
> = {
  name: TName
}

const FormFieldContext = React.createContext<FormFieldContextValue>(
  {} as FormFieldContextValue
)

const FormField = <
  TFieldValues extends FieldValues = FieldValues,
  TName extends FieldPath<TFieldValues> = FieldPath<TFieldValues>
>({
  ...props
}: ControllerProps<TFieldValues, TName>) => {
  return (
    <FormFieldContext.Provider value={{ name: props.name }}>
      <Controller {...props} />
    </FormFieldContext.Provider>
  )
}

const useFormField = () => {
  const fieldContext = React.useContext(FormFieldContext)
  const itemContext = React.useContext(FormItemContext)
  const { getFieldState, formState } = useFormContext()

  const fieldState = getFieldState(fieldContext.name, formState)

  if (!fieldContext) {
    throw new Error("useFormField should be used within <FormField>")
  }

  const { id } = itemContext

  return {
    id,
    name: fieldContext.name,
    formItemId: `${id}-form-item`,
    formDescriptionId: `${id}-form-item-description`,
    formMessageId: `${id}-form-item-message`,
    ...fieldState,
  }
}

type FormItemContextValue = {
  id: string
}

const FormItemContext = React.createContext<FormItemContextValue>(
  {} as FormItemContextValue
)

const FormItem = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => {
  const id = React.useId()

  return (
    <FormItemContext.Provider value={{ id }}>
      <div ref={ref} className={cn("space-y-2", className)} {...props} />
    </FormItemContext.Provider>
  )
})
FormItem.displayName = "FormItem"

const FormLabel = React.forwardRef<
  React.ElementRef<typeof LabelPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof LabelPrimitive.Root>
>(({ className, ...props }, ref) => {
  const { error, formItemId } = useFormField()

  return (
    <Label
      ref={ref}
      className={cn(error && "text-destructive", className)}
      htmlFor={formItemId}
      {...props}
    />
  )
})
FormLabel.displayName = "FormLabel"

const FormControl = React.forwardRef<
  React.ElementRef<typeof Slot>,
  React.ComponentPropsWithoutRef<typeof Slot>
>(({ ...props }, ref) => {
  const { error, formItemId, formDescriptionId, formMessageId } = useFormField()

  return (
    <Slot
      ref={ref}
      id={formItemId}
      aria-describedby={
        !error
          ? `${formDescriptionId}`
          : `${formDescriptionId} ${formMessageId}`
      }
      aria-invalid={!!error}
      {...props}
    />
  )
})
FormControl.displayName = "FormControl"

const FormDescription = React.forwardRef<
  HTMLParagraphElement,
  React.HTMLAttributes<HTMLParagraphElement>
>(({ className, ...props }, ref) => {
  const { formDescriptionId } = useFormField()

  return (
    <p
      ref={ref}
      id={formDescriptionId}
      className={cn("text-[0.8rem] text-muted-foreground", className)}
      {...props}
    />
  )
})
FormDescription.displayName = "FormDescription"

const FormMessage = React.forwardRef<
  HTMLParagraphElement,
  React.HTMLAttributes<HTMLParagraphElement>
>(({ className, children, ...props }, ref) => {
  const { error, formMessageId } = useFormField()
  const body = error ? String(error?.message ?? "") : children

  if (!body) {
    return null
  }

  return (
    <p
      ref={ref}
      id={formMessageId}
      className={cn("text-[0.8rem] font-medium text-destructive", className)}
      {...props}
    >
      {body}
    </p>
  )
})
FormMessage.displayName = "FormMessage"

export {
  useFormField,
  Form,
  FormItem,
  FormLabel,
  FormControl,
  FormDescription,
  FormMessage,
  FormField,
}
</file>

<file path="components/ui/glass-card.tsx">
import * as React from "react"
import { cn } from "@/lib/utils"

export interface GlassCardProps extends React.HTMLAttributes<HTMLDivElement> {
  variant?: 'default' | 'strong' | 'modal' | 'panel'
  children: React.ReactNode
}

const GlassCard = React.forwardRef<HTMLDivElement, GlassCardProps>(
  ({ className, variant = 'default', children, ...props }, ref) => {
    const variants = {
      default: 'glass',
      strong: 'glass-strong',
      modal: 'glass-modal',
      panel: 'bg-stone-300/90 backdrop-blur-md border border-stone-400/30 rounded-xl shadow-glass'
    }
    
    return (
      <div 
        ref={ref}
        className={cn(variants[variant], className)}
        {...props}
      >
        {children}
      </div>
    )
  }
)
GlassCard.displayName = "GlassCard"

export { GlassCard }
</file>

<file path="components/ui/glass-modal.tsx">
import * as React from "react"
import { motion, AnimatePresence } from "framer-motion"
import { cn } from "@/lib/utils"

export interface GlassModalProps {
  isOpen: boolean
  onClose: () => void
  children: React.ReactNode
  className?: string
  overlayClassName?: string
  sizeClassName?: string
}

const GlassModal = React.forwardRef<HTMLDivElement, GlassModalProps>(
  ({ isOpen, onClose, children, className, overlayClassName, sizeClassName }, ref) => {
    return (
      <AnimatePresence>
        {isOpen && (
          <motion.div 
            className={cn("fixed inset-0 z-50 flex items-center justify-center p-4 bg-stone-900/90 backdrop-blur", overlayClassName)}
            style={{ WebkitBackdropFilter: 'blur(8px)' }}
            initial={{ opacity: 0 }}
            animate={{ opacity: 1 }}
            exit={{ opacity: 0 }}
            onClick={onClose}
          >
            <motion.div
              ref={ref}
              className={cn("glass-modal relative z-10 w-full", sizeClassName, className)}
              initial={{ scale: 0.9, opacity: 0, y: 20 }}
              animate={{ scale: 1, opacity: 1, y: 0 }}
              exit={{ scale: 0.9, opacity: 0, y: 20 }}
              transition={{ type: "spring", damping: 25, stiffness: 300 }}
              onClick={(e) => e.stopPropagation()}
              layout
            >
              {children}
            </motion.div>
          </motion.div>
        )}
      </AnimatePresence>
    )
  }
)
GlassModal.displayName = "GlassModal"

export { GlassModal }
</file>

<file path="components/ui/input.tsx">
import * as React from "react"

import { cn } from "@/lib/utils"

const Input = React.forwardRef<HTMLInputElement, React.ComponentProps<"input">>(
  ({ className, type, ...props }, ref) => {
    return (
      <input
        type={type}
        className={cn(
          "flex h-9 w-full rounded-md border border-input bg-transparent px-3 py-1 text-base shadow-sm transition-colors file:border-0 file:bg-transparent file:text-sm file:font-medium file:text-foreground placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:cursor-not-allowed disabled:opacity-50 md:text-sm",
          className
        )}
        ref={ref}
        {...props}
      />
    )
  }
)
Input.displayName = "Input"

export { Input }
</file>

<file path="components/ui/label.tsx">
"use client"

import * as React from "react"
import * as LabelPrimitive from "@radix-ui/react-label"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const labelVariants = cva(
  "text-sm font-medium leading-none peer-disabled:cursor-not-allowed peer-disabled:opacity-70"
)

const Label = React.forwardRef<
  React.ElementRef<typeof LabelPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof LabelPrimitive.Root> &
    VariantProps<typeof labelVariants>
>(({ className, ...props }, ref) => (
  <LabelPrimitive.Root
    ref={ref}
    className={cn(labelVariants(), className)}
    {...props}
  />
))
Label.displayName = LabelPrimitive.Root.displayName

export { Label }
</file>

<file path="components/ui/loading-spinner.tsx">
import * as React from "react"
import { cn } from "@/lib/utils"

export interface LoadingSpinnerProps {
  size?: 'sm' | 'md' | 'lg'
  variant?: 'default' | 'glass'
  className?: string
}

const LoadingSpinner = React.forwardRef<HTMLDivElement, LoadingSpinnerProps>(
  ({ size = 'md', variant = 'default', className }, ref) => {
    const sizes = {
      sm: 'w-4 h-4',
      md: 'w-8 h-8',
      lg: 'w-12 h-12'
    }
    
    const variants = {
      default: 'border-2 border-stone-300 border-t-stone-600',
      glass: 'border-2 border-white/30 border-t-white'
    }
    
    return (
      <div
        ref={ref}
        className={cn(
          "animate-spin rounded-full",
          sizes[size],
          variants[variant],
          className
        )}
      />
    )
  }
)
LoadingSpinner.displayName = "LoadingSpinner"

export { LoadingSpinner }
</file>

<file path="components/ui/MappingSourcesPanel.tsx">
'use client';

import React, { useMemo, useEffect, useState } from 'react';
import { useDrag } from 'react-dnd';
import { Zap, Music, Activity } from 'lucide-react';
import { cn } from '@/lib/utils';
import { useAudioFeatures, AudioFeature } from '@/hooks/use-audio-features';
import { debugLog } from '@/lib/utils';

// Enhanced FeatureNode with live meter
const FeatureNode = ({ 
  feature, 
  category, 
  currentTime, 
  cachedAnalysis,
  isPlaying 
}: { 
  feature: AudioFeature; 
  category: string;
  currentTime: number;
  cachedAnalysis: any[];
  isPlaying: boolean;
}) => {
  const [liveValue, setLiveValue] = useState(0);
  const [isActive, setIsActive] = useState(false);
  
  // Calculate live feature value from cached analysis
  useEffect(() => {
    if (!cachedAnalysis || cachedAnalysis.length === 0 || !feature.stemType) {
      setLiveValue(0);
      setIsActive(false);
      return;
    }

    // Find the analysis data for this feature's stem type
    const analysis = cachedAnalysis.find(a => a.stemType === feature.stemType);
    if (!analysis || !analysis.analysisData) {
      setLiveValue(0);
      setIsActive(false);
      return;
    }

    // Map feature ID to enhanced analysis data (aligned with consolidated hook shape)
    const getEnhancedFeatureValue = (featureId: string, time: number): number => {
      const parts = featureId.split('-');
      if (parts.length >= 2) {
        const featureName = parts.slice(1).join('-');

        const times = (analysis.analysisData as any).frameTimes as Float32Array | number[] | undefined;
        const getTimeSeriesValue = (arr: Float32Array | undefined): number => {
          if (!arr || arr.length === 0 || !times || times.length === 0) return 0;
          // Binary search on times
          let lo = 0;
          let hi = Math.min(times.length - 1, arr.length - 1);
          while (lo < hi) {
            const mid = (lo + hi + 1) >>> 1;
            const tmid = (times as any)[mid];
            if (tmid <= time) lo = mid; else hi = mid - 1;
          }
          const index = Math.max(0, Math.min(arr.length - 1, lo));
          return arr[index] ?? 0;
        };

        switch (featureName) {
          case 'impact': {
            const transient = analysis.analysisData.transients?.find((t: any) => Math.abs(t.time - time) < 0.1);
            return transient?.intensity ?? 0;
          }
          case 'pitch-height': {
            const chromaHit = analysis.analysisData.chroma?.find((c: any) => Math.abs(c.time - time) < 0.1);
            return chromaHit?.pitch ?? 0;
          }
          case 'brightness': {
            const chromaHit = analysis.analysisData.chroma?.find((c: any) => Math.abs(c.time - time) < 0.1);
            return chromaHit?.confidence ?? 0;
          }
          case 'rms':
            return getTimeSeriesValue(analysis.analysisData.rms);
          case 'volume':
            return getTimeSeriesValue(analysis.analysisData.volume ?? analysis.analysisData.rms);
          case 'loudness':
            return getTimeSeriesValue(analysis.analysisData.loudness);
          default:
            return 0;
        }
      }
      return 0;
    };

    const featureValue = getEnhancedFeatureValue(feature.id, currentTime);
    
    // Normalize value to 0-1 range for display
    const normalizedValue = Math.max(0, Math.min(1, featureValue));
    
    setLiveValue(normalizedValue);
    setIsActive(isPlaying && normalizedValue > 0.1); // Active if playing and has significant value
  }, [feature, currentTime, cachedAnalysis, isPlaying]);

  // Wrap useDrag in try-catch to handle context errors
  let dragState = { isDragging: false };
  let dragRef: React.RefCallback<HTMLDivElement> = () => {};
  
  try {
    const dragResult = useDrag({
      type: 'feature',
      item: { 
        id: feature.id, 
        name: feature.name, 
        stemType: feature.stemType 
      },
      collect: (monitor) => ({
        isDragging: monitor.isDragging(),
      }),
    });
    
    dragState = dragResult[0];
    const drag = dragResult[1];
    
    dragRef = React.useCallback((node: HTMLDivElement | null) => {
      drag(node);
    }, [drag]);
  } catch (error) {
    // If drag context is not available, just use a no-op
    debugLog.warn('Drag context not available for FeatureNode:', error);
  }
  
  return (
    <div 
      ref={dragRef}
      className={`cursor-grab transition-all duration-200 hover:bg-gray-800 ${dragState.isDragging ? 'opacity-50' : ''}`} 
      title={feature.description}
    >
      <div className={cn(
        "w-full px-2 py-1.5 text-xs font-medium border border-gray-700 transition-all duration-200",
        "bg-black hover:bg-gray-900",
        dragState.isDragging && "shadow-lg",
        isActive && "ring-1 ring-opacity-50",
        isActive && category === 'rhythm' && "ring-red-400",
        isActive && category === 'pitch' && "ring-blue-400", 
        isActive && category === 'intensity' && "ring-yellow-400",
        isActive && category === 'timbre' && "ring-purple-400"
      )}>
        <div className="flex items-center justify-between w-full mb-1">
          <span className="truncate font-medium text-gray-300">{feature.name}</span>
          {feature.stemType && (
            <span className="text-xs opacity-60 ml-1 text-gray-400">
              {getStemTypeDisplayName(feature.stemType)}
            </span>
          )}
        </div>
        
        {/* Live Meter */}
        <div className="w-full bg-gray-800 rounded-sm h-1 mb-1 overflow-hidden">
          <div 
            className={cn(
              "h-full rounded-sm transition-all duration-150 ease-out",
              category === 'rhythm' && "bg-red-500",
              category === 'pitch' && "bg-blue-500", 
              category === 'intensity' && "bg-yellow-500",
              category === 'timbre' && "bg-purple-500"
            )}
            style={{ 
              width: `${liveValue * 100}%`,
              transform: isActive ? 'scaleY(1.1)' : 'scaleY(1)',
              transition: 'width 150ms ease-out, transform 150ms ease-out'
            }}
          />
        </div>
        
        {/* Value indicator */}
        <div className="flex items-center justify-between text-xs opacity-70 text-gray-400">
          <span>{(liveValue * 100).toFixed(0)}%</span>
          {isActive && (
            <span className={cn(
              "w-1 h-1 rounded-full animate-pulse",
              category === 'rhythm' && "bg-red-400",
              category === 'pitch' && "bg-blue-400",
              category === 'intensity' && "bg-yellow-400", 
              category === 'timbre' && "bg-purple-400"
            )} />
          )}
        </div>
      </div>
    </div>
  );
};

interface MappingSourcesPanelProps {
  activeTrackId?: string;
  className?: string;
  selectedStemType?: string;
  currentTime?: number;
  cachedAnalysis?: any[];
  isPlaying?: boolean;
}

const categoryIcons = {
  rhythm: Activity,
  pitch: Music,
  intensity: Zap,
  timbre: Music, // Using Music as fallback for timbre
};



// Map technical category names to intuitive display names
const categoryDisplayNames = {
  rhythm: 'Rhythm & Groove',
  pitch: 'Pitch & Tone',
  intensity: 'Energy & Impact',
  timbre: 'Texture & Character',
};

// Map stem types to intuitive display names
const getStemTypeDisplayName = (stemType: string): string => {
  const displayNames: Record<string, string> = {
    'drums': ' Drums',
    'bass': ' Bass',
    'vocals': ' Vocals',
    'melody': ' Melody',
    'other': ' Other',
  };
  return displayNames[stemType] || stemType;
};

export function MappingSourcesPanel({ 
  activeTrackId, 
  className, 
  selectedStemType,
  currentTime = 0,
  cachedAnalysis = [],
  isPlaying = false
}: MappingSourcesPanelProps) {
  const features = useAudioFeatures(activeTrackId, selectedStemType);
  
  const featuresByCategory = useMemo(() => {
    return features.reduce((acc, feature) => {
      if (!acc[feature.category]) {
        acc[feature.category] = [];
      }
      acc[feature.category].push(feature);
      return acc;
    }, {} as Record<string, AudioFeature[]>);
  }, [features]);

  if (!activeTrackId) {
    return (
      <div className={cn("bg-black border border-gray-800", className)}>
        <div className="p-3 border-b border-gray-800">
          <div className="flex items-center gap-2">
            <Zap className="h-4 w-4 text-gray-300" />
            <span className="text-sm font-semibold text-gray-100">Audio Features</span>
          </div>
        </div>
        <div className="p-4">
          <div className="text-xs text-gray-500 text-center py-2">
            Select a track to see available features
          </div>
        </div>
      </div>
    );
  }

  return (
    <div className={cn("bg-black border border-gray-800 flex flex-col", className)}>
      <div className="p-3 border-b border-gray-800">
        <div className="flex items-center gap-2">
          <Zap className="h-4 w-4 text-gray-300" />
          <span className="text-sm font-semibold text-gray-100">Audio Features</span>
        </div>
        <div className="text-xs text-gray-500 mt-1">
          Drag features to map to effect parameters
        </div>
      </div>
      <div className="flex-1 overflow-y-auto p-3 space-y-3">
        {Object.entries(featuresByCategory).map(([category, categoryFeatures]) => {
          const Icon = categoryIcons[category as keyof typeof categoryIcons];
          
          return (
            <div key={category} className="space-y-1.5">
              <div className="flex items-center gap-2">
                <Icon className="h-3 w-3 text-gray-400" />
                <span className="text-xs font-medium text-gray-400 uppercase tracking-wider">
                  {categoryDisplayNames[category as keyof typeof categoryDisplayNames] || category}
                </span>
                <span className="text-xs text-gray-600 bg-gray-800 px-1.5 py-0.5 rounded border border-gray-700">
                  {categoryFeatures.length}
                </span>
              </div>
              <div className="space-y-1">
                {(categoryFeatures as AudioFeature[]).map((feature) => (
                  <FeatureNode
                    key={feature.id}
                    feature={feature}
                    category={feature.category}
                    currentTime={currentTime}
                    cachedAnalysis={cachedAnalysis}
                    isPlaying={isPlaying}
                  />
                ))}
              </div>
            </div>
          );
        })}
      </div>
    </div>
  );
}
</file>

<file path="components/ui/modulation-attenuator.tsx">
'use client';

import React, { useState, useRef } from 'react';
import { cn } from '@/lib/utils';

interface ModulationAttenuatorProps {
  value: number; // 0-1
  onChange: (value: number) => void;
  className?: string;
  size?: 'sm' | 'md';
}

export function ModulationAttenuator({ 
  value, 
  onChange, 
  className,
  size = 'sm'
}: ModulationAttenuatorProps) {
  const [isDragging, setIsDragging] = useState(false);
  const knobRef = useRef<HTMLDivElement>(null);
  const previousY = useRef(0);
  const currentValueRef = useRef(0);
  const isPointerDownRef = useRef(false);

  const sizeClasses = {
    sm: 'w-8 h-8',
    md: 'w-10 h-10'
  };

  const knobSize = size === 'sm' ? 6 : 8;
  const knobRadius = size === 'sm' ? 12 : 15;

  // Map value [0..1] to angle [-135..+135], noon at 0
  const knobAngle = (value - 0.5) * 270; // -135 at 0, 0 at .5, +135 at 1

  const handlePointerDown = (e: React.PointerEvent) => {
    e.preventDefault();
    e.stopPropagation();
    
    setIsDragging(true);
    isPointerDownRef.current = true;
    previousY.current = e.clientY;
    currentValueRef.current = value;
    
    const handlePointerMove = (ev: PointerEvent) => {
      if (!isPointerDownRef.current) return;
      
      // Calculate delta from previous position
      const deltaY = previousY.current - ev.clientY; // down is negative, up is positive
      const sensitivity = 0.005; // Adjust sensitivity for smoother control
      const proposedDelta = deltaY * sensitivity;
      
      // Calculate tentative new value
      let tentative = currentValueRef.current + proposedDelta;
      
      // Clamp to [0, 1] range - no wrap-around
      const nextValue = Math.max(0, Math.min(1, tentative));
      
      // Only update if value actually changed (prevents jitter at bounds)
      if (nextValue !== currentValueRef.current) {
        currentValueRef.current = nextValue;
        onChange(nextValue);
      }
      
      // Always update previousY to track cursor position
      previousY.current = ev.clientY;
    };

    const handlePointerUp = () => {
      isPointerDownRef.current = false;
      setIsDragging(false);
      document.removeEventListener('pointermove', handlePointerMove);
      document.removeEventListener('pointerup', handlePointerUp);
    };

    // Attach global listeners for robust drag
    document.addEventListener('pointermove', handlePointerMove);
    document.addEventListener('pointerup', handlePointerUp);
  };

  return (
    <div className={cn(
      "relative flex items-center gap-2 select-none",
      className
    )}
      onMouseEnter={(e) => e.stopPropagation()}
      onMouseLeave={(e) => e.stopPropagation()}
    >
      {/* Value display - positioned to the left */}
      <div className="text-xs text-white font-mono min-w-[5ch] text-right">
        {(() => { const pct = Math.round((value - 0.5) * 100); return `${pct>0?'+':''}${pct}%`; })()}
      </div>
      
      {/* Knob container */}
      <div 
        className={cn(
          "relative flex items-center justify-center cursor-ns-resize",
          sizeClasses[size],
          "pointer-events-auto"
        )}
        style={{ pointerEvents: 'auto' }}
        onPointerDown={(e) => { e.stopPropagation(); handlePointerDown(e as unknown as React.PointerEvent); }}
      >
        {/* Knob base */}
        <div className={cn(
          "absolute inset-0 rounded-full border-2",
          isDragging ? "border-white/30" : "border-white/20",
        )}
          style={{ backgroundColor: '#0b0b0b' }}
        />

        {/* Indicator line */}
        <div
          className="absolute left-1/2 top-1/2 origin-bottom bg-white"
          style={{
            width: 2,
            height: knobRadius,
            transform: `translate(-50%, -100%) rotate(${knobAngle}deg)`,
            borderRadius: 1
          }}
        />
      </div>
    </div>
  );
}
</file>

<file path="components/ui/phonoglyph-logo.tsx">
import React from 'react';
import { cn } from '@/lib/utils';

interface PhonoglyphLogoProps {
  className?: string;
  size?: 'sm' | 'md' | 'lg';
}

export function PhonoglyphLogo({ className, size = 'md' }: PhonoglyphLogoProps) {
  const sizeClasses = {
    sm: 'text-[2px] leading-[2px]',
    md: 'text-[3px] leading-[3px]',
    lg: 'text-[4px] leading-[4px]'
  };

  return (
    <pre className={cn(
      "font-mono whitespace-pre text-gray-100 overflow-hidden w-full",
      sizeClasses[size],
      className
    )}>
{`                                                                                                                    
                                                                                                                    
\`7MM"""Mq.\`7MMF'  \`7MMF' .g8""8q. \`7MN.   \`7MF' .g8""8q.     .g8"""bgd \`7MMF'   \`YMM'   \`MM'\`7MM"""Mq.\`7MMF'  \`7MMF'
  MM   \`MM. MM      MM .dP'    \`YM. MMN.    M .dP'    \`YM. .dP'     \`M   MM       VMA   ,V    MM   \`MM. MM      MM  
  MM   ,M9  MM      MM dM'      \`MM M YMb   M dM'      \`MM dM'       \`   MM        VMA ,V     MM   ,M9  MM      MM  
  MMmmdM9   MMmmmmmmMM MM        MM M  \`MN. M MM        MM MM            MM         VMMP      MMmmdM9   MMmmmmmmMM  
  MM        MM      MM MM.      ,MP M   \`MM.M MM.      ,MP MM.    \`7MMF' MM      ,   MM       MM        MM      MM  
  MM        MM      MM \`Mb.    ,dP' M     YMM \`Mb.    ,dP' \`Mb.     MM   MM     ,M   MM       MM        MM      MM  
.JMML.    .JMML.  .JMML. \`"bmmd"' .JML.    YM   \`"bmmd"'     \`"bmmmdPY .JMMmmmmMMM .JMML.   .JMML.    .JMML.  .JMML.
                                                                                                                    
                                                                                                                    `}
    </pre>
  );
}
</file>

<file path="components/ui/portal-modal.tsx">
import React, { useRef, useEffect, useState, useCallback } from 'react';
import { createPortal } from 'react-dom';
import Draggable from 'react-draggable';
import { cn } from '@/lib/utils';
import { debugLog } from '@/lib/utils';

interface PortalModalProps {
  children: React.ReactNode;
  title: string;
  isOpen: boolean;
  onClose: () => void;
  initialPosition?: { x: number; y: number };
  className?: string;
  bounds?: string;
  portalContainerId?: string;
}

export function PortalModal({
  children,
  title,
  isOpen,
  onClose,
  initialPosition = { x: 0, y: 0 },
  className,
  bounds = '#editor-bounds',
  portalContainerId = 'modal-portal-root',
}: PortalModalProps) {
  const nodeRef = useRef<HTMLDivElement>(null);
  const [portalContainer, setPortalContainer] = useState<HTMLElement | null>(null);
  const [boundingBox, setBoundingBox] = useState<{ left: number; top: number; right: number; bottom: number } | null>(null);

  // Calculate and update bounds
  const updateBounds = useCallback(() => {
    if (!bounds) return;
    
    const boundsEl = document.querySelector(bounds);
    if (!boundsEl) return;

    const boundsRect = boundsEl.getBoundingClientRect();
    const modalWidth = 288; // w-72 = 18rem = 288px
    const modalHeight = nodeRef.current?.offsetHeight || 400; // Fallback height

    setBoundingBox({
      left: Math.floor(boundsRect.left),
      top: Math.floor(boundsRect.top),
      right: Math.floor(boundsRect.right - modalWidth),
      bottom: Math.floor(boundsRect.bottom - modalHeight)
    });
  }, [bounds]);

  // Set up bounds calculation and window resize handler
  useEffect(() => {
    if (!isOpen) return;

    // Initial bounds calculation
    updateBounds();

    // Recalculate on resize
    window.addEventListener('resize', updateBounds);
    
    // Set up mutation observer to watch for DOM changes that might affect bounds
    const observer = new MutationObserver(updateBounds);
    const boundsEl = document.querySelector(bounds || '');
    if (boundsEl) {
      observer.observe(boundsEl, { 
        attributes: true,
        childList: true,
        subtree: true 
      });
    }

    return () => {
      window.removeEventListener('resize', updateBounds);
      observer.disconnect();
    };
  }, [isOpen, bounds, updateBounds]);

  // Create portal container
  useEffect(() => {
    let container = document.getElementById(portalContainerId);
    if (!container) {
      container = document.createElement('div');
      container.id = portalContainerId;
      container.style.position = 'fixed';
      container.style.top = '0';
      container.style.left = '0';
      container.style.width = '100vw';
      container.style.height = '100vh';
      container.style.pointerEvents = 'none';
      container.style.zIndex = '50';
      document.body.appendChild(container);
    }
    setPortalContainer(container);

    return () => {
      // Only cleanup if this is the last modal being closed
      if (container && container.childNodes.length === 0) {
        // Use a small delay to ensure all cleanup is complete
        setTimeout(() => {
          if (container && container.childNodes.length === 0 && container.parentNode) {
            try {
        document.body.removeChild(container);
            } catch (error) {
              // Container might have already been removed, ignore the error
              debugLog.warn('Portal container cleanup error:', error);
            }
          }
        }, 100);
      }
    };
  }, [portalContainerId]);

  if (!isOpen || !portalContainer) return null;

  const modalContent = (
    <div style={{ pointerEvents: 'auto' }}>
      <Draggable
        nodeRef={nodeRef}
        handle=".drag-handle"
        defaultPosition={initialPosition}
        bounds={boundingBox || undefined}
        onStart={updateBounds}
        onDrag={updateBounds}
      >
        <div 
          ref={nodeRef} 
          className={cn(
            "absolute top-0 left-0 w-72 rounded-lg shadow-2xl",
            "bg-white/10 backdrop-blur-xl border border-white/20",
            className
          )}
          style={{
            background: 'linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0.05))'
          }}
        >
          {/* Title Bar */}
          <div className="drag-handle cursor-move bg-white p-1 rounded-t-md border-b border-black/30 flex items-center gap-1.5 h-7">
            {/* Close Button */}
            <button
              onClick={onClose}
              className="w-4 h-4 border border-black/80 flex-shrink-0 bg-white hover:bg-gray-100 transition-colors duration-200 flex items-center justify-center group relative"
              aria-label="Close"
            >
              <div className="absolute w-full h-0.5 bg-black transform rotate-45 scale-x-0 group-hover:scale-x-100 transition-transform duration-200"></div>
              <div className="absolute w-full h-0.5 bg-black transform -rotate-45 scale-x-0 group-hover:scale-x-100 transition-transform duration-200"></div>
            </button>

            {/* Title Text and Lines */}
            <div className="flex-grow flex items-center justify-center gap-1.5 overflow-hidden">
              <div className="space-y-0.5 flex-grow">
                {Array.from({ length: 6 }).map((_, i) => (
                  <div key={i} className="h-px bg-black"></div>
                ))}
              </div>
              <span className="flex-shrink-0 bg-white px-1 text-xs font-mono font-bold text-black">{title}</span>
              <div className="space-y-0.5 flex-grow">
                {Array.from({ length: 6 }).map((_, i) => (
                  <div key={i} className="h-px bg-black"></div>
                ))}
              </div>
            </div>
          </div>
          
          {/* Content Area */}
          <div className="p-4 rounded-b-md bg-transparent">
            {children}
          </div>
        </div>
      </Draggable>
    </div>
  );

  return createPortal(modalContent, portalContainer);
}
</file>

<file path="components/ui/progress.tsx">
"use client"

import * as React from "react"
import * as ProgressPrimitive from "@radix-ui/react-progress"

import { cn } from "@/lib/utils"

const Progress = React.forwardRef<
  React.ElementRef<typeof ProgressPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof ProgressPrimitive.Root>
>(({ className, value, ...props }, ref) => (
  <ProgressPrimitive.Root
    ref={ref}
    className={cn(
      "relative h-4 w-full overflow-hidden rounded-full bg-secondary",
      className
    )}
    {...props}
  >
    <ProgressPrimitive.Indicator
      className="h-full w-full flex-1 bg-primary transition-all"
      style={{ transform: `translateX(-${100 - (value || 0)}%)` }}
    />
  </ProgressPrimitive.Root>
))
Progress.displayName = ProgressPrimitive.Root.displayName

export { Progress }
</file>

<file path="components/ui/select.tsx">
"use client"

import * as React from "react"
import * as SelectPrimitive from "@radix-ui/react-select"
import { Check, ChevronDown, ChevronUp } from "lucide-react"

import { cn } from "@/lib/utils"

const Select = SelectPrimitive.Root

const SelectGroup = SelectPrimitive.Group

const SelectValue = SelectPrimitive.Value

const SelectTrigger = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Trigger>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Trigger>
>(({ className, children, ...props }, ref) => (
  <SelectPrimitive.Trigger
    ref={ref}
    className={cn(
      "flex h-10 w-full items-center justify-between rounded-md border border-input bg-background px-3 py-2 text-sm ring-offset-background placeholder:text-muted-foreground focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 [&>span]:line-clamp-1",
      className
    )}
    {...props}
  >
    {children}
    <SelectPrimitive.Icon asChild>
      <ChevronDown className="h-4 w-4 opacity-50" />
    </SelectPrimitive.Icon>
  </SelectPrimitive.Trigger>
))
SelectTrigger.displayName = SelectPrimitive.Trigger.displayName

const SelectScrollUpButton = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.ScrollUpButton>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.ScrollUpButton>
>(({ className, ...props }, ref) => (
  <SelectPrimitive.ScrollUpButton
    ref={ref}
    className={cn(
      "flex cursor-default items-center justify-center py-1",
      className
    )}
    {...props}
  >
    <ChevronUp className="h-4 w-4" />
  </SelectPrimitive.ScrollUpButton>
))
SelectScrollUpButton.displayName = SelectPrimitive.ScrollUpButton.displayName

const SelectScrollDownButton = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.ScrollDownButton>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.ScrollDownButton>
>(({ className, ...props }, ref) => (
  <SelectPrimitive.ScrollDownButton
    ref={ref}
    className={cn(
      "flex cursor-default items-center justify-center py-1",
      className
    )}
    {...props}
  >
    <ChevronDown className="h-4 w-4" />
  </SelectPrimitive.ScrollDownButton>
))
SelectScrollDownButton.displayName =
  SelectPrimitive.ScrollDownButton.displayName

const SelectContent = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Content>
>(({ className, children, position = "popper", ...props }, ref) => (
  <SelectPrimitive.Portal>
    <SelectPrimitive.Content
      ref={ref}
      className={cn(
        "relative z-50 max-h-96 min-w-[8rem] overflow-hidden rounded-md border bg-popover text-popover-foreground shadow-md data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2",
        position === "popper" &&
          "data-[side=bottom]:translate-y-1 data-[side=left]:-translate-x-1 data-[side=right]:translate-x-1 data-[side=top]:-translate-y-1",
        className
      )}
      position={position}
      {...props}
    >
      <SelectScrollUpButton />
      <SelectPrimitive.Viewport
        className={cn(
          "p-1",
          position === "popper" &&
            "h-[var(--radix-select-trigger-height)] w-full min-w-[var(--radix-select-trigger-width)]"
        )}
      >
        {children}
      </SelectPrimitive.Viewport>
      <SelectScrollDownButton />
    </SelectPrimitive.Content>
  </SelectPrimitive.Portal>
))
SelectContent.displayName = SelectPrimitive.Content.displayName

const SelectLabel = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Label>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Label>
>(({ className, ...props }, ref) => (
  <SelectPrimitive.Label
    ref={ref}
    className={cn("py-1.5 pl-8 pr-2 text-sm font-semibold", className)}
    {...props}
  />
))
SelectLabel.displayName = SelectPrimitive.Label.displayName

const SelectItem = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Item>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Item>
>(({ className, children, ...props }, ref) => (
  <SelectPrimitive.Item
    ref={ref}
    className={cn(
      "relative flex w-full cursor-default select-none items-center rounded-sm py-1.5 pl-8 pr-2 text-sm outline-none focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50",
      className
    )}
    {...props}
  >
    <span className="absolute left-2 flex h-3.5 w-3.5 items-center justify-center">
      <SelectPrimitive.ItemIndicator>
        <Check className="h-4 w-4" />
      </SelectPrimitive.ItemIndicator>
    </span>

    <SelectPrimitive.ItemText>{children}</SelectPrimitive.ItemText>
  </SelectPrimitive.Item>
))
SelectItem.displayName = SelectPrimitive.Item.displayName

const SelectSeparator = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Separator>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Separator>
>(({ className, ...props }, ref) => (
  <SelectPrimitive.Separator
    ref={ref}
    className={cn("-mx-1 my-1 h-px bg-muted", className)}
    {...props}
  />
))
SelectSeparator.displayName = SelectPrimitive.Separator.displayName

export {
  Select,
  SelectGroup,
  SelectValue,
  SelectTrigger,
  SelectContent,
  SelectLabel,
  SelectItem,
  SelectSeparator,
  SelectScrollUpButton,
  SelectScrollDownButton,
}
</file>

<file path="components/ui/separator.tsx">
"use client"

import * as React from "react"
import * as SeparatorPrimitive from "@radix-ui/react-separator"

import { cn } from "@/lib/utils"

const Separator = React.forwardRef<
  React.ElementRef<typeof SeparatorPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof SeparatorPrimitive.Root>
>(
  (
    { className, orientation = "horizontal", decorative = true, ...props },
    ref
  ) => (
    <SeparatorPrimitive.Root
      ref={ref}
      decorative={decorative}
      orientation={orientation}
      className={cn(
        "shrink-0 bg-border",
        orientation === "horizontal" ? "h-[1px] w-full" : "h-full w-[1px]",
        className
      )}
      {...props}
    />
  )
)
Separator.displayName = SeparatorPrimitive.Root.displayName

export { Separator }
</file>

<file path="components/ui/slider.tsx">
"use client"

import * as React from "react"
import * as SliderPrimitive from "@radix-ui/react-slider"

import { cn } from "@/lib/utils"

const Slider = React.forwardRef<
  React.ElementRef<typeof SliderPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof SliderPrimitive.Root>
>(({ className, ...props }, ref) => (
  <SliderPrimitive.Root
    ref={ref}
    className={cn(
      "relative flex w-full touch-none select-none items-center",
      className
    )}
    {...props}
  >
    <SliderPrimitive.Track className="relative h-1.5 w-full grow overflow-hidden rounded-full bg-white/20">
      <SliderPrimitive.Range className="absolute h-full bg-white/80" />
    </SliderPrimitive.Track>
    <SliderPrimitive.Thumb className="block h-4 w-4 rounded-full border-2 border-white/80 bg-white/50 ring-offset-background focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-white/60 focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50" />
  </SliderPrimitive.Root>
))
Slider.displayName = SliderPrimitive.Root.displayName

export { Slider }
</file>

<file path="components/ui/stat-bar.tsx">
import React from "react";
import { cn } from "@/lib/utils";

export function StatBar({ label, value, max = 5, color = "bg-lcd-green", className }: {
  label: string;
  value: number;
  max?: number;
  color?: string;
  className?: string;
}) {
  return (
    <div className={cn("flex items-center gap-2", className)}>
      <span className="w-20 text-xs font-bold text-lcd-green font-mono uppercase tracking-widest drop-shadow-lcd">{label}</span>
      <div className="flex gap-1">
        {Array.from({ length: max }).map((_, i) => (
          <div
            key={i}
            className={cn(
              "h-3 w-6 rounded-[2px] border border-lcd-green transition-all duration-200",
              i < value ? color : "bg-lcd-dark"
            )}
          />
        ))}
      </div>
    </div>
  );
}
</file>

<file path="components/ui/status-indicator.tsx">
import * as React from "react"
import { cn } from "@/lib/utils"

export interface StatusIndicatorProps {
  status: 'live' | 'processing' | 'completed' | 'error' | 'warning'
  children: React.ReactNode
  className?: string
}

const StatusIndicator = React.forwardRef<HTMLDivElement, StatusIndicatorProps>(
  ({ status, children, className }, ref) => {
    const statusStyles = {
      live: 'status-live',
      processing: 'bg-amber-muted/80 text-amber-800 px-3 py-1 rounded-xl font-sans font-bold uppercase tracking-wider text-xs flex items-center gap-2',
      completed: 'bg-sage-accent/80 text-white px-3 py-1 rounded-xl font-sans font-bold uppercase tracking-wider text-xs flex items-center gap-2',
      error: 'bg-terracotta-accent/80 text-white px-3 py-1 rounded-xl font-sans font-bold uppercase tracking-wider text-xs flex items-center gap-2',
      warning: 'bg-amber-muted/80 text-amber-800 px-3 py-1 rounded-xl font-sans font-bold uppercase tracking-wider text-xs flex items-center gap-2'
    }
    
    return (
      <div
        ref={ref}
        className={cn(statusStyles[status], className)}
      >
        {status === 'live' && (
          <div className="w-2 h-2 bg-white rounded-full animate-pulse" />
        )}
        {status === 'processing' && (
          <div className="w-2 h-2 bg-amber-800 rounded-full animate-pulse" />
        )}
        {status === 'completed' && (
          <div className="w-2 h-2 bg-white rounded-full" />
        )}
        {status === 'error' && (
          <div className="w-2 h-2 bg-white rounded-full" />
        )}
        {status === 'warning' && (
          <div className="w-2 h-2 bg-amber-800 rounded-full" />
        )}
        {children}
      </div>
    )
  }
)
StatusIndicator.displayName = "StatusIndicator"

export { StatusIndicator }
</file>

<file path="components/ui/switch.tsx">
"use client"

import * as React from "react"
import * as SwitchPrimitives from "@radix-ui/react-switch"

import { cn } from "@/lib/utils"

const Switch = React.forwardRef<
  React.ElementRef<typeof SwitchPrimitives.Root>,
  React.ComponentPropsWithoutRef<typeof SwitchPrimitives.Root>
>(({ className, ...props }, ref) => (
  <SwitchPrimitives.Root
    className={cn(
      "peer inline-flex h-[24px] w-[44px] shrink-0 cursor-pointer items-center rounded-full border-2 border-transparent transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 focus-visible:ring-offset-background disabled:cursor-not-allowed disabled:opacity-50 data-[state=checked]:bg-primary data-[state=unchecked]:bg-input",
      className
    )}
    {...props}
    ref={ref}
  >
    <SwitchPrimitives.Thumb
      className={cn(
        "pointer-events-none block h-5 w-5 rounded-full bg-background shadow-lg ring-0 transition-transform data-[state=checked]:translate-x-5 data-[state=unchecked]:translate-x-0"
      )}
    />
  </SwitchPrimitives.Root>
))
Switch.displayName = SwitchPrimitives.Root.displayName

export { Switch }
</file>

<file path="components/ui/technical-button.tsx">
import * as React from "react"
import { cn } from "@/lib/utils"

export interface TechnicalButtonProps extends React.ButtonHTMLAttributes<HTMLButtonElement> {
  variant?: 'primary' | 'secondary'
  size?: 'sm' | 'md' | 'lg'
  children: React.ReactNode
}

const TechnicalButton = React.forwardRef<HTMLButtonElement, TechnicalButtonProps>(
  ({ className, variant = 'primary', size = 'md', children, type = 'button', ...props }, ref) => {
    const variants = {
      primary: 'technical-button-primary',
      secondary: 'technical-button-secondary'
    }
    
    const sizes = {
      sm: 'px-3 py-2 text-xs',
      md: 'px-6 py-3 text-sm',
      lg: 'px-8 py-4 text-base'
    }
    
    return (
      <button
        ref={ref}
        type={type}
        className={cn(
          variants[variant],
          sizes[size],
          "transition-all duration-300 ease-in-out",
          className
        )}
        {...props}
      >
        {children}
      </button>
    )
  }
)
TechnicalButton.displayName = "TechnicalButton"

export { TechnicalButton }
</file>

<file path="components/ui/toast.tsx">
"use client"

import * as React from "react"
import * as ToastPrimitives from "@radix-ui/react-toast"
import { cva, type VariantProps } from "class-variance-authority"
import { X } from "lucide-react"

import { cn } from "@/lib/utils"

const ToastProvider = ToastPrimitives.Provider

const ToastViewport = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Viewport>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Viewport>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Viewport
    ref={ref}
    className={cn(
      "fixed top-0 z-[100] flex max-h-screen w-full flex-col-reverse p-4 sm:bottom-0 sm:right-0 sm:top-auto sm:flex-col md:max-w-[420px]",
      className
    )}
    {...props}
  />
))
ToastViewport.displayName = ToastPrimitives.Viewport.displayName

const toastVariants = cva(
  "group pointer-events-auto relative flex w-full items-center justify-between space-x-2 overflow-hidden rounded-md border p-4 pr-6 shadow-lg transition-all data-[swipe=cancel]:translate-x-0 data-[swipe=end]:translate-x-[var(--radix-toast-swipe-end-x)] data-[swipe=move]:translate-x-[var(--radix-toast-swipe-move-x)] data-[swipe=move]:transition-none data-[state=open]:animate-in data-[state=closed]:animate-out data-[swipe=end]:animate-out data-[state=closed]:fade-out-80 data-[state=closed]:slide-out-to-right-full data-[state=open]:slide-in-from-top-full data-[state=open]:sm:slide-in-from-bottom-full",
  {
    variants: {
      variant: {
        default: "border bg-background text-foreground",
        destructive:
          "destructive group border-destructive bg-destructive text-destructive-foreground",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  }
)

const Toast = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Root>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Root> &
    VariantProps<typeof toastVariants>
>(({ className, variant, ...props }, ref) => {
  return (
    <ToastPrimitives.Root
      ref={ref}
      className={cn(toastVariants({ variant }), className)}
      {...props}
    />
  )
})
Toast.displayName = ToastPrimitives.Root.displayName

const ToastAction = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Action>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Action>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Action
    ref={ref}
    className={cn(
      "inline-flex h-8 shrink-0 items-center justify-center rounded-md border bg-transparent px-3 text-sm font-medium transition-colors hover:bg-secondary focus:outline-none focus:ring-1 focus:ring-ring disabled:pointer-events-none disabled:opacity-50 group-[.destructive]:border-muted/40 group-[.destructive]:hover:border-destructive/30 group-[.destructive]:hover:bg-destructive group-[.destructive]:hover:text-destructive-foreground group-[.destructive]:focus:ring-destructive",
      className
    )}
    {...props}
  />
))
ToastAction.displayName = ToastPrimitives.Action.displayName

const ToastClose = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Close>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Close>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Close
    ref={ref}
    className={cn(
      "absolute right-1 top-1 rounded-md p-1 text-foreground/50 opacity-0 transition-opacity hover:text-foreground focus:opacity-100 focus:outline-none focus:ring-1 group-hover:opacity-100 group-[.destructive]:text-red-300 group-[.destructive]:hover:text-red-50 group-[.destructive]:focus:ring-red-400 group-[.destructive]:focus:ring-offset-red-600",
      className
    )}
    toast-close=""
    {...props}
  >
    <X className="h-4 w-4" />
  </ToastPrimitives.Close>
))
ToastClose.displayName = ToastPrimitives.Close.displayName

const ToastTitle = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Title>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Title>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Title
    ref={ref}
    className={cn("text-sm font-semibold [&+div]:text-xs", className)}
    {...props}
  />
))
ToastTitle.displayName = ToastPrimitives.Title.displayName

const ToastDescription = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Description>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Description>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Description
    ref={ref}
    className={cn("text-sm opacity-90", className)}
    {...props}
  />
))
ToastDescription.displayName = ToastPrimitives.Description.displayName

type ToastProps = React.ComponentPropsWithoutRef<typeof Toast>

type ToastActionElement = React.ReactElement<typeof ToastAction>

export {
  type ToastProps,
  type ToastActionElement,
  ToastProvider,
  ToastViewport,
  Toast,
  ToastTitle,
  ToastDescription,
  ToastClose,
  ToastAction,
}
</file>

<file path="components/ui/toaster.tsx">
"use client"

import { useToast } from "@/hooks/use-toast"
import {
  Toast,
  ToastClose,
  ToastDescription,
  ToastProvider,
  ToastTitle,
  ToastViewport,
} from "@/components/ui/toast"

export function Toaster() {
  const { toasts } = useToast()

  return (
    <ToastProvider>
      {toasts.map(function ({ id, title, description, action, ...props }) {
        return (
          <Toast key={id} {...props}>
            <div className="grid gap-1">
              {title && <ToastTitle>{title}</ToastTitle>}
              {description && (
                <ToastDescription>{description}</ToastDescription>
              )}
            </div>
            {action}
            <ToastClose />
          </Toast>
        )
      })}
      <ToastViewport />
    </ToastProvider>
  )
}
</file>

<file path="components/video-composition/DraggableFile.tsx">
import React from 'react';
import { useDrag } from 'react-dnd';
import { Trash2 } from 'lucide-react';
import { cn } from '@/lib/utils';

interface DraggableFileProps {
  file: {
    id: string;
    name: string;
    file_type: string;
    file_size?: number;
    uploading?: boolean;
  };
  onClick?: () => void;
  onDelete?: () => void;
  isSelected?: boolean;
  className?: string;
}

export const DraggableFile: React.FC<DraggableFileProps> = ({
  file,
  onClick,
  onDelete,
  isSelected = false,
  className
}) => {
  const getFileType = () => {
    const ext = file.name.toLowerCase().split('.').pop();
    if (["mp4", "mov", "avi", "mkv", "webm"].includes(ext || "")) return "video";
    if (["jpg", "jpeg", "png", "gif", "bmp", "webp"].includes(ext || "")) return "image";
    if (["mp3", "wav", "ogg", "m4a", "aac"].includes(ext || "")) return "audio";
    if (["mid", "midi"].includes(ext || "")) return "midi";
    return "unknown";
  };

  const getIcon = () => {
    const type = getFileType();
    switch (type) {
      case "video": return <span className="text-xs"></span>;
      case "image": return <span className="text-xs"></span>;
      case "audio": return <span className="text-xs"></span>;
      case "midi": return <span className="text-xs"></span>;
      default: return <span className="text-xs"></span>;
    }
  };

  const formatFileSize = (bytes?: number) => {
    if (!bytes) return '';
    const sizes = ['B', 'KB', 'MB', 'GB'];
    if (bytes === 0) return '0 B';
    const i = Math.floor(Math.log(bytes) / Math.log(1024));
    return Math.round(bytes / Math.pow(1024, i) * 100) / 100 + ' ' + sizes[i];
  };

  const dragResult = useDrag({
    type: getFileType().toUpperCase() + '_FILE',
    item: {
      type: getFileType().toUpperCase() + '_FILE',
      id: file.id,
      name: file.name,
      fileType: getFileType(),
      src: `/api/files/${file.id}/download`,
      size: file.file_size,
    },
    collect: (monitor) => ({
      isDragging: monitor.isDragging(),
    }),
  });
  const { isDragging } = dragResult[0];
  const drag = dragResult[1];
  const dragRef = React.useCallback((node: HTMLDivElement | null) => { drag(node); }, [drag]);

  return (
    <div
      ref={dragRef}
      className={cn(
        "flex items-center border border-stone-400 bg-stone-300 text-black font-mono text-xs h-8 px-2 gap-2 select-none transition-colors duration-100",
        "hover:bg-stone-900 hover:text-stone-100 hover:border-stone-500 cursor-grab active:cursor-grabbing",
        isSelected && "bg-stone-900 text-stone-100 border-stone-500",
        isDragging && "relative z-20 bg-white/30 backdrop-blur-md border border-white/40 shadow-2xl text-black",
        className
      )}
      style={{ borderRadius: 2, minHeight: 32, maxHeight: 32 }}
      onClick={onClick}
      tabIndex={0}
    >
      {/* Icon */}
      <div className="flex-shrink-0 w-4 h-4 flex items-center justify-center">{getIcon()}</div>
      {/* Name */}
      <div className="truncate flex-1 font-medium" title={file.name} style={{ maxWidth: 140 }}>{file.name}</div>
      {/* Delete */}
      <button
        className="ml-1 p-0.5 text-black hover:text-red-600 border-none bg-transparent focus:outline-none"
        style={{ lineHeight: 1, borderRadius: 1 }}
        tabIndex={-1}
        onClick={e => { e.stopPropagation(); onDelete && onDelete(); }}
        aria-label="Delete file"
      >
        <Trash2 size={12} strokeWidth={2} />
      </button>
      {/* Loading bar if uploading */}
      {file.uploading && (
        <div className="absolute left-0 bottom-0 w-full h-0.5 bg-gradient-to-r from-black to-gray-400 animate-pulse" />
      )}
    </div>
  );
};
</file>

<file path="components/video-composition/EffectLayer.tsx">
'use client';

import React from 'react';
import type { AudioBinding, MIDIBinding, EffectType } from '@/types/video-composition';
import type { AudioAnalysisData, LiveMIDIData } from '@/types/visualizer';
import { 
  calculateOpacity, 
  calculateScale, 
  calculatePosition 
} from '@/lib/video-composition/parameter-calculator';

interface EffectLayerProps {
  effectType: EffectType;
  settings: any; // Effect-specific settings
  position: { x: number; y: number };
  scale: { x: number; y: number };
  opacity: number;
  audioBindings: AudioBinding[];
  midiBindings: MIDIBinding[];
  zIndex: number;
  blendMode: 'normal' | 'multiply' | 'screen' | 'overlay';
  startTime?: number;
  endTime?: number;
  currentTime?: number;
  audioFeatures?: AudioAnalysisData;
  midiData?: LiveMIDIData;
  onEffectUpdate?: (effectId: string, settings: any) => void;
}

export const EffectLayer: React.FC<EffectLayerProps> = ({
  effectType,
  settings,
  position,
  scale,
  opacity,
  audioBindings,
  midiBindings,
  zIndex,
  blendMode,
  startTime = 0,
  endTime,
  currentTime = 0,
  audioFeatures,
  midiData,
  onEffectUpdate
}) => {
  // Check if this layer should be visible based on timeline
  const isVisible = !endTime || (currentTime >= startTime && currentTime <= endTime);
  
  // Real-time parameter calculation
  const currentOpacity = calculateOpacity(opacity, audioBindings, audioFeatures || { frequencies: [], timeData: [], volume: 0, bass: 0, mid: 0, treble: 0 }, midiBindings, midiData || { activeNotes: [], currentTime: 0, tempo: 120, totalNotes: 0, trackActivity: {} });
  const currentScale = calculateScale(scale, audioBindings, audioFeatures || { frequencies: [], timeData: [], volume: 0, bass: 0, mid: 0, treble: 0 }, midiBindings, midiData || { activeNotes: [], currentTime: 0, tempo: 120, totalNotes: 0, trackActivity: {} });
  const currentPosition = calculatePosition(position, audioBindings, audioFeatures || { frequencies: [], timeData: [], volume: 0, bass: 0, mid: 0, treble: 0 }, midiBindings, midiData || { activeNotes: [], currentTime: 0, tempo: 120, totalNotes: 0, trackActivity: {} });
  
  // Get the appropriate Three.js effect component
  const getEffectComponent = (type: EffectType) => {
    // This would integrate with the existing Three.js effects
    // For now, return a placeholder div
    return () => (
      <div className="effect-placeholder bg-gradient-to-r from-purple-500 to-pink-500 w-full h-full rounded-lg flex items-center justify-center">
        <span className="text-white text-xs font-mono">{type}</span>
      </div>
    );
  };
  
  const EffectComponent = getEffectComponent(effectType);
  
  if (!isVisible) {
    return null;
  }
  
  return (
    <div 
      className="effect-layer absolute"
      style={{
        left: `${currentPosition.x}%`,
        top: `${currentPosition.y}%`,
        transform: `translate(-50%, -50%) scale(${currentScale.x}, ${currentScale.y})`,
        opacity: currentOpacity,
        zIndex,
        mixBlendMode: blendMode,
        pointerEvents: 'none',
        width: '200px', // Default size, can be made configurable
        height: '150px'
      }}
    >
      <EffectComponent />
    </div>
  );
};
</file>

<file path="components/video-composition/ImageLayer.tsx">
'use client';

import React from 'react';
import type { AudioBinding, MIDIBinding } from '@/types/video-composition';
import type { AudioAnalysisData, LiveMIDIData } from '@/types/visualizer';
import { 
  calculateOpacity, 
  calculateScale, 
  calculateRotation, 
  calculatePosition 
} from '@/lib/video-composition/parameter-calculator';

interface ImageLayerProps {
  src: string;
  position: { x: number; y: number };
  scale: { x: number; y: number };
  rotation: number;
  opacity: number;
  audioBindings: AudioBinding[];
  midiBindings: MIDIBinding[];
  zIndex: number;
  blendMode: 'normal' | 'multiply' | 'screen' | 'overlay';
  startTime?: number;
  endTime?: number;
  currentTime?: number;
  audioFeatures?: AudioAnalysisData;
  midiData?: LiveMIDIData;
}

export const ImageLayer: React.FC<ImageLayerProps> = ({
  src,
  position,
  scale,
  rotation,
  opacity,
  audioBindings,
  midiBindings,
  zIndex,
  blendMode,
  startTime = 0,
  endTime,
  currentTime = 0,
  audioFeatures,
  midiData
}) => {
  // Check if this layer should be visible based on timeline
  const isVisible = !endTime || (currentTime >= startTime && currentTime <= endTime);
  
  // Real-time parameter calculation
  const currentOpacity = calculateOpacity(opacity, audioBindings, audioFeatures || { frequencies: [], timeData: [], volume: 0, bass: 0, mid: 0, treble: 0 }, midiBindings, midiData || { activeNotes: [], currentTime: 0, tempo: 120, totalNotes: 0, trackActivity: {} });
  const currentScale = calculateScale(scale, audioBindings, audioFeatures || { frequencies: [], timeData: [], volume: 0, bass: 0, mid: 0, treble: 0 }, midiBindings, midiData || { activeNotes: [], currentTime: 0, tempo: 120, totalNotes: 0, trackActivity: {} });
  const currentRotation = calculateRotation(rotation, audioBindings, audioFeatures || { frequencies: [], timeData: [], volume: 0, bass: 0, mid: 0, treble: 0 }, midiBindings, midiData || { activeNotes: [], currentTime: 0, tempo: 120, totalNotes: 0, trackActivity: {} });
  const currentPosition = calculatePosition(position, audioBindings, audioFeatures || { frequencies: [], timeData: [], volume: 0, bass: 0, mid: 0, treble: 0 }, midiBindings, midiData || { activeNotes: [], currentTime: 0, tempo: 120, totalNotes: 0, trackActivity: {} });
  
  if (!isVisible) {
    return null;
  }
  
  return (
    <div 
      className="image-layer absolute"
      style={{
        left: `${currentPosition.x}%`,
        top: `${currentPosition.y}%`,
        transform: `translate(-50%, -50%) scale(${currentScale.x}, ${currentScale.y}) rotate(${currentRotation}deg)`,
        opacity: currentOpacity,
        zIndex,
        mixBlendMode: blendMode,
        pointerEvents: 'none',
        width: '200px', // Default size, can be made configurable
        height: '150px'
      }}
    >
      <img 
        src={src} 
        alt="Layer"
        style={{ 
          width: '100%', 
          height: '100%', 
          objectFit: 'cover',
          borderRadius: '4px'
        }}
      />
    </div>
  );
};
</file>

<file path="components/video-composition/LayerContainer.tsx">
'use client';

import React from 'react';
import { VideoLayer } from './VideoLayer';
import { ImageLayer } from './ImageLayer';
import { EffectLayer } from './EffectLayer';
import type { Layer } from '@/types/video-composition';
import type { AudioAnalysisData, LiveMIDIData } from '@/types/visualizer';

interface LayerContainerProps {
  layers: Layer[];
  width: number;
  height: number;
  currentTime: number;
  isPlaying: boolean;
  audioFeatures?: AudioAnalysisData;
  midiData?: LiveMIDIData;
  onLayerUpdate?: (layerId: string, updates: Partial<Layer>) => void;
  onLayerDelete?: (layerId: string) => void;
}

export const LayerContainer: React.FC<LayerContainerProps> = ({
  layers,
  width,
  height,
  currentTime,
  isPlaying,
  audioFeatures,
  midiData,
  onLayerUpdate,
  onLayerDelete
}) => {
  // Sort layers by z-index for proper stacking
  const sortedLayers = [...layers].sort((a, b) => a.zIndex - b.zIndex);
  
  return (
    <div 
      className="layer-container relative overflow-hidden"
      style={{
        width: `${width}px`,
        height: `${height}px`,
        background: 'transparent'
      }}
    >
      {sortedLayers.map((layer) => {
        const commonProps = {
          key: layer.id,
          startTime: layer.startTime,
          endTime: layer.endTime,
          currentTime,
          isPlaying,
          audioFeatures,
          midiData,
          position: layer.position,
          scale: layer.scale,
          rotation: layer.rotation,
          opacity: layer.opacity,
          audioBindings: layer.audioBindings,
          midiBindings: layer.midiBindings,
          zIndex: layer.zIndex,
          blendMode: layer.blendMode
        };
        
        switch (layer.type) {
          case 'video':
            return (
              <VideoLayer
                {...commonProps}
                src={layer.src!}
              />
            );
          case 'image':
            return (
              <ImageLayer
                {...commonProps}
                src={layer.src!}
              />
            );
          case 'effect':
            return (
              <EffectLayer
                {...commonProps}
                effectType={layer.effectType!}
                settings={layer.settings}
                onEffectUpdate={(effectId, settings) => {
                  onLayerUpdate?.(layer.id, { settings });
                }}
              />
            );
          default:
            return null;
        }
      })}
    </div>
  );
};
</file>

<file path="components/video-composition/TestVideoComposition.tsx">
'use client';

import React from 'react';
import { Button } from '@/components/ui/button';
import { Plus, Video, Image, Zap } from 'lucide-react';
import type { Layer } from '@/types/video-composition';

interface TestVideoCompositionProps {
  onAddLayer: (layer: Layer) => void;
  className?: string;
}

export const TestVideoComposition: React.FC<TestVideoCompositionProps> = ({
  onAddLayer,
  className
}) => {
  const addSampleVideoLayer = () => {
    const layer: Layer = {
      id: `video-${Date.now()}`,
      type: 'video',
      src: 'https://sample-videos.com/zip/10/mp4/SampleVideo_1280x720_1mb.mp4', // Sample video URL
      position: { x: 50, y: 50 },
      scale: { x: 1, y: 1 },
      rotation: 0,
      opacity: 1,
      audioBindings: [
        {
          feature: 'volume',
          inputRange: [0, 1],
          outputRange: [0.5, 1],
          blendMode: 'multiply'
        }
      ],
      midiBindings: [
        {
          source: 'velocity',
          inputRange: [0, 127],
          outputRange: [0.8, 1.2],
          blendMode: 'multiply'
        }
      ],
      zIndex: 0,
      blendMode: 'normal',
      startTime: 0,
      endTime: 30,
      duration: 30
    };
    onAddLayer(layer);
  };

  const addSampleImageLayer = () => {
    const layer: Layer = {
      id: `image-${Date.now()}`,
      type: 'image',
      src: 'https://picsum.photos/400/300', // Random image
      position: { x: 25, y: 25 },
      scale: { x: 0.8, y: 0.8 },
      rotation: 15,
      opacity: 0.8,
      audioBindings: [
        {
          feature: 'bass',
          inputRange: [0, 1],
          outputRange: [0.5, 1.5],
          blendMode: 'multiply'
        }
      ],
      midiBindings: [],
      zIndex: 1,
      blendMode: 'multiply',
      startTime: 5,
      endTime: 25,
      duration: 20
    };
    onAddLayer(layer);
  };

  const addSampleEffectLayer = () => {
    const layer: Layer = {
      id: `effect-${Date.now()}`,
      type: 'effect',
      effectType: 'metaballs',
      settings: {
        animationSpeed: 1.0,
        glowIntensity: 0.8
      },
      position: { x: 75, y: 75 },
      scale: { x: 1.2, y: 1.2 },
      rotation: 0,
      opacity: 0.9,
      audioBindings: [
        {
          feature: 'treble',
          inputRange: [0, 1],
          outputRange: [0.5, 2.0],
          blendMode: 'multiply'
        }
      ],
      midiBindings: [
        {
          source: 'velocity',
          inputRange: [0, 127],
          outputRange: [0.5, 1.5],
          blendMode: 'multiply'
        }
      ],
      zIndex: 2,
      blendMode: 'screen',
      startTime: 0,
      endTime: 30,
      duration: 30
    };
    onAddLayer(layer);
  };

  return (
    <div className={`flex items-center gap-2 p-2 bg-stone-800/50 rounded-lg border border-stone-600 ${className}`}>
      <span className="text-xs font-mono text-stone-400">TEST:</span>
      <Button
        size="sm"
        variant="outline"
        onClick={addSampleVideoLayer}
        className="h-6 px-2 text-xs bg-blue-900/20 border-blue-600 text-blue-300 hover:bg-blue-800/30"
      >
        <Video className="h-3 w-3 mr-1" />
        Video
      </Button>
      <Button
        size="sm"
        variant="outline"
        onClick={addSampleImageLayer}
        className="h-6 px-2 text-xs bg-green-900/20 border-green-600 text-green-300 hover:bg-green-800/30"
      >
        <Image className="h-3 w-3 mr-1" />
        Image
      </Button>
      <Button
        size="sm"
        variant="outline"
        onClick={addSampleEffectLayer}
        className="h-6 px-2 text-xs bg-purple-900/20 border-purple-600 text-purple-300 hover:bg-purple-800/30"
      >
        <Zap className="h-3 w-3 mr-1" />
        Effect
      </Button>
    </div>
  );
};
</file>

<file path="components/video-composition/UnifiedTimeline.tsx">
import React, { useState, useCallback, useEffect } from 'react';
import { useDrop } from 'react-dnd';
import { useDrag } from 'react-dnd';
import { ChevronDown, ChevronUp, Plus, Video, Image, Zap, Music, FileAudio, FileMusic, Settings } from 'lucide-react';
import { cn } from '@/lib/utils';
import type { Layer } from '@/types/video-composition';
import { StemWaveform, WaveformData } from '@/components/stem-visualization/stem-waveform';
import { Badge } from '@/components/ui/badge';
import { Button } from '@/components/ui/button';
import { HudOverlayProvider, HudOverlayConfig, useHudOverlayContext } from '@/components/hud/HudOverlayManager';
import { debugLog } from '@/lib/utils';

interface EffectClip {
  id: string;
  effectId: string;
  name: string;
  startTime: number;
  endTime: number;
  parameters: Record<string, any>;
}

interface Stem {
  id: string;
  file_name: string;
  is_master?: boolean;
  stem_type?: string;
  analysis_status?: string;
}

interface UnifiedTimelineProps {
  // Video composition layers
  layers: Layer[];
  onLayerAdd: (layer: Layer) => void;
  onLayerUpdate: (layerId: string, updates: Partial<Layer>) => void;
  onLayerDelete: (layerId: string) => void;
  onLayerSelect: (layerId: string) => void;
  selectedLayerId?: string;
  
  // Effects timeline (now part of layers)
  effectClips: EffectClip[];
  onEffectClipAdd: (effect: any) => void;
  onEffectClipRemove: (clipId: string) => void;
  onEffectClipEdit: (clipId: string) => void;
  
  // Audio/MIDI stems
  stems?: Stem[];
  masterStemId?: string | null;
  onStemSelect?: (stemId: string) => void;
  activeTrackId?: string | null;
  soloedStems?: Set<string>;
  onToggleSolo?: (stemId: string) => void;
  analysisProgress?: Record<string, { progress: number; message: string } | null>;
  cachedAnalysis?: any[]; // Using any for now to avoid complex type imports
  stemLoadingState?: boolean;
  stemError?: string | null;
  
  // Timeline state
  currentTime: number;
  duration: number;
  isPlaying: boolean;
  onSeek?: (time: number) => void;
  
  // Collapsible sections
  className?: string;
}

interface TimelineSectionProps {
  title: string;
  icon: React.ReactNode;
  isExpanded: boolean;
  onToggle: () => void;
  children: React.ReactNode;
  itemCount: number;
  itemType: string;
}

interface StemTrackProps {
  id: string;
  name: string;
  waveformData: any | null; // Can be from cachedAnalysis or real-time
  isLoading: boolean;
  isActive: boolean;
  onClick: () => void;
  isSoloed: boolean;
  onToggleSolo: () => void;
  isMaster: boolean;
  onSeek?: (time: number) => void;
  currentTime: number;
  stemType: string;
  isPlaying: boolean;
  analysisStatus?: string;
  analysisProgress?: { progress: number; message: string } | null;
}

const TimelineSection: React.FC<TimelineSectionProps> = ({
  title,
  icon,
  isExpanded,
  onToggle,
  children,
  itemCount,
  itemType
}) => {
  return (
    <div className="mb-1">
      <button
        onClick={onToggle}
        className="w-full flex items-center justify-between py-1 px-2 bg-black border-b border-stone-700 text-xs font-mono font-bold text-white uppercase tracking-widest hover:bg-stone-900 transition-colors"
        style={{ borderRadius: 0 }}
      >
        <div className="flex items-center gap-2">{icon}<span>{title}</span></div>
        <div className="flex items-center gap-2">
          <span className="text-stone-400 font-normal">{itemCount} {itemType}</span>
          {isExpanded ? (
            <ChevronUp className="h-3 w-3 text-stone-400" />
          ) : (
            <ChevronDown className="h-3 w-3 text-stone-400" />
          )}
        </div>
      </button>
      {isExpanded && <div className="pl-2">{children}</div>}
    </div>
  );
};

// Droppable Lane Component
const DroppableLane: React.FC<{
  layer: Layer;
  index: number;
  startX: number;
  width: number;
  isActive: boolean;
  isSelected: boolean;
  isEmptyLane: boolean;
  onLayerSelect: (layerId: string) => void;
  onLayerDelete: (layerId: string) => void;
  onEffectClipEdit: (layerId: string) => void;
  onEffectClipRemove: (layerId: string) => void;
  onAssetDrop: (item: any, targetLayerId: string) => void;
  currentTime: number;
  duration: number;
}> = ({
  layer,
  index,
  startX,
  width,
  isActive,
  isSelected,
  isEmptyLane,
  onLayerSelect,
  onLayerDelete,
  onEffectClipEdit,
  onEffectClipRemove,
  onAssetDrop,
  currentTime,
  duration
}) => {
  const isEffect = layer.type === 'effect';
  
  const [{ isOver, canDrop }, drop] = useDrop({
    accept: ['VIDEO_FILE', 'IMAGE_FILE', 'EFFECT_CARD'],
    drop: (item: any) => {
      if (isEmptyLane) {
        onAssetDrop(item, layer.id);
      }
    },
    collect: (monitor) => ({
      isOver: monitor.isOver(),
      canDrop: monitor.canDrop(),
    }),
  });

  const dropRef = useCallback((node: HTMLDivElement | null) => {
    if (isEmptyLane) {
      drop(node);
    }
  }, [drop, isEmptyLane]);

  return (
    <div
      ref={dropRef}
      className={cn(
        "absolute border border-stone-700 cursor-pointer flex items-center px-2 transition-all rounded-md",
        isEmptyLane
          ? isOver && canDrop
            ? "bg-emerald-950 border-emerald-400 text-emerald-400"
            : "bg-stone-800/50 border-dashed border-stone-600 text-stone-400 hover:bg-stone-700/50 hover:border-stone-500"
          : isSelected
            ? "bg-white text-black border-white"
            : isActive
              ? isEffect 
                ? "bg-purple-400 text-black border-purple-500"
                : "bg-emerald-500 text-black border-emerald-400"
              : "bg-stone-700 text-stone-100 border-stone-700 hover:bg-stone-600 hover:text-white hover:border-white"
      )}
      style={{ 
        left: `${startX}px`, 
        width: `${width}px`, 
        minWidth: '60px',
        top: `${index * 32 + 8}px`,
        height: '24px'
      }}
      onClick={e => { 
        e.stopPropagation(); 
        if (isEffect) {
          onEffectClipEdit(layer.id);
        } else {
          onLayerSelect(layer.id);
        }
      }}
      onDoubleClick={e => { 
        e.stopPropagation(); 
        if (isEffect) {
          onEffectClipEdit(layer.id);
        }
      }}
    >
      <div className="flex items-center gap-1">
        {isEmptyLane ? (
          <>
            <Plus className="h-3 w-3" />
            <span className="truncate font-medium">
              {isOver && canDrop ? "Drop here" : "Empty Lane"}
            </span>
          </>
        ) : (
          <>
            {layer.type === 'video' ? <Video className="h-3 w-3" /> : 
             layer.type === 'image' ? <Image className="h-3 w-3" /> : 
             <Zap className="h-3 w-3" />}
            <span className="truncate font-medium">
              {layer.type === 'video' ? 'Video' : 
               layer.type === 'image' ? 'Image' : 
               layer.src || 'Effect'}
            </span>
          </>
        )}
      </div>
      {!isEmptyLane && (
        <span className="ml-2 text-[10px] text-stone-400">
          {(layer.startTime || 0).toFixed(1)}s - {(layer.endTime || duration).toFixed(1)}s
        </span>
      )}
      <button
        className="ml-auto px-1 text-stone-400 hover:text-red-500 border-none bg-transparent focus:outline-none text-xs rounded"
        onClick={e => { 
          e.stopPropagation(); 
          if (isEffect) {
            onEffectClipRemove(layer.id);
          } else {
            onLayerDelete(layer.id);
          }
        }}
        aria-label="Delete layer"
      ></button>
    </div>
  );
};

const StemTrack: React.FC<StemTrackProps> = ({
  id,
  name,
  waveformData,
  isLoading,
  isActive,
  onClick,
  isSoloed,
  onToggleSolo,
  isMaster,
  onSeek,
  currentTime,
  stemType,
  isPlaying,
  analysisStatus,
  analysisProgress,
}) => {
  const [{ isDragging }, drag] = useDrag({
    type: 'AUDIO_STEM',
    item: { id, name, stemType },
    collect: (monitor) => ({
      isDragging: monitor.isDragging(),
    }),
  });

  const getStatusText = () => {
    if (waveformData) return null; // Has data, no text needed
    if (isLoading) return 'Loading...';
    if (analysisStatus === 'pending' || analysisStatus === 'processing') return 'Analyzing...';
    return 'No analysis data.';
  };

  const statusText = getStatusText();

  return (
    <div
      ref={drag as unknown as React.Ref<HTMLDivElement>}
      className={cn(
        "flex items-center group bg-stone-900/50 cursor-pointer transition-all border-l-4",
        isActive ? "border-emerald-400 bg-emerald-900/30" : "border-transparent hover:bg-stone-800/40"
      )}
      style={{ opacity: isDragging ? 0.5 : 1, height: '32px', minHeight: '32px' }}
      onClick={onClick}
    >
      <div className="w-56 px-3 py-2 flex items-center justify-between gap-2 border-r border-stone-700/50 flex-shrink-0">
        <div className="flex-1 min-w-0">
          <p className="text-sm font-medium text-stone-200 truncate group-hover:text-emerald-400" title={name}>{name}</p>
          {waveformData && <p className="text-xs text-stone-400">{waveformData.duration.toFixed(2)}s</p>}
          {isLoading && !waveformData && <Badge variant="secondary" className="mt-1 text-xs">Loading...</Badge>}
        </div>
        
        {isMaster ? (
          <Badge variant="outline" className="border-amber-400 text-amber-400">MASTER</Badge>
        ) : (
          <Button
            variant={isSoloed ? "secondary" : "ghost"}
            size="sm"
            onClick={(e) => {
              e.stopPropagation();
              onToggleSolo();
            }}
            className={cn(
              "transition-all px-3 font-semibold",
              isSoloed ? "bg-yellow-400/80 text-black hover:bg-yellow-400" : "text-stone-400 hover:text-white hover:bg-stone-700"
            )}
          >
            Solo
          </Button>
        )}
      </div>

      <div className="flex-1 min-w-0 px-2 overflow-hidden">
        {analysisProgress ? (
          <div className="w-full bg-stone-700 rounded-full h-2.5 my-auto">
            <div className="bg-blue-600 h-2.5 rounded-full" style={{ width: `${analysisProgress.progress * 100}%` }}></div>
            <p className="text-xs text-stone-400 truncate">{analysisProgress.message}</p>
          </div>
        ) : (
          <div className="w-full overflow-hidden">
            <StemWaveform
              waveformData={waveformData}
              duration={waveformData?.duration || 1}
              currentTime={currentTime}
              onSeek={onSeek}
              isPlaying={isPlaying}
              isLoading={isLoading}
            />
          </div>
        )}
      </div>
    </div>
  );
};
StemTrack.displayName = 'StemTrack';

// Overlay Lane Card
const OverlayCard: React.FC<{
  overlay: any;
  index: number;
  moveOverlay: (from: number, to: number) => void;
  onOpenModal: () => void;
  onDelete: () => void;
}> = ({ overlay, index, moveOverlay, onOpenModal, onDelete }) => {
  const ref = React.useRef<HTMLDivElement>(null);
  const [{ isDragging }, drag] = useDrag({
    type: 'HUD_OVERLAY_CARD',
    item: { index },
    collect: monitor => ({ isDragging: monitor.isDragging() })
  });
  const [, drop] = useDrop({
    accept: 'HUD_OVERLAY_CARD',
    hover: (item: any) => {
      if (item.index !== index) {
        moveOverlay(item.index, index);
        item.index = index;
      }
    }
  });
  drag(drop(ref));
  return (
    <div
      ref={ref}
      style={{
        opacity: isDragging ? 0.5 : 1,
        width: 56,
        height: 56,
        margin: 4,
        background: '#111',
        border: '2px solid #00ffff',
        borderRadius: 8,
        boxShadow: '0 0 8px #00ffff88',
        display: 'flex',
        alignItems: 'center',
        justifyContent: 'center',
        cursor: 'grab',
        position: 'relative',
      }}
      onDoubleClick={onOpenModal}
      title={overlay.type}
    >
      <span style={{ color: '#00ffff', fontWeight: 700, fontSize: 12, textShadow: '0 0 4px #00ffff' }}>{overlay.type}</span>
      <button
        onClick={e => { e.stopPropagation(); onDelete(); }}
        style={{ position: 'absolute', top: 2, right: 2, background: 'none', border: 'none', color: '#00ffff', fontWeight: 900, fontSize: 14, cursor: 'pointer', padding: 0 }}
        title="Remove overlay"
      ></button>
    </div>
  );
};

// Overlay Lane
const OverlayLane: React.FC = () => {
  const { overlays, moveOverlay, openOverlayModal, removeOverlay, addOverlay } = useHudOverlayContext();
  const [, drop] = useDrop({
    accept: ['EFFECT_CARD'],
    drop: (item: any) => {
      if (item.type === 'EFFECT_CARD' && item.category === 'Overlays') {
        addOverlay(item.id); // id should match overlay type
      }
    },
  });
  return (
    <div ref={drop as unknown as React.Ref<HTMLDivElement>} style={{
      display: 'flex',
      alignItems: 'center',
      minHeight: 72,
      background: 'linear-gradient(90deg, #0ff2, #222 60%)',
      borderBottom: '2px solid #00ffff',
      position: 'relative',
      padding: '0 8px',
      marginBottom: 8,
    }}>
      <div style={{ marginRight: 12, display: 'flex', alignItems: 'center', gap: 4 }}>
        <span style={{ color: '#00ffff', fontWeight: 700, fontSize: 13 }}>HUD Overlays</span>
        <span title="Overlays are always visible. Drag up/down to reorder stacking. Drag from sidebar to add.">
          <svg width="16" height="16" style={{ verticalAlign: 'middle' }}><rect x="2" y="2" width="12" height="12" rx="3" fill="#00ffff33" stroke="#00ffff" strokeWidth="2" /></svg>
        </span>
      </div>
      <div style={{ display: 'flex', flexDirection: 'row', gap: 4 }}>
        {overlays.map((overlay, i) => (
          <OverlayCard
            key={overlay.id}
            overlay={overlay}
            index={i}
            moveOverlay={moveOverlay}
            onOpenModal={() => openOverlayModal(overlay.id)}
            onDelete={() => removeOverlay(overlay.id)}
          />
        ))}
      </div>
    </div>
  );
};

export const UnifiedTimeline: React.FC<UnifiedTimelineProps> = ({
  layers,
  onLayerAdd,
  onLayerUpdate,
  onLayerDelete,
  onLayerSelect,
  selectedLayerId,
  effectClips,
  onEffectClipAdd,
  onEffectClipRemove,
  onEffectClipEdit,
  stems = [],
  masterStemId = null,
  onStemSelect,
  activeTrackId = null,
  soloedStems = new Set(),
  onToggleSolo,
  analysisProgress = {},
  cachedAnalysis = [],
  stemLoadingState = false,
  stemError = null,
  currentTime,
  duration,
  isPlaying,
  onSeek,
  className
}) => {
  const [expandedSections, setExpandedSections] = useState({
    composition: true, // Combined visual and effects layers
    audio: true // Changed from false to true to ensure audio section is visible by default
  });

  // Create a default empty lane if no layers exist
  useEffect(() => {
    if (layers.length === 0 && effectClips.length === 0) {
      const defaultEmptyLane: Layer = {
        id: `layer-${Date.now()}`,
        type: 'image', // Placeholder type, will be replaced when content is dropped
        src: '', // Empty src indicates this is an empty lane
        position: { x: 50, y: 50 },
        scale: { x: 1, y: 1 },
        rotation: 0,
        opacity: 1,
        audioBindings: [],
        midiBindings: [],
        zIndex: 0,
        blendMode: 'normal',
        startTime: 0,
        endTime: duration,
        duration: duration
      };
      onLayerAdd(defaultEmptyLane);
    }
  }, []); // Only run once on mount

  const handleAssetDrop = (item: any, targetLayerId?: string) => {
    debugLog.log('Asset dropped on timeline:', item, 'target layer:', targetLayerId);
    
    if (targetLayerId) {
      // Dropped on a specific layer
      const targetLayer = layers.find(layer => layer.id === targetLayerId);
      if (targetLayer && !targetLayer.src) {
        // Fill the empty lane with the dropped content
        switch (item.type) {
          case 'VIDEO_FILE':
            onLayerUpdate(targetLayerId, {
              type: 'video',
              src: item.src
            });
            break;
          case 'IMAGE_FILE':
            onLayerUpdate(targetLayerId, {
              type: 'image',
              src: item.src
            });
            break;
          case 'EFFECT_CARD':
            // Convert effect to a layer
            onLayerUpdate(targetLayerId, {
              type: 'effect',
              src: item.name || item.id,
              effectType: item.id,
              settings: item.parameters || {}
            });
            break;
          default:
            debugLog.warn('Unknown asset type:', item.type);
            return;
        }
        return;
      }
    }
    
    // Fallback: check if there's an empty lane to fill
    const emptyLane = layers.find(layer => !layer.src && layer.type !== 'effect');
    
    if (emptyLane) {
      // Fill the empty lane with the dropped content
      switch (item.type) {
        case 'VIDEO_FILE':
          onLayerUpdate(emptyLane.id, {
            type: 'video',
            src: item.src
          });
          break;
        case 'IMAGE_FILE':
          onLayerUpdate(emptyLane.id, {
            type: 'image',
            src: item.src
          });
          break;
        case 'EFFECT_CARD':
          // Convert effect to a layer
          onLayerUpdate(emptyLane.id, {
            type: 'effect',
            src: item.name || item.id,
            effectType: item.id,
            settings: item.parameters || {}
          });
          break;
        default:
          debugLog.warn('Unknown asset type:', item.type);
          return;
      }
    } else {
      // No empty lane, create a new layer
      switch (item.type) {
        case 'VIDEO_FILE':
          const videoLayer: Layer = {
            id: `video-${Date.now()}`,
            type: 'video',
            src: item.src,
            position: { x: 50, y: 50 },
            scale: { x: 1, y: 1 },
            rotation: 0,
            opacity: 1,
            audioBindings: [],
            midiBindings: [],
            zIndex: layers.length,
            blendMode: 'normal',
            startTime: 0,
            endTime: duration,
            duration: duration
          };
          onLayerAdd(videoLayer);
          break;
        case 'IMAGE_FILE':
          const imageLayer: Layer = {
            id: `image-${Date.now()}`,
            type: 'image',
            src: item.src,
            position: { x: 50, y: 50 },
            scale: { x: 1, y: 1 },
            rotation: 0,
            opacity: 1,
            audioBindings: [],
            midiBindings: [],
            zIndex: layers.length,
            blendMode: 'normal',
            startTime: 0,
            endTime: duration,
            duration: duration
          };
          onLayerAdd(imageLayer);
          break;
        case 'EFFECT_CARD':
          // Create a new effect layer
          const effectLayer: Layer = {
            id: `effect-${Date.now()}`,
            type: 'effect',
            src: item.name || item.id,
            effectType: item.id,
            settings: item.parameters || {},
            position: { x: 50, y: 50 },
            scale: { x: 1, y: 1 },
            rotation: 0,
            opacity: 1,
            audioBindings: [],
            midiBindings: [],
            zIndex: layers.length,
            blendMode: 'normal',
            startTime: 0,
            endTime: duration,
            duration: duration
          };
          onLayerAdd(effectLayer);
          break;
        default:
          debugLog.warn('Unknown asset type:', item.type);
          return;
      }
    }
  };

  const timeToX = (time: number) => {
    return time * 100; // 100px per second
  };

  const xToTime = (x: number) => {
    return x / 100;
  };

  // Calculate timeline width based on duration to match audio stems
  const timelineWidth = Math.max(duration * 100, 800); // Minimum 800px width

  const toggleSection = (section: keyof typeof expandedSections) => {
    setExpandedSections(prev => ({
      ...prev,
      [section]: !prev[section]
    }));
  };

  const handleTimelineClick = (e: React.MouseEvent<HTMLDivElement>) => {
    if (!onSeek) return;
    
    const rect = e.currentTarget.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const time = xToTime(x);
    onSeek(Math.max(0, Math.min(duration, time)));
  };

  return (
    <div className={cn("bg-stone-800 border border-stone-700 font-mono text-xs rounded-xl", className)}>
      {/* Header */}
      <div className="flex items-center gap-2 px-2 py-1 border-b border-stone-700 text-white font-bold font-mono text-xs uppercase tracking-widest rounded-t-xl">
        <Zap className="h-4 w-4" /> Timeline
      </div>
      <div className="p-0">
        <div className="overflow-x-auto">
          <div className="min-w-max">
            {/* Composition Layers Section */}
            <TimelineSection
              title="Composition Layers"
              icon={<Video className="h-3 w-3" />}
              isExpanded={expandedSections.composition}
              onToggle={() => toggleSection('composition')}
              itemCount={layers.length + effectClips.length}
              itemType="layers"
            >
              <div className="space-y-1">
                {/* Add Layer Button */}
                <div className="flex justify-between items-center mb-2">
                  <div className="flex gap-2">
                    <button
                      onClick={() => {
                        const newLayer: Layer = {
                          id: `layer-${Date.now()}`,
                          type: 'image', // Placeholder type, will be replaced when content is dropped
                          src: '', // Empty src indicates this is an empty lane
                          position: { x: 50, y: 50 },
                          scale: { x: 1, y: 1 },
                          rotation: 0,
                          opacity: 1,
                          audioBindings: [],
                          midiBindings: [],
                          zIndex: layers.length,
                          blendMode: 'normal',
                          startTime: 0,
                          endTime: duration,
                          duration: duration
                        };
                        onLayerAdd(newLayer);
                      }}
                      className="px-3 py-1 bg-stone-700 hover:bg-stone-600 text-white text-xs font-mono rounded border border-stone-600 transition-colors"
                    >
                      + Add Layer
                    </button>
                  </div>
                </div>

                {/* Combined Timeline */}
                <div
                  className="relative border-2 border-dashed border-stone-700 transition-all mb-1 bg-stone-800 rounded-lg overflow-hidden"
                  onClick={handleTimelineClick}
                  style={{ width: `${timelineWidth}px`, height: `${Math.max(layers.length + effectClips.length, 1) * 32 + 16}px` }}
                >
                  {(layers.length === 0 && effectClips.length === 0) && (
                    <div className="absolute inset-0 flex items-center justify-center">
                      <div className="text-center text-stone-500">
                        <Plus className="h-4 w-4 mx-auto mb-1" />
                        <div className="text-xs">Add layers and drag assets to them</div>
                      </div>
                    </div>
                  )}

                  {/* Render layers in z-index order (bottom to top) */}
                  {[...layers, ...effectClips.map((clip, clipIndex) => ({
                    id: clip.id,
                    type: 'effect' as const,
                    src: clip.name,
                    position: { x: 50, y: 50 },
                    scale: { x: 1, y: 1 },
                    rotation: 0,
                    opacity: 1,
                    audioBindings: [],
                    midiBindings: [],
                    zIndex: layers.length + clipIndex, // Use numeric index instead of string id
                    blendMode: 'normal' as const,
                    startTime: clip.startTime,
                    endTime: clip.endTime,
                    duration: clip.endTime - clip.startTime
                  }))].sort((a, b) => a.zIndex - b.zIndex).map((layer, index) => {
                    const startX = timeToX(layer.startTime || 0);
                    const width = timeToX((layer.endTime || duration) - (layer.startTime || 0));
                    const isActive = currentTime >= (layer.startTime || 0) && currentTime <= (layer.endTime || duration);
                    const isSelected = selectedLayerId === layer.id;
                    const isEffect = layer.type === 'effect';
                    const isEmptyLane = !isEffect && !layer.src; // Empty lane that can accept any content
                    
                    return (
                      <DroppableLane
                        key={layer.id}
                        layer={layer}
                        index={index}
                        startX={startX}
                        width={width}
                        isActive={isActive}
                        isSelected={isSelected}
                        isEmptyLane={isEmptyLane}
                        onLayerSelect={onLayerSelect}
                        onLayerDelete={onLayerDelete}
                        onEffectClipEdit={onEffectClipEdit}
                        onEffectClipRemove={onEffectClipRemove}
                        onAssetDrop={handleAssetDrop}
                        currentTime={currentTime}
                        duration={duration}
                      />
                    );
                  })}

                  {/* Current time indicator */}
                  <div
                    className="absolute top-0 w-0.5 bg-emerald-400 pointer-events-none z-10"
                    style={{ 
                      left: `${timeToX(currentTime)}px`,
                      height: '100%'
                    }}
                  />
                </div>
              </div>
            </TimelineSection>
            {/* Audio/MIDI Section */}
            <TimelineSection
              title="Audio & MIDI"
              icon={<Music className="h-3 w-3" />}
              isExpanded={expandedSections.audio}
              onToggle={() => toggleSection('audio')}
              itemCount={stems.length}
              itemType="tracks"
            >
              <div className="space-y-1">
                {stems.map((stem) => {
                  const analysis = cachedAnalysis?.find((a: any) => a.fileMetadataId === stem.id);
                  const progress = analysisProgress?.[stem.id];
                  return (
                    <StemTrack
                      key={stem.id}
                      id={stem.id}
                      name={stem.file_name}
                      waveformData={analysis?.waveformData ?? null}
                      isLoading={stemLoadingState}
                      isActive={stem.id === activeTrackId}
                      onClick={() => onStemSelect?.(stem.id)}
                      isSoloed={soloedStems.has(stem.id)}
                      onToggleSolo={() => onToggleSolo?.(stem.id)}
                      isMaster={stem.id === masterStemId}
                      onSeek={onSeek}
                      currentTime={currentTime}
                      stemType={analysis?.stemType ?? stem.stem_type ?? 'unknown'}
                      isPlaying={isPlaying}
                      analysisStatus={stem.analysis_status}
                      analysisProgress={progress}
                    />
                  );
                })}
                {stems.length === 0 && (
                  <div className="h-8 bg-stone-800 border-2 border-dashed border-stone-700 flex items-center justify-center rounded-lg">
                    <div className="text-center text-stone-500">
                      <div className="flex items-center gap-2 mb-1">
                        <FileAudio className="h-3 w-3" />
                        <FileMusic className="h-3 w-3" />
                      </div>
                      <div className="text-xs">No audio stems available</div>
                    </div>
                  </div>
                )}
                {stemError && <p className="text-xs text-red-500 p-2">{stemError}</p>}
              </div>
            </TimelineSection>
            {/* HUD Overlays Section */}
            <TimelineSection
              title="HUD Overlays"
              icon={<Settings className="h-3 w-3" />}
              isExpanded={expandedSections.composition} // Assuming HUD overlays are part of composition
              onToggle={() => toggleSection('composition')}
              itemCount={0} // No direct count of overlays here, they are managed by context
              itemType="overlays"
            >
              <OverlayLane />
            </TimelineSection>
          </div>
        </div>
      </div>
    </div>
  );
};
</file>

<file path="components/video-composition/VideoCompositionTimeline.tsx">
'use client';

import React, { useState } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { Plus, Video, Image, Zap, Trash2, Settings } from 'lucide-react';
import { useDrop } from 'react-dnd';
import type { Layer, LayerType } from '@/types/video-composition';

interface VideoCompositionTimelineProps {
  layers: Layer[];
  currentTime: number;
  duration: number;
  onLayerAdd: (layer: Layer) => void;
  onLayerUpdate: (layerId: string, updates: Partial<Layer>) => void;
  onLayerDelete: (layerId: string) => void;
  onLayerSelect: (layerId: string) => void;
  selectedLayerId?: string;
  className?: string;
}

export const VideoCompositionTimeline: React.FC<VideoCompositionTimelineProps> = ({
  layers,
  currentTime,
  duration,
  onLayerAdd,
  onLayerUpdate,
  onLayerDelete,
  onLayerSelect,
  selectedLayerId,
  className
}) => {
  const [showAddMenu, setShowAddMenu] = useState(false);
  
  // Drop zone for dragging assets from file browser
  const [{ isOver, canDrop }, drop] = useDrop({
    accept: ['VIDEO_FILE', 'IMAGE_FILE', 'EFFECT_CARD'],
    drop: (item: any) => {
      handleAssetDrop(item);
    },
    collect: (monitor) => ({
      isOver: monitor.isOver(),
      canDrop: monitor.canDrop(),
    }),
  });

  const handleAssetDrop = (item: any) => {
    let newLayer: Layer;
    
    switch (item.type) {
      case 'VIDEO_FILE':
        newLayer = createVideoLayer(item);
        break;
      case 'IMAGE_FILE':
        newLayer = createImageLayer(item);
        break;
      case 'EFFECT_CARD':
        newLayer = createEffectLayer(item);
        break;
      default:
        return;
    }
    
    onLayerAdd(newLayer);
  };

  const createVideoLayer = (item: any): Layer => ({
    id: `video-${Date.now()}`,
    type: 'video',
    src: item.src,
    position: { x: 50, y: 50 },
    scale: { x: 1, y: 1 },
    rotation: 0,
    opacity: 1,
    audioBindings: [],
    midiBindings: [],
    zIndex: layers.length,
    blendMode: 'normal',
    startTime: 0,
    endTime: duration,
    duration: duration
  });

  const createImageLayer = (item: any): Layer => ({
    id: `image-${Date.now()}`,
    type: 'image',
    src: item.src,
    position: { x: 50, y: 50 },
    scale: { x: 1, y: 1 },
    rotation: 0,
    opacity: 1,
    audioBindings: [],
    midiBindings: [],
    zIndex: layers.length,
    blendMode: 'normal',
    startTime: 0,
    endTime: duration,
    duration: duration
  });

  const createEffectLayer = (item: any): Layer => ({
    id: `effect-${Date.now()}`,
    type: 'effect',
    effectType: item.effectId,
    settings: item.settings || {},
    position: { x: 50, y: 50 },
    scale: { x: 1, y: 1 },
    rotation: 0,
    opacity: 1,
    audioBindings: [],
    midiBindings: [],
    zIndex: layers.length,
    blendMode: 'normal',
    startTime: 0,
    endTime: duration,
    duration: duration
  });

  const timeToX = (time: number) => {
    return (time / duration) * 100;
  };

  const xToTime = (x: number) => {
    return (x / 100) * duration;
  };

  const getLayerIcon = (type: LayerType) => {
    switch (type) {
      case 'video':
        return <Video className="h-3 w-3" />;
      case 'image':
        return <Image className="h-3 w-3" />;
      case 'effect':
        return <Zap className="h-3 w-3" />;
      default:
        return null;
    }
  };

  const getLayerColor = (type: LayerType) => {
    switch (type) {
      case 'video':
        return 'bg-blue-500';
      case 'image':
        return 'bg-green-500';
      case 'effect':
        return 'bg-purple-500';
      default:
        return 'bg-gray-500';
    }
  };

  return (
    <Card className={`bg-stone-900/70 border border-stone-700 rounded-lg overflow-hidden backdrop-blur-sm ${className}`}>
      <CardHeader className="pb-2">
        <div className="flex items-center justify-between">
          <CardTitle className="text-sm font-semibold uppercase tracking-wider flex items-center gap-2">
            <Video className="h-4 w-4" />
            Video Composition Timeline
          </CardTitle>
          <div className="flex items-center gap-2">
            <Badge variant="outline" className="text-xs text-stone-400">
              {layers.length} layers
            </Badge>
            <Button
              size="sm"
              variant="ghost"
              onClick={() => setShowAddMenu(!showAddMenu)}
              className="h-6 w-6 p-0"
            >
              <Plus className="h-3 w-3" />
            </Button>
          </div>
        </div>
      </CardHeader>
      
      <CardContent className="p-2 space-y-2">
        {/* Drop zone */}
        <div
          ref={drop as unknown as React.Ref<HTMLDivElement>}
          className={`relative h-16 border-2 border-dashed rounded-lg transition-all ${
            isOver && canDrop 
              ? "border-emerald-400 bg-emerald-900/20" 
              : "border-stone-600 hover:border-stone-500"
          }`}
        >
          {isOver && canDrop && (
            <div className="absolute inset-0 flex items-center justify-center">
              <div className="text-emerald-400 text-sm font-medium">
                Drop asset here
              </div>
            </div>
          )}
          
          {layers.length === 0 && !isOver && (
            <div className="absolute inset-0 flex items-center justify-center">
              <div className="text-center text-stone-500">
                <Plus className="h-6 w-6 mx-auto mb-2" />
                <div className="text-xs">Drag video/image assets here</div>
              </div>
            </div>
          )}
        </div>
        
        {/* Layer tracks */}
        {layers.map((layer) => {
          const startX = timeToX(layer.startTime);
          const width = timeToX(layer.endTime - layer.startTime);
          const isActive = currentTime >= layer.startTime && currentTime <= layer.endTime;
          const isSelected = selectedLayerId === layer.id;
          
          return (
            <div
              key={layer.id}
              className={`relative h-12 rounded border-2 cursor-pointer transition-all group ${
                isSelected 
                  ? "bg-emerald-500/80 border-emerald-400 shadow-emerald-400/50" 
                  : isActive
                  ? "bg-stone-700/80 border-stone-600"
                  : "bg-stone-800/80 border-stone-700 hover:border-stone-500"
              }`}
              style={{
                left: `${startX}%`,
                width: `${width}%`,
                minWidth: '60px'
              }}
              onClick={() => onLayerSelect(layer.id)}
            >
              <div className="flex items-center justify-between h-full px-2">
                <div className="flex items-center gap-2 flex-1 min-w-0">
                  <div className={`p-1 rounded ${getLayerColor(layer.type)}`}>
                    {getLayerIcon(layer.type)}
                  </div>
                  <div className="flex-1 min-w-0">
                    <div className="text-xs font-medium text-white truncate">
                      {layer.type === 'video' || layer.type === 'image' 
                        ? layer.src?.split('/').pop()?.split('.')[0] || 'Untitled'
                        : layer.effectType || 'Effect'
                      }
                    </div>
                    <div className="text-xs text-stone-400">
                      {layer.startTime.toFixed(1)}s - {layer.endTime.toFixed(1)}s
                    </div>
                  </div>
                </div>
                
                <div className="flex items-center gap-1 opacity-0 group-hover:opacity-100 transition-opacity">
                  <Button
                    size="sm"
                    variant="ghost"
                    className="h-5 w-5 p-0 text-stone-400 hover:text-blue-400"
                    onClick={(e) => {
                      e.stopPropagation();
                      // Note: Layer settings functionality pending implementation
                    }}
                  >
                    <Settings className="h-3 w-3" />
                  </Button>
                  <Button
                    size="sm"
                    variant="ghost"
                    className="h-5 w-5 p-0 text-stone-400 hover:text-red-400"
                    onClick={(e) => {
                      e.stopPropagation();
                      onLayerDelete(layer.id);
                    }}
                  >
                    <Trash2 className="h-3 w-3" />
                  </Button>
                </div>
              </div>
            </div>
          );
        })}
        
        {/* Current time indicator */}
        <div
          className="absolute top-0 w-0.5 h-full bg-red-500 pointer-events-none z-10"
          style={{ left: `${timeToX(currentTime)}%` }}
        />
      </CardContent>
    </Card>
  );
};
</file>

<file path="components/video-composition/VideoLayer.tsx">
'use client';

import React, { useRef, useEffect, useState } from 'react';
import type { AudioBinding, MIDIBinding } from '@/types/video-composition';
import type { AudioAnalysisData, LiveMIDIData } from '@/types/visualizer';
import { 
  calculateOpacity, 
  calculateScale, 
  calculateRotation, 
  calculatePosition 
} from '@/lib/video-composition/parameter-calculator';
import { debugLog } from '@/lib/utils';

interface VideoLayerProps {
  src: string;
  position: { x: number; y: number };
  scale: { x: number; y: number };
  rotation: number;
  opacity: number;
  audioBindings: AudioBinding[];
  midiBindings: MIDIBinding[];
  zIndex: number;
  blendMode: 'normal' | 'multiply' | 'screen' | 'overlay';
  startTime?: number;
  endTime?: number;
  currentTime?: number;
  isPlaying?: boolean;
  audioFeatures?: AudioAnalysisData;
  midiData?: LiveMIDIData;
}

export const VideoLayer: React.FC<VideoLayerProps> = ({
  src,
  position,
  scale,
  rotation,
  opacity,
  audioBindings,
  midiBindings,
  zIndex,
  blendMode,
  startTime = 0,
  endTime,
  currentTime = 0,
  isPlaying = false,
  audioFeatures,
  midiData
}) => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const [videoCurrentTime, setVideoCurrentTime] = useState(0);
  const [isLoaded, setIsLoaded] = useState(false);
  
  // Check if this layer should be visible based on timeline
  const isVisible = !endTime || (currentTime >= startTime && currentTime <= endTime);
  
  // Real-time parameter calculation
  const currentOpacity = calculateOpacity(opacity, audioBindings, audioFeatures || { frequencies: [], timeData: [], volume: 0, bass: 0, mid: 0, treble: 0 }, midiBindings, midiData || { activeNotes: [], currentTime: 0, tempo: 120, totalNotes: 0, trackActivity: {} });
  const currentScale = calculateScale(scale, audioBindings, audioFeatures || { frequencies: [], timeData: [], volume: 0, bass: 0, mid: 0, treble: 0 }, midiBindings, midiData || { activeNotes: [], currentTime: 0, tempo: 120, totalNotes: 0, trackActivity: {} });
  const currentRotation = calculateRotation(rotation, audioBindings, audioFeatures || { frequencies: [], timeData: [], volume: 0, bass: 0, mid: 0, treble: 0 }, midiBindings, midiData || { activeNotes: [], currentTime: 0, tempo: 120, totalNotes: 0, trackActivity: {} });
  const currentPosition = calculatePosition(position, audioBindings, audioFeatures || { frequencies: [], timeData: [], volume: 0, bass: 0, mid: 0, treble: 0 }, midiBindings, midiData || { activeNotes: [], currentTime: 0, tempo: 120, totalNotes: 0, trackActivity: {} });
  
  useEffect(() => {
    const video = videoRef.current;
    if (!video) return;
    
    const handleTimeUpdate = () => setVideoCurrentTime(video.currentTime);
    const handleLoadedData = () => setIsLoaded(true);
    
    video.addEventListener('timeupdate', handleTimeUpdate);
    video.addEventListener('loadeddata', handleLoadedData);
    
    return () => {
      video.removeEventListener('timeupdate', handleTimeUpdate);
      video.removeEventListener('loadeddata', handleLoadedData);
    };
  }, []);
  
  // Sync video playback with timeline
  useEffect(() => {
    const video = videoRef.current;
    if (!video || !isLoaded) return;
    
    if (isPlaying) {
      video.play().catch(debugLog.error);
    } else {
      video.pause();
    }
  }, [isPlaying, isLoaded]);
  
  // Sync video time with timeline
  useEffect(() => {
    const video = videoRef.current;
    if (!video || !isLoaded) return;
    
    const targetTime = currentTime - startTime;
    if (Math.abs(video.currentTime - targetTime) > 0.1) {
      video.currentTime = Math.max(0, targetTime);
    }
  }, [currentTime, startTime, isLoaded]);
  
  if (!isVisible) {
    return null;
  }
  
  return (
    <div 
      className="video-layer absolute"
      style={{
        left: `${currentPosition.x}%`,
        top: `${currentPosition.y}%`,
        transform: `translate(-50%, -50%) scale(${currentScale.x}, ${currentScale.y}) rotate(${currentRotation}deg)`,
        opacity: currentOpacity,
        zIndex,
        mixBlendMode: blendMode,
        pointerEvents: 'none',
        width: '200px', // Default size, can be made configurable
        height: '150px'
      }}
    >
      <video 
        ref={videoRef}
        src={src} 
        autoPlay={false}
        loop 
        muted 
        playsInline
        style={{ 
          width: '100%', 
          height: '100%',
          objectFit: 'cover',
          borderRadius: '4px'
        }}
      />
    </div>
  );
};
</file>

<file path="components/dashboard.tsx">
import * as React from "react"
import { motion } from "framer-motion"
import { GlassCard } from "@/components/ui/glass-card"
import { TechnicalButton } from "@/components/ui/technical-button"
import { StatusIndicator } from "@/components/ui/status-indicator"
import { LoadingSpinner } from "@/components/ui/loading-spinner"
import { cn } from "@/lib/utils"

export interface DashboardProps {
  user: any
  files?: any[]
  currentFile?: any
  onFileSelect?: (file: any) => void
  onFileUpload?: (files: FileList) => void
  isLoading?: boolean
}

const Dashboard = React.forwardRef<HTMLDivElement, DashboardProps>(
  ({ user, files = [], currentFile, onFileSelect, onFileUpload, isLoading = false }, ref) => {
    const [isUploading, setIsUploading] = React.useState(false)

    const handleFileUpload = async (event: React.ChangeEvent<HTMLInputElement>) => {
      const fileList = event.target.files
      if (fileList && onFileUpload) {
        setIsUploading(true)
        try {
          await onFileUpload(fileList)
        } finally {
          setIsUploading(false)
        }
      }
    }

    return (
      <div ref={ref} className="min-h-screen bg-gradient-to-br from-stone-50 to-stone-100">
        <div className="container mx-auto px-4 lg:px-8 py-8">
          {/* Header */}
          <motion.div
            className="mb-8"
            initial={{ opacity: 0, y: 20 }}
            animate={{ opacity: 1, y: 0 }}
            transition={{ duration: 0.5 }}
          >
            <div className="flex flex-col lg:flex-row justify-between items-start lg:items-center gap-4">
              <div>
                <h1 className="text-3xl lg:text-4xl font-display font-bold text-stone-800">
                  DASHBOARD
                </h1>
                <p className="text-lg font-mono text-stone-600">
                  Welcome back, {user?.user_metadata?.name || user?.email}
                </p>
              </div>
              <StatusIndicator status="live">
                SYSTEM ONLINE
              </StatusIndicator>
            </div>
          </motion.div>

          <div className="grid grid-cols-1 lg:grid-cols-4 gap-8">
            {/* Sidebar */}
            <motion.aside
              className="lg:col-span-1 space-y-6"
              initial={{ opacity: 0, x: -20 }}
              animate={{ opacity: 1, x: 0 }}
              transition={{ duration: 0.5, delay: 0.1 }}
            >
              {/* File Library Panel */}
              <GlassCard variant="panel" className="p-6">
                <h3 className="text-lg font-display font-bold text-stone-700 mb-4">
                  FILE LIBRARY
                </h3>
                
                {/* Upload Zone */}
                <div className="mb-4">
                  <label className="upload-zone-compact cursor-pointer">
                    <input
                      type="file"
                      accept=".mid,.midi"
                      onChange={handleFileUpload}
                      className="hidden"
                      disabled={isUploading}
                    />
                    {isUploading ? (
                      <div className="flex flex-col items-center">
                        <LoadingSpinner size="sm" className="mb-2" />
                        <span className="text-xs font-mono text-stone-600">UPLOADING...</span>
                      </div>
                    ) : (
                      <div className="flex flex-col items-center">
                        <span className="text-2xl mb-2"></span>
                        <span className="text-sm font-mono text-stone-600">DROP MIDI FILE</span>
                        <span className="text-xs font-mono text-stone-500">OR CLICK TO BROWSE</span>
                      </div>
                    )}
                  </label>
                </div>

                {/* File List */}
                <div className="space-y-2">
                  {files.length === 0 ? (
                    <div className="text-center py-8">
                      <p className="text-sm font-mono text-stone-500">NO FILES UPLOADED</p>
                      <p className="text-xs font-mono text-stone-400 mt-1">Upload your first MIDI file to get started</p>
                    </div>
                  ) : (
                    files.map((file) => (
                      <div
                        key={file.id}
                        className={cn(
                          "file-list-item",
                          currentFile?.id === file.id && "selected"
                        )}
                        onClick={() => onFileSelect?.(file)}
                      >
                        <div className="font-sans font-medium text-stone-700">
                          {file.name}
                        </div>
                        <div className="file-metadata">
                          {file.size}  {file.uploaded_at}
                        </div>
                      </div>
                    ))
                  )}
                </div>
              </GlassCard>

              {/* Settings Panel */}
              <GlassCard variant="panel" className="p-6">
                <h3 className="text-lg font-display font-bold text-stone-700 mb-4">
                  SETTINGS
                </h3>
                <div className="space-y-3">
                  <TechnicalButton variant="secondary" size="sm" className="w-full">
                    Account Settings
                  </TechnicalButton>
                  <TechnicalButton variant="secondary" size="sm" className="w-full">
                    Preferences
                  </TechnicalButton>
                  <TechnicalButton variant="secondary" size="sm" className="w-full">
                    Help & Support
                  </TechnicalButton>
                </div>
              </GlassCard>
            </motion.aside>

            {/* Main Content */}
            <motion.main
              className="lg:col-span-3"
              initial={{ opacity: 0, x: 20 }}
              animate={{ opacity: 1, x: 0 }}
              transition={{ duration: 0.5, delay: 0.2 }}
            >
              <GlassCard className="p-8 min-h-[600px]">
                {isLoading ? (
                  <div className="flex flex-col items-center justify-center h-full">
                    <LoadingSpinner size="lg" className="mb-4" />
                    <p className="text-lg font-mono text-stone-600">LOADING VISUALIZATION...</p>
                  </div>
                ) : currentFile ? (
                  <div>
                    <div className="flex justify-between items-center mb-6">
                      <div>
                        <h2 className="text-2xl font-display font-bold text-stone-700">
                          {currentFile.name}
                        </h2>
                        <p className="text-sm font-mono text-stone-500">
                          Currently visualizing
                        </p>
                      </div>
                      <StatusIndicator status="completed">
                        READY
                      </StatusIndicator>
                    </div>
                    
                    {/* Visualization Area */}
                    <div className="bg-stone-500 rounded-xl p-4 shadow-inner">
                      <div className="bg-stone-400 rounded-lg h-96 flex items-center justify-center">
                        <p className="text-stone-600 font-mono">
                          VISUALIZATION CANVAS
                        </p>
                      </div>
                    </div>
                  </div>
                ) : (
                  <div className="flex flex-col items-center justify-center h-full text-center">
                    <div className="text-6xl mb-6"></div>
                    <h2 className="text-2xl font-display font-bold text-stone-700 mb-4">
                      NO FILE SELECTED
                    </h2>
                    <p className="text-lg font-mono text-stone-600 mb-6 max-w-md">
                      Select a MIDI file from your library to begin visualization
                    </p>
                    <TechnicalButton variant="primary" size="lg">
                      Upload First File
                    </TechnicalButton>
                  </div>
                )}
              </GlassCard>
            </motion.main>
          </div>
        </div>
      </div>
    )
  }
)
Dashboard.displayName = "Dashboard"

export { Dashboard }
</file>

<file path="components/landing-page.tsx">
import * as React from "react"
import Link from "next/link"
import { motion } from "framer-motion"
import { TechnicalButton } from "@/components/ui/technical-button"
import { GlassCard } from "@/components/ui/glass-card"
import { StatusIndicator } from "@/components/ui/status-indicator"

export interface LandingPageProps {
  user: any | null
}

const LandingPage = React.forwardRef<HTMLDivElement, LandingPageProps>(
  ({ user }, ref) => {
    const features = [
      {
        title: "Real-time MIDI Visualization",
        description: "Transform your MIDI files into stunning visual experiences with our advanced rendering engine.",
        icon: ""
      },
      {
        title: "Technical Precision",
        description: "Built for musicians and developers who demand accuracy and control over their visualizations.",
        icon: ""
      },
      {
        title: "Glassmorphism UI",
        description: "Experience the future of interface design with our cutting-edge glassmorphism aesthetic.",
        icon: ""
      }
    ]

    return (
      <div ref={ref} className="min-h-screen bg-gradient-to-br from-stone-50 to-stone-100">
        {/* Hero Section */}
        <section className="relative py-24 lg:py-32 overflow-hidden">
          <div className="container mx-auto px-4 lg:px-8">
            <motion.div
              className="text-center max-w-4xl mx-auto"
              initial={{ opacity: 0, y: 50 }}
              animate={{ opacity: 1, y: 0 }}
              transition={{ duration: 0.8, ease: "easeOut" }}
            >
              <motion.h1
                className="text-5xl lg:text-6xl font-display font-bold text-stone-800 mb-6"
                initial={{ opacity: 0, y: 30 }}
                animate={{ opacity: 1, y: 0 }}
                transition={{ duration: 0.8, delay: 0.2 }}
              >
                MIDI VISUALIZATION
                <br />
                <span className="text-sage-accent">REIMAGINED</span>
              </motion.h1>
              
              <motion.p
                className="text-xl lg:text-2xl font-mono text-stone-600 mb-8 max-w-2xl mx-auto"
                initial={{ opacity: 0, y: 30 }}
                animate={{ opacity: 1, y: 0 }}
                transition={{ duration: 0.8, delay: 0.4 }}
              >
                Transform your musical data into stunning visual experiences with our technical brutalist aesthetic
              </motion.p>

              <motion.div
                className="flex flex-col sm:flex-row gap-4 justify-center items-center mb-12"
                initial={{ opacity: 0, y: 30 }}
                animate={{ opacity: 1, y: 0 }}
                transition={{ duration: 0.8, delay: 0.6 }}
              >
                <StatusIndicator status="live" className="mb-4 sm:mb-0">
                  LIVE DEMO AVAILABLE
                </StatusIndicator>
                
                <div className="flex flex-col sm:flex-row gap-4">
                  {user ? (
                    <Link href="/dashboard">
                      <TechnicalButton variant="primary" size="lg">
                        Go to Dashboard
                      </TechnicalButton>
                    </Link>
                  ) : (
                    <>
                      <Link href="/signup">
                        <TechnicalButton variant="primary" size="lg">
                          Get Started
                        </TechnicalButton>
                      </Link>
                      <Link href="/creative-visualizer">
                        <TechnicalButton variant="secondary" size="lg">
                          Try Demo
                        </TechnicalButton>
                      </Link>
                    </>
                  )}
                </div>
              </motion.div>
            </motion.div>
          </div>
        </section>

        {/* Features Section */}
        <section className="py-24 bg-white/50">
          <div className="container mx-auto px-4 lg:px-8">
            <motion.div
              className="text-center mb-16"
              initial={{ opacity: 0, y: 30 }}
              whileInView={{ opacity: 1, y: 0 }}
              transition={{ duration: 0.8 }}
              viewport={{ once: true }}
            >
              <h2 className="text-4xl font-display font-bold text-stone-800 mb-4">
                TECHNICAL EXCELLENCE
              </h2>
              <p className="text-lg font-mono text-stone-600 max-w-2xl mx-auto">
                Built for precision, designed for beauty
              </p>
            </motion.div>

            <div className="grid grid-cols-1 md:grid-cols-3 gap-8">
              {features.map((feature, index) => (
                <motion.div
                  key={feature.title}
                  initial={{ opacity: 0, y: 30 }}
                  whileInView={{ opacity: 1, y: 0 }}
                  transition={{ duration: 0.8, delay: index * 0.2 }}
                  viewport={{ once: true }}
                >
                  <GlassCard className="p-8 h-full text-center">
                    <div className="text-4xl mb-4">{feature.icon}</div>
                    <h3 className="text-xl font-display font-bold text-stone-700 mb-3">
                      {feature.title}
                    </h3>
                    <p className="text-stone-600 font-sans">
                      {feature.description}
                    </p>
                  </GlassCard>
                </motion.div>
              ))}
            </div>
          </div>
        </section>

        {/* CTA Section */}
        <section className="py-24">
          <div className="container mx-auto px-4 lg:px-8">
            <motion.div
              className="text-center"
              initial={{ opacity: 0, y: 30 }}
              whileInView={{ opacity: 1, y: 0 }}
              transition={{ duration: 0.8 }}
              viewport={{ once: true }}
            >
              <GlassCard className="p-12 max-w-3xl mx-auto">
                <h2 className="text-3xl lg:text-4xl font-display font-bold text-stone-800 mb-6">
                  READY TO VISUALIZE?
                </h2>
                <p className="text-lg font-mono text-stone-600 mb-8">
                  Join the revolution in MIDI visualization technology
                </p>
                <div className="flex flex-col sm:flex-row gap-4 justify-center">
                  {user ? (
                    <Link href="/dashboard">
                      <TechnicalButton variant="primary" size="lg">
                        Continue Creating
                      </TechnicalButton>
                    </Link>
                  ) : (
                    <>
                      <Link href="/signup">
                        <TechnicalButton variant="primary" size="lg">
                          Start Free Trial
                        </TechnicalButton>
                      </Link>
                      <Link href="/creative-visualizer">
                        <TechnicalButton variant="secondary" size="lg">
                          Explore Demo
                        </TechnicalButton>
                      </Link>
                    </>
                  )}
                </div>
              </GlassCard>
            </motion.div>
          </div>
        </section>
      </div>
    )
  }
)
LandingPage.displayName = "LandingPage"

export { LandingPage }
</file>

<file path="components/navigation.tsx">
import * as React from "react"
import Link from "next/link"
import { motion } from "framer-motion"
import { cn } from "@/lib/utils"
import { TechnicalButton } from "@/components/ui/technical-button"
import { ProfileMenu } from "@/components/auth/profile-menu"
import { EnhancedBreadcrumbNav } from "@/components/layout/breadcrumb-nav"
import { PhonoglyphLogo } from "@/components/ui/phonoglyph-logo"

export interface NavigationProps {
  user: any | null
  currentPath: string
  currentProject?: any
  recentProjects?: any[]
  showBreadcrumbs?: boolean
}

const Navigation = React.forwardRef<HTMLElement, NavigationProps>(
  ({ user, currentPath, currentProject, recentProjects = [], showBreadcrumbs = true }, ref) => {
    const navItems = [
      { href: "/", label: "Home" },
      { href: "/creative-visualizer", label: "Visualizer" },
      { href: "/files", label: "Files" },
      { href: "/dashboard", label: "Dashboard" },
    ]

    return (
      <motion.nav
        ref={ref}
        className="sticky top-0 z-40 w-full glass-strong border-b border-white/20"
        initial={{ y: -100, opacity: 0 }}
        animate={{ y: 0, opacity: 1 }}
        transition={{ duration: 0.5, ease: "easeOut" }}
      >
        <div className="container mx-auto px-4 lg:px-8">
          <div className="flex h-16 items-center justify-between">
            {/* Logo */}
            <Link href="/" className="flex items-center space-x-2">
              <motion.div
                className="flex items-center"
                whileHover={{ scale: 1.05 }}
                transition={{ type: "spring", stiffness: 400, damping: 10 }}
              >
                <PhonoglyphLogo size="md" className="text-stone-700" />
              </motion.div>
            </Link>

            {/* Navigation Links */}
            <div className="hidden md:flex items-center space-x-8">
              {navItems.map((item) => (
                <Link
                  key={item.href}
                  href={item.href}
                  className={cn(
                    "text-sm font-sans font-medium transition-colors duration-200",
                    currentPath === item.href
                      ? "text-stone-700 border-b-2 border-stone-600"
                      : "text-stone-600 hover:text-stone-700"
                  )}
                >
                  {item.label}
                </Link>
              ))}
            </div>

            {/* Auth Section */}
            <div className="flex items-center space-x-4">
              {user ? (
                <ProfileMenu user={user} />
              ) : (
                <div className="flex items-center space-x-3">
                  <Link href="/login">
                    <TechnicalButton variant="secondary" size="sm">
                      Sign In
                    </TechnicalButton>
                  </Link>
                  <Link href="/signup">
                    <TechnicalButton variant="primary" size="sm">
                      Sign Up
                    </TechnicalButton>
                  </Link>
                </div>
              )}
            </div>
          </div>
          
          {/* Breadcrumb Navigation */}
          {showBreadcrumbs && (
            <div className="border-t border-white/10 px-0 py-2">
              <EnhancedBreadcrumbNav
                currentProject={currentProject}
                recentProjects={recentProjects}
                className="text-xs"
              />
            </div>
          )}
        </div>
      </motion.nav>
    )
  }
)
Navigation.displayName = "Navigation"

export { Navigation }
</file>

<file path="hooks/use-audio-analysis.ts">
import { useState, useCallback, useEffect, useRef } from 'react';
import { trpc } from '@/lib/trpc';
import { debugLog } from '@/lib/utils';
import { WaveformData } from '@/components/stem-visualization/stem-waveform';

interface TransientData {
  time: number;
  intensity: number;
  frequency?: number;
}

interface ChromaData {
  time: number;
  pitch: number;
  confidence: number;
  chroma: number[];
}

// Consolidated data structure matching worker output
export interface AudioAnalysisData {
  id: string;
  fileMetadataId: string;
  stemType: string;
  
  // Keep as 'analysisData' to match worker output
  analysisData: {
    // Shared frame timestamps for dense time-series features
    frameTimes?: Float32Array;
    // Core time-series features
    rms: Float32Array;
    loudness: Float32Array;
    spectralCentroid: Float32Array;
    spectralRolloff?: Float32Array;
    spectralFlatness?: Float32Array;
    zcr?: Float32Array;
    
    // FFT data
    fft: Float32Array;
    fftFrequencies?: Float32Array;
    amplitudeSpectrum?: Float32Array;
    
    // Legacy/derived fields (for backward compatibility)
    volume?: Float32Array;
    bass?: Float32Array;
    mid?: Float32Array;
    treble?: Float32Array;
    features?: Float32Array;
    markers?: Float32Array;
    frequencies?: Float32Array;
    timeData?: Float32Array;
    
    // Stereo data
    stereoWindow_left?: Float32Array;
    stereoWindow_right?: Float32Array;
    
    // Enhanced features
    transients?: TransientData[];
    chroma?: ChromaData[];
  };
  
  waveformData: WaveformData;
  
  metadata: {
    sampleRate: number;
    duration: number;
    bufferSize: number;
    featuresExtracted: string[];
    analysisDuration: number;
  };
}

export interface UseAudioAnalysis {
  // State
  cachedAnalysis: AudioAnalysisData[]; // Keep name for backward compatibility
  isLoading: boolean;
  analysisProgress: Record<string, { progress: number; message: string }>; // Keep name
  error: string | null;
  
  // Methods
  loadAnalysis: (fileIds: string[], stemType?: string) => Promise<void>; // Keep name
  analyze: (fileId: string, audioBuffer: AudioBuffer, stemType: string) => void;
  analyzeAudioBuffer: (fileId: string, audioBuffer: AudioBuffer, stemType: string) => void; // Alias
  getAnalysis: (fileId: string, stemType?: string) => AudioAnalysisData | null;
  getFeatureValue: (fileId: string, feature: string, time: number, stemType?: string) => number;
}

export function useAudioAnalysis(): UseAudioAnalysis {
  const [cachedAnalysis, setCachedAnalysis] = useState<AudioAnalysisData[]>([]);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [analysisProgress, setAnalysisProgress] = useState<Record<string, { progress: number; message: string }>>({});
  
  const workerRef = useRef<Worker | null>(null);
  const [queryState, setQueryState] = useState<{ fileIds: string[]; stemType?: string }>({ fileIds: [] });

  // tRPC hooks
  const {
    data: cachedData,
    isLoading: isQueryLoading,
    error: queryError,
  } = trpc.stem.getCachedAnalysis.useQuery(
    { fileIds: queryState.fileIds, stemType: queryState.stemType },
    { enabled: queryState.fileIds.length > 0 }
  );
  
  const cacheMutation = trpc.stem.cacheClientSideAnalysis.useMutation({
    onSuccess: (data) => {
      if (data.cached) {
        debugLog.log(' Analysis cached on server:', data);
      }
    },
    onError: (error) => {
      debugLog.error(' Failed to cache analysis:', error);
    }
  });

  // Worker initialization
  useEffect(() => {
    workerRef.current = new Worker('/workers/audio-analysis-worker.js');

    workerRef.current.onmessage = (event) => {
      const { type, data } = event.data;
      
      switch (type) {
        case 'ANALYSIS_PROGRESS':
          setAnalysisProgress(prev => ({ 
            ...prev, 
            [data.fileId]: { progress: data.progress, message: data.message } 
          }));
          break;
          
        case 'ANALYSIS_COMPLETE':
          debugLog.log(' Analysis complete for:', data.fileId);
          const newAnalysis: AudioAnalysisData = data.result;
          
          setCachedAnalysis(prev => [
            ...prev.filter(a => !(a.fileMetadataId === data.fileId && a.stemType === newAnalysis.stemType)),
            newAnalysis
          ]);
          
          setAnalysisProgress(prev => {
            const { [data.fileId]: removed, ...rest } = prev;
            return rest;
          });
          
          // Cache to backend
          cacheMutation.mutate(newAnalysis as any);
          break;
          
        case 'ANALYSIS_ERROR':
          debugLog.error(` Analysis error for ${data.fileId}:`, data.error);
          setAnalysisProgress(prev => ({ 
            ...prev, 
            [data.fileId]: { progress: 1, message: `Error: ${data.error}` } 
          }));
          setError(`Analysis failed for ${data.fileId}: ${data.error}`);
          break;
      }
    };

    return () => {
      if (workerRef.current) {
        debugLog.log(' Terminating audio analysis worker');
        workerRef.current.terminate();
        workerRef.current = null;
      }
    };
  }, []); // Empty deps - worker should only init once on mount

  // Handle cached data from server
  useEffect(() => {
    setIsLoading(isQueryLoading);

    if (queryError) {
      setError(queryError.message);
    } else if (cachedData) {
      const newAnalyses = (Array.isArray(cachedData) ? cachedData : [cachedData])
        .filter(Boolean) as unknown as AudioAnalysisData[];
      
      setCachedAnalysis(prev => {
        const existingKeys = new Set(prev.map(a => `${a.fileMetadataId}-${a.stemType}`));
        const trulyNew = newAnalyses.filter(a => 
          a && a.fileMetadataId && !existingKeys.has(`${a.fileMetadataId}-${a.stemType}`)
        );
        
        if (trulyNew.length > 0) {
          debugLog.log(' Loaded from cache:', trulyNew.map(a => `${a.fileMetadataId} (${a.stemType})`));
          return [...prev, ...trulyNew];
        }
        return prev;
      });
      setError(null);
    }
  }, [cachedData, isQueryLoading, queryError]);

  // API methods
  const loadAnalysis = useCallback(async (fileIds: string[], stemType?: string) => {
    if (!fileIds || fileIds.length === 0) return;
    
    const idsToFetch = fileIds.filter(id => 
      !cachedAnalysis.some(a => a.fileMetadataId === id && (!stemType || a.stemType === stemType))
    );
    
    if (idsToFetch.length > 0) {
      debugLog.log(' Loading from cache:', idsToFetch, stemType);
      setQueryState({ fileIds: idsToFetch, stemType });
    } else {
      debugLog.log(' All analyses already loaded');
    }
  }, [cachedAnalysis]);

  const analyze = useCallback((fileId: string, audioBuffer: AudioBuffer, stemType: string) => {
    if (!workerRef.current) {
      debugLog.error(" Analysis worker not initialized");
      return;
    }
    
    // Skip if already in progress
    if (analysisProgress[fileId]) {
      debugLog.log(' Analysis already in progress:', fileId);
      return;
    }

    // Skip if already exists
    const existing = cachedAnalysis.find(a => a.fileMetadataId === fileId && a.stemType === stemType);
    if (existing) {
      debugLog.log(' Analysis already exists:', fileId, stemType);
      return;
    }
    
    debugLog.log(' Starting analysis:', fileId, stemType);
    setAnalysisProgress(prev => ({ 
      ...prev, 
      [fileId]: { progress: 0, message: 'Queued for analysis...' } 
    }));
    
    // Copy channel data to avoid detachment
    const channelData = audioBuffer.getChannelData(0);
    const channelDataCopy = new Float32Array(channelData);
    
    workerRef.current.postMessage({
      type: 'ANALYZE_BUFFER',
      data: { 
        fileId, 
        channelData: channelDataCopy,
        sampleRate: audioBuffer.sampleRate,
        duration: audioBuffer.duration,
        stemType,
      }
    });
  }, [analysisProgress, cachedAnalysis]);

  const getAnalysis = useCallback((fileId: string, stemType?: string): AudioAnalysisData | null => {
    const targetStemType = stemType ?? 'master';
    return cachedAnalysis.find(a => 
      a.fileMetadataId === fileId && a.stemType === targetStemType
    ) ?? null;
  }, [cachedAnalysis]);
  
  const getFeatureValue = useCallback((
    fileId: string, 
    feature: string, 
    time: number,
    stemType?: string
  ): number => {
    // Parse feature format: "drums-rms" or "rms"
    const [parsedStem, parsedFeature] = feature.includes('-') 
      ? feature.split('-', 2) 
      : [stemType ?? 'master', feature];
    
    const analysis = getAnalysis(fileId, parsedStem);
    if (!analysis?.analysisData || time < 0 || time > analysis.metadata.duration) {
      return 0;
    }

    const { analysisData, metadata } = analysis;
    const featureLower = parsedFeature.toLowerCase();

    // Event-based features (transients, chroma)
    if (featureLower === 'impact' || featureLower === 'transient') {
      const transient = analysisData.transients?.find(t => Math.abs(t.time - time) < 0.05);
      return transient?.intensity ?? 0;
    }
    
    if (featureLower === 'pitch-height' || featureLower === 'pitch') {
      const chroma = analysisData.chroma?.find(c => Math.abs(c.time - time) < 0.05);
      return chroma?.pitch ?? 0;
    }

    if (featureLower === 'brightness' || featureLower === 'confidence') {
      const chroma = analysisData.chroma?.find(c => Math.abs(c.time - time) < 0.05);
      return chroma?.confidence ?? 0;
    }

    // Time-series features - timestamp-based indexing using analysisData.frameTimes
    const getTimeSeriesValue = (arr: Float32Array | undefined): number => {
      if (!arr || arr.length === 0) return 0;
      const times = (analysisData as any).frameTimes as Float32Array | number[] | undefined;
      if (!times || times.length === 0) return 0;
      // Binary search: find last index with times[idx] <= time
      let lo = 0;
      let hi = Math.min(times.length - 1, arr.length - 1);
      while (lo < hi) {
        const mid = (lo + hi + 1) >>> 1; // upper mid to avoid infinite loop
        const tmid = (times as any)[mid];
        if (tmid <= time) {
          lo = mid;
        } else {
          hi = mid - 1;
        }
      }
      const index = Math.max(0, Math.min(arr.length - 1, lo));
      return arr[index] ?? 0;
    };

    switch (featureLower) {
      case 'rms':
        return getTimeSeriesValue(analysisData.rms);
      case 'volume':
        return getTimeSeriesValue(analysisData.volume ?? analysisData.rms);
      case 'loudness':
        return getTimeSeriesValue(analysisData.loudness);
      case 'spectral-centroid':
      case 'spectralcentroid':
        return getTimeSeriesValue(analysisData.spectralCentroid);
      case 'spectral-rolloff':
      case 'spectralrolloff':
        return getTimeSeriesValue(analysisData.spectralRolloff);
      case 'bass':
        return getTimeSeriesValue(analysisData.bass);
      case 'mid':
        return getTimeSeriesValue(analysisData.mid);
      case 'treble':
        return getTimeSeriesValue(analysisData.treble);
      default:
        return 0;
    }
  }, [getAnalysis]);

  return {
    cachedAnalysis,
    isLoading,
    analysisProgress,
    error,
    loadAnalysis,
    analyze,
    analyzeAudioBuffer: analyze, // Alias for backward compatibility
    getAnalysis,
    getFeatureValue,
  };
}
</file>

<file path="hooks/use-audio-features.ts">
import { useState, useEffect, useMemo } from 'react';

export interface AudioFeature {
  id: string;
  name: string;
  description: string;
  category: 'rhythm' | 'pitch' | 'intensity' | 'timbre';
  stemType?: string;
}

/**
 * Provides a list of available audio features using intuitive musical language.
 * Focuses on the 3-4 most crucial features per stem type for visual mapping.
 * @param trackId The ID of the currently selected track.
 * @param stemType The type of stem currently selected (e.g., 'bass', 'drums', 'vocals', 'melody').
 * @returns An array of available feature descriptors relevant to the stem type.
 */
export function useAudioFeatures(trackId?: string, stemType?: string): AudioFeature[] {
  // Use useMemo to compute features without state updates during render
  const features = useMemo(() => {
    if (!trackId) {
      return [];
    }

    // Create features for ALL stem types, not just the selected one
    // This prevents mappings from changing when switching stems
    const allFeatures: AudioFeature[] = [
      //  DRUMS & PERCUSSION - Focus on rhythm and impact
      { id: 'drums-rms', name: 'RMS Energy', description: 'Raw audio energy and intensity of drum hits', category: 'intensity', stemType: 'drums' },
      { id: 'drums-impact', name: 'Impact', description: 'Sharp, punchy energy for every drum hit', category: 'rhythm', stemType: 'drums' },
      { id: 'drums-brightness', name: 'Brightness', description: 'Tone of the drum - bright hi-hats vs deep kicks', category: 'pitch', stemType: 'drums' },
      { id: 'drums-harshness', name: 'Harshness', description: 'Sharpness of snare cracks and rimshots', category: 'intensity', stemType: 'drums' },
      { id: 'drums-volume', name: 'Volume', description: 'Overall drum energy and power', category: 'rhythm', stemType: 'drums' },
      { id: 'drums-spectral-rolloff', name: 'Spectral Rolloff', description: 'High-frequency content and brightness', category: 'pitch', stemType: 'drums' },
      { id: 'drums-spectral-flatness', name: 'Spectral Flatness', description: 'Tone vs noise ratio in drum sounds', category: 'timbre', stemType: 'drums' },
      { id: 'drums-zcr', name: 'Zero Crossing Rate', description: 'Percussive attack and transient content', category: 'rhythm', stemType: 'drums' },
      
      //  BASS - Focus on groove and texture
      { id: 'bass-rms', name: 'RMS Energy', description: 'Raw audio energy and intensity of bass notes', category: 'intensity', stemType: 'bass' },
      { id: 'bass-volume', name: 'Volume', description: 'Sustained power of the bassline foundation', category: 'rhythm', stemType: 'bass' },
      { id: 'bass-brightness', name: 'Brightness', description: 'Filter changes - bright vs dull bass tones', category: 'pitch', stemType: 'bass' },
      { id: 'bass-noisiness', name: 'Noisiness', description: 'Clean sub-bass vs gritty distorted bass', category: 'timbre', stemType: 'bass' },
      { id: 'bass-warmth', name: 'Warmth', description: 'Perceived warmth and richness of bass', category: 'timbre', stemType: 'bass' },
      { id: 'bass-spectral-rolloff', name: 'Spectral Rolloff', description: 'High-frequency content and presence', category: 'pitch', stemType: 'bass' },
      { id: 'bass-spectral-flatness', name: 'Spectral Flatness', description: 'Harmonic richness vs noise', category: 'timbre', stemType: 'bass' },
      { id: 'bass-perceptual-spread', name: 'Perceptual Spread', description: 'Spectral width and stereo image', category: 'timbre', stemType: 'bass' },
      
      //  MELODY & HARMONY - Focus on emotional character and pitch
      { id: 'melody-rms', name: 'RMS Energy', description: 'Raw audio energy and intensity of melody notes', category: 'intensity', stemType: 'melody' },
      { id: 'melody-volume', name: 'Volume', description: 'Swell and decay of chords and melodies', category: 'rhythm', stemType: 'melody' },
      { id: 'melody-brightness', name: 'Brightness', description: 'Mood - bright happy vs dark moody passages', category: 'pitch', stemType: 'melody' },
      { id: 'melody-pitch-height', name: 'Pitch Height', description: 'Average pitch of the melody line', category: 'pitch', stemType: 'melody' },
      { id: 'melody-harmonic-content', name: 'Harmonic Content', description: 'Richness and complexity of harmonies', category: 'timbre', stemType: 'melody' },
      { id: 'melody-spectral-rolloff', name: 'Spectral Rolloff', description: 'High-frequency harmonics and overtones', category: 'pitch', stemType: 'melody' },
      { id: 'melody-spectral-flatness', name: 'Spectral Flatness', description: 'Tone quality and harmonic richness', category: 'timbre', stemType: 'melody' },
      { id: 'melody-perceptual-sharpness', name: 'Perceptual Sharpness', description: 'Perceived sharpness and clarity', category: 'timbre', stemType: 'melody' },
      
      //  VOCALS & LEADS - Focus on human performance and dynamics
      { id: 'vocals-rms', name: 'RMS Energy', description: 'Raw audio energy and intensity of vocal performance', category: 'intensity', stemType: 'vocals' },
      { id: 'vocals-loudness', name: 'Loudness', description: 'Natural dynamics of the human voice', category: 'intensity', stemType: 'vocals' },
      { id: 'vocals-pitch-height', name: 'Pitch Height', description: 'Average pitch of the vocal melody', category: 'pitch', stemType: 'vocals' },
      { id: 'vocals-noisiness', name: 'Noisiness', description: 'Clean singing vs breathy or raspy vocals', category: 'timbre', stemType: 'vocals' },
      { id: 'vocals-expression', name: 'Expression', description: 'Emotional intensity of vocal performance', category: 'intensity', stemType: 'vocals' },
      { id: 'vocals-spectral-rolloff', name: 'Spectral Rolloff', description: 'High-frequency harmonics and sibilance', category: 'pitch', stemType: 'vocals' },
      { id: 'vocals-spectral-flatness', name: 'Spectral Flatness', description: 'Tone quality and breathiness', category: 'timbre', stemType: 'vocals' },
      { id: 'vocals-perceptual-sharpness', name: 'Perceptual Sharpness', description: 'Clarity and presence of vocals', category: 'timbre', stemType: 'vocals' },
      
      //  OTHER INSTRUMENTS - Focus on general musical characteristics
      { id: 'other-rms', name: 'RMS Energy', description: 'Raw audio energy and intensity of the instrument', category: 'intensity', stemType: 'other' },
      { id: 'other-volume', name: 'Volume', description: 'Overall energy and power of the instrument', category: 'rhythm', stemType: 'other' },
      { id: 'other-brightness', name: 'Brightness', description: 'Tone and mood of the instrument', category: 'pitch', stemType: 'other' },
      { id: 'other-harmonic-content', name: 'Harmonic Content', description: 'Richness and complexity of the sound', category: 'timbre', stemType: 'other' },
      { id: 'other-texture', name: 'Texture', description: 'Textural characteristics and timbre', category: 'timbre', stemType: 'other' },
      { id: 'other-spectral-rolloff', name: 'Spectral Rolloff', description: 'High-frequency content and brightness', category: 'pitch', stemType: 'other' },
      { id: 'other-spectral-flatness', name: 'Spectral Flatness', description: 'Tone vs noise characteristics', category: 'timbre', stemType: 'other' },
      { id: 'other-perceptual-spread', name: 'Perceptual Spread', description: 'Spectral width and stereo image', category: 'timbre', stemType: 'other' },
      
      //  MASTER STEM - Focus on overall mix characteristics
      { id: 'master-rms', name: 'RMS Energy', description: 'Overall mix energy and intensity', category: 'intensity', stemType: 'master' },
      { id: 'master-volume', name: 'Volume', description: 'Overall mix volume and power', category: 'rhythm', stemType: 'master' },
      { id: 'master-brightness', name: 'Brightness', description: 'Overall mix brightness and mood', category: 'pitch', stemType: 'master' },
      { id: 'master-harmonic-content', name: 'Harmonic Content', description: 'Overall mix richness and complexity', category: 'timbre', stemType: 'master' },
      { id: 'master-spectral-rolloff', name: 'Spectral Rolloff', description: 'Overall mix high-frequency content', category: 'pitch', stemType: 'master' },
      { id: 'master-spectral-flatness', name: 'Spectral Flatness', description: 'Overall mix tone quality', category: 'timbre', stemType: 'master' },
      { id: 'master-perceptual-spread', name: 'Perceptual Spread', description: 'Overall mix stereo width', category: 'timbre', stemType: 'master' },
      { id: 'master-loudness', name: 'Loudness', description: 'Overall mix perceived loudness', category: 'intensity', stemType: 'master' },
    ];

    // Filter features by stemType if provided, but keep all features available
    // This prevents mappings from changing when switching stems
    const filteredFeatures = stemType
      ? allFeatures.filter(f => f.stemType === stemType)
      : allFeatures;

    return filteredFeatures;
  }, [trackId, stemType]);

  return features;
}
</file>

<file path="hooks/use-auth.ts">
"use client"

import { useState, useEffect } from 'react'
import { AuthService } from '@/lib/auth'
import { guestUserService, type GuestUser } from '@/lib/guest-user'
import { trpc } from '@/lib/trpc'
import type { User } from 'phonoglyph-types'
import { debugLog } from '@/lib/utils';

export type AuthUser = User | GuestUser

export function useAuth() {
  const [user, setUser] = useState<AuthUser | null>(null)
  const [loading, setLoading] = useState(true)
  const [error, setError] = useState<string | null>(null)

  // Load user session on mount
  useEffect(() => {
    const loadUser = async () => {
      try {
        setLoading(true)
        
        // First try to get authenticated user
        const currentUser = await AuthService.getCurrentUser()
        if (currentUser) {
          setUser(currentUser)
          setError(null)
          return
        }

        // If no authenticated user, check for guest user
        let guestUser = guestUserService.getCurrentGuestUser()
        if (!guestUser) {
          // Create new guest session if none exists
          guestUser = guestUserService.createGuestSession()
        }
        
        setUser(guestUser)
        setError(null)
      } catch (err) {
        setError(err instanceof Error ? err.message : 'Failed to load user')
        
        // Fall back to guest user on error
        try {
          const guestUser = guestUserService.createGuestSession()
          setUser(guestUser)
        } catch (guestErr) {
          setUser(null)
        }
      } finally {
        setLoading(false)
      }
    }

    loadUser()

    // Listen for auth state changes
    const { data: { subscription } } = AuthService.onAuthStateChange(async (event, session) => {
      if (event === 'SIGNED_OUT') {
        // When user signs out, create a new guest session
        const guestUser = guestUserService.createGuestSession()
        setUser(guestUser)
      } else if (event === 'SIGNED_IN' && session?.user) {
        // When user signs in, check if they had guest data to transfer
        const currentGuestUser = user && 'isGuest' in user ? user as GuestUser : null
        
        const newUser: User = {
          id: session.user.id,
          email: session.user.email!,
          name: session.user.user_metadata?.name,
          image: session.user.user_metadata?.avatar_url,
          created_at: session.user.created_at || '',
          updated_at: session.user.updated_at || ''
        }

        setUser(newUser)

        // Transfer guest data if exists
        if (currentGuestUser) {
          try {
            const transferredData = guestUserService.transferGuestDataToUser(
              currentGuestUser.id,
              newUser.id
            )
            debugLog.log('Transferred guest data:', transferredData)
            // Note: Guest data transfer completed - API integration pending
          } catch (error) {
            debugLog.error('Failed to transfer guest data:', error)
          }
        }
      }
    })

    return () => subscription.unsubscribe()
  }, [])

  // Refresh user session
  const refreshUser = async () => {
    try {
      setLoading(true)
      const currentUser = await AuthService.getCurrentUser()
      if (currentUser) {
        setUser(currentUser)
        setError(null)
        return currentUser
      }

      // If no authenticated user, maintain guest session
      const guestUser = guestUserService.getCurrentGuestUser() || guestUserService.createGuestSession()
      setUser(guestUser)
      setError(null)
      return guestUser
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to refresh user')
      const guestUser = guestUserService.createGuestSession()
      setUser(guestUser)
      return guestUser
    } finally {
      setLoading(false)
    }
  }

  // Enhanced sign out that creates guest session
  const signOut = async () => {
    try {
      await AuthService.signOut()
      const guestUser = guestUserService.createGuestSession()
      setUser(guestUser)
    } catch (error) {
      debugLog.error('Sign out error:', error)
      throw error
    }
  }

  // Helper properties
  const isAuthenticated = user && !('isGuest' in user)
  const isGuest = user && 'isGuest' in user
  const shouldShowConversionPrompt = isGuest && user ? guestUserService.shouldShowConversionPrompt(user as GuestUser) : false

  return {
    user,
    loading,
    error,
    isAuthenticated: !!isAuthenticated,
    isGuest: !!isGuest,
    shouldShowConversionPrompt,
    refreshUser,
    signOut,
    // Re-export auth service methods for convenience
    getCurrentUser: AuthService.getCurrentUser,
  }
}
</file>

<file path="hooks/use-auto-save.ts">
"use client"

import { useState, useEffect, useCallback, useRef } from 'react'
import { trpc } from '@/lib/trpc'
import { useAuth } from './use-auth'
import { debugLog } from '@/lib/utils'

export interface AutoSaveConfig {
  enabled: boolean
  interval: number // milliseconds
  maxHistory: number // number of saved states to keep
  debounceTime: number // milliseconds
}

export interface EditState {
  id: string
  userId: string
  projectId: string
  timestamp: Date
  data: {
    visualizationParams: Record<string, any>
    stemMappings: Record<string, any>
    effectSettings: Record<string, any>
    timelineState: any
  }
  version: number
  isCurrent: boolean
}

export interface UseAutoSave {
  isSaving: boolean
  lastSaved: Date | null
  saveHistory: EditState[]
  saveState: () => Promise<void>
  restoreState: (stateId: string) => Promise<void>
  clearHistory: () => Promise<void>
  getCurrentState: () => Promise<EditState | null>
  config: AutoSaveConfig
  updateConfig: (config: Partial<AutoSaveConfig>) => void
}

const DEFAULT_CONFIG: AutoSaveConfig = {
  enabled: true,
  interval: 5000, // 5 seconds
  maxHistory: 10,
  debounceTime: 1000, // 1 second
}

export function useAutoSave(projectId: string): UseAutoSave {
  const { user, isAuthenticated } = useAuth()
  const [config, setConfig] = useState<AutoSaveConfig>(DEFAULT_CONFIG)
  const [isSaving, setIsSaving] = useState(false)
  const [lastSaved, setLastSaved] = useState<Date | null>(null)
  const [saveHistory, setSaveHistory] = useState<EditState[]>([])
  
  const saveTimeoutRef = useRef<NodeJS.Timeout>()
  const intervalRef = useRef<NodeJS.Timeout>()
  const currentStateRef = useRef<Record<string, any> | null>(null)

  // tRPC mutations and queries
  const saveStateMutation = trpc.autoSave.saveState.useMutation()
  const restoreStateMutation = trpc.autoSave.restoreState.useMutation()
  const clearHistoryMutation = trpc.autoSave.clearProjectHistory.useMutation()
  const getCurrentStateQuery = trpc.autoSave.getCurrentState.useQuery(
    { projectId },
    { enabled: !!projectId && isAuthenticated }
  )
  const getProjectStatesQuery = trpc.autoSave.getProjectStates.useQuery(
    { projectId, limit: config.maxHistory },
    { enabled: !!projectId && isAuthenticated }
  )

  // Update save history when query data changes
  useEffect(() => {
    if (getProjectStatesQuery.data) {
      setSaveHistory(getProjectStatesQuery.data.map((state: any) => ({
        ...state,
        timestamp: new Date(state.timestamp)
      })))
    }
  }, [getProjectStatesQuery.data])

  // Update last saved when current state changes
  useEffect(() => {
    if (getCurrentStateQuery.data) {
      setLastSaved(new Date(getCurrentStateQuery.data.timestamp))
    }
  }, [getCurrentStateQuery.data])

  // Save state function
  const saveState = useCallback(async (stateData?: Record<string, any>) => {
    if (!projectId || !isAuthenticated || !user || !config.enabled) {
      return
    }

    try {
      setIsSaving(true)
      
      const dataToSave = stateData || currentStateRef.current
      if (!dataToSave) {
        debugLog.warn('No state data to save')
        return
      }

      // Validate state data structure
      const isValidData = validateStateData(dataToSave)
      if (!isValidData) {
        debugLog.warn('Invalid state data structure')
        return
      }

      await saveStateMutation.mutateAsync({
        projectId,
        data: dataToSave
      })

      setLastSaved(new Date())
      
      // Refresh queries to get updated data
      await getCurrentStateQuery.refetch()
      await getProjectStatesQuery.refetch()
      
    } catch (error) {
      debugLog.error('Failed to save state:', error)
      // Don't throw error to avoid breaking the UI
    } finally {
      setIsSaving(false)
    }
  }, [projectId, isAuthenticated, user, config.enabled, saveStateMutation, getCurrentStateQuery, getProjectStatesQuery])

  // Restore state function
  const restoreState = useCallback(async (stateId: string) => {
    if (!projectId || !isAuthenticated || !user) {
      throw new Error('Authentication required to restore state')
    }

    try {
      setIsSaving(true)
      
      const restoredState = await restoreStateMutation.mutateAsync({ stateId })
      
      setLastSaved(new Date())
      
      // Refresh queries to get updated data
      await getCurrentStateQuery.refetch()
      await getProjectStatesQuery.refetch()
      
      return restoredState
    } catch (error) {
      debugLog.error('Failed to restore state:', error)
      throw error
    } finally {
      setIsSaving(false)
    }
  }, [projectId, isAuthenticated, user, restoreStateMutation, getCurrentStateQuery, getProjectStatesQuery])

  // Clear history function
  const clearHistory = useCallback(async () => {
    if (!projectId || !isAuthenticated || !user) {
      throw new Error('Authentication required to clear history')
    }

    try {
      setIsSaving(true)
      
      await clearHistoryMutation.mutateAsync({ projectId })
      
      setSaveHistory([])
      setLastSaved(null)
      
    } catch (error) {
      debugLog.error('Failed to clear history:', error)
      throw error
    } finally {
      setIsSaving(false)
    }
  }, [projectId, isAuthenticated, user, clearHistoryMutation])

  // Get current state function
  const getCurrentState = useCallback(async (): Promise<EditState | null> => {
    if (!projectId || !isAuthenticated) {
      return null
    }

    try {
      const currentState = await getCurrentStateQuery.refetch()
      return currentState.data || null
    } catch (error) {
      debugLog.error('Failed to get current state:', error)
      return null
    }
  }, [projectId, isAuthenticated, getCurrentStateQuery])

  // Update config function
  const updateConfig = useCallback((newConfig: Partial<AutoSaveConfig>) => {
    setConfig(prev => ({ ...prev, ...newConfig }))
  }, [])

  // Debounced save function
  const debouncedSave = useCallback((stateData: Record<string, any>) => {
    currentStateRef.current = stateData
    
    // Clear existing timeout
    if (saveTimeoutRef.current) {
      clearTimeout(saveTimeoutRef.current)
    }

    // Set new timeout
    saveTimeoutRef.current = setTimeout(() => {
      saveState(stateData)
    }, config.debounceTime)
  }, [saveState, config.debounceTime])

  // Auto-save interval
  useEffect(() => {
    if (!config.enabled || !isAuthenticated || !projectId) {
      return
    }

    intervalRef.current = setInterval(() => {
      if (currentStateRef.current) {
        saveState(currentStateRef.current)
      }
    }, config.interval)

    return () => {
      if (intervalRef.current) {
        clearInterval(intervalRef.current)
      }
    }
  }, [config.enabled, config.interval, isAuthenticated, projectId, saveState])

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      if (saveTimeoutRef.current) {
        clearTimeout(saveTimeoutRef.current)
      }
      if (intervalRef.current) {
        clearInterval(intervalRef.current)
      }
    }
  }, [])

  // Guest user fallback using localStorage
  const saveStateGuest = useCallback(async (stateData?: Record<string, any>) => {
    if (!projectId || isAuthenticated) {
      return
    }

    try {
      setIsSaving(true)
      
      const dataToSave = stateData || currentStateRef.current
      if (!dataToSave) {
        return
      }

      const guestKey = `guest_auto_save_${projectId}`
      const timestamp = new Date().toISOString()
      
      const guestState = {
        id: `guest_${Date.now()}`,
        projectId,
        timestamp,
        data: dataToSave,
        version: 1,
        isCurrent: true
      }

      // Store in localStorage with expiry (24 hours)
      const guestData = {
        ...guestState,
        expiresAt: new Date(Date.now() + 24 * 60 * 60 * 1000).toISOString()
      }

      localStorage.setItem(guestKey, JSON.stringify(guestData))
      setLastSaved(new Date(timestamp))
      
    } catch (error) {
      debugLog.error('Failed to save guest state:', error)
    } finally {
      setIsSaving(false)
    }
  }, [projectId, isAuthenticated])

  const getCurrentStateGuest = useCallback(async (): Promise<EditState | null> => {
    if (!projectId || isAuthenticated) {
      return null
    }

    try {
      const guestKey = `guest_auto_save_${projectId}`
      const guestData = localStorage.getItem(guestKey)
      
      if (!guestData) {
        return null
      }

      const parsed = JSON.parse(guestData)
      const expiresAt = new Date(parsed.expiresAt)
      
      // Check if expired
      if (expiresAt < new Date()) {
        localStorage.removeItem(guestKey)
        return null
      }

      return {
        ...parsed,
        timestamp: new Date(parsed.timestamp)
      }
    } catch (error) {
      debugLog.error('Failed to get guest state:', error)
      return null
    }
  }, [projectId, isAuthenticated])

  // Return appropriate functions based on authentication status
  const saveStateFn = isAuthenticated ? saveState : saveStateGuest
  const getCurrentStateFn = isAuthenticated ? getCurrentState : getCurrentStateGuest

  return {
    isSaving,
    lastSaved,
    saveHistory: isAuthenticated ? saveHistory : [],
    saveState: saveStateFn,
    restoreState: isAuthenticated ? restoreState : async () => { throw new Error('Restore not available for guest users') },
    clearHistory: isAuthenticated ? clearHistory : async () => { throw new Error('Clear history not available for guest users') },
    getCurrentState: getCurrentStateFn,
    config,
    updateConfig
  }
}

// Helper function to validate state data structure
function validateStateData(data: Record<string, any>): boolean {
  try {
    // Check for required top-level keys
    const requiredKeys = ['visualizationParams', 'stemMappings', 'effectSettings', 'timelineState']
    const hasRequiredKeys = requiredKeys.every(key => key in data)
    
    if (!hasRequiredKeys) {
      return false
    }

    // Validate data types
    const isValid = 
      typeof data.visualizationParams === 'object' &&
      typeof data.stemMappings === 'object' &&
      typeof data.effectSettings === 'object'

    return isValid
  } catch (error) {
    debugLog.error('Error validating state data:', error)
    return false
  }
}
</file>

<file path="hooks/use-feature-value.ts">
import { useState, useEffect } from 'react';

/**
 * Provides the real-time, normalized (0.0 to 1.0) value of a specific feature.
 * @param featureId The unique ID of the feature to monitor.
 * @returns The latest value of the feature, updated on every animation frame.
 */
export function useFeatureValue(featureId: string | null): number {
  const [value, setValue] = useState(0);

  useEffect(() => {
    if (!featureId) {
      setValue(0);
      return;
    }

    // Mock real-time value generation
    let animationId: number;
    let time = 0;

    const updateValue = () => {
      time += 0.016; // ~60fps
      
      // Generate different patterns based on feature type
      let newValue = 0;
      
      if (featureId.includes('rms')) {
        // RMS features have rhythmic patterns
        newValue = 0.3 + 0.4 * Math.sin(time * 2) + 0.1 * Math.random();
      } else if (featureId.includes('spectral')) {
        // Spectral features have smoother patterns
        newValue = 0.4 + 0.3 * Math.sin(time * 0.5) + 0.2 * Math.cos(time * 1.5);
      } else if (featureId.includes('loudness')) {
        // Loudness features have more dynamic patterns
        newValue = 0.2 + 0.6 * Math.abs(Math.sin(time * 3)) + 0.1 * Math.random();
      } else {
        // Default pattern
        newValue = 0.5 + 0.3 * Math.sin(time) + 0.1 * Math.random();
      }
      
      // Clamp to 0-1 range
      newValue = Math.max(0, Math.min(1, newValue));
      
      setValue(newValue);
      animationId = requestAnimationFrame(updateValue);
    };

    animationId = requestAnimationFrame(updateValue);

    return () => {
      if (animationId) {
        cancelAnimationFrame(animationId);
      }
    };
  }, [featureId]);

  return value;
}
</file>

<file path="hooks/use-stem-audio-controller.ts">
import { useRef, useState, useCallback, useEffect } from 'react';
import { StemAnalysis, AudioFeature } from '@/types/stem-audio-analysis';
import { AudioAnalysisData } from '@/types/visualizer';
import { debugLog } from '@/lib/utils';

interface Stem {
  id: string;
  url: string;
  label?: string;
  isMaster: boolean;
}

interface StemFeatures {
  [stemId: string]: StemAnalysis | null;
}

interface UseStemAudioController {
  play: () => void;
  pause: () => void;
  stop: () => void;
  isPlaying: boolean;
  featuresByStem: StemFeatures;
  currentTime: number;
  setCurrentTime: (t: number) => void;
  loadStems: (stems: Stem[], onDecode?: (stemId: string, buffer: AudioBuffer) => void) => Promise<void>;
  clearStems: () => void;
  setStemVolume: (stemId: string, volume: number) => void;
  getStemVolume: (stemId: string) => number;
  testAudioOutput: () => Promise<void>;
  visualizationData: AudioAnalysisData | null;
  stemsLoaded: boolean;
  isLooping: boolean;
  setLooping: (looping: boolean) => void;
  soloedStems: Set<string>;
  toggleStemSolo: (stemId: string) => void;
  getAudioLatency: () => number;
  getAudioContextTime: () => number;
  scheduledStartTimeRef: React.MutableRefObject<number>;
  duration: number;
  getStereoWindow: (stemId: string, windowSize: number) => { left: number[], right: number[] } | null;
}

export function useStemAudioController(): UseStemAudioController {
  const [isPlaying, setIsPlaying] = useState(false);
  const [featuresByStem, setFeaturesByStem] = useState<StemFeatures>({});
  const [currentTime, setCurrentTime] = useState(0);
  const [visualizationData, setVisualizationData] = useState<AudioAnalysisData | null>(null);
  
  // Add state to track if stems are already loaded and worker is set up
  const [stemsLoaded, setStemsLoaded] = useState(false);
  const [workerSetupComplete, setWorkerSetupComplete] = useState(false);
  const loadingRef = useRef(false);
  const [isLooping, setIsLooping] = useState(true); // Default to looping
  const [soloedStems, setSoloedStems] = useState<Set<string>>(new Set());
  const masterStemIdRef = useRef<string | null>(null);

  // Track which stems have finished playing
  const finishedStemsRef = useRef<Set<string>>(new Set());

  // Refs for audio context and buffers
  const audioContextRef = useRef<AudioContext | null>(null);
  const audioBuffersRef = useRef<Record<string, AudioBuffer>>({});
  const audioSourcesRef = useRef<Record<string, AudioBufferSourceNode>>({});
  const gainNodesRef = useRef<Record<string, GainNode>>({});
  const startTimeRef = useRef(0);
  const scheduledStartTimeRef = useRef(0); // Scheduled start time for precise sync
  const pausedTimeRef = useRef(0);
  const timeUpdateIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const isIntentionallyStoppingRef = useRef(false);



  // Remove advanced audio system initialization
  useEffect(() => {
    const initializeAudioSystem = async () => {
      try {
        // Create AudioContext
        audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
        
        // Log initial audio context state
        debugLog.log(' Audio context created with state:', audioContextRef.current.state);
        debugLog.log(' Audio context sample rate:', audioContextRef.current.sampleRate);
        
        // Try to resume immediately if possible
        if (audioContextRef.current.state === 'suspended') {
          debugLog.log(' Audio context is suspended, attempting to resume...');
          try {
            await audioContextRef.current.resume();
            debugLog.log(' Audio context resumed successfully');
          } catch (resumeError) {
            debugLog.warn(' Could not resume audio context immediately:', resumeError);
            debugLog.log(' User interaction will be required to start audio');
          }
        }
        
        
        
        debugLog.log(' Advanced audio analysis system initialized');
        
      } catch (error) {
        debugLog.error(' Failed to initialize audio analysis system:', error);
      }
    };

    initializeAudioSystem();

    // Cleanup on unmount
    return () => {
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close();
      }
    };
  }, []);

  useEffect(() => {
    if (!isPlaying || !audioContextRef.current) return;

    const audioContext = audioContextRef.current;
    const activeSoloStems = soloedStems.size > 0;
    const masterStemId = masterStemIdRef.current;

    Object.entries(gainNodesRef.current).forEach(([stemId, gainNode]) => {
      const isSoloed = soloedStems.has(stemId);
      let targetVolume = 0;

      if (activeSoloStems) {
        // If any stem is soloed, only it should be audible.
        targetVolume = isSoloed ? 0.7 : 0;
      } else {
        // If no stems are soloed, only the master should be audible.
        targetVolume = (stemId === masterStemId) ? 0.7 : 0;
      }

      // Smoothly ramp the volume to the new target.
      gainNode.gain.linearRampToValueAtTime(targetVolume, audioContext.currentTime + 0.1);
    });
  }, [soloedStems, isPlaying]);

  const toggleStemSolo = useCallback((stemId: string) => {
    setSoloedStems(prev => {
      const newSoloed = new Set(prev);
      if (newSoloed.has(stemId)) {
        newSoloed.delete(stemId);
      } else {
        newSoloed.add(stemId);
      }
      return newSoloed;
    });
  }, []);

  // In loadStems, remove all worker/processor/feature pipeline logic, just load and decode audio buffers for playback
  const loadStems = useCallback(async (stems: Stem[], onDecode?: (stemId: string, buffer: AudioBuffer) => void) => {
    if (stems.length === 0) return;
    if (loadingRef.current || stemsLoaded) {
      debugLog.log(' Stems already loading or loaded, skipping duplicate request');
      return;
    }
    loadingRef.current = true;
    try {
      debugLog.log(` Starting to load ${stems.length} stems...`);
      debugLog.log(' Stem master info:', stems.map(s => ({ id: s.id, label: s.label, isMaster: s.isMaster })));
      // Only fetch and decode audio buffers
      const decodedBuffers: Record<string, AudioBuffer> = {};
      const masterStem = stems.find(s => s.isMaster);
      if (masterStem) {
        masterStemIdRef.current = masterStem.id;
        debugLog.log(' Master stem identified:', masterStem.id, masterStem.label);
      } else if (stems.length > 0) {
        // Fallback: if no master is flagged, assume the first one is.
        masterStemIdRef.current = stems[0].id;
        debugLog.warn(' No master stem designated. Defaulting to first stem:', stems[0].id);
      }


      for (const stem of stems) {
        try {
          const resp = await fetch(stem.url);
          if (!resp.ok) throw new Error(`Failed to load stem ${stem.id}: ${resp.status}`);
          
          const buffer = await resp.arrayBuffer();
          const audioBuffer = await audioContextRef.current!.decodeAudioData(buffer);
          decodedBuffers[stem.id] = audioBuffer;
          
          // Create gain node for volume control
          const gainNode = audioContextRef.current!.createGain();
          gainNode.gain.value = 0.7; // Default volume
          gainNodesRef.current[stem.id] = gainNode;
          
          debugLog.log(` Decoded audio buffer for ${stem.id}: ${audioBuffer.duration.toFixed(2)}s`);
          
          if (onDecode) {
            onDecode(stem.id, audioBuffer);
          }
        } catch (error) {
          debugLog.error(` Failed to decode audio buffer for ${stem.id}:`, error);
        }
      }

      // Store all decoded buffers (MERGE instead of replace)
      audioBuffersRef.current = { ...audioBuffersRef.current, ...decodedBuffers };
      setStemsLoaded(true);
      loadingRef.current = false;
      // REMOVED VERBOSE LOGGING
      // debugLog.log(` Successfully loaded ${stems.length} stems`);
      
    } catch (error) {
      debugLog.error(' Failed to load stems:', error);
      loadingRef.current = false;
    }
  }, []);

  // Remove startAnalysis and stopAnalysis logic

  const play = useCallback(async () => {
    if (!audioContextRef.current || !stemsLoaded) {
      debugLog.warn(' Cannot play: AudioContext not ready or stems not loaded');
      return;
    }

    try {
      if (audioContextRef.current.state === 'suspended') {
        await audioContextRef.current.resume();
      }

      Object.values(audioSourcesRef.current).forEach(source => {
        try { source.stop(); } catch (e) { /* Ignore */ }
      });
      audioSourcesRef.current = {};

      const now = audioContextRef.current.currentTime;
      const scheduleDelay = 0.1;
      const scheduledStartTime = now + scheduleDelay;
      
      // Use pausedTimeRef to resume from the correct position
      const offset = pausedTimeRef.current;
      startTimeRef.current = scheduledStartTime - offset;
      scheduledStartTimeRef.current = scheduledStartTime - offset;

      const activeSoloStems = soloedStems.size > 0;
      const masterId = masterStemIdRef.current;

      Object.entries(audioBuffersRef.current).forEach(([stemId, buffer]) => {
        const source = audioContextRef.current!.createBufferSource();
        const gainNode = gainNodesRef.current[stemId];
        
        const isSoloed = soloedStems.has(stemId);
        
        // Determine initial volume based on solo state
        let initialVolume = 0;
        if (activeSoloStems) {
            initialVolume = isSoloed ? 0.7 : 0;
        } else {
            initialVolume = (stemId === masterId) ? 0.7 : 0;
        }
        gainNode.gain.setValueAtTime(initialVolume, audioContextRef.current!.currentTime);
        
        source.buffer = buffer;
        source.connect(gainNode);
        gainNode.connect(audioContextRef.current!.destination);
        
        // *** THE KEY FIX ***
        // Use the Web Audio API's native looping.
        source.loop = isLooping;
        
        // Remove the complex onended handler entirely as it's no longer needed.
        source.onended = () => {
          // Can be used for cleanup if a track is stopped manually
          if (isIntentionallyStoppingRef.current) {
            delete audioSourcesRef.current[stemId];
          }
        };
        
        source.start(scheduledStartTime, offset); // Start at scheduled time from the correct offset
        audioSourcesRef.current[stemId] = source;
      });

      pausedTimeRef.current = 0; // Reset paused time
      setIsPlaying(true);
      isIntentionallyStoppingRef.current = false;

      // Start time updates
      timeUpdateIntervalRef.current = setInterval(() => {
        if (audioContextRef.current && isPlaying) {
          const elapsedTime = audioContextRef.current.currentTime - startTimeRef.current;
          //  FIX: Handle looping by wrapping currentTime to audio duration
          const masterDuration = getMasterDuration();
          const currentTime = masterDuration > 0 ? elapsedTime % masterDuration : Math.max(0, elapsedTime);
          setCurrentTime(currentTime);
        }
      }, 16);

    } catch (error) {
      debugLog.error(' Failed to start audio playback:', error);
      setIsPlaying(false);
    }
  }, [stemsLoaded, isLooping, soloedStems]);

  const pause = useCallback(() => {
    if (!isPlaying) return;
    
    isIntentionallyStoppingRef.current = true;
    
    Object.values(audioSourcesRef.current).forEach(source => {
      try { source.stop(); } catch (e) { /* Ignore */ }
    });
    
    audioSourcesRef.current = {};

    if (timeUpdateIntervalRef.current) {
      clearInterval(timeUpdateIntervalRef.current);
      timeUpdateIntervalRef.current = null;
    }
    
    // Correctly calculate and store the paused time
    pausedTimeRef.current = audioContextRef.current!.currentTime - startTimeRef.current;
    setIsPlaying(false);
  }, [isPlaying]);

  const stop = useCallback(() => {
    try {
      setIsPlaying(false);
      // stopAnalysis(); // This line was removed
      
      // Set flag to indicate intentional stopping
      isIntentionallyStoppingRef.current = true;
      
      // Stop all audio sources and clear them
      Object.entries(audioSourcesRef.current).forEach(([stemId, source]) => {
        try {
          source.stop();
        } catch (error) {
          debugLog.error(` Failed to stop playback for ${stemId}:`, error);
        }
      });
      
      // Clear all audio sources to prevent layering
      audioSourcesRef.current = {};
      
      // Reset the flag after a short delay
      setTimeout(() => {
        isIntentionallyStoppingRef.current = false;
      }, 100);
      
      // Reset playback position
      setCurrentTime(0);
      pausedTimeRef.current = 0;
      startTimeRef.current = 0;
    } catch (error) {
      debugLog.error(' Failed to stop playback:', error);
    }
  }, []); // This line was removed

  const clearStems = useCallback(() => {
    try {
      setIsPlaying(false);
      // stopAnalysis(); // This line was removed
      setCurrentTime(0);
      setFeaturesByStem({});
      setVisualizationData(null);
      
      // Reset loading state
      setStemsLoaded(false);
      setWorkerSetupComplete(false);
      loadingRef.current = false;
      
      // Stop and clear all audio sources
      Object.entries(audioSourcesRef.current).forEach(([stemId, source]) => {
        try {
          source.stop();
        } catch (error) {
          // Ignore errors when stopping already stopped sources
        }
      });
      
      // Clear audio references
      audioSourcesRef.current = {};
      audioBuffersRef.current = {};
      gainNodesRef.current = {};
      pausedTimeRef.current = 0;
      startTimeRef.current = 0;
      
      // Clear audio processor
      // if (audioProcessorRef.current) { // This line was removed
      //   audioProcessorRef.current.dispose(); // This line was removed
      // } // This line was removed
      
      debugLog.log(' Advanced audio analysis and playback cleared');
    } catch (error) {
      debugLog.error(' Failed to clear stems:', error);
    }
  }, []); // This line was removed

  // DISABLED: Real-time visualization data processing (now using cached analysis)
  // useEffect(() => {
  //   if (!isPlaying || !featurePipelineRef.current) return;

  //   const processVisualizationData = () => {
  //     try {
  //       // Get current features from all stems
  //       const allFeatures = Object.values(featuresByStem).filter(Boolean) as StemAnalysis[];
        
  //       if (allFeatures.length > 0) {
  //         // Convert array to record format for processing
  //         const featuresRecord: Record<string, StemAnalysis> = {};
  //         allFeatures.forEach((analysis, index) => {
  //           featuresRecord[`stem_${index}`] = analysis;
  //         });
          
  //         // Process features through visualization pipeline
  //         const visualizationParams = featurePipelineRef.current!.processFeatures(featuresRecord);
          
  //         // Convert VisualizationParameters to AudioAnalysisData
  //         const audioAnalysisData: AudioAnalysisData = {
  //           frequencies: new Array(256).fill(visualizationParams.energy),
  //           timeData: new Array(256).fill(visualizationParams.brightness),
  //           volume: visualizationParams.energy,
  //           bass: visualizationParams.color.warmth,
  //           mid: visualizationParams.movement.speed,
  //           treble: visualizationParams.scale
  //         };
          
  //         setVisualizationData(audioAnalysisData);
  //       }
  //     } catch (error) {
  //       debugLog.error(' Failed to process visualization data:', error);
  //     }
  //   };

  //   const interval = setInterval(processVisualizationData, 16); // ~60fps
  //   return () => clearInterval(interval);
  // }, [isPlaying, featuresByStem]);

  // OPTIMIZED REAL-TIME TIME TRACKING
  useEffect(() => {
    if (!isPlaying || !audioContextRef.current) return;

    // Use requestAnimationFrame for more accurate timing, but cap at 30fps
    let animationFrameId: number;
    let lastUpdateTime = 0;
    const targetFrameTime = 1000 / 30; // 33.33ms for 30fps
    
    const updateTime = () => {
      try {
        const now = performance.now();
        const elapsed = now - lastUpdateTime;
        
        // Only update if enough time has passed (30fps cap)
        if (elapsed >= targetFrameTime) {
          const elapsedTime = audioContextRef.current!.currentTime - startTimeRef.current;
          //  FIX: Handle looping by wrapping currentTime to audio duration
          const masterDuration = getMasterDuration();
          const currentAudioTime = masterDuration > 0 ? elapsedTime % masterDuration : Math.max(0, elapsedTime);
          setCurrentTime(currentAudioTime);
          lastUpdateTime = now;
        }
        
        animationFrameId = requestAnimationFrame(updateTime);
      } catch (error) {
        debugLog.error(' Failed to update time:', error);
      }
    };

    animationFrameId = requestAnimationFrame(updateTime);
    
    return () => {
      if (animationFrameId) {
        cancelAnimationFrame(animationFrameId);
      }
    };
  }, [isPlaying]);

  // Add user interaction handler to resume audio context
  useEffect(() => {
    const handleUserInteraction = async () => {
      if (audioContextRef.current && audioContextRef.current.state === 'suspended') {
        debugLog.log(' User interaction detected, resuming audio context...');
        try {
          await audioContextRef.current.resume();
          debugLog.log(' Audio context resumed via user interaction');
        } catch (error) {
          debugLog.error(' Failed to resume audio context on user interaction:', error);
        }
      }
    };

    // Listen for user interactions that should enable audio
    const events = ['click', 'touchstart', 'keydown', 'mousedown'];
    events.forEach(event => {
      document.addEventListener(event, handleUserInteraction, { once: true, passive: true });
    });

    return () => {
      events.forEach(event => {
        document.removeEventListener(event, handleUserInteraction);
      });
    };
  }, []);

  // Adaptive performance optimization
  useEffect(() => {
    // if (!deviceOptimizerRef.current || !performanceMonitorRef.current) return; // This line was removed

    // const optimizePerformance = () => { // This line was removed
    //   try { // This line was removed
    //     const metrics = performanceMonitorRef.current!.getCurrentMetrics(); // This line was removed
    //     deviceOptimizerRef.current!.updatePerformanceMetrics( // This line was removed
    //       metrics.fps, // This line was removed
    //       metrics.analysisLatency, // This line was removed
    //       metrics.memoryUsage // This line was removed
    //     ); // This line was removed
    //   } catch (error) { // This line was removed
    //     debugLog.error(' Failed to optimize performance:', error); // This line was removed
    //   } // This line was removed
    // }; // This line was removed

    // const interval = setInterval(optimizePerformance, 1000); // Every second // This line was removed
    // return () => clearInterval(interval); // This line was removed
  }, []);

  const setStemVolume = useCallback((stemId: string, volume: number) => {
    const gainNode = gainNodesRef.current[stemId];
    if (gainNode) {
      gainNode.gain.value = Math.max(0, Math.min(1, volume));
      debugLog.log(` Set volume for ${stemId}: ${volume}`);
    }
  }, []);

  const getStemVolume = useCallback((stemId: string): number => {
    const gainNode = gainNodesRef.current[stemId];
    return gainNode ? gainNode.gain.value : 0.7;
  }, []);

  // Test audio output function
  const testAudioOutput = useCallback(async () => {
    if (!audioContextRef.current) {
      debugLog.warn(' No audio context available for test');
      return;
    }

    try {
      debugLog.log(' Testing audio output...');
      
      // Create a simple test tone
      const oscillator = audioContextRef.current.createOscillator();
      const gainNode = audioContextRef.current.createGain();
      
      oscillator.frequency.setValueAtTime(440, audioContextRef.current.currentTime); // A4 note
      oscillator.type = 'sine';
      
      gainNode.gain.setValueAtTime(0.1, audioContextRef.current.currentTime); // Low volume
      gainNode.gain.exponentialRampToValueAtTime(0.01, audioContextRef.current.currentTime + 0.5);
      
      oscillator.connect(gainNode);
      gainNode.connect(audioContextRef.current.destination);
      
      oscillator.start(audioContextRef.current.currentTime);
      oscillator.stop(audioContextRef.current.currentTime + 0.5);
      
      debugLog.log(' Test tone played - you should hear a 440Hz tone for 0.5 seconds');
    } catch (error) {
      debugLog.error(' Audio output test failed:', error);
    }
  }, []);

  // Helper function to get the maximum duration of all loaded stems
  const getMaxDuration = useCallback((): number => {
    const durations = Object.values(audioBuffersRef.current).map(buffer => buffer.duration);
    return Math.max(...durations, 0);
  }, []);

  // Helper function to get the master stem duration if available
  const getMasterDuration = useCallback((): number => {
    const masterId = masterStemIdRef.current;
    if (masterId && audioBuffersRef.current[masterId]) {
      return audioBuffersRef.current[masterId].duration;
    }
    return getMaxDuration();
  }, [getMaxDuration]);

  // Expose audio context latency and time
  const getAudioLatency = useCallback((): number => {
    const ctx = audioContextRef.current;
    if (!ctx) return 0;
    // baseLatency is always present, outputLatency is optional
    return (ctx.baseLatency || 0) + (ctx.outputLatency || 0);
  }, []);

  const getAudioContextTime = useCallback((): number => {
    return audioContextRef.current ? audioContextRef.current.currentTime : 0;
  }, []);

  // Helper: Get a real-time stereo window for a stem
  const getStereoWindow = useCallback((stemId: string, windowSize: number = 1024) => {
    const buffer = audioBuffersRef.current[stemId];
    if (!buffer) {
      debugLog.warn('[getStereoWindow] No buffer for stemId', stemId, 'Available buffers:', Object.keys(audioBuffersRef.current));
      return null;
    }
    const numChannels = buffer.numberOfChannels;
    const currentSample = Math.floor((audioContextRef.current?.currentTime || 0 - startTimeRef.current) * buffer.sampleRate);
    const start = Math.max(0, currentSample - windowSize);
    const end = Math.min(buffer.length, currentSample);
    let left: number[] = [];
    let right: number[] = [];
    try {
      if (numChannels === 1) {
        const channel = buffer.getChannelData(0).slice(start, end);
        left = Array.from(channel);
        right = Array.from(channel);
      } else {
        left = Array.from(buffer.getChannelData(0).slice(start, end));
        right = Array.from(buffer.getChannelData(1).slice(start, end));
      }
    } catch (err) {
      debugLog.error('[getStereoWindow] Error accessing buffer:', err, { stemId, buffer });
      return null;
    }
    // Pad if needed
    if (left.length < windowSize) {
      left = Array(windowSize - left.length).fill(0).concat(left);
      right = Array(windowSize - right.length).fill(0).concat(right);
    }
    return { left, right };
  }, []);

  return {
    play,
    pause,
    stop,
    isPlaying,
    featuresByStem,
    currentTime,
    setCurrentTime,
    loadStems,
    clearStems,
    setStemVolume,
    getStemVolume,
    testAudioOutput,
    visualizationData,
    stemsLoaded,
    isLooping,
    setLooping: setIsLooping,
    soloedStems,
    toggleStemSolo,
    getAudioLatency, // <-- add this
    getAudioContextTime, // <-- add this
    scheduledStartTimeRef, // <-- expose for mapping loop
    duration: getMasterDuration(), // <-- expose duration
    getStereoWindow, // <-- expose real-time stereo window
  };
}

// Helper function to create mock audio buffer for fallback
function createMockAudioBuffer(durationSeconds: number = 10): ArrayBuffer {
  const sampleRate = 44100;
  const samples = durationSeconds * sampleRate;
  const buffer = new ArrayBuffer(samples * 4); // 32-bit float
  const view = new Float32Array(buffer);
  
  // Generate realistic audio data
  for (let i = 0; i < samples; i++) {
    view[i] = Math.sin(2 * Math.PI * 440 * i / sampleRate) * 0.5; // 440Hz tone
  }
  
  return buffer;
}
</file>

<file path="hooks/use-toast.ts">
"use client"

// Inspired by react-hot-toast library
import * as React from "react"

import type {
  ToastActionElement,
  ToastProps,
} from "@/components/ui/toast"

const TOAST_LIMIT = 1
const TOAST_REMOVE_DELAY = 1000000

type ToasterToast = ToastProps & {
  id: string
  title?: React.ReactNode
  description?: React.ReactNode
  action?: ToastActionElement
}

const actionTypes = {
  ADD_TOAST: "ADD_TOAST",
  UPDATE_TOAST: "UPDATE_TOAST",
  DISMISS_TOAST: "DISMISS_TOAST",
  REMOVE_TOAST: "REMOVE_TOAST",
} as const

let count = 0

function genId() {
  count = (count + 1) % Number.MAX_SAFE_INTEGER
  return count.toString()
}

type ActionType = typeof actionTypes

type Action =
  | {
      type: ActionType["ADD_TOAST"]
      toast: ToasterToast
    }
  | {
      type: ActionType["UPDATE_TOAST"]
      toast: Partial<ToasterToast>
    }
  | {
      type: ActionType["DISMISS_TOAST"]
      toastId?: ToasterToast["id"]
    }
  | {
      type: ActionType["REMOVE_TOAST"]
      toastId?: ToasterToast["id"]
    }

interface State {
  toasts: ToasterToast[]
}

const toastTimeouts = new Map<string, ReturnType<typeof setTimeout>>()

const addToRemoveQueue = (toastId: string) => {
  if (toastTimeouts.has(toastId)) {
    return
  }

  const timeout = setTimeout(() => {
    toastTimeouts.delete(toastId)
    dispatch({
      type: "REMOVE_TOAST",
      toastId: toastId,
    })
  }, TOAST_REMOVE_DELAY)

  toastTimeouts.set(toastId, timeout)
}

export const reducer = (state: State, action: Action): State => {
  switch (action.type) {
    case "ADD_TOAST":
      return {
        ...state,
        toasts: [action.toast, ...state.toasts].slice(0, TOAST_LIMIT),
      }

    case "UPDATE_TOAST":
      return {
        ...state,
        toasts: state.toasts.map((t) =>
          t.id === action.toast.id ? { ...t, ...action.toast } : t
        ),
      }

    case "DISMISS_TOAST": {
      const { toastId } = action

      // ! Side effects ! - This could be extracted into a dismissToast() action,
      // but I'll keep it here for simplicity
      if (toastId) {
        addToRemoveQueue(toastId)
      } else {
        state.toasts.forEach((toast) => {
          addToRemoveQueue(toast.id)
        })
      }

      return {
        ...state,
        toasts: state.toasts.map((t) =>
          t.id === toastId || toastId === undefined
            ? {
                ...t,
                open: false,
              }
            : t
        ),
      }
    }
    case "REMOVE_TOAST":
      if (action.toastId === undefined) {
        return {
          ...state,
          toasts: [],
        }
      }
      return {
        ...state,
        toasts: state.toasts.filter((t) => t.id !== action.toastId),
      }
  }
}

const listeners: Array<(state: State) => void> = []

let memoryState: State = { toasts: [] }

function dispatch(action: Action) {
  memoryState = reducer(memoryState, action)
  listeners.forEach((listener) => {
    listener(memoryState)
  })
}

type Toast = Omit<ToasterToast, "id">

function toast({ ...props }: Toast) {
  const id = genId()

  const update = (props: ToasterToast) =>
    dispatch({
      type: "UPDATE_TOAST",
      toast: { ...props, id },
    })
  const dismiss = () => dispatch({ type: "DISMISS_TOAST", toastId: id })

  dispatch({
    type: "ADD_TOAST",
    toast: {
      ...props,
      id,
      open: true,
      onOpenChange: (open) => {
        if (!open) dismiss()
      },
    },
  })

  return {
    id: id,
    dismiss,
    update,
  }
}

function useToast() {
  const [state, setState] = React.useState<State>(memoryState)

  React.useEffect(() => {
    listeners.push(setState)
    return () => {
      const index = listeners.indexOf(setState)
      if (index > -1) {
        listeners.splice(index, 1)
      }
    }
  }, [state])

  return {
    ...state,
    toast,
    dismiss: (toastId?: string) => dispatch({ type: "DISMISS_TOAST", toastId }),
  }
}

export { useToast, toast }
</file>

<file path="hooks/use-upload.ts">
import { useState, useCallback } from 'react'
import { useToast } from './use-toast'
import { trpc } from '@/lib/trpc'
import { debugLog } from '@/lib/utils';

export interface UploadFile {
  file: File
  id: string
  status: 'pending' | 'uploading' | 'completed' | 'failed'
  progress: number
  error?: string
  fileId?: string
  compressedSize?: number
}

export interface UseUploadOptions {
  onUploadComplete?: (file: UploadFile) => void
  onUploadError?: (file: UploadFile, error: string) => void
  onAllUploadsComplete?: () => void
  maxConcurrentUploads?: number
  projectId?: string // NEW: Associate uploads with project
}

export function useUpload(options: UseUploadOptions = {}) {
  const { onUploadComplete, onUploadError, onAllUploadsComplete, maxConcurrentUploads = 3, projectId } = options
  const [files, setFiles] = useState<UploadFile[]>([])
  const [isUploading, setIsUploading] = useState(false)
  const { toast } = useToast()

  /**
   * tRPC mutations  we create them once at hook initialisation so that they can
   * be reused inside callbacks without violating the Rules of Hooks.
   */
  const getUploadUrlMutation = trpc.file.getUploadUrl.useMutation()
  const confirmUploadMutation = trpc.file.confirmUpload.useMutation()
  const uploadFileMutation = trpc.file.uploadFile.useMutation()

  // Generate unique ID for each file
  const generateFileId = useCallback(() => {
    return `upload_${Date.now()}_${Math.random().toString(36).substring(2)}`
  }, [])

  // Validate files - EXTENDED for video and image
  const validateFiles = useCallback((newFiles: File[]) => {
    const validFiles: File[] = []
    const errors: string[] = []

    newFiles.forEach(file => {
      // Check file extension
      const extension = file.name.toLowerCase().split('.').pop()
      const allowedExtensions = ['mid', 'midi', 'mp3', 'wav', 'mp4', 'mov', 'webm', 'jpg', 'jpeg', 'png', 'gif', 'webp'] // EXTENDED
      
      if (!extension || !allowedExtensions.includes(extension)) {
        errors.push(`${file.name}: Invalid file type. Allowed types: ${allowedExtensions.join(', ')}`)
        return
      }

      // Check file size based on type
      let maxSize: number
      const isMidi = ['mid', 'midi'].includes(extension)
      const isAudio = ['mp3', 'wav'].includes(extension)
      const isVideo = ['mp4', 'mov', 'webm'].includes(extension)
      const isImage = ['jpg', 'jpeg', 'png', 'gif', 'webp'].includes(extension)
      
      if (isMidi) {
        maxSize = 5 * 1024 * 1024 // 5MB for MIDI
      } else if (isAudio) {
        maxSize = 50 * 1024 * 1024 // 50MB for audio
      } else if (isVideo) {
        maxSize = 500 * 1024 * 1024 // 500MB for video
      } else if (isImage) {
        maxSize = 25 * 1024 * 1024 // 25MB for images
      } else {
        errors.push(`${file.name}: Unsupported file type`)
        return
      }
      
      if (file.size > maxSize) {
        const maxSizeMB = maxSize / (1024 * 1024)
        errors.push(`${file.name}: File too large. Maximum size: ${maxSizeMB}MB`)
        return
      }

      validFiles.push(file)
    })

    if (errors.length > 0) {
      toast({
        title: 'Invalid Files',
        description: errors.join('\n'),
        variant: 'destructive',
      })
    }

    return validFiles
  }, [toast])

  // Add files to upload queue
  const addFiles = useCallback((newFiles: File[]) => {
    const validFiles = validateFiles(newFiles)
    const uploadFiles: UploadFile[] = validFiles.map(file => ({
      file,
      id: generateFileId(),
      status: 'pending',
      progress: 0,
    }))

    setFiles(prev => [...prev, ...uploadFiles])
    return uploadFiles
  }, [generateFileId, validateFiles])

  // Remove file from queue
  const removeFile = useCallback((fileId: string) => {
    setFiles(prev => prev.filter(f => f.id !== fileId))
  }, [])

  // Clear all files
  const clearFiles = useCallback(() => {
    setFiles([])
  }, [])

  // Update file status
  const updateFileStatus = useCallback((
    fileId: string, 
    updates: Partial<Pick<UploadFile, 'status' | 'progress' | 'error' | 'fileId' | 'compressedSize'>>
  ) => {
    setFiles(prev => prev.map(f => 
      f.id === fileId ? { ...f, ...updates } : f
    ))
  }, [])

  // Add compression utility
  const compressFile = async (file: File): Promise<File> => {
    // For now, just return the original file
    // In production, this would implement actual compression
    // using libraries like browser-image-compression for images/videos
    // or custom logic for MIDI files
    return file
  }

  // Add resumable upload simulation
  const createResumableUpload = (file: File) => {
    const chunkSize = 1024 * 1024 // 1MB chunks
    const totalChunks = Math.ceil(file.size / chunkSize)
    
    return {
      totalChunks,
      chunkSize,
      uploadChunk: (chunkIndex: number) => {
        const start = chunkIndex * chunkSize
        const end = Math.min(start + chunkSize, file.size)
        return file.slice(start, end)
      }
    }
  }

  /**
   * Core upload routine  uploads file directly through backend to avoid CORS issues
   * EXTENDED for video and image support
   */
  const uploadFileToS3 = useCallback(async (uploadFile: UploadFile) => {
    try {
      updateFileStatus(uploadFile.id, { status: 'uploading', progress: 10 })

      /* ------------------------------------------------------------------ */
      /* 1. Convert file to base64 and upload through backend               */
      /* ------------------------------------------------------------------ */
      const fileReader = new FileReader()
      
      await new Promise<void>((resolve, reject) => {
        fileReader.onload = async () => {
          try {
            const base64Data = (fileReader.result as string).split(',')[1] // Remove data URL prefix
            
            updateFileStatus(uploadFile.id, { progress: 30 })
            
            // Determine file type - EXTENDED
            const extension = uploadFile.file.name.toLowerCase().split('.').pop()
            let fileType: 'midi' | 'audio' | 'video' | 'image'
            
            if (['mid', 'midi'].includes(extension || '')) {
              fileType = 'midi'
            } else if (['mp3', 'wav'].includes(extension || '')) {
              fileType = 'audio'
            } else if (['mp4', 'mov', 'webm'].includes(extension || '')) {
              fileType = 'video'
            } else if (['jpg', 'jpeg', 'png', 'gif', 'webp'].includes(extension || '')) {
              fileType = 'image'
            } else {
              throw new Error('Unsupported file type')
            }
            
            const result = await uploadFileMutation.mutateAsync({
              fileName: uploadFile.file.name,
              fileType,
              mimeType: uploadFile.file.type || 'application/octet-stream',
              fileSize: uploadFile.file.size,
              fileData: base64Data,
              projectId: projectId, // NEW: Associate with project
            })
            
            updateFileStatus(uploadFile.id, { 
              status: 'completed', 
              progress: 100,
              fileId: result.fileId 
            })
            
            // After successful upload and updateFileStatus, call onUploadComplete with fileId
            onUploadComplete?.({ ...uploadFile, fileId: result.fileId, status: 'completed', progress: 100 });
            
            resolve()
          } catch (error) {
            reject(error)
          }
        }
        
        fileReader.onerror = () => {
          reject(new Error('Failed to read file'))
        }
        
        fileReader.readAsDataURL(uploadFile.file)
      })

      /* ------------------------------------------------------------------ */
      /* 2. Mark local state as completed                                   */
      /* ------------------------------------------------------------------ */
      updateFileStatus(uploadFile.id, { status: 'completed', progress: 100 })

      /* ------------------------------------------------------------------ */
      /* 3. Notify caller of completion                                     */
      /* ------------------------------------------------------------------ */
      onAllUploadsComplete?.()

    } catch (error) {
      debugLog.error('Upload error:', error)
      
      const errorMessage = error instanceof Error ? error.message : 'Upload failed'
      updateFileStatus(uploadFile.id, { 
        status: 'failed', 
        error: errorMessage 
      })
      
      onUploadError?.(uploadFile, errorMessage)
    }
  }, [updateFileStatus, uploadFileMutation, onUploadComplete, onUploadError, onAllUploadsComplete])

  // Add files and immediately start uploading them (bypasses state timing issues)
  const addAndUploadFiles = useCallback(async (newFiles: File[]) => {
    // Validate files first
    const validFiles = validateFiles(newFiles)
    if (validFiles.length === 0) return []

    // Create upload file objects
    const uploadFiles: UploadFile[] = validFiles.map(file => ({
      file,
      id: generateFileId(),
      status: 'pending',
      progress: 0,
    }))

    // Add to state for UI display
    setFiles(prev => [...prev, ...uploadFiles])
    
    // Start uploading immediately without waiting for state update
    if (uploadFiles.length > 0) {
      setIsUploading(true)
      
      try {
        // Process uploads in batches
        const batches = []
        for (let i = 0; i < uploadFiles.length; i += maxConcurrentUploads) {
          batches.push(uploadFiles.slice(i, i + maxConcurrentUploads))
        }

        for (const batch of batches) {
          await Promise.allSettled(
            batch.map(file => uploadFileToS3(file))
          )
        }

        onAllUploadsComplete?.()
        
        const successCount = uploadFiles.filter(f => f.status === 'completed').length
        if (successCount > 0) {
          toast({
            title: 'Upload Complete',
            description: `Successfully uploaded ${successCount} file${successCount > 1 ? 's' : ''}`,
          })
        }

      } catch (error) {
        debugLog.error('Upload error:', error)
        toast({
          title: 'Upload Error',
          description: 'Upload failed',
          variant: 'destructive',
        })
      } finally {
        setIsUploading(false)
      }
    }
    
    return uploadFiles
  }, [validateFiles, generateFileId, maxConcurrentUploads, uploadFileToS3, onAllUploadsComplete, toast])

  // Start uploading all pending files
  const startUpload = useCallback(async () => {
    const pendingFiles = files.filter(f => f.status === 'pending')
    if (pendingFiles.length === 0) return

    setIsUploading(true)

    try {
      // Process uploads in batches
      const batches = []
      for (let i = 0; i < pendingFiles.length; i += maxConcurrentUploads) {
        batches.push(pendingFiles.slice(i, i + maxConcurrentUploads))
      }

      for (const batch of batches) {
        await Promise.allSettled(
          batch.map(file => uploadFileToS3(file))
        )
      }

      onAllUploadsComplete?.()
      
      const successCount = files.filter(f => f.status === 'completed').length
      if (successCount > 0) {
        toast({
          title: 'Upload Complete',
          description: `Successfully uploaded ${successCount} file${successCount > 1 ? 's' : ''}`,
        })
      }

    } catch (error) {
      debugLog.error('Upload error:', error)
      toast({
        title: 'Upload Error',
        description: 'Upload failed',
        variant: 'destructive',
      })
    } finally {
      setIsUploading(false)
    }
  }, [files, maxConcurrentUploads, uploadFileToS3, onAllUploadsComplete, toast])

  // Retry failed upload
  const retryUpload = useCallback(async (fileId: string) => {
    const file = files.find(f => f.id === fileId)
    if (!file || file.status !== 'failed') return

    updateFileStatus(fileId, { status: 'pending', progress: 0, error: undefined })
    await uploadFileToS3(file)
  }, [files, updateFileStatus, uploadFileToS3])

  return {
    // State
    files,
    isUploading,
    
    // Actions
    addFiles,
    addAndUploadFiles,
    removeFile,
    clearFiles,
    startUpload,
    retryUpload,
    
    // Computed values
    pendingCount: files.filter(f => f.status === 'pending').length,
    uploadingCount: files.filter(f => f.status === 'uploading').length,
    completedCount: files.filter(f => f.status === 'completed').length,
    failedCount: files.filter(f => f.status === 'failed').length,
    totalProgress: files.length > 0 
      ? Math.round(files.reduce((sum, f) => sum + f.progress, 0) / files.length)
      : 0,
  }
}
</file>

<file path="lib/video-composition/parameter-calculator.ts">
import type { AudioBinding, MIDIBinding } from '@/types/video-composition';
import type { AudioAnalysisData, LiveMIDIData } from '@/types/visualizer';

export function mapRange(
  value: number,
  inputMin: number,
  inputMax: number,
  outputMin: number,
  outputMax: number
): number {
  return ((value - inputMin) / (inputMax - inputMin)) * (outputMax - outputMin) + outputMin;
}

export function applyBlendMode(
  baseValue: number,
  newValue: number,
  blendMode: 'add' | 'multiply' | 'replace'
): number {
  switch (blendMode) {
    case 'add':
      return baseValue + newValue;
    case 'multiply':
      return baseValue * newValue;
    case 'replace':
      return newValue;
    default:
      return newValue;
  }
}

export function getMIDIValue(midiData: LiveMIDIData, source: string): number | undefined {
  switch (source) {
    case 'velocity':
      return midiData.activeNotes.length > 0 
        ? midiData.activeNotes.reduce((sum, note) => sum + note.velocity, 0) / midiData.activeNotes.length
        : 0;
    case 'cc':
      // For now, return a mock CC value - would come from actual MIDI CC data
      return Math.sin(Date.now() * 0.001) * 0.5 + 0.5;
    case 'pitchBend':
      // Mock pitch bend value
      return Math.sin(Date.now() * 0.002) * 0.5 + 0.5;
    case 'channelPressure':
      // Mock channel pressure value
      return Math.sin(Date.now() * 0.003) * 0.5 + 0.5;
    default:
      return undefined;
  }
}

export function calculateOpacity(
  baseOpacity: number,
  audioBindings: AudioBinding[],
  audioFeatures: AudioAnalysisData,
  midiBindings: MIDIBinding[],
  midiData: LiveMIDIData
): number {
  let opacity = baseOpacity;
  
  // Apply audio bindings
  audioBindings.forEach(binding => {
    let featureValue: number | undefined;
    
    // Handle different feature types
    switch (binding.feature) {
      case 'volume':
      case 'bass':
      case 'mid':
      case 'treble':
        featureValue = audioFeatures[binding.feature];
        break;
      case 'frequencies':
        // Use average frequency value
        featureValue = audioFeatures.frequencies.length > 0 
          ? audioFeatures.frequencies.reduce((sum, val) => sum + val, 0) / audioFeatures.frequencies.length
          : 0;
        break;
      case 'timeData':
        // Use average time data value
        featureValue = audioFeatures.timeData.length > 0
          ? audioFeatures.timeData.reduce((sum, val) => sum + val, 0) / audioFeatures.timeData.length
          : 0;
        break;
    }
    
    if (featureValue !== undefined) {
      const mappedValue = mapRange(
        featureValue,
        binding.inputRange[0],
        binding.inputRange[1],
        binding.outputRange[0],
        binding.outputRange[1]
      );
      // Apply modulation amount (default to 1.0 if not specified)
      const modulationAmount = binding.modulationAmount ?? 1.0;
      const modulatedValue = mappedValue * modulationAmount;
      opacity = applyBlendMode(opacity, modulatedValue, binding.blendMode);
    }
  });
  
  // Apply MIDI bindings
  midiBindings.forEach(binding => {
    const midiValue = getMIDIValue(midiData, binding.source);
    if (midiValue !== undefined) {
      const mappedValue = mapRange(
        midiValue,
        binding.inputRange[0],
        binding.inputRange[1],
        binding.outputRange[0],
        binding.outputRange[1]
      );
      opacity = applyBlendMode(opacity, mappedValue, binding.blendMode);
    }
  });
  
  return Math.max(0, Math.min(1, opacity));
}

export function calculateScale(
  baseScale: { x: number; y: number },
  audioBindings: AudioBinding[],
  audioFeatures: AudioAnalysisData,
  midiBindings: MIDIBinding[],
  midiData: LiveMIDIData
): { x: number; y: number } {
  let scaleX = baseScale.x;
  let scaleY = baseScale.y;
  
  // Apply audio bindings
  audioBindings.forEach(binding => {
    let featureValue: number | undefined;
    
    // Handle different feature types
    switch (binding.feature) {
      case 'volume':
      case 'bass':
      case 'mid':
      case 'treble':
        featureValue = audioFeatures[binding.feature];
        break;
      case 'frequencies':
        // Use average frequency value
        featureValue = audioFeatures.frequencies.length > 0 
          ? audioFeatures.frequencies.reduce((sum, val) => sum + val, 0) / audioFeatures.frequencies.length
          : 0;
        break;
      case 'timeData':
        // Use average time data value
        featureValue = audioFeatures.timeData.length > 0
          ? audioFeatures.timeData.reduce((sum, val) => sum + val, 0) / audioFeatures.timeData.length
          : 0;
        break;
    }
    
    if (featureValue !== undefined) {
      const mappedValue = mapRange(
        featureValue,
        binding.inputRange[0],
        binding.inputRange[1],
        binding.outputRange[0],
        binding.outputRange[1]
      );
      // Apply modulation amount (default to 1.0 if not specified)
      const modulationAmount = binding.modulationAmount ?? 1.0;
      const modulatedValue = mappedValue * modulationAmount;
      scaleX = applyBlendMode(scaleX, modulatedValue, binding.blendMode);
      scaleY = applyBlendMode(scaleY, modulatedValue, binding.blendMode);
    }
  });
  
  // Apply MIDI bindings
  midiBindings.forEach(binding => {
    const midiValue = getMIDIValue(midiData, binding.source);
    if (midiValue !== undefined) {
      const mappedValue = mapRange(
        midiValue,
        binding.inputRange[0],
        binding.inputRange[1],
        binding.outputRange[0],
        binding.outputRange[1]
      );
      scaleX = applyBlendMode(scaleX, mappedValue, binding.blendMode);
      scaleY = applyBlendMode(scaleY, mappedValue, binding.blendMode);
    }
  });
  
  return {
    x: Math.max(0.1, Math.min(5, scaleX)),
    y: Math.max(0.1, Math.min(5, scaleY))
  };
}

export function calculateRotation(
  baseRotation: number,
  audioBindings: AudioBinding[],
  audioFeatures: AudioAnalysisData,
  midiBindings: MIDIBinding[],
  midiData: LiveMIDIData
): number {
  let rotation = baseRotation;
  
  // Apply audio bindings
  audioBindings.forEach(binding => {
    let featureValue: number | undefined;
    
    // Handle different feature types
    switch (binding.feature) {
      case 'volume':
      case 'bass':
      case 'mid':
      case 'treble':
        featureValue = audioFeatures[binding.feature];
        break;
      case 'frequencies':
        // Use average frequency value
        featureValue = audioFeatures.frequencies.length > 0 
          ? audioFeatures.frequencies.reduce((sum, val) => sum + val, 0) / audioFeatures.frequencies.length
          : 0;
        break;
      case 'timeData':
        // Use average time data value
        featureValue = audioFeatures.timeData.length > 0
          ? audioFeatures.timeData.reduce((sum, val) => sum + val, 0) / audioFeatures.timeData.length
          : 0;
        break;
    }
    
    if (featureValue !== undefined) {
      const mappedValue = mapRange(
        featureValue,
        binding.inputRange[0],
        binding.inputRange[1],
        binding.outputRange[0],
        binding.outputRange[1]
      );
      // Apply modulation amount (default to 1.0 if not specified)
      const modulationAmount = binding.modulationAmount ?? 1.0;
      const modulatedValue = mappedValue * modulationAmount;
      rotation = applyBlendMode(rotation, modulatedValue, binding.blendMode);
    }
  });
  
  // Apply MIDI bindings
  midiBindings.forEach(binding => {
    const midiValue = getMIDIValue(midiData, binding.source);
    if (midiValue !== undefined) {
      const mappedValue = mapRange(
        midiValue,
        binding.inputRange[0],
        binding.inputRange[1],
        binding.outputRange[0],
        binding.outputRange[1]
      );
      rotation = applyBlendMode(rotation, mappedValue, binding.blendMode);
    }
  });
  
  return rotation % 360;
}

export function calculatePosition(
  basePosition: { x: number; y: number },
  audioBindings: AudioBinding[],
  audioFeatures: AudioAnalysisData,
  midiBindings: MIDIBinding[],
  midiData: LiveMIDIData
): { x: number; y: number } {
  let x = basePosition.x;
  let y = basePosition.y;
  
  // Apply audio bindings
  audioBindings.forEach(binding => {
    let featureValue: number | undefined;
    
    // Handle different feature types
    switch (binding.feature) {
      case 'volume':
      case 'bass':
      case 'mid':
      case 'treble':
        featureValue = audioFeatures[binding.feature];
        break;
      case 'frequencies':
        // Use average frequency value
        featureValue = audioFeatures.frequencies.length > 0 
          ? audioFeatures.frequencies.reduce((sum, val) => sum + val, 0) / audioFeatures.frequencies.length
          : 0;
        break;
      case 'timeData':
        // Use average time data value
        featureValue = audioFeatures.timeData.length > 0
          ? audioFeatures.timeData.reduce((sum, val) => sum + val, 0) / audioFeatures.timeData.length
          : 0;
        break;
    }
    
    if (featureValue !== undefined) {
      const mappedValue = mapRange(
        featureValue,
        binding.inputRange[0],
        binding.inputRange[1],
        binding.outputRange[0],
        binding.outputRange[1]
      );
      // Apply modulation amount (default to 1.0 if not specified)
      const modulationAmount = binding.modulationAmount ?? 1.0;
      const modulatedValue = mappedValue * modulationAmount;
      x = applyBlendMode(x, modulatedValue, binding.blendMode);
      y = applyBlendMode(y, modulatedValue, binding.blendMode);
    }
  });
  
  // Apply MIDI bindings
  midiBindings.forEach(binding => {
    const midiValue = getMIDIValue(midiData, binding.source);
    if (midiValue !== undefined) {
      const mappedValue = mapRange(
        midiValue,
        binding.inputRange[0],
        binding.inputRange[1],
        binding.outputRange[0],
        binding.outputRange[1]
      );
      x = applyBlendMode(x, mappedValue, binding.blendMode);
      y = applyBlendMode(y, mappedValue, binding.blendMode);
    }
  });
  
  return { x, y };
}
</file>

<file path="lib/visualizer/core/AudioTextureManager.ts">
import * as THREE from 'three';

export interface AudioFeatureData {
  features: Record<string, number[]>;
  duration: number;
  sampleRate: number;
  stemTypes: string[];
}

export interface AudioFeatureMapping {
  featureIndex: number;
  stemType: string;
  featureName: string;
  minValue: number;
  maxValue: number;
}

export class AudioTextureManager {
  private audioTexture: THREE.DataTexture;
  private featureTexture: THREE.DataTexture;
  private timeTexture: THREE.DataTexture;
  
  // Texture layout: X = time, Y = feature index, RGBA = feature values
  private audioData: Float32Array;
  private featureData: Float32Array;
  private timeData: Float32Array;
  
  // Configuration
  private readonly textureWidth = 256;  // Time samples
  private readonly textureHeight = 64;  // Feature rows (16 features per row)
  private readonly maxFeatures = 256;   // 64 rows  4 channels
  
  // Feature mapping
  private featureMappings: AudioFeatureMapping[] = [];
  private featureIndexMap: Map<string, number> = new Map();
  
  constructor() {
    // Initialize audio data array (256644 = 65,536 values)
    this.audioData = new Float32Array(this.textureWidth * this.textureHeight * 4);
    
    // Initialize feature metadata (644 = 256 values)
    this.featureData = new Float32Array(this.textureHeight * 4);
    
    // Initialize time synchronization (4 values: currentTime, duration, normalizedTime, padding)
    this.timeData = new Float32Array(4);
    
    // Create GPU textures
    this.audioTexture = new THREE.DataTexture(
      this.audioData,
      this.textureWidth,
      this.textureHeight,
      THREE.RGBAFormat,
      THREE.FloatType
    );
    this.audioTexture.needsUpdate = true;
    this.audioTexture.wrapS = THREE.ClampToEdgeWrapping;
    this.audioTexture.wrapT = THREE.ClampToEdgeWrapping;
    this.audioTexture.magFilter = THREE.LinearFilter;
    this.audioTexture.minFilter = THREE.LinearFilter;
    
    this.featureTexture = new THREE.DataTexture(
      this.featureData,
      4,
      this.textureHeight,
      THREE.RGBAFormat,
      THREE.FloatType
    );
    this.featureTexture.needsUpdate = true;
    this.featureTexture.wrapS = THREE.ClampToEdgeWrapping;
    this.featureTexture.wrapT = THREE.ClampToEdgeWrapping;
    this.featureTexture.magFilter = THREE.NearestFilter;
    this.featureTexture.minFilter = THREE.NearestFilter;
    
    this.timeTexture = new THREE.DataTexture(
      this.timeData,
      1,
      1,
      THREE.RGBAFormat,
      THREE.FloatType
    );
    this.timeTexture.needsUpdate = true;
    this.timeTexture.wrapS = THREE.ClampToEdgeWrapping;
    this.timeTexture.wrapT = THREE.ClampToEdgeWrapping;
    this.timeTexture.magFilter = THREE.NearestFilter;
    this.timeTexture.minFilter = THREE.NearestFilter;
  }
  
  /**
   * Load cached audio analysis into GPU textures
   */
  public loadAudioAnalysis(analysisData: AudioFeatureData): void {
    this.buildFeatureMapping(analysisData);
    this.packFeaturesIntoTexture(analysisData);
  }
  
  /**
   * Build feature mapping from analysis data
   */
  private buildFeatureMapping(analysisData: AudioFeatureData): void {
    this.featureMappings = [];
    this.featureIndexMap.clear();
    
    let featureIndex = 0;
    
    // Map features by stem type and feature name
    for (const stemType of analysisData.stemTypes) {
      const stemFeatures = analysisData.features[stemType];
      if (!stemFeatures) continue;
      
      // Common audio features
      const featureNames = ['rms', 'spectralCentroid', 'spectralRolloff', 'zcr'];
      
      for (const featureName of featureNames) {
        if (featureIndex >= this.maxFeatures) break;
        
        const mapping: AudioFeatureMapping = {
          featureIndex,
          stemType,
          featureName,
          minValue: 0,
          maxValue: 1
        };
        
        this.featureMappings.push(mapping);
        this.featureIndexMap.set(`${stemType}-${featureName}`, featureIndex);
        featureIndex++;
      }
    }
    
    // Pack feature metadata into texture
    this.packFeatureMetadata();
  }
  
  /**
   * Pack feature metadata into feature texture
   */
  private packFeatureMetadata(): void {
    for (let i = 0; i < this.featureMappings.length; i++) {
      const mapping = this.featureMappings[i];
      const row = Math.floor(i / 4);
      const col = i % 4;
      const index = row * 4 + col;
      
      // Store feature index, stem type hash, feature name hash, and value range
      this.featureData[index * 4 + 0] = mapping.featureIndex;
      this.featureData[index * 4 + 1] = this.hashString(mapping.stemType);
      this.featureData[index * 4 + 2] = this.hashString(mapping.featureName);
      this.featureData[index * 4 + 3] = mapping.maxValue - mapping.minValue;
    }
    
    this.featureTexture.needsUpdate = true;
  }
  
  /**
   * Pack audio features into main texture
   */
  private packFeaturesIntoTexture(analysisData: AudioFeatureData): void {
    // Clear texture data
    this.audioData.fill(0);
    
    // Pack features by time and feature index
    for (const mapping of this.featureMappings) {
      const stemFeatures = analysisData.features[mapping.stemType];
      if (!stemFeatures) continue;
      
      const featureData = this.extractFeatureData(stemFeatures, mapping.featureName);
      if (!featureData) continue;
      
      // Pack into texture: X = time, Y = feature row, RGBA = feature values
      const row = Math.floor(mapping.featureIndex / 4);
      const channel = mapping.featureIndex % 4;
      
      for (let timeIndex = 0; timeIndex < Math.min(this.textureWidth, featureData.length); timeIndex++) {
        const textureIndex = (timeIndex + row * this.textureWidth) * 4 + channel;
        const normalizedValue = this.normalizeValue(featureData[timeIndex], mapping.minValue, mapping.maxValue);
        this.audioData[textureIndex] = normalizedValue;
      }
    }
    
    this.audioTexture.needsUpdate = true;
  }
  
  /**
   * Extract specific feature data from stem features
   */
  private extractFeatureData(stemFeatures: number[], featureName: string): number[] | null {
    // This is a simplified extraction - in practice, you'd parse the actual feature data structure
    // For now, we'll use the stem features directly as if they're the requested feature
    return stemFeatures;
  }
  
  /**
   * Update time synchronization (called once per frame)
   */
  public updateTime(currentTime: number, duration: number): void {
    this.timeData[0] = currentTime;
    this.timeData[1] = duration;
    this.timeData[2] = currentTime / duration; // Normalized progress
    this.timeData[3] = 0; // Padding
    
    this.timeTexture.needsUpdate = true;
  }
  
  /**
   * Get shader uniforms for audio texture access
   */
  public getShaderUniforms(): Record<string, THREE.Uniform> {
    return {
      uAudioTexture: new THREE.Uniform(this.audioTexture),
      uFeatureTexture: new THREE.Uniform(this.featureTexture),
      uTimeTexture: new THREE.Uniform(this.timeTexture),
      uAudioTextureSize: new THREE.Uniform(new THREE.Vector2(this.textureWidth, this.textureHeight)),
      uFeatureTextureSize: new THREE.Uniform(new THREE.Vector2(4, this.textureHeight))
    };
  }
  
  /**
   * Generate shader code for audio feature access
   */
  public generateShaderCode(): string {
    return `
      uniform sampler2D uAudioTexture;
      uniform sampler2D uFeatureTexture;
      uniform sampler2D uTimeTexture;
      uniform vec2 uAudioTextureSize;
      uniform vec2 uFeatureTextureSize;
      
      float sampleAudioFeature(float featureIndex) {
        vec4 timeData = texture2D(uTimeTexture, vec2(0.5));
        float normalizedTime = timeData.z;
        
        float rowIndex = floor(featureIndex / 4.0);
        vec2 uv = vec2(normalizedTime, rowIndex / uAudioTextureSize.y);
        vec4 featureData = texture2D(uAudioTexture, uv);
        
        // Extract correct channel based on feature index
        float channelIndex = mod(featureIndex, 4.0);
        if (channelIndex < 0.5) return featureData.r;
        else if (channelIndex < 1.5) return featureData.g;
        else if (channelIndex < 2.5) return featureData.b;
        else return featureData.a;
      }
      
      float sampleAudioFeatureByName(float stemTypeHash, float featureNameHash) {
        // Find feature index by name (simplified - in practice you'd use a lookup table)
        for (float i = 0.0; i < uFeatureTextureSize.y; i++) {
          vec2 featureUv = vec2(0.5, (i + 0.5) / uFeatureTextureSize.y);
          vec4 featureInfo = texture2D(uFeatureTexture, featureUv);
          
          if (featureInfo.y == stemTypeHash && featureInfo.z == featureNameHash) {
            return sampleAudioFeature(featureInfo.x);
          }
        }
        return 0.0;
      }
    `;
  }
  
  /**
   * Get feature value by name (for debugging/testing)
   */
  public getFeatureValue(stemType: string, featureName: string): number {
    const key = `${stemType}-${featureName}`;
    const featureIndex = this.featureIndexMap.get(key);
    if (featureIndex === undefined) return 0;
    
    const row = Math.floor(featureIndex / 4);
    const channel = featureIndex % 4;
    const timeIndex = Math.floor(this.timeData[2] * this.textureWidth);
    const textureIndex = (timeIndex + row * this.textureWidth) * 4 + channel;
    
    return this.audioData[textureIndex] || 0;
  }
  
  /**
   * Simple string hash function
   */
  private hashString(str: string): number {
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
      const char = str.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash; // Convert to 32-bit integer
    }
    return Math.abs(hash) / 2147483647; // Normalize to 0-1
  }
  
  /**
   * Normalize value to 0-1 range
   */
  private normalizeValue(value: number, min: number, max: number): number {
    return Math.max(0, Math.min(1, (value - min) / (max - min)));
  }
  
  /**
   * Dispose of textures
   */
  public dispose(): void {
    this.audioTexture.dispose();
    this.featureTexture.dispose();
    this.timeTexture.dispose();
  }
}
</file>

<file path="lib/visualizer/core/MediaLayerManager.ts">
import * as THREE from 'three';

export interface MediaLayerConfig {
  id: string;
  type: 'canvas' | 'video' | 'image';
  source: HTMLCanvasElement | HTMLVideoElement | HTMLImageElement | string;
  blendMode: 'normal' | 'multiply' | 'screen' | 'overlay' | 'add' | 'subtract';
  opacity: number;
  zIndex: number;
  
  // Audio-reactive bindings
  audioBindings?: {
    feature: string;                    // 'drums-rms', 'bass-spectralCentroid'
    property: 'opacity' | 'scale' | 'rotation' | 'position';
    inputRange: [number, number];       // Audio feature range
    outputRange: [number, number];      // Visual property range
    blendMode: 'multiply' | 'add' | 'replace';
  }[];
  
  // Transform properties
  position: { x: number; y: number };
  scale: { x: number; y: number };
  rotation: number;
}

export interface AudioFeatures {
  [key: string]: number;
}

export class MediaLayerManager {
  private mediaLayers: Map<string, MediaLayerConfig> = new Map();
  private layerMaterials: Map<string, THREE.ShaderMaterial> = new Map();
  private layerTextures: Map<string, THREE.Texture> = new Map();
  private layerMeshes: Map<string, THREE.Mesh> = new Map();
  
  private scene: THREE.Scene;
  private camera: THREE.OrthographicCamera;
  private renderer: THREE.WebGLRenderer;
  
  constructor(scene: THREE.Scene, camera: THREE.Camera, renderer: THREE.WebGLRenderer) {
    this.scene = scene;
    this.camera = camera as THREE.OrthographicCamera;
    this.renderer = renderer;
  }
  
  /**
   * Add a media layer
   */
  public addMediaLayer(config: MediaLayerConfig): void {
    this.mediaLayers.set(config.id, config);
    
    // Create texture from media source
    const texture = this.createTextureFromSource(config.source, config.type);
    this.layerTextures.set(config.id, texture);
    
    // Create material with audio-reactive uniforms
    const material = this.createMaterial(config, texture);
    this.layerMaterials.set(config.id, material);
    
    // Create mesh
    const mesh = this.createMesh(config, material);
    this.layerMeshes.set(config.id, mesh);
    
    // Add to scene
    this.scene.add(mesh);
  }
  
  /**
   * Remove a media layer
   */
  public removeMediaLayer(id: string): void {
    const mesh = this.layerMeshes.get(id);
    if (mesh) {
      this.scene.remove(mesh);
      mesh.geometry.dispose();
      this.layerMeshes.delete(id);
    }
    
    const material = this.layerMaterials.get(id);
    if (material) {
      material.dispose();
      this.layerMaterials.delete(id);
    }
    
    const texture = this.layerTextures.get(id);
    if (texture) {
      texture.dispose();
      this.layerTextures.delete(id);
    }
    
    this.mediaLayers.delete(id);
  }
  
  /**
   * Update media layer with audio features
   * @deprecated Legacy method - effects now receive modulated parameters through the mapping system
   */
  public updateWithAudioFeatures(audioFeatures: AudioFeatures): void {
    for (const [id, config] of this.mediaLayers) {
      if (!config.audioBindings) continue;
      
      const material = this.layerMaterials.get(id);
      if (!material) continue;
      
      for (const binding of config.audioBindings) {
        const featureValue = audioFeatures[binding.feature];
        if (featureValue === undefined) continue;
        
        const mappedValue = this.mapRange(
          featureValue,
          binding.inputRange[0], binding.inputRange[1],
          binding.outputRange[0], binding.outputRange[1]
        );
        
        // Apply to shader uniforms
        switch (binding.property) {
          case 'opacity':
            material.uniforms.uOpacity.value = mappedValue;
            break;
          case 'scale':
            material.uniforms.uScale.value.set(mappedValue, mappedValue);
            break;
          case 'rotation':
            material.uniforms.uRotation.value = mappedValue;
            break;
          case 'position':
            material.uniforms.uPosition.value.set(
              config.position.x + mappedValue,
              config.position.y + mappedValue
            );
            break;
        }
      }
    }
  }
  
  /**
   * Update textures (for video elements)
   */
  public updateTextures(): void {
    for (const [id, texture] of this.layerTextures) {
      if (texture instanceof THREE.VideoTexture) {
        texture.needsUpdate = true;
      }
    }
  }
  
  /**
   * Create texture from media source
   */
  private createTextureFromSource(
    source: HTMLCanvasElement | HTMLVideoElement | HTMLImageElement | string,
    type: string
  ): THREE.Texture {
    switch (type) {
      case 'video':
        if (typeof source === 'string') {
          const video = document.createElement('video');
          video.src = source;
          video.loop = true;
          video.muted = true;
          video.play();
          return new THREE.VideoTexture(video);
        } else if (source instanceof HTMLVideoElement) {
          return new THREE.VideoTexture(source);
        }
        break;
        
      case 'image':
        if (typeof source === 'string') {
          return new THREE.TextureLoader().load(source);
        } else if (source instanceof HTMLImageElement) {
          return new THREE.Texture(source);
        }
        break;
        
      case 'canvas':
        if (source instanceof HTMLCanvasElement) {
          return new THREE.CanvasTexture(source);
        }
        break;
    }
    
    // Fallback to a default texture
    return new THREE.Texture();
  }
  
  /**
   * Create material with audio-reactive uniforms
   */
  private createMaterial(config: MediaLayerConfig, texture: THREE.Texture): THREE.ShaderMaterial {
    return new THREE.ShaderMaterial({
      vertexShader: `
        uniform vec2 uPosition;
        uniform vec2 uScale;
        uniform float uRotation;
        varying vec2 vUv;
        
        void main() {
          vUv = uv;
          
          vec3 pos = position;
          
          // Apply scale
          pos.xy *= uScale;
          
          // Apply rotation
          float c = cos(uRotation);
          float s = sin(uRotation);
          mat2 rotationMatrix = mat2(c, -s, s, c);
          pos.xy = rotationMatrix * pos.xy;
          
          // Apply position
          pos.xy += uPosition;
          
          gl_Position = projectionMatrix * modelViewMatrix * vec4(pos, 1.0);
        }
      `,
      fragmentShader: `
        uniform sampler2D tDiffuse;
        uniform float uOpacity;
        varying vec2 vUv;
        
        void main() {
          vec4 texel = texture2D(tDiffuse, vUv);
          gl_FragColor = vec4(texel.rgb, texel.a * uOpacity);
        }
      `,
      uniforms: {
        tDiffuse: new THREE.Uniform(texture),
        uOpacity: new THREE.Uniform(config.opacity),
        uPosition: new THREE.Uniform(new THREE.Vector2(config.position.x, config.position.y)),
        uScale: new THREE.Uniform(new THREE.Vector2(config.scale.x, config.scale.y)),
        uRotation: new THREE.Uniform(config.rotation)
      },
      transparent: true,
      depthTest: false,
      depthWrite: false
    });
  }
  
  /**
   * Create mesh for media layer
   */
  private createMesh(config: MediaLayerConfig, material: THREE.ShaderMaterial): THREE.Mesh {
    const geometry = new THREE.PlaneGeometry(1, 1);
    const mesh = new THREE.Mesh(geometry, material);
    
    // Set initial transform
    mesh.position.set(config.position.x, config.position.y, -config.zIndex);
    mesh.scale.set(config.scale.x, config.scale.y, 1);
    mesh.rotation.z = config.rotation;
    
    return mesh;
  }
  
  /**
   * Map value from one range to another
   */
  private mapRange(value: number, inMin: number, inMax: number, outMin: number, outMax: number): number {
    return ((value - inMin) * (outMax - outMin)) / (inMax - inMin) + outMin;
  }
  
  /**
   * Get media layer by ID
   */
  public getMediaLayer(id: string): MediaLayerConfig | undefined {
    return this.mediaLayers.get(id);
  }
  
  /**
   * Get all media layer IDs
   */
  public getMediaLayerIds(): string[] {
    return [...this.mediaLayers.keys()];
  }
  
  /**
   * Update layer configuration
   */
  public updateLayerConfig(id: string, updates: Partial<MediaLayerConfig>): void {
    const config = this.mediaLayers.get(id);
    if (!config) return;
    
    Object.assign(config, updates);
    
    // Update material uniforms
    const material = this.layerMaterials.get(id);
    if (material) {
      if (updates.opacity !== undefined) {
        material.uniforms.uOpacity.value = updates.opacity;
      }
      if (updates.position !== undefined) {
        material.uniforms.uPosition.value.set(updates.position.x, updates.position.y);
      }
      if (updates.scale !== undefined) {
        material.uniforms.uScale.value.set(updates.scale.x, updates.scale.y);
      }
      if (updates.rotation !== undefined) {
        material.uniforms.uRotation.value = updates.rotation;
      }
    }
    
    // Update mesh transform
    const mesh = this.layerMeshes.get(id);
    if (mesh) {
      if (updates.position !== undefined) {
        mesh.position.set(updates.position.x, updates.position.y, -config.zIndex);
      }
      if (updates.scale !== undefined) {
        mesh.scale.set(updates.scale.x, updates.scale.y, 1);
      }
      if (updates.rotation !== undefined) {
        mesh.rotation.z = updates.rotation;
      }
      if (updates.zIndex !== undefined) {
        mesh.position.z = -updates.zIndex;
      }
    }
  }
  
  /**
   * Dispose of all resources
   */
  public dispose(): void {
    for (const [id] of this.mediaLayers) {
      this.removeMediaLayer(id);
    }
    
    this.mediaLayers.clear();
    this.layerMaterials.clear();
    this.layerTextures.clear();
    this.layerMeshes.clear();
  }
}
</file>

<file path="lib/visualizer/core/MultiLayerCompositor.ts">
import * as THREE from 'three';

export interface LayerRenderTarget {
  id: string;
  renderTarget: THREE.WebGLRenderTarget;
  scene: THREE.Scene;
  camera: THREE.Camera;
  enabled: boolean;
  blendMode: 'normal' | 'multiply' | 'screen' | 'overlay' | 'add' | 'subtract';
  opacity: number;
  zIndex: number;
  material?: THREE.ShaderMaterial;
}

export interface CompositorConfig {
  width: number;
  height: number;
  enableBloom?: boolean;
  enableAntialiasing?: boolean;
  pixelRatio?: number;
}

export class MultiLayerCompositor {
  private renderer: THREE.WebGLRenderer;
  private config: CompositorConfig;
  
  // Layer management
  private layers: Map<string, LayerRenderTarget> = new Map();
  private layerOrder: string[] = [];
  
  // Render targets
  private mainRenderTarget: THREE.WebGLRenderTarget;
  private bloomRenderTarget: THREE.WebGLRenderTarget;
  private tempRenderTarget: THREE.WebGLRenderTarget;
  
  // Shared geometry for full-screen rendering
  private quadGeometry: THREE.PlaneGeometry;
  private quadCamera: THREE.OrthographicCamera;
  
  // Blend mode shaders
  private blendShaders: Map<string, string> = new Map();
  
  constructor(renderer: THREE.WebGLRenderer, config: CompositorConfig) {
    this.renderer = renderer;
    this.config = {
      enableBloom: false,
      enableAntialiasing: true,
      pixelRatio: window.devicePixelRatio || 1,
      ...config
    };
    
    // Create render targets
    this.mainRenderTarget = new THREE.WebGLRenderTarget(
      this.config.width,
      this.config.height,
      {
        format: THREE.RGBAFormat,
        type: THREE.UnsignedByteType,
        minFilter: THREE.LinearFilter,
        magFilter: THREE.LinearFilter,
        generateMipmaps: false
      }
    );
    
    this.bloomRenderTarget = new THREE.WebGLRenderTarget(
      this.config.width,
      this.config.height,
      {
        format: THREE.RGBAFormat,
        type: THREE.UnsignedByteType,
        minFilter: THREE.LinearFilter,
        magFilter: THREE.LinearFilter,
        generateMipmaps: false
      }
    );
    
    this.tempRenderTarget = new THREE.WebGLRenderTarget(
      this.config.width,
      this.config.height,
      {
        format: THREE.RGBAFormat,
        type: THREE.UnsignedByteType,
        minFilter: THREE.LinearFilter,
        magFilter: THREE.LinearFilter,
        generateMipmaps: false
      }
    );
    
    // Create shared geometry and camera
    this.quadGeometry = new THREE.PlaneGeometry(2, 2);
    this.quadCamera = new THREE.OrthographicCamera(-1, 1, 1, -1, 0, 1);
    
    // Initialize blend mode shaders
    this.initializeBlendShaders();
  }
  
  /**
   * Create a new layer
   */
  public createLayer(
    id: string,
    scene: THREE.Scene,
    camera: THREE.Camera,
    options: Partial<Omit<LayerRenderTarget, 'id' | 'scene' | 'camera'>> = {}
  ): LayerRenderTarget {
    const renderTarget = new THREE.WebGLRenderTarget(
      this.config.width,
      this.config.height,
      {
        format: THREE.RGBAFormat,
        type: THREE.UnsignedByteType,
        minFilter: THREE.LinearFilter,
        magFilter: THREE.LinearFilter,
        generateMipmaps: false
      }
    );
    
    const layer: LayerRenderTarget = {
      id,
      renderTarget,
      scene,
      camera,
      enabled: true,
      blendMode: 'normal',
      opacity: 1.0,
      zIndex: 0,
      ...options
    };
    
    this.layers.set(id, layer);
    this.layerOrder.push(id);
    this.sortLayers();
    
    return layer;
  }
  
  /**
   * Remove a layer
   */
  public removeLayer(id: string): void {
    const layer = this.layers.get(id);
    if (layer) {
      layer.renderTarget.dispose();
      this.layers.delete(id);
      this.layerOrder = this.layerOrder.filter(layerId => layerId !== id);
    }
  }
  
  /**
   * Update layer properties
   */
  public updateLayer(id: string, updates: Partial<LayerRenderTarget>): void {
    const layer = this.layers.get(id);
    if (layer) {
      Object.assign(layer, updates);
      if (updates.zIndex !== undefined) {
        this.sortLayers();
      }
    }
  }
  
  /**
   * Sort layers by z-index
   */
  private sortLayers(): void {
    this.layerOrder.sort((a, b) => {
      const layerA = this.layers.get(a);
      const layerB = this.layers.get(b);
      return (layerA?.zIndex || 0) - (layerB?.zIndex || 0);
    });
  }
  
  /**
   * Main render method
   */
  public render(): void {
    // Step 1: Render each layer to its render target
    for (const layerId of this.layerOrder) {
      const layer = this.layers.get(layerId);
      if (!layer || !layer.enabled) continue;
      
      this.renderer.setRenderTarget(layer.renderTarget);
      this.renderer.clear();
      this.renderer.render(layer.scene, layer.camera);
    }
    
    // Step 2: Composite layers using GPU shaders
    this.compositeLayersToMain();
    
    // Step 3: Apply post-processing (bloom, etc.)
    if (this.config.enableBloom) {
      this.applyBloomEffect();
    }
    
    // Step 4: Final output
    this.renderFinalOutput();
  }
  
  /**
   * Composite all layers to main render target
   */
  private compositeLayersToMain(): void {
    this.renderer.setRenderTarget(this.mainRenderTarget);
    this.renderer.clear();
    
    // Composite layers in order
    for (const layerId of this.layerOrder) {
      const layer = this.layers.get(layerId);
      if (!layer || !layer.enabled) continue;
      
      this.renderLayerWithBlending(layer);
    }
  }
  
  /**
   * Render a single layer with blending
   */
  private renderLayerWithBlending(layer: LayerRenderTarget): void {
    const blendShader = this.getBlendModeShader(layer.blendMode);
    const material = new THREE.ShaderMaterial({
      vertexShader: `
        varying vec2 vUv;
        void main() {
          vUv = uv;
          gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
        }
      `,
      fragmentShader: blendShader,
      uniforms: {
        tDiffuse: new THREE.Uniform(layer.renderTarget.texture),
        opacity: new THREE.Uniform(layer.opacity)
      },
      transparent: true,
      depthTest: false,
      depthWrite: false
    });
    
    const mesh = new THREE.Mesh(this.quadGeometry, material);
    const scene = new THREE.Scene();
    scene.add(mesh);
    
    this.renderer.render(scene, this.quadCamera);
    
    // Cleanup
    material.dispose();
    mesh.geometry.dispose();
  }
  
  /**
   * Apply bloom effect
   */
  private applyBloomEffect(): void {
    // Simple bloom implementation - in practice you'd use a more sophisticated approach
    this.renderer.setRenderTarget(this.bloomRenderTarget);
    this.renderer.clear();
    
    const bloomMaterial = new THREE.ShaderMaterial({
      vertexShader: `
        varying vec2 vUv;
        void main() {
          vUv = uv;
          gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
        }
      `,
      fragmentShader: `
        uniform sampler2D tDiffuse;
        varying vec2 vUv;
        
        void main() {
          vec4 texel = texture2D(tDiffuse, vUv);
          float brightness = (texel.r + texel.g + texel.b) / 3.0;
          float threshold = 0.7;
          float bloom = max(0.0, brightness - threshold);
          gl_FragColor = vec4(texel.rgb * bloom, bloom);
        }
      `,
      uniforms: {
        tDiffuse: new THREE.Uniform(this.mainRenderTarget.texture)
      }
    });
    
    const mesh = new THREE.Mesh(this.quadGeometry, bloomMaterial);
    const scene = new THREE.Scene();
    scene.add(mesh);
    
    this.renderer.render(scene, this.quadCamera);
    
    // Blend bloom with main
    this.renderer.setRenderTarget(this.tempRenderTarget);
    this.renderer.clear();
    
    const blendMaterial = new THREE.ShaderMaterial({
      vertexShader: `
        varying vec2 vUv;
        void main() {
          vUv = uv;
          gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
        }
      `,
      fragmentShader: `
        uniform sampler2D tMain;
        uniform sampler2D tBloom;
        varying vec2 vUv;
        
        void main() {
          vec4 mainColor = texture2D(tMain, vUv);
          vec4 bloomColor = texture2D(tBloom, vUv);
          gl_FragColor = mainColor + bloomColor * 0.5;
        }
      `,
      uniforms: {
        tMain: new THREE.Uniform(this.mainRenderTarget.texture),
        tBloom: new THREE.Uniform(this.bloomRenderTarget.texture)
      }
    });
    
    const blendMesh = new THREE.Mesh(this.quadGeometry, blendMaterial);
    const blendScene = new THREE.Scene();
    blendScene.add(blendMesh);
    
    this.renderer.render(blendScene, this.quadCamera);
    
    // Swap render targets
    const temp = this.mainRenderTarget;
    this.mainRenderTarget = this.tempRenderTarget;
    this.tempRenderTarget = temp;
    
    // Cleanup
    bloomMaterial.dispose();
    blendMaterial.dispose();
    mesh.geometry.dispose();
    blendMesh.geometry.dispose();
  }
  
  /**
   * Render final output to screen
   */
  private renderFinalOutput(): void {
    this.renderer.setRenderTarget(null);
    
    const finalMaterial = new THREE.ShaderMaterial({
      vertexShader: `
        varying vec2 vUv;
        void main() {
          vUv = uv;
          gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
        }
      `,
      fragmentShader: `
        uniform sampler2D tDiffuse;
        varying vec2 vUv;
        
        void main() {
          vec4 texel = texture2D(tDiffuse, vUv);
          gl_FragColor = texel;
        }
      `,
      uniforms: {
        tDiffuse: new THREE.Uniform(this.mainRenderTarget.texture)
      }
    });
    
    const mesh = new THREE.Mesh(this.quadGeometry, finalMaterial);
    const scene = new THREE.Scene();
    scene.add(mesh);
    
    this.renderer.render(scene, this.quadCamera);
    
    // Cleanup
    finalMaterial.dispose();
    mesh.geometry.dispose();
  }
  
  /**
   * Initialize blend mode shaders
   */
  private initializeBlendShaders(): void {
    this.blendShaders.set('normal', `
      uniform sampler2D tDiffuse;
      uniform float opacity;
      varying vec2 vUv;
      
      void main() {
        vec4 texel = texture2D(tDiffuse, vUv);
        gl_FragColor = vec4(texel.rgb, texel.a * opacity);
      }
    `);
    
    this.blendShaders.set('multiply', `
      uniform sampler2D tDiffuse;
      uniform float opacity;
      varying vec2 vUv;
      
      void main() {
        vec4 texel = texture2D(tDiffuse, vUv);
        gl_FragColor = vec4(texel.rgb * texel.rgb, texel.a * opacity);
      }
    `);
    
    this.blendShaders.set('screen', `
      uniform sampler2D tDiffuse;
      uniform float opacity;
      varying vec2 vUv;
      
      void main() {
        vec4 texel = texture2D(tDiffuse, vUv);
        gl_FragColor = vec4(1.0 - (1.0 - texel.rgb) * (1.0 - texel.rgb), texel.a * opacity);
      }
    `);
    
    this.blendShaders.set('overlay', `
      uniform sampler2D tDiffuse;
      uniform float opacity;
      varying vec2 vUv;
      
      void main() {
        vec4 texel = texture2D(tDiffuse, vUv);
        vec3 base = vec3(0.5);
        vec3 overlay = mix(
          2.0 * base * texel.rgb, 
          1.0 - 2.0 * (1.0 - base) * (1.0 - texel.rgb), 
          step(0.5, base)
        );
        gl_FragColor = vec4(overlay, texel.a * opacity);
      }
    `);
    
    this.blendShaders.set('add', `
      uniform sampler2D tDiffuse;
      uniform float opacity;
      varying vec2 vUv;
      
      void main() {
        vec4 texel = texture2D(tDiffuse, vUv);
        gl_FragColor = vec4(texel.rgb + texel.rgb, texel.a * opacity);
      }
    `);
    
    this.blendShaders.set('subtract', `
      uniform sampler2D tDiffuse;
      uniform float opacity;
      varying vec2 vUv;
      
      void main() {
        vec4 texel = texture2D(tDiffuse, vUv);
        gl_FragColor = vec4(max(texel.rgb - texel.rgb, 0.0), texel.a * opacity);
      }
    `);
  }
  
  /**
   * Get blend mode shader
   */
  private getBlendModeShader(blendMode: string): string {
    return this.blendShaders.get(blendMode) || this.blendShaders.get('normal')!;
  }
  
  /**
   * Get layer by ID
   */
  public getLayer(id: string): LayerRenderTarget | undefined {
    return this.layers.get(id);
  }
  
  /**
   * Get all layer IDs
   */
  public getLayerIds(): string[] {
    return [...this.layerOrder];
  }
  
  /**
   * Resize render targets
   */
  public resize(width: number, height: number): void {
    this.config.width = width;
    this.config.height = height;
    
    // Resize all render targets
    this.mainRenderTarget.setSize(width, height);
    this.bloomRenderTarget.setSize(width, height);
    this.tempRenderTarget.setSize(width, height);
    
    // Resize layer render targets
    for (const layer of this.layers.values()) {
      layer.renderTarget.setSize(width, height);
    }
  }
  
  /**
   * Dispose of resources
   */
  public dispose(): void {
    this.mainRenderTarget.dispose();
    this.bloomRenderTarget.dispose();
    this.tempRenderTarget.dispose();
    
    for (const layer of this.layers.values()) {
      layer.renderTarget.dispose();
    }
    
    this.quadGeometry.dispose();
    this.layers.clear();
    this.layerOrder = [];
  }
}
</file>

<file path="lib/visualizer/core/VisualizerManager.ts">
import * as THREE from 'three';
import { VisualEffect, VisualizerConfig, LiveMIDIData, AudioAnalysisData, VisualizerControls } from '@/types/visualizer';
import { BloomEffect } from '../effects/BloomEffect';
import { VisualizationPreset } from '@/types/stem-visualization';
import { debugLog } from '@/lib/utils';
import { AudioTextureManager, AudioFeatureData } from './AudioTextureManager';
import { MediaLayerManager } from './MediaLayerManager';

export class VisualizerManager {
  private static instanceCounter = 0;
  private instanceId: number;
  
  private scene!: THREE.Scene;
  private camera!: THREE.PerspectiveCamera;
  private renderer!: THREE.WebGLRenderer;
  private canvas: HTMLCanvasElement;
  private animationId: number | null = null;
  private clock: THREE.Clock;
  
  private effects: Map<string, VisualEffect> = new Map();
  private isPlaying = false;
  private lastTime = 0;
  
  // Audio analysis
  private audioContext: AudioContext | null = null;
  private audioSources: AudioBufferSourceNode[] = [];
  private currentAudioBuffer: AudioBuffer | null = null;
  
  // Bloom post-processing
  private bloomEffect: BloomEffect | null = null;
  
  // GPU compositing system
  private audioTextureManager: AudioTextureManager | null = null;
  private mediaLayerManager: MediaLayerManager | null = null;
  
  // Performance monitoring
  private frameCount = 0;
  private fps = 60;
  private lastFPSUpdate = 0;
  private consecutiveSlowFrames = 0;
  private maxSlowFrames = 10; // Emergency pause after 10 consecutive slow frames
  
  // Visualization parameters
  private visualParams = {
    globalScale: 1.0,
    rotationSpeed: 0.0,
    colorIntensity: 1.0,
    emissionIntensity: 1.0,
    positionOffset: 0.0,
    heightScale: 1.0,
    hueRotation: 0.0,
    brightness: 1.0,
    complexity: 0.5,
    particleSize: 1.0,
    opacity: 1.0,
    animationSpeed: 1.0,
    particleCount: 5000
  };
  
  constructor(canvas: HTMLCanvasElement, config: VisualizerConfig) {
    debugLog.log(' VisualizerManager constructor called');
    this.instanceId = ++VisualizerManager.instanceCounter;
    this.canvas = canvas;
    this.clock = new THREE.Clock();
    
    this.initScene(config);
    this.setupEventListeners();
    this.initBloomEffect();
    this.initAudioTextureManager();
    this.initMediaLayerManager();
    debugLog.log(' VisualizerManager constructor complete');
  }
  
  private initScene(config: VisualizerConfig) {
    // Scene setup
    this.scene = new THREE.Scene();
    this.scene.background = new THREE.Color(0x000000); // Pure black for bloom effect
    this.scene.fog = new THREE.Fog(0x000000, 10, 50);
    
      // Camera setup - use aspect ratio from config if available, otherwise use 1:1
  const initialAspectRatio = config.aspectRatio 
    ? config.aspectRatio.width / config.aspectRatio.height 
    : 1; // Default to square aspect ratio
  
  this.camera = new THREE.PerspectiveCamera(
    75,
    initialAspectRatio,
    0.1,
    1000
  );
    this.camera.position.set(0, 0, 5);
    
    // Renderer setup with error handling and fallbacks
    try {
      // First, check if canvas already has a context to avoid conflicts
      const existingContext = this.canvas.getContext('webgl2') || this.canvas.getContext('webgl');
      if (existingContext) {
        debugLog.log(' Found existing WebGL context, will attempt to reuse');
      }
      
      this.renderer = new THREE.WebGLRenderer({
        canvas: this.canvas,
        antialias: true,
        alpha: true,
        powerPreference: 'default', // Changed from high-performance to reduce resource usage
        failIfMajorPerformanceCaveat: false // Allow software rendering
      });
      
      debugLog.log(' WebGL Renderer created successfully');
      debugLog.log(' WebGL Context:', this.renderer.getContext());
    } catch (error) {
      debugLog.error(' Primary WebGL renderer failed:', error);
      
      // Try minimal fallback settings
      try {
        debugLog.log(' Attempting fallback renderer with minimal settings...');
        this.renderer = new THREE.WebGLRenderer({
          canvas: this.canvas,
          antialias: false,
          alpha: true,
          powerPreference: 'low-power',
          failIfMajorPerformanceCaveat: false
        });
        debugLog.log(' Fallback renderer created successfully');
      } catch (fallbackError) {
        debugLog.error(' Fallback renderer also failed:', fallbackError);
        throw new Error('WebGL is not available. Please refresh the page and try again. If the problem persists, try closing other browser tabs or restarting your browser.');
      }
    }
    
    this.renderer.setSize(config.canvas.width, config.canvas.height);
    this.renderer.setPixelRatio(Math.min(window.devicePixelRatio, config.canvas.pixelRatio || 2));
    this.renderer.setClearColor(0x000000, 1); // Pure black background
    
    debugLog.log(' Renderer configured with size:', config.canvas.width, 'x', config.canvas.height);
    
    // Performance optimizations for 30fps
    this.renderer.setAnimationLoop(null); // Use manual RAF control
    this.renderer.info.autoReset = false; // Manual reset for performance monitoring
    
    // Enable tone mapping for better color reproduction
    this.renderer.toneMapping = THREE.ACESFilmicToneMapping;
    this.renderer.toneMappingExposure = 1.0;
    
    // Disable shadows for better performance
    this.renderer.shadowMap.enabled = false;
    this.renderer.shadowMap.type = THREE.PCFSoftShadowMap;
  }

  private initBloomEffect() {
    // Initialize bloom post-processing
    this.bloomEffect = new BloomEffect();
    this.bloomEffect.init(this.scene, this.camera, this.renderer);
    debugLog.log(' Bloom post-processing initialized');
  }

  private initAudioTextureManager() {
    this.audioTextureManager = new AudioTextureManager();
    debugLog.log(' AudioTextureManager initialized');
  }

  private initMediaLayerManager() {
    this.mediaLayerManager = new MediaLayerManager(this.scene, this.camera, this.renderer);
    debugLog.log(' MediaLayerManager initialized');
  }
  
  private async initAudioAnalyzer() {
    if (!this.audioContext) {
      debugLog.log(' Creating AudioContext after user interaction...');
      this.audioContext = new AudioContext();
      // Resume the context to ensure it's active
      await this.audioContext.resume();
    }
    
    try {
      // This method is no longer used as AudioAnalyzer is removed.
      // Keeping it for now to avoid breaking existing calls, but it will be removed.
      debugLog.log(' Audio analyzer initialization (placeholder)');
    } catch (error) {
      debugLog.error(' Failed to initialize audio analyzer:', error);
    }
  }
  
  private setupEventListeners() {
    // Handle window resize
    const handleResize = () => {
      const width = this.canvas.clientWidth;
      const height = this.canvas.clientHeight;
      
      // Use the new responsive resize method
      this.handleViewportResize(width, height);
    };
    
    window.addEventListener('resize', handleResize);
    
    // Handle visibility change (pause when not visible)
    document.addEventListener('visibilitychange', () => {
      if (document.hidden && this.isPlaying) {
        this.pause();
      }
    });
    
    // Handle WebGL context lost/restored
    this.canvas.addEventListener('webglcontextlost', (event) => {
      debugLog.warn(' WebGL context lost!');
      event.preventDefault();
      this.pause(); // Stop rendering
    });
    
    this.canvas.addEventListener('webglcontextrestored', () => {
      debugLog.log(' WebGL context restored, reinitializing...');
      // Context restoration would require reinitializing all GPU resources
      // For now, we'll just log and suggest a page refresh
      debugLog.log(' Please refresh the page to restore full functionality');
    });
  }
  
  // Effect management
  public addEffect(effect: VisualEffect) {
    try {
      debugLog.log(` Adding effect: ${effect.name} (${effect.id})`);
      effect.init(this.scene, this.camera, this.renderer);
      this.effects.set(effect.id, effect);
      
      // Set initial visibility based on enabled status
      if (effect.enabled) {
        this.showEffectInScene(effect);
      } else {
        this.hideEffectFromScene(effect);
      }
      
      debugLog.log(` Added effect: ${effect.name}. Total effects: ${this.effects.size}`);
    } catch (error) {
      debugLog.error(` Failed to add effect ${effect.name}:`, error);
    }
  }
  
  public addEffectWithId(effect: VisualEffect, customId: string) {
    try {
      debugLog.log(` Adding effect with custom ID: ${effect.name} (${customId})`);
      // Don't call init again - effect is already initialized by addEffect()
      // Just add the reference with the custom ID
      this.effects.set(customId, effect);
      
      debugLog.log(` Added effect reference with custom ID: ${effect.name} (${customId}). Total effects: ${this.effects.size}`);
    } catch (error) {
      debugLog.error(` Failed to add effect ${effect.name} with custom ID ${customId}:`, error);
    }
  }
  
  public removeEffect(effectId: string) {
    const effect = this.effects.get(effectId);
    if (effect) {
      effect.destroy();
      this.effects.delete(effectId);
      debugLog.log(` Removed effect: ${effect.name}. Remaining effects: ${this.effects.size}`);
    }
  }
  
  getEffect(effectId: string): VisualEffect | undefined {
    return this.effects.get(effectId);
  }
  
  getAllEffects(): VisualEffect[] {
    return Array.from(this.effects.values());
  }
  
  enableEffect(effectId: string): void {
    const effect = this.effects.get(effectId);
    if (effect) {
      effect.enabled = true;
      // Show the effect's visual elements in the scene
      this.showEffectInScene(effect);
      debugLog.log(` Enabled effect: ${effect.name} (${effectId})`);
    } else {
      debugLog.warn(` Effect not found: ${effectId}`);
    }
  }
  
  disableEffect(effectId: string): void {
    const effect = this.effects.get(effectId);
    if (effect) {
      effect.enabled = false;
      // Hide the effect's visual elements from the scene
      this.hideEffectFromScene(effect);
      debugLog.log(` Disabled effect: ${effect.name} (${effectId})`);
    }
  }
  
  private showEffectInScene(effect: VisualEffect): void {
    // Show the effect's visual elements by setting their visibility to true
    
    // Handle MetaballsEffect (has 'mesh' property)
    if ('mesh' in effect && (effect as any).mesh) {
      (effect as any).mesh.visible = true;
    }
    
    // Handle ParticleNetworkEffect (has 'instancedMesh' and 'connectionLines')
    if ('instancedMesh' in effect && (effect as any).instancedMesh) {
      (effect as any).instancedMesh.visible = true;
    }
    if ('connectionLines' in effect && (effect as any).connectionLines) {
      (effect as any).connectionLines.visible = true;
    }
    
    // Handle TestCubeEffect (has 'mesh' property)
    if ('mesh' in effect && (effect as any).mesh) {
      (effect as any).mesh.visible = true;
    }
    
    // Handle other visual elements that might need to be shown
    if ('materials' in effect && Array.isArray((effect as any).materials)) {
      (effect as any).materials.forEach((material: any) => {
        if (material && material.visible !== undefined) {
          material.visible = true;
        }
      });
    }
  }
  
  private hideEffectFromScene(effect: VisualEffect): void {
    // Hide the effect's visual elements by setting their visibility to false
    
    // Handle MetaballsEffect (has 'mesh' property)
    if ('mesh' in effect && (effect as any).mesh) {
      (effect as any).mesh.visible = false;
    }
    
    // Handle ParticleNetworkEffect (has 'instancedMesh' and 'connectionLines')
    if ('instancedMesh' in effect && (effect as any).instancedMesh) {
      (effect as any).instancedMesh.visible = false;
    }
    if ('connectionLines' in effect && (effect as any).connectionLines) {
      (effect as any).connectionLines.visible = false;
    }
    
    // Handle TestCubeEffect (has 'mesh' property)
    if ('mesh' in effect && (effect as any).mesh) {
      (effect as any).mesh.visible = false;
    }
    
    // Handle other visual elements that might need to be hidden
    if ('materials' in effect && Array.isArray((effect as any).materials)) {
      (effect as any).materials.forEach((material: any) => {
        if (material && material.visible !== undefined) {
          material.visible = false;
        }
      });
    }
  }
  
  // Playback control
  play(): void {
    debugLog.log(` Play() called. Current state: isPlaying=${this.isPlaying}, effects=${this.effects.size}`);
    if (!this.isPlaying) {
      this.isPlaying = true;
      this.clock.start();
      this.animate();
      debugLog.log(` Animation started`);
      
      // Start audio playback
      this.audioSources.forEach((source, index) => {
        try {
          source.start(0);
          debugLog.log(` Started audio source ${index}`);
        } catch (error) {
          debugLog.warn(` Audio source ${index} already playing or ended`);
        }
      });
    }
  }
  
  pause(): void {
    this.isPlaying = false;
    this.clock.stop();
    if (this.animationId) {
      cancelAnimationFrame(this.animationId);
      this.animationId = null;
    }
    
    // Stop audio playback
    this.audioSources.forEach((source, index) => {
      try {
        source.stop();
        debugLog.log(` Stopped audio source ${index}`);
      } catch (error) {
        debugLog.warn(` Audio source ${index} already stopped`);
      }
    });
  }
  
  stop(): void {
    this.pause();
    this.clock.elapsedTime = 0;
  }
  
  private animate = () => {
    if (!this.isPlaying) return;
    
    this.animationId = requestAnimationFrame(this.animate);
    
    // IMPLEMENT 30FPS CAP - Much more reasonable for audio-visual sync
    const now = performance.now();
    const elapsed = now - this.lastTime;
    const targetFrameTime = 1000 / 30; // 33.33ms for 30fps
    
    if (elapsed < targetFrameTime) {
      return; // Skip this frame to maintain 30fps cap
    }
    
    // Only skip frames if we're severely behind (emergency performance protection)
    const frameTime = elapsed;
    if (frameTime > 100) { // If frame takes more than 100ms (10fps), skip next frame
      this.consecutiveSlowFrames++;
      
      // Emergency pause if too many consecutive slow frames
      if (this.consecutiveSlowFrames >= this.maxSlowFrames) {
        debugLog.error(` Emergency pause: ${this.maxSlowFrames} consecutive slow frames detected. Pausing to prevent browser freeze.`);
        this.pause();
        // Suggest recovery action
        setTimeout(() => {
          debugLog.log(' Tip: Try refreshing the page or closing other browser tabs to improve performance.');
        }, 1000);
        return;
      }
      
      this.lastTime = now;
      return;
    } else {
      this.consecutiveSlowFrames = 0; // Reset counter on good frame
    }
    
    const deltaTime = Math.min(this.clock.getDelta(), 0.1); // Cap delta time to prevent large jumps
    const currentTime = now;
    
    // Update FPS counter
    this.frameCount++;
    if (currentTime - this.lastFPSUpdate > 1000) {
      this.fps = Math.round((this.frameCount * 1000) / (currentTime - this.lastFPSUpdate));
      this.frameCount = 0;
      this.lastFPSUpdate = currentTime;
    }
    
    // Performance monitoring - check memory usage
    if (this.frameCount % 300 === 0) { // Every 10 seconds at 30fps
      const memInfo = this.getMemoryUsage();
      if (memInfo.geometries > 100 || memInfo.textures > 50) {
        debugLog.warn(` High memory usage detected: ${memInfo.geometries} geometries, ${memInfo.textures} textures`);
      }
    }
    
    // Update all enabled effects with improved performance
    let activeEffectCount = 0;
    const maxEffectsPerFrame = 3; // Reduced back to 3 for 30fps
    let updatedEffects = 0;
    
    this.effects.forEach(effect => {
      if (effect.enabled && updatedEffects < maxEffectsPerFrame) {
        activeEffectCount++;
        updatedEffects++;
        
        try {
          // Use real data if available, otherwise fallback to mock data
          const audioData: AudioAnalysisData = this.currentAudioData || this.createMockAudioData();
          const midiData: LiveMIDIData = this.currentMidiData || this.createMockMidiData();
          
          effect.update(deltaTime, audioData, midiData);
        } catch (error) {
          debugLog.error(` Effect ${effect.id} update failed:`, error);
          // Disable problematic effect to prevent further issues
          effect.enabled = false;
        }
      } else if (effect.enabled) {
        activeEffectCount++; // Count but don't update this frame
      }
    });
    
    // Update GPU audio texture system
    if (this.audioTextureManager && this.currentAudioData) {
      // Convert audio analysis to GPU texture format using existing structure
      const audioFeatureData: AudioFeatureData = {
        features: {
          'main': [this.currentAudioData.volume, this.currentAudioData.bass, this.currentAudioData.mid, this.currentAudioData.treble]
        },
        duration: 0, // Will be set when real audio is loaded
        sampleRate: 44100,
        stemTypes: ['main']
      };
      
      // Update audio texture with current time
      this.audioTextureManager.updateTime(currentTime / 1000, audioFeatureData.duration);
    }
    
    // Update media layer textures (for video elements)
    if (this.mediaLayerManager) {
      this.mediaLayerManager.updateTextures();
    }
    
    // Update bloom effect
    if (this.bloomEffect) {
      const audioData: AudioAnalysisData = this.currentAudioData || this.createMockAudioData();
      const midiData: LiveMIDIData = this.currentMidiData || this.createMockMidiData();
      this.bloomEffect.update(deltaTime, audioData, midiData);
      
      // Render with bloom post-processing
      this.bloomEffect.render();
    } else {
      // Fallback to direct rendering
      this.renderer.render(this.scene, this.camera);
    }
    
    this.lastTime = currentTime;
  };
  
  // Mock data generators (will be replaced with real data)
  private createMockAudioData(): AudioAnalysisData {
    const frequencies = new Array(256);
    const timeData = new Array(256);
    
    // Generate more realistic frequency data
    for (let i = 0; i < 256; i++) {
      frequencies[i] = Math.sin(this.clock.elapsedTime * 2 + i * 0.1) * 0.5 + 0.5;
      timeData[i] = Math.cos(this.clock.elapsedTime * 3 + i * 0.05) * 0.3 + 0.3;
    }
    
    return {
      frequencies,
      timeData,
      volume: (Math.sin(this.clock.elapsedTime * 1.5) + 1) * 0.5,
      bass: (Math.sin(this.clock.elapsedTime * 0.8) + 1) * 0.5,
      mid: (Math.sin(this.clock.elapsedTime * 1.2) + 1) * 0.5,
      treble: (Math.sin(this.clock.elapsedTime * 2.0) + 1) * 0.5
    };
  }
  
  private createMockMidiData(): LiveMIDIData {
    return {
      activeNotes: [],
      currentTime: this.clock.elapsedTime,
      tempo: 120,
      totalNotes: 0,
      trackActivity: {}
    };
  }
  
  // Update methods for real data
  updateMIDIData(midiData: LiveMIDIData): void {
    // Store MIDI data to be used in next animation frame
    this.currentMidiData = midiData;
    debugLog.log(' MIDI data received:', midiData);
  }

  updateAudioData(audioData: AudioAnalysisData): void {
    // Store audio data to be used in next animation frame
    this.currentAudioData = audioData;
    debugLog.log(' Audio data received:', audioData);
  }
  
  
  updateEffectParameter(effectId: string, paramName: string, value: any): void {
    const effect = this.effects.get(effectId);
    if (effect && effect.parameters.hasOwnProperty(paramName)) {
      const oldValue = (effect.parameters as any)[paramName];
      (effect.parameters as any)[paramName] = value;
      
      // REMOVED VERBOSE LOGGING - Only log significant changes or errors
      // If the effect has an updateParameter method, call it for immediate updates
      if (typeof (effect as any).updateParameter === 'function') {
        (effect as any).updateParameter(paramName, value);
      }
    } else {
      // Only log errors, not every parameter update
      if (!effect) {
        debugLog.warn(` Effect ${effectId} not found`);
      } else if (!effect.parameters.hasOwnProperty(paramName)) {
        debugLog.warn(` Parameter ${paramName} not found in effect ${effectId}`);
      }
    }
  }
  
  private currentMidiData?: LiveMIDIData;
  private currentAudioData?: AudioAnalysisData;
  
  // Performance monitoring
  getFPS(): number {
    return this.fps;
  }
  
  getMemoryUsage(): { geometries: number; textures: number; programs: number } {
    return {
      geometries: this.renderer.info.memory.geometries,
      textures: this.renderer.info.memory.textures,
      programs: this.renderer.info.programs?.length || 0
    };
  }
  
  // Cleanup
  dispose(): void {
    debugLog.log(` VisualizerManager.dispose() called. Effects: ${this.effects.size}`);
    this.stop();
    
    // Dispose bloom effect
    if (this.bloomEffect) {
      this.bloomEffect.destroy();
      this.bloomEffect = null;
    }
    
    // Dispose all effects
    debugLog.log(` Disposing ${this.effects.size} effects`);
    this.effects.forEach(effect => effect.destroy());
    this.effects.clear();
    debugLog.log(` Effects cleared. Remaining: ${this.effects.size}`);
    
    // Dispose Three.js resources
    this.scene.traverse((object) => {
      if (object instanceof THREE.Mesh) {
        object.geometry.dispose();
        if (object.material instanceof Array) {
          object.material.forEach(material => material.dispose());
        } else {
          object.material.dispose();
        }
      }
    });
    
    this.renderer.dispose();
  }

  public async loadAudioBuffer(buffer: ArrayBuffer): Promise<void> {
    if (!this.audioContext) {
      throw new Error('AudioContext not initialized');
    }
    try {
      // Log buffer info for debugging
      debugLog.log('Audio buffer length:', buffer.byteLength);
      debugLog.log('First 16 bytes:', Array.from(new Uint8Array(buffer.slice(0, 16))));
      this.currentAudioBuffer = await this.audioContext.decodeAudioData(buffer);
      // Create audio source for playback
      const audioSource = this.audioContext.createBufferSource();
      audioSource.buffer = this.currentAudioBuffer;
      audioSource.connect(this.audioContext.destination);
      // Store the source for control
      if (!this.audioSources) {
        this.audioSources = [];
      }
      this.audioSources.push(audioSource);
      // Remove any call to audioAnalyzer/analyzeStem
    } catch (error) {
      debugLog.error(' Failed to load audio buffer:', error);
      throw error;
    }
  }

  // Parameter setters
  public setGlobalScale(value: number) {
    this.visualParams.globalScale = value;
    this.effects.forEach(effect => {
      if ('setScale' in effect) {
        (effect as any).setScale(value);
      }
    });
  }

  public setRotationSpeed(value: number) {
    this.visualParams.rotationSpeed = value;
    this.effects.forEach(effect => {
      if ('setRotationSpeed' in effect) {
        (effect as any).setRotationSpeed(value);
      }
    });
  }

  public setColorIntensity(value: number) {
    this.visualParams.colorIntensity = value;
    this.effects.forEach(effect => {
      if ('setColorIntensity' in effect) {
        (effect as any).setColorIntensity(value);
      }
    });
  }

  public setEmissionIntensity(value: number) {
    this.visualParams.emissionIntensity = value;
    this.effects.forEach(effect => {
      if ('setEmissionIntensity' in effect) {
        (effect as any).setEmissionIntensity(value);
      }
    });
  }

  public setPositionOffset(value: number) {
    this.visualParams.positionOffset = value;
    this.effects.forEach(effect => {
      if ('setPositionOffset' in effect) {
        (effect as any).setPositionOffset(value);
      }
    });
  }

  public setHeightScale(value: number) {
    this.visualParams.heightScale = value;
    this.effects.forEach(effect => {
      if ('setHeightScale' in effect) {
        (effect as any).setHeightScale(value);
      }
    });
  }

  public setHueRotation(value: number) {
    this.visualParams.hueRotation = value;
    this.effects.forEach(effect => {
      if ('setHueRotation' in effect) {
        (effect as any).setHueRotation(value);
      }
    });
  }

  public setBrightness(value: number) {
    this.visualParams.brightness = value;
    this.effects.forEach(effect => {
      if ('setBrightness' in effect) {
        (effect as any).setBrightness(value);
      }
    });
  }

  public setComplexity(value: number) {
    this.visualParams.complexity = value;
    this.effects.forEach(effect => {
      if ('setComplexity' in effect) {
        (effect as any).setComplexity(value);
      }
    });
  }

  public setParticleSize(value: number) {
    this.visualParams.particleSize = value;
    this.effects.forEach(effect => {
      if ('setParticleSize' in effect) {
        (effect as any).setParticleSize(value);
      }
    });
  }

  public setOpacity(value: number) {
    this.visualParams.opacity = value;
    this.effects.forEach(effect => {
      if ('setOpacity' in effect) {
        (effect as any).setOpacity(value);
      }
    });
  }

  public setAnimationSpeed(value: number) {
    this.visualParams.animationSpeed = value;
    this.effects.forEach(effect => {
      if ('setAnimationSpeed' in effect) {
        (effect as any).setAnimationSpeed(value);
      }
    });
  }

  public setParticleCount(value: number) {
    this.visualParams.particleCount = value;
    this.effects.forEach(effect => {
      if ('setParticleCount' in effect) {
        (effect as any).setParticleCount(value);
      }
    });
  }

  public updateSettings(settings: Record<string, number>) {
    Object.entries(settings).forEach(([key, value]) => {
      switch (key) {
        case 'globalIntensity':
          this.setColorIntensity(value);
          this.setEmissionIntensity(value);
          break;
        case 'smoothingFactor':
          // Apply to all effects that support smoothing
          this.effects.forEach(effect => {
            if ('setSmoothingFactor' in effect) {
              (effect as any).setSmoothingFactor(value);
            }
          });
          break;
        case 'responsiveness':
          // Apply to all effects that support responsiveness
          this.effects.forEach(effect => {
            if ('setResponsiveness' in effect) {
              (effect as any).setResponsiveness(value);
            }
          });
          break;
      }
    });
  }

  // Method to handle responsive resizing (no letterboxing, always fill canvas)
  public handleViewportResize(canvasWidth: number, canvasHeight: number) {
    this.renderer.setSize(canvasWidth, canvasHeight);
    this.camera.aspect = canvasWidth / canvasHeight;
    this.camera.updateProjectionMatrix();
    
    // Update resolution uniforms for all effects
    this.effects.forEach(effect => {
      if ('uniforms' in effect && (effect as any).uniforms?.uResolution) {
        (effect as any).uniforms.uResolution.value.set(canvasWidth, canvasHeight);
      }
    });
    
    if (this.bloomEffect) {
      this.bloomEffect.handleResize(canvasWidth, canvasHeight);
    }
    debugLog.log(' Responsive resize:', canvasWidth, canvasHeight, 'aspect:', this.camera.aspect);
  }

  // 2D Composition Layer for future video/image integration
  public createCompositionLayer() {
    // Create an orthographic camera for 2D composition
    const aspectRatio = this.camera.aspect;
    const frustumSize = 2;
    const orthographicCamera = new THREE.OrthographicCamera(
      frustumSize * aspectRatio / -2,
      frustumSize * aspectRatio / 2,
      frustumSize / 2,
      frustumSize / -2,
      0.1,
      1000
    );
    orthographicCamera.position.set(0, 0, 1);
    orthographicCamera.lookAt(0, 0, 0);

    // Create a composition scene for 2D elements
    const compositionScene = new THREE.Scene();
    
    return {
      scene: compositionScene,
      camera: orthographicCamera,
      addVideoLayer: (video: HTMLVideoElement, position: {x: number, y: number}, scale: {x: number, y: number}) => {
        const texture = new THREE.VideoTexture(video);
        const plane = new THREE.PlaneGeometry(1, 1);
        const material = new THREE.MeshBasicMaterial({ map: texture });
        const mesh = new THREE.Mesh(plane, material);
        
        // Position in 2D space (orthographic camera)
        mesh.position.set(position.x, position.y, 0);
        mesh.scale.set(scale.x, scale.y, 1);
        
        compositionScene.add(mesh);
        return mesh;
      },
      addImageLayer: (image: HTMLImageElement, position: {x: number, y: number}, scale: {x: number, y: number}) => {
        const texture = new THREE.TextureLoader().load(image.src);
        const plane = new THREE.PlaneGeometry(1, 1);
        const material = new THREE.MeshBasicMaterial({ map: texture });
        const mesh = new THREE.Mesh(plane, material);
        
        // Position in 2D space (orthographic camera)
        mesh.position.set(position.x, position.y, 0);
        mesh.scale.set(scale.x, scale.y, 1);
        
        compositionScene.add(mesh);
        return mesh;
      }
    };
  }

  // GPU Compositing System Access Methods
  
  public getAudioTextureManager(): AudioTextureManager | null {
    return this.audioTextureManager;
  }

  public getMediaLayerManager(): MediaLayerManager | null {
    return this.mediaLayerManager;
  }

  public enableGPUCompositing(): void {
    if (this.bloomEffect) {
      this.bloomEffect.enableMultiLayerCompositing();
      debugLog.log(' GPU compositing enabled');
    }
  }

  public disableGPUCompositing(): void {
    if (this.bloomEffect) {
      this.bloomEffect.disableMultiLayerCompositing();
      debugLog.log(' GPU compositing disabled');
    }
  }

  public loadAudioAnalysisForGPU(analysisData: AudioFeatureData): void {
    if (this.audioTextureManager) {
      this.audioTextureManager.loadAudioAnalysis(analysisData);
      debugLog.log(' Audio analysis loaded into GPU textures');
    }
  }
}
</file>

<file path="lib/visualizer/effects/BloomEffect.ts">
import * as THREE from 'three';
import { EffectComposer } from 'three/examples/jsm/postprocessing/EffectComposer.js';
import { RenderPass } from 'three/examples/jsm/postprocessing/RenderPass.js';
import { UnrealBloomPass } from 'three/examples/jsm/postprocessing/UnrealBloomPass.js';
import { ShaderPass } from 'three/examples/jsm/postprocessing/ShaderPass.js';
import { VisualEffect, AudioAnalysisData, LiveMIDIData } from '@/types/visualizer';
import { MultiLayerCompositor } from '../core/MultiLayerCompositor';
import { debugLog } from '@/lib/utils';

export class BloomEffect implements VisualEffect {
  id = 'bloom';
  name = 'Bloom Post-Processing';
  description = 'Global bloom effect for all visualizations';
  enabled = true;
  parameters = {
    threshold: 0.25,  // Increased threshold to make bloom less sensitive
    strength: 0.1,    // Reduced strength for a softer glow
    radius: 0.4,      // Tighter radius for the glow
    exposure: 0.8     // Keep exposure neutral
  };

  private scene!: THREE.Scene;
  private camera!: THREE.Camera;
  private renderer!: THREE.WebGLRenderer;
  private composer!: EffectComposer;
  private bloomPass!: UnrealBloomPass;
  private finalPass!: ShaderPass;

  private renderPass!: RenderPass;
  
  // GPU compositing integration
  private useMultiLayerCompositing: boolean = false; // Disabled by default
  private multiLayerCompositor: MultiLayerCompositor | null = null;

  constructor() {
    debugLog.log(' BloomEffect constructor called');
  }

  init(scene: THREE.Scene, camera: THREE.Camera, renderer: THREE.WebGLRenderer): void {
    debugLog.log(' BloomEffect.init() called');
    this.scene = scene;
    this.camera = camera;
    this.renderer = renderer;

    this.setupComposer();
    this.setupMultiLayerCompositor();
    debugLog.log(' Bloom effect initialized');
  }

  private setupComposer() {
    // Create effect composer
    this.composer = new EffectComposer(this.renderer);

    // Add render pass
    this.renderPass = new RenderPass(this.scene, this.camera);
    this.composer.addPass(this.renderPass);

    // Add bloom pass
    const size = this.renderer.getSize(new THREE.Vector2());
    this.bloomPass = new UnrealBloomPass(
      new THREE.Vector2(size.x, size.y),
      this.parameters.strength,
      this.parameters.radius,
      this.parameters.threshold
    );
    this.composer.addPass(this.bloomPass);

    // Create final pass for exposure control
    const finalPassShader = {
      uniforms: {
        tDiffuse: { value: null },
        uExposure: { value: this.parameters.exposure }
      },
      vertexShader: `
        varying vec2 vUv;
        void main() {
          vUv = uv;
          gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
        }
      `,
      fragmentShader: `
        uniform sampler2D tDiffuse;
        uniform float uExposure;
        varying vec2 vUv;
        
        void main() {
          vec4 color = texture2D(tDiffuse, vUv);
          
          // Apply exposure
          color.rgb *= uExposure;
          
          // Gamma correction
          color.rgb = pow(color.rgb, vec3(1.0 / 2.2));
          
          gl_FragColor = color;
        }
      `
    };

    this.finalPass = new ShaderPass(finalPassShader);
    this.composer.addPass(this.finalPass);

    debugLog.log(' Bloom composer setup complete');
  }

  private setupMultiLayerCompositor(): void {
    try {
      const size = this.renderer.getSize(new THREE.Vector2());
      this.multiLayerCompositor = new MultiLayerCompositor(this.renderer, {
        width: size.x,
        height: size.y,
        enableBloom: true,
        enableAntialiasing: true,
        pixelRatio: window.devicePixelRatio || 1
      });
      
      // Create main 3D effects layer
      this.multiLayerCompositor.createLayer('main-3d', this.scene, this.camera, {
        blendMode: 'normal',
        opacity: 1.0,
        zIndex: 100,
        enabled: true
      });
      
      debugLog.log(' MultiLayerCompositor initialized (disabled by default)');
    } catch (error) {
      debugLog.error('Failed to initialize MultiLayerCompositor:', error);
      this.useMultiLayerCompositing = false;
    }
  }

  update(deltaTime: number, audioData: AudioAnalysisData, midiData: LiveMIDIData): void {
    // Keep bloom parameters more static for consistent white glow
    const intensity = Math.max(0.3, Math.min(midiData.activeNotes.length / 5.0, 1.0));
    
    // Much more subtle dynamic bloom - less variation to avoid color shifts
    this.bloomPass.strength = this.parameters.strength * (0.9 + intensity * 0.1);
    
    // Keep threshold more stable
    this.bloomPass.threshold = this.parameters.threshold * (1.0 + intensity * 0.1);
    
    // Keep exposure stable for consistent white color
    this.finalPass.uniforms.uExposure.value = this.parameters.exposure;
  }

  // Custom render method to replace the normal renderer.render call
  render(): void {
    if (this.useMultiLayerCompositing && this.multiLayerCompositor) {
      // Use GPU-based multi-layer compositing
      this.multiLayerCompositor.render();
    } else if (this.composer) {
      // Fallback to traditional composer
      this.composer.render();
    }
  }

  // Enable GPU compositing (for testing)
  public enableMultiLayerCompositing(): void {
    this.useMultiLayerCompositing = true;
    debugLog.log(' GPU compositing enabled');
  }

  // Disable GPU compositing (fallback to traditional)
  public disableMultiLayerCompositing(): void {
    this.useMultiLayerCompositing = false;
    debugLog.log(' GPU compositing disabled');
  }

  // Get the multi-layer compositor for external access
  public getMultiLayerCompositor(): MultiLayerCompositor | null {
    return this.multiLayerCompositor;
  }

  // Method to handle window resize
  handleResize(width: number, height: number): void {
    if (this.composer) {
      this.composer.setSize(width, height);
      this.bloomPass.setSize(width, height);
    }
    
    if (this.multiLayerCompositor) {
      this.multiLayerCompositor.resize(width, height);
    }
  }

  destroy(): void {
    if (this.composer) {
      this.composer.dispose();
    }
    
    if (this.multiLayerCompositor) {
      this.multiLayerCompositor.dispose();
    }
  }
}
</file>

<file path="lib/visualizer/effects/EffectDefinitions.ts">
import { EffectRegistry } from './EffectRegistry';
import { MetaballsEffect } from './MetaballsEffect';
import { ParticleNetworkEffect } from './ParticleNetworkEffect';
import { BloomEffect } from './BloomEffect';

// Register built-in effects at module import time
EffectRegistry.register({
  id: 'metaballs',
  name: 'MIDI Metaballs',
  description: 'Fluid droplet-like spheres that respond to MIDI notes',
  category: 'organic',
  version: '1.0.0',
  constructor: MetaballsEffect,
  defaultConfig: {}
});

EffectRegistry.register({
  id: 'particleNetwork',
  name: 'Particle Network',
  description: 'Glowing particle network that responds to MIDI and audio',
  category: 'particles',
  version: '1.0.0',
  constructor: ParticleNetworkEffect,
  defaultConfig: {}
});

EffectRegistry.register({
  id: 'bloom',
  name: 'Bloom Post-Processing',
  description: 'Global bloom post-processing effect',
  category: 'postfx',
  version: '1.0.0',
  constructor: BloomEffect,
  defaultConfig: {}
});
</file>

<file path="lib/visualizer/effects/EffectRegistry.ts">
import { debugLog } from '@/lib/utils';
import type { VisualEffect } from '@/types/visualizer';

export interface EffectConstructor {
  new (config?: any): VisualEffect;
}

export interface EffectDefinition {
  id: string;
  name: string;
  description: string;
  category?: string;
  version?: string;
  author?: string;
  constructor: EffectConstructor;
  defaultConfig?: any;
}

export class EffectRegistry {
  private static effects = new Map<string, EffectDefinition>();

  static register(effectDef: EffectDefinition): void {
    if (!effectDef?.id || !effectDef?.constructor) {
      debugLog.warn('Attempted to register invalid effect definition', effectDef);
      return;
    }
    this.effects.set(effectDef.id, effectDef);
    debugLog.log(`[EffectRegistry] Registered effect: ${effectDef.id}`);
  }

  static createEffect(effectId: string, config?: any): VisualEffect | null {
    const effectDef = this.effects.get(effectId);
    if (!effectDef) {
      debugLog.warn(`[EffectRegistry] Effect not found: ${effectId}`);
      return null;
    }
    try {
      return new effectDef.constructor(config ?? effectDef.defaultConfig);
    } catch (error) {
      debugLog.error(`[EffectRegistry] Failed to create effect ${effectId}:`, error);
      return null;
    }
  }

  static getAvailableEffects(): EffectDefinition[] {
    return Array.from(this.effects.values());
  }

  static getEffectById(id: string): EffectDefinition | null {
    return this.effects.get(id) ?? null;
  }

  static getRegisteredEffectIds(): string[] {
    return Array.from(this.effects.keys());
  }
}
</file>

<file path="lib/visualizer/effects/MetaballsEffect.ts">
import * as THREE from 'three';
import { VisualEffect, AudioAnalysisData, LiveMIDIData, MetaballConfig } from '@/types/visualizer';
import { debugLog } from '@/lib/utils';


export class MetaballsEffect implements VisualEffect {
  id = 'metaballs';
  name = 'MIDI Metaballs';
  description = 'Fluid droplet-like spheres that respond to MIDI notes';
  enabled = true;
  parameters: MetaballConfig;

  private scene!: THREE.Scene;
  private camera!: THREE.Camera;
  private renderer!: THREE.WebGLRenderer;
  private material!: THREE.ShaderMaterial;
  private mesh!: THREE.Mesh;
  private uniforms!: Record<string, THREE.IUniform>;

  // Camera animation state
  private baseCameraDistance = 3.0;
  private cameraOrbitRadius = 2.0;
  private cameraHeight = 1.0;
  private cameraSmoothing = 0.02;

  constructor(config: Partial<MetaballConfig> = {}) {
    this.parameters = {
      trailLength: 15,
      baseRadius: 0.25,
      smoothingFactor: 0.3,
      colorPalette: ['#CC66FF', '#33CCFF', '#FF9933'],
      animationSpeed: 0.8,
      noiseIntensity: 1.5,
      highlightColor: [0.8, 0.5, 1.0], // default purple
      ...config
    };
    
    this.setupUniforms();
  }


  private setupUniforms() {
    this.uniforms = {
      uTime: { value: 0.0 },
      uIntensity: { value: 1.0 },
      uResolution: { value: new THREE.Vector2(1024, 1024) },
      uCameraPos: { value: new THREE.Vector3(0.0, 0.0, 3.0) },
      uCameraTarget: { value: new THREE.Vector3(0.0, 0.0, 0.0) },
      uBaseRadius: { value: this.parameters.baseRadius },
      uSmoothingFactor: { value: this.parameters.smoothingFactor },
      uNoiseIntensity: { value: this.parameters.noiseIntensity },
      uAnimationSpeed: { value: this.parameters.animationSpeed },
      uHighlightColor: { value: new THREE.Color(...this.parameters.highlightColor) },
    };
  }

  init(scene: THREE.Scene, camera: THREE.Camera, renderer: THREE.WebGLRenderer): void {
    this.scene = scene;
    this.camera = camera;
    this.renderer = renderer;
    // Set resolution uniform based on renderer size
    const size = renderer.getSize(new THREE.Vector2());
    this.uniforms.uResolution.value.set(size.x, size.y);
    this.createMaterial();
    this.createMesh();
  }

  private createMaterial() {
    const vertexShader = `
      varying vec2 vUv;
      
      void main() {
        vUv = uv;
        gl_Position = vec4(position, 1.0);
      }
    `;

    const fragmentShader = `
      precision highp float;

      uniform float uTime;
      uniform float uIntensity;
      uniform vec2 uResolution;
      uniform vec3 uCameraPos;
      uniform vec3 uCameraTarget;
      uniform float uBaseRadius;
      uniform float uSmoothingFactor;
      uniform float uNoiseIntensity;
      uniform float uAnimationSpeed;
      uniform vec3 uHighlightColor;
      varying vec2 vUv;

      const int MAX_STEPS = 32;
      const float MIN_DIST = 0.0;
      const float MAX_DIST = 50.0;
      const float EPSILON = 0.002;

      // Gooey neon palette
      vec3 neon1 = vec3(0.7, 0.2, 1.0); // purple
      vec3 neon2 = vec3(0.2, 0.7, 1.0); // blue
      vec3 neon3 = vec3(0.9, 0.3, 0.8); // pink

      // 3D noise for organic movement
      vec3 random3(vec3 c) {
        float j = 4096.0 * sin(dot(c, vec3(17.0, 59.4, 15.0)));
        vec3 r;
        r.z = fract(512.0 * j);
        j *= 0.125;
        r.x = fract(512.0 * j);
        j *= 0.125;
        r.y = fract(512.0 * j);
        return r - 0.5;
      }
      float noise(vec3 p) {
        vec3 pi = floor(p);
        vec3 pf = p - pi;
        vec3 u = pf * pf * (3.0 - 2.0 * pf);
        return mix(mix(mix(dot(random3(pi + vec3(0, 0, 0)), pf - vec3(0, 0, 0)),
                          dot(random3(pi + vec3(1, 0, 0)), pf - vec3(1, 0, 0)), u.x),
                      mix(dot(random3(pi + vec3(0, 1, 0)), pf - vec3(0, 1, 0)),
                          dot(random3(pi + vec3(1, 1, 0)), pf - vec3(1, 1, 0)), u.x), u.y),
                  mix(mix(dot(random3(pi + vec3(0, 0, 1)), pf - vec3(0, 0, 1)),
                          dot(random3(pi + vec3(1, 0, 1)), pf - vec3(1, 0, 1)), u.x),
                      mix(dot(random3(pi + vec3(0, 1, 1)), pf - vec3(0, 1, 1)),
                          dot(random3(pi + vec3(1, 1, 1)), pf - vec3(1, 1, 1)), u.x), u.y), u.z);
      }
      float smin(float a, float b, float k) {
        float h = max(k - abs(a - b), 0.0) / k;
        return min(a, b) - h * h * h * k * (1.0 / 6.0);
      }
      float sphere(vec3 p, float s) {
        return length(p) - s;
      }
      float map(vec3 pos) {
        float t = uTime * uAnimationSpeed * 0.5;
        float intensity = 0.5 + uIntensity * 0.5;
        float noiseAmt = uNoiseIntensity * 0.05;
        vec3 sphere1Pos = vec3(sin(t) * 0.8, cos(t * 1.3) * 0.6, sin(t * 0.7) * 0.4);
        vec3 sphere2Pos = vec3(cos(t * 1.1) * 0.6, sin(t * 0.9) * 0.8, cos(t * 1.4) * 0.5);
        vec3 sphere3Pos = vec3(sin(t * 1.7) * 0.4, cos(t * 0.6) * 0.3, sin(t * 1.2) * 0.6);
        vec3 sphere4Pos = vec3(cos(t * 0.8) * 0.7, sin(t * 1.5) * 0.4, cos(t) * 0.3);
        sphere1Pos += vec3(sin(t * 2.3), cos(t * 1.9), sin(t * 2.7)) * noiseAmt;
        sphere2Pos += vec3(cos(t * 1.7), sin(t * 2.1), cos(t * 1.3)) * noiseAmt;
        sphere3Pos += vec3(sin(t * 3.1), cos(t * 2.5), sin(t * 1.8)) * noiseAmt;
        sphere4Pos += vec3(cos(t * 2.9), sin(t * 1.6), cos(t * 2.2)) * noiseAmt;
        float radius1 = uBaseRadius * 1.2 + intensity * 0.2;
        float radius2 = uBaseRadius * 1.0 + intensity * 0.15;
        float radius3 = uBaseRadius * 0.8 + intensity * 0.1;
        float radius4 = uBaseRadius * 0.6 + intensity * 0.1;
        float d1 = sphere(pos - sphere1Pos, radius1);
        float d2 = sphere(pos - sphere2Pos, radius2);
        float d3 = sphere(pos - sphere3Pos, radius3);
        float d4 = sphere(pos - sphere4Pos, radius4);
        float smoothness = uSmoothingFactor;
        float result = smin(d1, d2, smoothness);
        result = smin(result, d3, smoothness);
        result = smin(result, d4, smoothness);
        return result;
      }
      vec3 calcNormal(vec3 pos) {
        vec2 e = vec2(EPSILON, 0.0);
        return normalize(vec3(
          map(pos + e.xyy) - map(pos - e.xyy),
          map(pos + e.yxy) - map(pos - e.yxy),
          map(pos + e.yyx) - map(pos - e.yyx)
        ));
      }
      float rayMarch(vec3 ro, vec3 rd) {
        float dO = MIN_DIST;
        for (int i = 0; i < MAX_STEPS; i++) {
          vec3 p = ro + rd * dO;
          float dS = map(p);
          dO += dS;
          if (dO > MAX_DIST || abs(dS) < EPSILON) break;
        }
        return dO;
      }
      vec3 getNeonColor(vec3 pos, float fresnel, float edge, float core) {
        float mix1 = 0.5 + 0.5 * sin(pos.x * 2.0 + uTime * 0.7);
        float mix2 = 0.5 + 0.5 * cos(pos.y * 2.0 + uTime * 1.1);
        vec3 color = mix(neon1, neon2, mix1);
        color = mix(color, neon3, mix2 * fresnel);
        color += vec3(1.0, 0.7, 1.0) * pow(edge, 2.5) * 1.2;
        color += uHighlightColor * pow(core, 2.0) * 0.7;
        return color;
      }

      // Thickness approximation for more liquid look
      float getThickness(vec3 pos, vec3 normal) {
        // Sample SDF in both directions to estimate thickness
        float stepSize = 0.08;
        float t1 = abs(map(pos + normal * stepSize));
        float t2 = abs(map(pos - normal * stepSize));
        return 1.0 - clamp((t1 + t2) * 2.5, 0.0, 1.0); // 0 = thin, 1 = thick
      }

      // 3D value noise with trilinear interpolation
      float hash(vec3 p) {
        p = fract(p * 0.3183099 + .1);
        p *= 17.0;
        return fract(p.x * p.y * p.z * (p.x + p.y + p.z));
      }
      float valueNoise3D(vec3 p) {
        vec3 pi = floor(p);
        vec3 pf = fract(p);
        // 8 corners of the cube
        float a000 = hash(pi + vec3(0,0,0));
        float a100 = hash(pi + vec3(1,0,0));
        float a010 = hash(pi + vec3(0,1,0));
        float a110 = hash(pi + vec3(1,1,0));
        float a001 = hash(pi + vec3(0,0,1));
        float a101 = hash(pi + vec3(1,0,1));
        float a011 = hash(pi + vec3(0,1,1));
        float a111 = hash(pi + vec3(1,1,1));
        // Trilinear interpolation
        float k0 = a000;
        float k1 = a100 - a000;
        float k2 = a010 - a000;
        float k3 = a001 - a000;
        float k4 = a000 - a100 - a010 + a110;
        float k5 = a000 - a010 - a001 + a011;
        float k6 = a000 - a100 - a001 + a101;
        float k7 = -a000 + a100 + a010 - a110 + a001 - a101 - a011 + a111;
        vec3 u = pf;
        return k0 + k1 * u.x + k2 * u.y + k3 * u.z + k4 * u.x * u.y + k5 * u.y * u.z + k6 * u.z * u.x + k7 * u.x * u.y * u.z;
      }

      void main() {
        vec2 uv = (vUv - 0.5) * 2.0;
        
        // Apply aspect ratio correction to prevent stretching
        float aspectRatio = uResolution.x / uResolution.y;
        uv.x *= aspectRatio;
        
        vec3 cameraPos = uCameraPos;
        vec3 cameraTarget = uCameraTarget;
        vec3 cameraDir = normalize(cameraTarget - cameraPos);
        vec3 cameraRight = normalize(cross(cameraDir, vec3(0.0, 1.0, 0.0)));
        vec3 cameraUp = cross(cameraRight, cameraDir);
        vec3 rayDir = normalize(cameraDir + uv.x * cameraRight + uv.y * cameraUp);
        float dist = rayMarch(cameraPos, rayDir);
        vec4 finalColor = vec4(0.0);
        if (dist < MAX_DIST) {
          vec3 pos = cameraPos + rayDir * dist;
          vec3 normal = calcNormal(pos);
          float fresnel = pow(1.0 - max(0.0, dot(normal, -rayDir)), 2.5);
          float edge = smoothstep(0.0, 0.08, abs(map(pos)));
          float core = 1.0 - edge;
          float thickness = getThickness(pos, normal);
          // Water droplet color using value noise and reflection vector
          vec3 reflectDir = reflect(rayDir, normal);
          // Define unique offsets for each metaball
          vec3 offsets[4];
          offsets[0] = vec3(1.3, 2.1, 0.7);
          offsets[1] = vec3(-2.2, 0.5, 1.8);
          offsets[2] = vec3(0.9, -1.4, 2.3);
          offsets[3] = vec3(-1.7, 1.2, -2.5);
          vec3 colorSum = vec3(0.0);
          for (int i = 0; i < 4; i++) {
            vec3 metaballReflect = reflectDir + offsets[i];
            float noiseVal = valueNoise3D(metaballReflect * 2.0 + uTime * (1.0 + float(i) * 0.3));
            float modFactor = 0.8 + 0.2 * float(i); // unique per metaball
            colorSum += uHighlightColor * modFactor * noiseVal;
          }
          vec3 color = colorSum / 4.0;
          color = pow(color, vec3(7.0));
          // Add a subtle neon rim from before
          color = mix(color, getNeonColor(pos, fresnel, edge, core), 0.25 * fresnel);
          // Translucency: base alpha is very low, highlights/rims are subtle
          float alpha = 0.07 + 0.10 * thickness;
          alpha += 0.25 * fresnel;
          alpha += 0.10 * pow(core, 2.0);
          alpha = clamp(alpha, 0.0, 0.55);
          finalColor = vec4(color, alpha);
        }
        gl_FragColor = finalColor;
      }
    `;

    // Add shader compilation error checking
    try {
          this.material = new THREE.ShaderMaterial({
      vertexShader,
      fragmentShader,
      uniforms: this.uniforms,
      transparent: true,
      side: THREE.DoubleSide
    });
    } catch (error) {
      debugLog.error(' Shader compilation error:', error);
      // Fallback to basic material
      this.material = new THREE.MeshBasicMaterial({
        color: 0xff00ff,
        transparent: true,
        opacity: 0.8
      }) as any;
    }
  }

  private createMesh() {
    const geometry = new THREE.PlaneGeometry(2, 2);
    this.mesh = new THREE.Mesh(geometry, this.material);
    // Ensure metaballs render on top of other content and occlude it
    this.mesh.renderOrder = 9999; // very last
    this.material.depthWrite = true; // write depth so underlying particles are hidden
    this.material.depthTest = true; // keep depth testing enabled
    this.scene.add(this.mesh);
    this.mesh.position.set(0, 0, 0);
    this.mesh.scale.set(2, 2, 1); // Fill viewport
  }

  updateParameter(paramName: string, value: any): void {
    // Immediately update uniforms when parameters change
    if (!this.uniforms) return;
    
    switch (paramName) {
      case 'animationSpeed':
        this.uniforms.uAnimationSpeed.value = value;
        break;
      case 'baseRadius':
        this.uniforms.uBaseRadius.value = value;
        break;
      case 'smoothingFactor':
        this.uniforms.uSmoothingFactor.value = value;
        break;
      case 'noiseIntensity':
        this.uniforms.uNoiseIntensity.value = value;
        break;
      case 'highlightColor':
        this.uniforms.uHighlightColor.value.set(...value);
        break;
    }
  }

  update(deltaTime: number, audioData: AudioAnalysisData, midiData: LiveMIDIData): void {
    if (!this.uniforms) return;

    // Generic: sync all parameters to uniforms
    for (const key in this.parameters) {
      const uniformKey = 'u' + key.charAt(0).toUpperCase() + key.slice(1);
      if (this.uniforms[uniformKey]) {
        this.uniforms[uniformKey].value = this.parameters[key as keyof MetaballConfig];
      }
    }

    // Update time
    this.uniforms.uTime.value += deltaTime * this.parameters.animationSpeed;

    // Calculate intensity based on both audio and MIDI activity
    const midiIntensity = Math.min(midiData.activeNotes.length / 3.0, 1.0);
    const audioIntensity = audioData.volume;
    // Ensure we always have a good base intensity so metaballs are visible
    this.uniforms.uIntensity.value = Math.max(0.8, (midiIntensity + audioIntensity) * 1.2);

    // Animate camera based on MIDI notes
    this.updateCameraAnimation(midiData, audioData);

    // Debug log to see if we're getting MIDI data
    if (midiData.activeNotes.length > 0) {
      // Removed console.log to reduce console noise
    }

    // Update shader resolution to match actual canvas size (not bounding box)
    if (this.uniforms.uResolution && this.renderer) {
      const size = this.renderer.getSize(new THREE.Vector2());
      this.uniforms.uResolution.value.set(size.x, size.y);
    }

    // No conditional visibility logic here
  }

  private updateCameraAnimation(midiData: LiveMIDIData, audioData: AudioAnalysisData): void {
    const time = this.uniforms.uTime.value;
    
    // Base camera orbit animation
    let cameraAngle = time * 0.3;
    let cameraElevation = Math.sin(time * 0.2) * 0.3;
    let cameraDistance = this.baseCameraDistance;

    // MIDI-based camera effects
    if (midiData.activeNotes.length > 0) {
      // Use note pitches to influence camera position
      const avgPitch = midiData.activeNotes.reduce((sum, note) => sum + note.note, 0) / midiData.activeNotes.length;
      const normalizedPitch = (avgPitch - 60) / 48; // Normalize around middle C
      
      // Use note velocities for camera movement intensity
      const avgVelocity = midiData.activeNotes.reduce((sum, note) => sum + note.velocity, 0) / midiData.activeNotes.length / 127;
      
      // Pitch affects camera angle and height
      cameraAngle += normalizedPitch * 2.0; // Higher notes move camera clockwise
      cameraElevation += normalizedPitch * 0.8; // Higher notes raise camera
      
      // Velocity affects camera distance and orbit speed
      cameraDistance += avgVelocity * 1.5; // Louder notes move camera back
      cameraAngle += avgVelocity * Math.sin(time * 4.0) * 0.5; // Add velocity-based wobble
      
      // Multiple notes create more dynamic movement
      const noteCount = Math.min(midiData.activeNotes.length, 5);
      const complexity = noteCount / 5.0;
      cameraElevation += Math.sin(time * 3.0 + complexity * 2.0) * complexity * 0.3;
      
      // Add chord-based camera effects
      if (midiData.activeNotes.length >= 3) {
        // For chords, add orbital variation
        cameraAngle += Math.sin(time * 2.0) * 0.4;
        cameraDistance += Math.cos(time * 1.5) * 0.3;
      }
    }

    // Audio-based subtle effects
    const audioInfluence = audioData.volume * 0.3;
    cameraDistance += audioInfluence;
    cameraElevation += Math.sin(time * 5.0) * audioInfluence * 0.2;

    // Calculate new camera position
    const newCameraPos = new THREE.Vector3(
      Math.cos(cameraAngle) * cameraDistance,
      cameraElevation + this.cameraHeight,
      Math.sin(cameraAngle) * cameraDistance
    );

    // Smooth camera movement
    const currentPos = this.uniforms.uCameraPos.value;
    currentPos.lerp(newCameraPos, this.cameraSmoothing);

    // Keep camera target at the center (where metaballs are)
    const target = new THREE.Vector3(0, 0, 0);

    // Add subtle target movement based on intense MIDI activity
    if (midiData.activeNotes.length > 2) {
      const intensity = Math.min(midiData.activeNotes.length / 5.0, 1.0);
      target.x = Math.sin(time * 2.0) * intensity * 0.2;
      target.y = Math.cos(time * 1.5) * intensity * 0.1;
    }

    this.uniforms.uCameraTarget.value.copy(target);
  }

  destroy(): void {
    if (this.mesh) {
      this.scene.remove(this.mesh);
      this.mesh.geometry.dispose();
      this.material.dispose();
    }
  }
}
</file>

<file path="lib/visualizer/effects/ParticleNetworkEffect.ts">
import * as THREE from 'three';
import { VisualEffect, AudioAnalysisData, LiveMIDIData } from '@/types/visualizer';
import { debugLog } from '@/lib/utils';

interface Particle {
  position: THREE.Vector3;
  velocity: THREE.Vector3;
  life: number;
  maxLife: number;
  size: number;
  note: number;
  noteVelocity: number;
  track: string;
  // Add audio feature data for audio-triggered particles
  audioFeature?: string;
  audioValue?: number;
  spawnType: 'midi' | 'audio';
}

export class ParticleNetworkEffect implements VisualEffect {
  id = 'particleNetwork';
  name = 'MIDI & Audio Particle Network';
  description = 'Glowing particle network that responds to MIDI notes and audio features';
  enabled = true;
  parameters = {
    maxParticles: 50,
    connectionDistance: 1.0,
    particleLifetime: 3.0,
    glowIntensity: 0.6,
    glowSoftness: 3.0,
    particleColor: [1.0, 1.0, 1.0],
    particleSize: 15.0,
    particleSpawning: 0.0, // Modulation destination for particle spawning (0-1)
    spawnThreshold: 0.5, // Threshold for when modulation signal spawns particles
  };

  private scene!: THREE.Scene;
  private camera!: THREE.Camera;
  private renderer!: THREE.WebGLRenderer;
  private particleSystem!: THREE.Points;
  private connectionLines!: THREE.LineSegments;
  private material!: THREE.ShaderMaterial;
  private uniforms!: Record<string, THREE.IUniform>;
  
  private particles: Particle[] = [];
  private geometry!: THREE.BufferGeometry;
  private positions!: Float32Array;
  private colors!: Float32Array;
  private sizes!: Float32Array;
  private lives!: Float32Array;
  
  // Connection data
  private connectionGeometry!: THREE.BufferGeometry;
  private connectionMaterial!: THREE.LineBasicMaterial;
  private connectionPositions!: Float32Array;
  private connectionColors!: Float32Array;
  private maxConnections: number = 500; // Limit connections
  private activeConnections: number = 0;
  
  // Performance optimization: skip frames
  private frameSkipCounter = 0;
  private frameSkipInterval = 2; // Update every 3rd frame for 30fps -> 10fps updates

  private instancedMesh!: THREE.InstancedMesh;
  private instanceColors!: Float32Array;
  private instanceLives!: Float32Array;
  private instanceSizes!: Float32Array;
  private dummyMatrix: THREE.Matrix4 = new THREE.Matrix4();

  // Audio spawning state
  private lastAudioSpawnTime: number = 0;
  private lastManualSpawnTime: number = 0;
  private currentAudioData: AudioAnalysisData | null = null;


  constructor() {
    this.setupUniforms();
  }

  

  private screenToWorld(screenX: number, screenY: number): THREE.Vector3 {
    // Convert screen px to NDC
    if (!this.renderer || !this.camera) return new THREE.Vector3();
    const size = this.renderer.getSize(new THREE.Vector2());
    const ndcX = (screenX / size.x) * 2 - 1;
    const ndcY = -((screenY / size.y) * 2 - 1);
    // Project to world at z=0
    const vector = new THREE.Vector3(ndcX, ndcY, 0.0);
    vector.unproject(this.camera);
    return vector;
  }


  private setupUniforms() {
    this.uniforms = {
      uTime: { value: 0.0 },
      uIntensity: { value: 1.0 },
      uGlowIntensity: { value: 1.0 }, // Reset to a reasonable default
      uGlowSoftness: { value: this.parameters.glowSoftness },
      uSizeMultiplier: { value: 1.0 } // Size control uniform
    };
  }

  init(scene: THREE.Scene, camera: THREE.Camera, renderer: THREE.WebGLRenderer): void {
    debugLog.log(' ParticleNetworkEffect.init() called');
    this.scene = scene;
    this.camera = camera;
    this.renderer = renderer;
    
    this.createParticleSystem();
    this.createConnectionSystem();
    
    // Initialize size multiplier based on current particleSize parameter
    if (this.uniforms) {
      this.uniforms.uSizeMultiplier.value = this.parameters.particleSize;
    }
    
    debugLog.log(' Particle Network initialized');
  }
  
  private createParticleSystem() {
    // Plane that will always face the camera (we'll orient in updateBuffers)
    const quad = new THREE.PlaneGeometry(1, 1);

    // Custom shader material for billboard
    const vertexShader = `
      attribute vec3 instanceColor;
      attribute float instanceLife;
      attribute float instanceSize;
      varying vec3 vColor;
      varying float vLife;
      varying float vSize;
      varying vec2 vUv;
      
      void main() {
        vColor = instanceColor;
        vLife  = instanceLife;
        vSize  = instanceSize;
        vUv    = uv;
        
        gl_Position = projectionMatrix * modelViewMatrix * instanceMatrix * vec4(position, 1.0);
      }
    `;

    const fragmentShader = `
      precision highp float;
      uniform float uGlowIntensity;
      uniform float uGlowSoftness;
      varying vec3 vColor;
      varying float vLife;
      varying float vSize;
      varying vec2 vUv;
      
      void main() {
        vec2 center = vUv - 0.5;
        float dist = length(center);
        if (dist > 0.5) discard; // keep circle
        
        // bloom using distance falloff with adjustable softness exponent
        float glow = pow(max(0.0, 0.5 - dist), uGlowSoftness);
        vec3 color = vColor * (1.0 + glow * uGlowIntensity * 0.6);
        
        float alpha = glow * vLife;
        gl_FragColor = vec4(color, alpha);
      }
    `;

    this.material = new THREE.ShaderMaterial({
      vertexShader,
      fragmentShader,
      uniforms: this.uniforms,
      transparent: true,
      blending: THREE.AdditiveBlending,
      depthWrite: false,
      depthTest: false,
      vertexColors: true
    });

    const maxParticles = this.parameters.maxParticles;
    this.instancedMesh = new THREE.InstancedMesh(quad, this.material, maxParticles);

    // Per-instance dynamic attributes
    this.instanceColors = new Float32Array(maxParticles * 3);
    this.instanceLives  = new Float32Array(maxParticles);
    this.instanceSizes  = new Float32Array(maxParticles);

    this.instancedMesh.instanceMatrix.setUsage(THREE.DynamicDrawUsage);
    this.instancedMesh.geometry.setAttribute(
      'instanceColor',
      new THREE.InstancedBufferAttribute(this.instanceColors, 3, false)
    );
    this.instancedMesh.geometry.setAttribute(
      'instanceLife',
      new THREE.InstancedBufferAttribute(this.instanceLives, 1, false)
    );
    this.instancedMesh.geometry.setAttribute(
      'instanceSize',
      new THREE.InstancedBufferAttribute(this.instanceSizes, 1, false)
    );

    // Initialize with a few default particles to make the effect visible
    this.initializeDefaultParticles();

    this.scene.add(this.instancedMesh);
  }

  private initializeDefaultParticles() {
    // Add a few default particles to ensure the system renders
    for (let i = 0; i < 5; i++) {
      const particle = this.createParticle(60 + i, 64, 'default');
      this.particles.push(particle);
    }
    this.updateBuffers();
  }
  
  private getRandomSpawnPosition(): THREE.Vector3 {
    // Spawn across entire viewport in world coordinates
    const x = (Math.random() - 0.5) * 4; // -2 to +2 in world space
    const y = (Math.random() - 0.5) * 4; // -2 to +2 in world space
    const z = 0;
    return new THREE.Vector3(x, y, z);
  }
  
  private createParticle(note: number, velocity: number, track: string, spawnType: 'midi' | 'audio' = 'midi', audioFeature?: string, audioValue?: number): Particle {
    // Spawn inside current viewport bounds
    const position = this.getRandomSpawnPosition();
    
    // Give them a random direction to drift in
    const vel = new THREE.Vector3(
      (Math.random() - 0.5) * 0.02,
      (Math.random() - 0.5) * 0.02,
      (Math.random() - 0.5) * 0.02
    );
    
    // Calculate size based on spawn type
    let size: number;
    if (spawnType === 'audio' && audioValue !== undefined) {
      // Audio particles: size based on audio value
      size = this.parameters.particleSize * (0.5 + audioValue * 1.5);
    } else {
      // MIDI particles: size based on velocity
      size = 3.0 + (velocity / 127) * 5.0;
    }
    
    return {
      position,
      velocity: vel,
      life: 1.0,
      maxLife: this.parameters.particleLifetime,
      size,
      note,
      noteVelocity: velocity,
      track,
      audioFeature,
      audioValue,
      spawnType
    };
  }
  
  private getNoteColor(note: number, velocity: number, spawnType: 'midi' | 'audio' = 'midi', audioValue?: number): THREE.Color {
    const baseColor = new THREE.Color(
      this.parameters.particleColor[0],
      this.parameters.particleColor[1], 
      this.parameters.particleColor[2]
    );
    
    if (spawnType === 'audio' && audioValue !== undefined) {
      // Audio particles: vary hue based on audio value
      const hue = (audioValue * 0.3) % 1.0;
      const audioColor = new THREE.Color().setHSL(hue, 0.7, 0.6);
      return audioColor.lerp(baseColor, 0.5);
    } else {
      // MIDI particles: note-based color
      const hue = (note % 12) / 12;
      const saturation = 0.4 + (velocity / 127) * 0.3;
      const lightness = 0.5 + (velocity / 127) * 0.2;
      
      const noteColor = new THREE.Color();
      noteColor.setHSL(hue, saturation, lightness);
      return noteColor.lerp(baseColor, 0.3);
    }
  }
  
  private updateParticles(deltaTime: number, midiData: LiveMIDIData, audioData?: AudioAnalysisData) {
    // Add new particles for active MIDI notes
    midiData.activeNotes.forEach(noteData => {
      if (this.particles.length < this.parameters.maxParticles) {
        // Check if we already have a recent particle for this note
        const hasRecentParticle = this.particles.some(p => 
          p.note === noteData.note && p.life > 0.8 && p.spawnType === 'midi'
        );
        
        if (!hasRecentParticle) {
          const particle = this.createParticle(noteData.note, noteData.velocity, noteData.track, 'midi');
          this.particles.push(particle);
        }
      }
    });
    
    // Spawn particles based on particleSpawning parameter (manual or audio-modulated)
    if (this.parameters.particleSpawning >= this.parameters.spawnThreshold) {
      this.spawnManualParticles(deltaTime);
    }
    
    // Update existing particles
    for (let i = this.particles.length - 1; i >= 0; i--) {
      const particle = this.particles[i];
      
      // Update life
      particle.life -= deltaTime / particle.maxLife;
      
      // Remove dead particles
      if (particle.life <= 0) {
        this.particles.splice(i, 1);
        continue;
      }
      
      // Update physics
      particle.velocity.multiplyScalar(0.98); // Damping
      
      // Apply velocity
      particle.position.add(particle.velocity);
    }
    
    this.updateBuffers();
    this.updateConnections();
  }
  
  
  private spawnManualParticles(deltaTime: number) {
    const currentTime = performance.now() / 1000;
    
    // Check cooldown for manual spawning
    if (currentTime - this.lastManualSpawnTime < 0.1) { // 100ms cooldown for manual testing
      return;
    }
    
    // Calculate spawn probability based on how much particleSpawning exceeds threshold
    const excessAmount = this.parameters.particleSpawning - this.parameters.spawnThreshold;
    const spawnProbability = Math.min(excessAmount * 2.0, 0.5); // Max 50% chance per frame
    
    if (Math.random() < spawnProbability && this.particles.length < this.parameters.maxParticles) {
      // Create manual test particle
      const particle = this.createParticle(
        60, // Default note
        Math.floor(this.parameters.particleSpawning * 127), // Use slider value as velocity
        'manual',
        'audio', // Use audio spawn type for visual distinction
        'manual',
        this.parameters.particleSpawning
      );
      
      this.particles.push(particle);
      this.lastManualSpawnTime = currentTime;
    }
  }
  
  
  private updateBuffers() {
    const cameraQuat = this.camera.quaternion;

    // Update per-instance data
    let index = 0;
    this.particles.forEach((particle) => {
      if (index >= this.parameters.maxParticles) return;
      // Compose matrix facing camera
      const baseFactor = 0.02; // world units per size unit
      // Clamp scale so full visible range reached at ~60% of slider (slider max ~50)
      const scaleMult = Math.min(this.parameters.particleSize, 30); // stop growing after 60%
      const scaleValue = particle.size * baseFactor * scaleMult;
      const scale = new THREE.Vector3(scaleValue, scaleValue, 1);
      this.dummyMatrix.compose(particle.position, cameraQuat, scale);
      this.instancedMesh.setMatrixAt(index, this.dummyMatrix);

      // Color
      const color = this.getNoteColor(particle.note, particle.noteVelocity, particle.spawnType, particle.audioValue);
      this.instanceColors[index * 3] = color.r;
      this.instanceColors[index * 3 + 1] = color.g;
      this.instanceColors[index * 3 + 2] = color.b;

      // Life & size
      this.instanceLives[index] = particle.life;
      this.instanceSizes[index] = particle.size;

      index++;
    });

    this.instancedMesh.count = index;
    this.instancedMesh.instanceMatrix.needsUpdate = true;
    (this.instancedMesh.geometry.getAttribute('instanceColor') as THREE.InstancedBufferAttribute).needsUpdate = true;
    (this.instancedMesh.geometry.getAttribute('instanceLife') as THREE.InstancedBufferAttribute).needsUpdate = true;
    (this.instancedMesh.geometry.getAttribute('instanceSize') as THREE.InstancedBufferAttribute).needsUpdate = true;
  }
  
  private createConnectionSystem() {
    // Create a single geometry for all connections
    this.connectionGeometry = new THREE.BufferGeometry();
    this.connectionPositions = new Float32Array(this.maxConnections * 6); // 2 points per line * 3 coords
    this.connectionColors = new Float32Array(this.maxConnections * 6); // 2 points per line * 3 colors
    
    this.connectionGeometry.setAttribute('position', new THREE.BufferAttribute(this.connectionPositions, 3));
    this.connectionGeometry.setAttribute('color', new THREE.BufferAttribute(this.connectionColors, 3));
    
    this.connectionMaterial = new THREE.LineBasicMaterial({
      vertexColors: true,
      transparent: true,
      opacity: 0.8,
      blending: THREE.AdditiveBlending,
      depthTest: false
    });
    
    this.connectionLines = new THREE.LineSegments(this.connectionGeometry, this.connectionMaterial);
    this.scene.add(this.connectionLines);
  }

  private updateConnections() {
    // Reset connection count
    this.activeConnections = 0;
    
    // Clear all connection data
    this.connectionPositions.fill(0);
    this.connectionColors.fill(0);
    
    // Create new connections (limit to prevent performance issues)
    let connectionCount = 0;
    for (let i = 0; i < this.particles.length - 1 && connectionCount < this.maxConnections; i++) {
      for (let j = i + 1; j < this.particles.length && connectionCount < this.maxConnections; j++) {
        const p1 = this.particles[i];
        const p2 = this.particles[j];
        const distance = p1.position.distanceTo(p2.position);
        
        if (distance < this.parameters.connectionDistance) {
          this.createConnection(p1, p2, distance, connectionCount);
          connectionCount++;
        }
      }
    }
    
    // Update geometry
    this.connectionGeometry.attributes.position.needsUpdate = true;
    this.connectionGeometry.attributes.color.needsUpdate = true;
    this.connectionGeometry.setDrawRange(0, connectionCount * 2); // 2 vertices per line
  }

  private createConnection(p1: Particle, p2: Particle, distance: number, index: number) {
    const strength = (1.0 - distance / this.parameters.connectionDistance) * 
                    Math.min(p1.life, p2.life) * 
                    ((p1.noteVelocity + p2.noteVelocity) / 254);
    
    const color = new THREE.Color().lerpColors(
      this.getNoteColor(p1.note, p1.noteVelocity),
      this.getNoteColor(p2.note, p2.noteVelocity),
      0.5
    );
    
    // Set positions for both points of the line
    const posIndex = index * 6;
    this.connectionPositions[posIndex] = p1.position.x;
    this.connectionPositions[posIndex + 1] = p1.position.y;
    this.connectionPositions[posIndex + 2] = p1.position.z;
    this.connectionPositions[posIndex + 3] = p2.position.x;
    this.connectionPositions[posIndex + 4] = p2.position.y;
    this.connectionPositions[posIndex + 5] = p2.position.z;
    
    // Set colors for both points of the line
    const colorIndex = index * 6;
    this.connectionColors[colorIndex] = color.r * strength;
    this.connectionColors[colorIndex + 1] = color.g * strength;
    this.connectionColors[colorIndex + 2] = color.b * strength;
    this.connectionColors[colorIndex + 3] = color.r * strength;
    this.connectionColors[colorIndex + 4] = color.g * strength;
    this.connectionColors[colorIndex + 5] = color.b * strength;
  }

  updateParameter(paramName: string, value: any): void {
    // Immediately update parameters for real-time control
    switch (paramName) {
      case 'maxParticles':
        // This affects the next particle creation cycle
        break;
      case 'connectionDistance':
        // This affects connection calculations in updateConnections
        break;
      case 'particleLifetime':
        // This affects particle creation
        break;
      case 'glowIntensity':
        if (this.uniforms) this.uniforms.uGlowIntensity.value = value;
        break;
      case 'glowSoftness':
        this.parameters.glowSoftness = value;
        if (this.uniforms) this.uniforms.uGlowSoftness.value = value;
        break;
      case 'particleColor':
        // This affects particle color generation
        break;
      case 'particleSize':
        this.parameters.particleSize = value;
        break;
      case 'particleSpawning':
        this.parameters.particleSpawning = value;
        break;
      case 'spawnThreshold':
        this.parameters.spawnThreshold = value;
        break;
    }
  }

  update(deltaTime: number, audioData: AudioAnalysisData, midiData: LiveMIDIData): void {
    if (!this.uniforms) {
      debugLog.warn(' Uniforms not initialized in ParticleNetworkEffect.update()');
      return;
    }

    // Store current audio data for particle spawning
    this.currentAudioData = audioData;

    // Generic: sync all parameters to uniforms
    for (const key in this.parameters) {
      const uniformKey = 'u' + key.charAt(0).toUpperCase() + key.slice(1);
      if (this.uniforms[uniformKey]) {
        this.uniforms[uniformKey].value = this.parameters[key as keyof typeof this.parameters];
      }
    }

    // Always update time and uniforms for smooth animation
    this.uniforms.uTime.value += deltaTime;
    this.uniforms.uIntensity.value = Math.max(0.5, Math.min(midiData.activeNotes.length / 3.0, 2.0));
    this.uniforms.uGlowIntensity.value = this.parameters.glowIntensity;
    
    // Ensure the instanced mesh is visible
    if (this.instancedMesh) {
      this.instancedMesh.visible = true;
    }
    
    // Skip heavy particle updates every few frames for performance
    this.frameSkipCounter++;
    if (this.frameSkipCounter >= this.frameSkipInterval) {
      this.frameSkipCounter = 0;
      this.updateParticles(deltaTime * this.frameSkipInterval, midiData, audioData);
    }
  }

  destroy(): void {
    if (this.instancedMesh) {
      this.scene.remove(this.instancedMesh);
      this.material.dispose();
    }
    
    if (this.connectionLines) {
      this.scene.remove(this.connectionLines);
      this.connectionGeometry.dispose();
      this.connectionMaterial.dispose();
    }
  }
}
</file>

<file path="lib/visualizer/effects/TestCubeEffect.ts">
import * as THREE from 'three';
import { VisualEffect, AudioAnalysisData, LiveMIDIData } from '@/types/visualizer';
import { debugLog } from '@/lib/utils';

export class TestCubeEffect implements VisualEffect {
  id = 'test-cube';
  name = 'Test Cube';
  description = 'Simple rotating cube for testing Three.js rendering';
  enabled = true;
  parameters = {};

  private scene!: THREE.Scene;
  private mesh!: THREE.Mesh;
  private rotationSpeed = 0.01;

  init(scene: THREE.Scene, camera: THREE.Camera, renderer: THREE.WebGLRenderer): void {
    debugLog.log(' TestCubeEffect.init() called');
    this.scene = scene;
    
    // Create a simple cube (make it bright and obvious)
    const geometry = new THREE.BoxGeometry(2, 2, 2);
    const material = new THREE.MeshBasicMaterial({ 
      color: 0xff0000, // Bright red
      wireframe: true  // Wireframe to ensure it's visible
    });
    
    this.mesh = new THREE.Mesh(geometry, material);
    this.mesh.position.set(0, 0, 0);
    
    this.scene.add(this.mesh);
    debugLog.log(' Test cube added to scene');
  }

  update(deltaTime: number, audioData: AudioAnalysisData, midiData: LiveMIDIData): void {
    if (!this.mesh) return;
    
    // Rotate the cube
    this.mesh.rotation.x += this.rotationSpeed;
    this.mesh.rotation.y += this.rotationSpeed * 0.7;
    
    // Scale based on audio intensity
    const scale = 1 + audioData.volume * 0.5;
    this.mesh.scale.setScalar(scale);
    
    // Change color based on MIDI activity
    if (midiData.activeNotes.length > 0) {
      (this.mesh.material as THREE.MeshBasicMaterial).color.setHex(0xff0000);
    } else {
      (this.mesh.material as THREE.MeshBasicMaterial).color.setHex(0x00ff00);
    }
  }

  destroy(): void {
    if (this.mesh) {
      this.scene.remove(this.mesh);
      this.mesh.geometry.dispose();
      (this.mesh.material as THREE.Material).dispose();
    }
  }
}
</file>

<file path="lib/visualizer/aspect-ratios.ts">
import { AspectRatioConfig } from '@/types/visualizer';

export const ASPECT_RATIOS: Record<string, AspectRatioConfig> = {
  mobile: {
    id: 'mobile',
    name: 'Mobile',
    width: 9,
    height: 16,
    maxWidth: '400px',
    maxHeight: '711px',
    className: 'max-w-md'
  },
  youtube: {
    id: 'youtube',
    name: 'YouTube',
    width: 16,
    height: 9,
    maxWidth: '1280px',
    maxHeight: '720px',
    className: 'max-w-4xl'
  },
  instagram: {
    id: 'instagram',
    name: 'Instagram',
    width: 1,
    height: 1,
    maxWidth: '600px',
    maxHeight: '600px',
    className: 'max-w-lg'
  },
  tiktok: {
    id: 'tiktok',
    name: 'TikTok',
    width: 9,
    height: 16,
    maxWidth: '360px',
    maxHeight: '640px',
    className: 'max-w-sm'
  },
  landscape: {
    id: 'landscape',
    name: 'Landscape',
    width: 16,
    height: 10,
    maxWidth: '1600px',
    maxHeight: '1000px',
    className: 'max-w-5xl'
  }
};

export function getAspectRatioConfig(id: string): AspectRatioConfig {
  return ASPECT_RATIOS[id] || ASPECT_RATIOS.mobile;
}

export function calculateCanvasSize(
  containerWidth: number,
  containerHeight: number,
  aspectRatio: AspectRatioConfig
): { width: number; height: number } {
  const { width: aspectWidth, height: aspectHeight } = aspectRatio;
  const aspectRatioValue = aspectWidth / aspectHeight;
  
  // Calculate maximum possible size within container
  const maxWidth = containerWidth;
  const maxHeight = containerHeight;
  
  // Calculate size maintaining aspect ratio
  let canvasWidth = maxWidth;
  let canvasHeight = maxWidth / aspectRatioValue;
  
  // If height exceeds container, scale down
  if (canvasHeight > maxHeight) {
    canvasHeight = maxHeight;
    canvasWidth = maxHeight * aspectRatioValue;
  }
  
  // Apply max constraints from aspect ratio config
  if (aspectRatio.maxWidth) {
    const maxWidthPx = parseInt(aspectRatio.maxWidth);
    if (canvasWidth > maxWidthPx) {
      canvasWidth = maxWidthPx;
      canvasHeight = maxWidthPx / aspectRatioValue;
    }
  }
  
  if (aspectRatio.maxHeight) {
    const maxHeightPx = parseInt(aspectRatio.maxHeight);
    if (canvasHeight > maxHeightPx) {
      canvasHeight = maxHeightPx;
      canvasWidth = maxHeightPx * aspectRatioValue;
    }
  }
  
  return {
    width: Math.floor(canvasWidth),
    height: Math.floor(canvasHeight)
  };
}
</file>

<file path="lib/auth.ts">
import { supabase } from './supabase'
import type { LoginCredentials, SignupCredentials, AuthProvider, User } from 'phonoglyph-types'

export class AuthService {
  // Email/Password Authentication
  static async signUpWithEmail({ email, password, name }: SignupCredentials) {
    const { data, error } = await supabase.auth.signUp({
      email,
      password,
      options: {
        data: {
          name: name || '',
        },
      },
    })

    if (error) {
      throw new Error(error.message)
    }

    return data
  }

  static async signInWithEmail({ email, password }: LoginCredentials) {
    const { data, error } = await supabase.auth.signInWithPassword({
      email,
      password,
    })

    if (error) {
      throw new Error(error.message)
    }

    return data
  }

  // OAuth Authentication
  static async signInWithOAuth({ provider, redirectTo }: AuthProvider) {
    const { data, error } = await supabase.auth.signInWithOAuth({
      provider,
      options: {
        redirectTo: redirectTo || `${window.location.origin}/auth/callback`,
      },
    })

    if (error) {
      throw new Error(error.message)
    }

    return data
  }

  // Session Management
  static async getCurrentUser(): Promise<User | null> {
    const { data: { user }, error } = await supabase.auth.getUser()
    
    if (error || !user) {
      return null
    }

    return {
      id: user.id,
      email: user.email || '',
      name: user.user_metadata?.name,
      image: user.user_metadata?.avatar_url,
      created_at: user.created_at || '',
      updated_at: user.updated_at || '',
    }
  }

  static async getSession() {
    const { data: { session }, error } = await supabase.auth.getSession()
    
    if (error) {
      throw new Error(error.message)
    }

    return session
  }

  static async signOut() {
    const { error } = await supabase.auth.signOut()
    
    if (error) {
      throw new Error(error.message)
    }
  }

  // Password Reset
  static async resetPassword(email: string) {
    const { error } = await supabase.auth.resetPasswordForEmail(email, {
      redirectTo: `${window.location.origin}/auth/reset-password`,
    })

    if (error) {
      throw new Error(error.message)
    }
  }

  static async updatePassword(password: string) {
    const { data, error } = await supabase.auth.updateUser({
      password,
    })

    if (error) {
      throw new Error(error.message)
    }

    return data
  }

  // Auth State Changes
  static onAuthStateChange(callback: (event: string, session: any) => void | Promise<void>) {
    return supabase.auth.onAuthStateChange(callback)
  }
}
</file>

<file path="lib/guest-user.ts">
/**
 * Guest User Service
 * Manages anonymous user sessions and temporary data storage
 */

export interface GuestUser {
  id: string
  isGuest: true
  sessionId: string
  createdAt: string
  tempData?: {
    projects: any[]
    preferences: Record<string, any>
  }
}

export interface GuestProject {
  id: string
  name: string
  guestUserId: string
  tempData: any
  createdAt: string
  expiresAt: string
}

class GuestUserService {
  private readonly GUEST_SESSION_KEY = 'guest_session_id'
  private readonly GUEST_DATA_KEY = 'guest_user_data'
  private readonly SESSION_DURATION = 24 * 60 * 60 * 1000 // 24 hours
  private readonly DATA_EXPIRY = 7 * 24 * 60 * 60 * 1000 // 7 days

  /**
   * Create or retrieve guest user session
   */
  createGuestSession(): GuestUser {
    let sessionId = this.getStoredSessionId()
    
    if (!sessionId || this.isSessionExpired(sessionId)) {
      sessionId = this.generateSessionId()
      this.storeSessionId(sessionId)
    }

    const guestUser: GuestUser = {
      id: `guest_${sessionId}`,
      isGuest: true,
      sessionId,
      createdAt: new Date().toISOString(),
      tempData: this.loadGuestData(sessionId)
    }

    return guestUser
  }

  /**
   * Get current guest user or null if no session
   */
  getCurrentGuestUser(): GuestUser | null {
    if (typeof window === 'undefined') return null
    
    const sessionId = this.getStoredSessionId()
    if (!sessionId || this.isSessionExpired(sessionId)) {
      return null
    }

    return {
      id: `guest_${sessionId}`,
      isGuest: true,
      sessionId,
      createdAt: this.getSessionCreatedAt(sessionId) || new Date().toISOString(),
      tempData: this.loadGuestData(sessionId)
    }
  }

  /**
   * Save temporary project data for guest user
   */
  saveGuestProject(project: Omit<GuestProject, 'id' | 'createdAt' | 'expiresAt'>): GuestProject {
    const guestProject: GuestProject = {
      ...project,
      id: `guest_project_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      createdAt: new Date().toISOString(),
      expiresAt: new Date(Date.now() + this.DATA_EXPIRY).toISOString()
    }

    const projects = this.getGuestProjects(project.guestUserId)
    projects.push(guestProject)
    this.saveGuestProjects(project.guestUserId, projects)

    return guestProject
  }

  /**
   * Get all guest projects for a user
   */
  getGuestProjects(guestUserId: string): GuestProject[] {
    if (typeof window === 'undefined') return []
    
    const key = `${this.GUEST_DATA_KEY}_${guestUserId}_projects`
    const stored = localStorage.getItem(key)
    
    if (!stored) return []

    try {
      const projects: GuestProject[] = JSON.parse(stored)
      // Filter out expired projects
      const validProjects = projects.filter(p => !this.isDataExpired(p.expiresAt))
      
      // If some projects were expired, save the filtered list
      if (validProjects.length !== projects.length) {
        this.saveGuestProjects(guestUserId, validProjects)
      }
      
      return validProjects
    } catch {
      return []
    }
  }

  /**
   * Convert guest data to user account
   */
  transferGuestDataToUser(guestUserId: string, realUserId: string): {
    projects: GuestProject[]
    preferences: Record<string, any>
  } {
    const projects = this.getGuestProjects(guestUserId)
    const preferences = this.getGuestPreferences(guestUserId)
    
    // Clean up guest data after transfer
    this.clearGuestData(guestUserId)
    
    return { projects, preferences }
  }

  /**
   * Clear all guest data and session
   */
  clearGuestSession(): void {
    if (typeof window === 'undefined') return
    
    const sessionId = this.getStoredSessionId()
    if (sessionId) {
      this.clearGuestData(`guest_${sessionId}`)
      localStorage.removeItem(this.GUEST_SESSION_KEY)
      localStorage.removeItem(`${this.GUEST_SESSION_KEY}_created`)
    }
  }

  /**
   * Check if user should see conversion prompts
   */
  shouldShowConversionPrompt(guestUser: GuestUser): boolean {
    const projects = this.getGuestProjects(guestUser.id)
    const sessionAge = Date.now() - new Date(guestUser.createdAt).getTime()
    const hasProjects = projects.length > 0
    const isOldSession = sessionAge > 2 * 60 * 60 * 1000 // 2 hours

    return hasProjects || isOldSession
  }

  // Private helper methods
  private generateSessionId(): string {
    return `${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
  }

  private getStoredSessionId(): string | null {
    if (typeof window === 'undefined') return null
    return localStorage.getItem(this.GUEST_SESSION_KEY)
  }

  private storeSessionId(sessionId: string): void {
    if (typeof window === 'undefined') return
    localStorage.setItem(this.GUEST_SESSION_KEY, sessionId)
    localStorage.setItem(`${this.GUEST_SESSION_KEY}_created`, new Date().toISOString())
  }

  private getSessionCreatedAt(sessionId: string): string | null {
    if (typeof window === 'undefined') return null
    return localStorage.getItem(`${this.GUEST_SESSION_KEY}_created`)
  }

  private isSessionExpired(sessionId: string): boolean {
    const createdAt = this.getSessionCreatedAt(sessionId)
    if (!createdAt) return true
    
    const sessionAge = Date.now() - new Date(createdAt).getTime()
    return sessionAge > this.SESSION_DURATION
  }

  private isDataExpired(expiresAt: string): boolean {
    return new Date(expiresAt).getTime() < Date.now()
  }

  private loadGuestData(sessionId: string): GuestUser['tempData'] {
    if (typeof window === 'undefined') return undefined
    
    const key = `${this.GUEST_DATA_KEY}_guest_${sessionId}`
    const stored = localStorage.getItem(key)
    
    if (!stored) return { projects: [], preferences: {} }

    try {
      return JSON.parse(stored)
    } catch {
      return { projects: [], preferences: {} }
    }
  }

  private saveGuestProjects(guestUserId: string, projects: GuestProject[]): void {
    if (typeof window === 'undefined') return
    
    const key = `${this.GUEST_DATA_KEY}_${guestUserId}_projects`
    localStorage.setItem(key, JSON.stringify(projects))
  }

  private getGuestPreferences(guestUserId: string): Record<string, any> {
    if (typeof window === 'undefined') return {}
    
    const key = `${this.GUEST_DATA_KEY}_${guestUserId}_preferences`
    const stored = localStorage.getItem(key)
    
    if (!stored) return {}

    try {
      return JSON.parse(stored)
    } catch {
      return {}
    }
  }

  private clearGuestData(guestUserId: string): void {
    if (typeof window === 'undefined') return
    
    const keys = [
      `${this.GUEST_DATA_KEY}_${guestUserId}`,
      `${this.GUEST_DATA_KEY}_${guestUserId}_projects`,
      `${this.GUEST_DATA_KEY}_${guestUserId}_preferences`
    ]
    
    keys.forEach(key => localStorage.removeItem(key))
  }
}

export const guestUserService = new GuestUserService()
</file>

<file path="lib/supabase.ts">
import { createClient } from '@supabase/supabase-js'
import { debugLog } from '@/lib/utils';

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY

const isDummyConfig = !supabaseUrl || !supabaseAnonKey;

if (isDummyConfig && typeof window !== 'undefined') {
  debugLog.error(' SUPABASE NOT CONFIGURED! Auth and database will not work.');
}

export const supabase = createClient(
  supabaseUrl || 'https://dummy.supabase.co',
  supabaseAnonKey || 'dummy-key'
)
</file>

<file path="lib/supabase.ts">
import { createClient } from '@supabase/supabase-js'
import { debugLog } from '@/lib/utils';

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY

const isDummyConfig = !supabaseUrl || !supabaseAnonKey;

if (isDummyConfig && typeof window !== 'undefined') {
  debugLog.error(' SUPABASE NOT CONFIGURED! Auth and database will not work.');
}

export const supabase = createClient(
  supabaseUrl || 'https://dummy.supabase.co',
  supabaseAnonKey || 'dummy-key'
)
</file>

<file path="lib/trpc-links.ts">
import { httpLink, TRPCLink } from '@trpc/client';
import type { AppRouter } from '../../../api/src/routers';
import { supabase } from './supabase';
// Minimal observable implementation for tRPC custom links
function observable<T>(subscribe: (observer: { next: (value: T) => void; error?: (err: any) => void; complete?: () => void; }) => void) {
  return {
    subscribe(observer: { next: (value: T) => void; error?: (err: any) => void; complete?: () => void; }) {
      subscribe(observer);
      return { unsubscribe() {} };
    },
    pipe() { return this; }, // no-op pipe for tRPC compatibility
  };
}
import { guestUserService } from './guest-user';
import { debugLog } from '@/lib/utils';

// Global session cache to avoid multiple calls
let sessionCache: any = null;
let sessionPromise: Promise<any> | null = null;

/**
 * Get session with caching to avoid multiple calls
 */
const getSession = async () => {
  if (sessionCache) {
    return sessionCache;
  }
  
  if (sessionPromise) {
    return sessionPromise;
  }
  
  sessionPromise = supabase.auth.getSession();
  const result = await sessionPromise;
  sessionCache = result.data.session;
  sessionPromise = null;
  return sessionCache;
};

/**
 * A TRPCLink that waits for the Supabase session to be loaded before
 * continuing with requests. This prevents race conditions on page load.
 */
const authLink: TRPCLink<AppRouter> = () => {
  return ({ next, op }) => {
    return observable((observer) => {
      const attemptRequest = async (retryCount = 0) => {
        try {
          const session = await getSession();
          
          // If no session and we haven't retried too many times, wait and retry
          if (!session && retryCount < 10) {
            setTimeout(() => attemptRequest(retryCount + 1), (retryCount + 1) * 200);
            return;
          }
          
          // Create headers object
          const headers: Record<string, string> = {};
          
          // Add Authorization header if session exists
          if (session?.access_token) {
            headers['Authorization'] = `Bearer ${session.access_token}`;
          } else {
            // If no authenticated session, try to add guest session header
            const guestUser = guestUserService.getCurrentGuestUser();
            if (guestUser?.sessionId) {
              headers['x-guest-session'] = guestUser.sessionId;
            }
          }
          
          const newOp = {
            ...op,
            context: {
              ...op.context,
              headers,
            },
          };
          
          next(newOp).subscribe(observer);
        } catch (error) {
          debugLog.warn('Auth link error, attempting request without auth:', error);
          // If there's an error, still try to make the request without auth
          const newOp = { ...op, context: op.context };
          next(newOp).subscribe(observer);
        }
      };

      attemptRequest();

      return () => {};
    });
  };
};

// Clear session cache when auth state changes
supabase.auth.onAuthStateChange(() => {
  sessionCache = null;
  sessionPromise = null;
});

// Determine API URL for tRPC
const apiUrl =
  process.env.NEXT_PUBLIC_API_URL ||
  (typeof window !== 'undefined' ? 'https://api.phonoglyph.rheome.tools' : 'http://localhost:3001'); // fallback for SSR dev

// Debug logging to see what URL is being used
debugLog.log(' tRPC API URL Debug:', {
  envVar: process.env.NEXT_PUBLIC_API_URL,
  apiUrl,
  isClient: typeof window !== 'undefined',
  finalUrl: `${apiUrl}/api/trpc`,
  environment: process.env.NODE_ENV
});

// Validate API URL
if (!apiUrl && typeof window !== 'undefined') {
  debugLog.error(' NEXT_PUBLIC_API_URL is not set! This will cause API calls to fail.');
}

export const trpcLinks = [
  authLink,
  httpLink({
    url: `${apiUrl}/api/trpc`, // Use env variable or relative path
    fetch: async (url, options) => {
      try {
        // Get the current session
        const session = await getSession();
        // Create headers
        const headers: Record<string, string> = {
          'Content-Type': 'application/json',
          ...(options?.headers as Record<string, string> || {}),
        };
        // Add Authorization header if session exists
        if (session?.access_token) {
          headers['Authorization'] = `Bearer ${session.access_token}`;
        } else {
          // If no authenticated session, try to add guest session header
          const guestUser = guestUserService.getCurrentGuestUser();
          if (guestUser?.sessionId) {
            headers['x-guest-session'] = guestUser.sessionId;
          }
        }
        const response = await fetch(url, {
          ...(options || {}),
          headers
        });
        // Check if the response is ok
        if (!response.ok) {
          debugLog.warn(`HTTP ${response.status}: ${response.statusText} for ${url}`);
        }
        return response;
      } catch (error) {
        debugLog.error('Network error in tRPC request:', error);
        throw error;
      }
    }
  })
];
</file>

<file path="lib/trpc.ts">
import { createTRPCReact } from '@trpc/react-query';
import type { AppRouter } from '../../../api/src/routers';
import { trpcLinks } from './trpc-links';

// Create the tRPC React client for hooks
export const trpc = createTRPCReact<AppRouter>();

/**
 * We need a single TRPC client instance, which is used both for the React
 * hooks and for server-side usage.
 */
export const trpcClient = trpc.createClient({
  links: trpcLinks,
});
</file>

<file path="lib/utils.ts">
import { clsx, type ClassValue } from "clsx"
import { twMerge } from "tailwind-merge"

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs))
}

// Debug logging utility to control console spam
const DEBUG_ENABLED = process.env.NODE_ENV === 'development' && 
  (process.env.NEXT_PUBLIC_DEBUG_LOGGING === 'true' || 
   typeof window !== 'undefined' && (window as any).__DEBUG_LOGGING__);

export const debugLog = {
  log: (...args: any[]) => {
    if (DEBUG_ENABLED) {
      console.log(...args);
    }
  },
  warn: (...args: any[]) => {
    if (DEBUG_ENABLED) {
      console.warn(...args);
    }
  },
  error: (...args: any[]) => {
    // Always log errors regardless of debug setting
    console.error(...args);
  },
  info: (...args: any[]) => {
    if (DEBUG_ENABLED) {
      console.info(...args);
    }
  }
};

// Allow toggling debug logging in development
if (typeof window !== 'undefined' && process.env.NODE_ENV === 'development') {
  (window as any).__DEBUG_LOGGING__ = false;
  (window as any).__toggleDebugLogging = () => {
    (window as any).__DEBUG_LOGGING__ = !(window as any).__DEBUG_LOGGING__;
    console.log('Debug logging:', (window as any).__DEBUG_LOGGING__ ? 'enabled' : 'disabled');
  };
}
</file>

<file path="lib/validations.ts">
import { z } from "zod"
import { createProjectSchema, updateProjectSchema, type CreateProjectInput, type UpdateProjectInput } from "phonoglyph-types"

export const loginSchema = z.object({
  email: z.string().email("Please enter a valid email address"),
  password: z.string().min(6, "Password must be at least 6 characters"),
})

export const signupSchema = z.object({
  name: z.string().min(2, "Name must be at least 2 characters").optional(),
  email: z.string().email("Please enter a valid email address"),
  password: z.string().min(6, "Password must be at least 6 characters"),
  confirmPassword: z.string(),
}).refine((data) => data.password === data.confirmPassword, {
  message: "Passwords don't match",
  path: ["confirmPassword"],
})

export const resetPasswordSchema = z.object({
  email: z.string().email("Please enter a valid email address"),
})

export const updatePasswordSchema = z.object({
  password: z.string().min(6, "Password must be at least 6 characters"),
  confirmPassword: z.string(),
}).refine((data) => data.password === data.confirmPassword, {
  message: "Passwords don't match",
  path: ["confirmPassword"],
})

// Re-export shared schemas
export { createProjectSchema, updateProjectSchema }

export type LoginInput = z.infer<typeof loginSchema>
export type SignupInput = z.infer<typeof signupSchema>
export type ResetPasswordInput = z.infer<typeof resetPasswordSchema>
export type UpdatePasswordInput = z.infer<typeof updatePasswordSchema>
export type { CreateProjectInput, UpdateProjectInput }
</file>

<file path="services/audio-analysis-sandbox-service.ts">
import { trpc } from '@/lib/trpc';
import { debugLog } from '@/lib/utils';

export interface SandboxAnalysisData {
  transients: Array<{
    time: number;
    intensity: number;
    frequency: number;
  }>;
  chroma: Array<{
    time: number;
    pitch: number;
    confidence: number;
    note: string;
  }>;
  rms: Array<{
    time: number;
    value: number;
  }>;
  waveform: number[];
  metadata: {
    sampleRate: number;
    duration: number;
    bufferSize: number;
    analysisParams: any;
  };
}

export interface CachedSandboxAnalysis {
  id: string;
  fileMetadataId: string;
  stemType: string;
  analysisData: SandboxAnalysisData;
  waveformData: {
    points: number[];
    duration: number;
    sampleRate: number;
    markers: any[];
  };
  metadata: {
    sampleRate: number;
    duration: number;
    bufferSize: number;
    featuresExtracted: string[];
    analysisDuration: number;
  };
}

export class AudioAnalysisSandboxService {
  /**
   * Convert sandbox analysis data to the format expected by the existing cached analysis system
   */
  static convertToCachedFormat(sandboxAnalysis: SandboxAnalysisData, fileId: string, stemType: string = 'master'): CachedSandboxAnalysis {
    // Convert transients to the format expected by the existing system
    const transientMarkers = sandboxAnalysis.transients.map(t => ({
      time: t.time,
      type: 'transient',
      intensity: t.intensity,
      frequency: t.frequency
    }));

    // Convert chroma to pitch data
    const pitchData = sandboxAnalysis.chroma.map(c => ({
      time: c.time,
      pitch: c.pitch,
      confidence: c.confidence,
      note: c.note
    }));

    // Convert RMS to volume data
    const volumeData = sandboxAnalysis.rms.map(r => ({
      time: r.time,
      value: r.value
    }));

    // Create analysis data in the expected format
    const analysisData = {
      // Core features
      transients: sandboxAnalysis.transients,
      chroma: sandboxAnalysis.chroma,
      rms: sandboxAnalysis.rms,
      
      // Legacy format compatibility
      features: sandboxAnalysis.transients.map(t => ({
        time: t.time,
        type: 'transient',
        intensity: t.intensity
      })),
      pitch: pitchData,
      volume: volumeData,
      
      // Additional analysis data
      markers: transientMarkers,
      timeData: sandboxAnalysis.transients.map(t => t.time),
      frequencies: sandboxAnalysis.transients.map(t => t.frequency),
      
      // Required properties for SandboxAnalysisData
      waveform: sandboxAnalysis.waveform,
      metadata: sandboxAnalysis.metadata
    };

    return {
      id: `sandbox_${fileId}_${Date.now()}`,
      fileMetadataId: fileId,
      stemType,
      analysisData,
      waveformData: {
        points: sandboxAnalysis.waveform,
        duration: sandboxAnalysis.metadata.duration,
        sampleRate: sandboxAnalysis.metadata.sampleRate,
        markers: transientMarkers
      },
      metadata: {
        sampleRate: sandboxAnalysis.metadata.sampleRate,
        duration: sandboxAnalysis.metadata.duration,
        bufferSize: sandboxAnalysis.metadata.bufferSize,
        featuresExtracted: ['transients', 'chroma', 'rms', 'waveform'],
        analysisDuration: 0 // Will be set by the analysis process
      }
    };
  }

  /**
   * Save sandbox analysis to the backend cache
   */
  static async saveToCache(sandboxAnalysis: SandboxAnalysisData, fileId: string, stemType: string = 'master'): Promise<boolean> {
    try {
      const cachedFormat = this.convertToCachedFormat(sandboxAnalysis, fileId, stemType);
      
      // Note: Currently logging cached format - tRPC integration pending
      debugLog.log('Sandbox analysis cached format:', cachedFormat);
      
      return true;
    } catch (error) {
      debugLog.error('Failed to save sandbox analysis to cache:', error);
      return false;
    }
  }

  /**
   * Load sandbox analysis from the backend cache
   */
  static async loadFromCache(fileId: string, stemType: string = 'master'): Promise<SandboxAnalysisData | null> {
    try {
      // Note: Currently returning null - tRPC integration pending
      debugLog.log('Loading sandbox analysis from cache:', { fileId, stemType });
      
      return null;
    } catch (error) {
      debugLog.error('Failed to load sandbox analysis from cache:', error);
      return null;
    }
  }

  /**
   * Load existing cached analysis and convert to sandbox format
   */
  static convertFromCachedFormat(cachedAnalysis: any): SandboxAnalysisData | null {
    try {
      if (!cachedAnalysis || !cachedAnalysis.analysisData) {
        return null;
      }

      const analysisData = cachedAnalysis.analysisData;
      
      return {
        transients: analysisData.transients || [],
        chroma: analysisData.chroma || [],
        rms: analysisData.rms || [],
        waveform: cachedAnalysis.waveformData?.points || [],
        metadata: {
          sampleRate: cachedAnalysis.metadata?.sampleRate || 44100,
          duration: cachedAnalysis.metadata?.duration || 0,
          bufferSize: cachedAnalysis.metadata?.bufferSize || 1024,
          analysisParams: analysisData.analysisParams || {}
        }
      };
    } catch (error) {
      debugLog.error('Failed to convert cached analysis to sandbox format:', error);
      return null;
    }
  }

  /**
   * Compare sandbox analysis with existing cached analysis
   */
  static compareAnalysis(sandboxAnalysis: SandboxAnalysisData, cachedAnalysis: any): {
    transients: { sandbox: number; cached: number; difference: number };
    chroma: { sandbox: number; cached: number; difference: number };
    rms: { sandbox: number; cached: number; difference: number };
  } {
    const sandboxTransients = sandboxAnalysis.transients.length;
    const sandboxChroma = sandboxAnalysis.chroma.length;
    const sandboxRms = sandboxAnalysis.rms.length;

    const cachedTransients = cachedAnalysis?.analysisData?.transients?.length || 0;
    const cachedChroma = cachedAnalysis?.analysisData?.chroma?.length || 0;
    const cachedRms = cachedAnalysis?.analysisData?.rms?.length || 0;

    return {
      transients: {
        sandbox: sandboxTransients,
        cached: cachedTransients,
        difference: sandboxTransients - cachedTransients
      },
      chroma: {
        sandbox: sandboxChroma,
        cached: cachedChroma,
        difference: sandboxChroma - cachedChroma
      },
      rms: {
        sandbox: sandboxRms,
        cached: cachedRms,
        difference: sandboxRms - cachedRms
      }
    };
  }
}
</file>

<file path="test/auth-service.test.ts">
import { describe, it, expect, vi, beforeEach } from 'vitest'
import { AuthService } from '../lib/auth'

// Mock Supabase client with any types to avoid complex type matching
vi.mock('../lib/supabase', () => ({
  supabase: {
    auth: {
      signUp: vi.fn(),
      signInWithPassword: vi.fn(),
      signInWithOAuth: vi.fn(),
      getUser: vi.fn(),
      getSession: vi.fn(),
      signOut: vi.fn(),
      resetPasswordForEmail: vi.fn(),
      updateUser: vi.fn(),
    },
  },
}))

describe('AuthService', () => {
  beforeEach(() => {
    vi.clearAllMocks()
  })

  describe('signUpWithEmail', () => {
    it('should sign up user with email and password', async () => {
      const mockResponse = { 
        data: { user: { id: '123' }, session: null }, 
        error: null 
      }
      const { supabase } = await import('../lib/supabase')
      ;(supabase.auth.signUp as any).mockResolvedValue(mockResponse)

      const credentials = {
        email: 'test@example.com',
        password: 'password123',
        name: 'Test User'
      }

      const result = await AuthService.signUpWithEmail(credentials)

      expect(supabase.auth.signUp).toHaveBeenCalledWith({
        email: 'test@example.com',
        password: 'password123',
        options: {
          data: {
            name: 'Test User',
          },
        },
      })
      expect(result).toEqual(mockResponse.data)
    })

    it('should throw error on signup failure', async () => {
      const mockResponse = { 
        data: { user: null, session: null }, 
        error: { message: 'Signup failed' } 
      }
      const { supabase } = await import('../lib/supabase')
      ;(supabase.auth.signUp as any).mockResolvedValue(mockResponse)

      const credentials = {
        email: 'test@example.com',
        password: 'password123'
      }

      await expect(AuthService.signUpWithEmail(credentials))
        .rejects
        .toThrow('Signup failed')
    })
  })

  describe('signInWithEmail', () => {
    it('should sign in user with email and password', async () => {
      const mockResponse = { 
        data: { user: { id: '123' }, session: {} }, 
        error: null 
      }
      const { supabase } = await import('../lib/supabase')
      ;(supabase.auth.signInWithPassword as any).mockResolvedValue(mockResponse)

      const credentials = {
        email: 'test@example.com',
        password: 'password123'
      }

      const result = await AuthService.signInWithEmail(credentials)

      expect(supabase.auth.signInWithPassword).toHaveBeenCalledWith({
        email: 'test@example.com',
        password: 'password123',
      })
      expect(result).toEqual(mockResponse.data)
    })
  })

  describe('signInWithOAuth', () => {
    it('should initiate OAuth sign in', async () => {
      const mockResponse = { 
        data: { provider: 'google', url: 'https://oauth-url.com' }, 
        error: null 
      }
      const { supabase } = await import('../lib/supabase')
      ;(supabase.auth.signInWithOAuth as any).mockResolvedValue(mockResponse)

      // Mock window.location.origin for Node environment
      Object.defineProperty(global, 'window', {
        value: {
          location: { origin: 'http://localhost:3000' }
        },
        writable: true,
      })

      const authProvider = {
        provider: 'google' as const,
        redirectTo: 'http://localhost:3000/dashboard'
      }

      const result = await AuthService.signInWithOAuth(authProvider)

      expect(supabase.auth.signInWithOAuth).toHaveBeenCalledWith({
        provider: 'google',
        options: {
          redirectTo: 'http://localhost:3000/dashboard',
        },
      })
      expect(result).toEqual(mockResponse.data)
    })
  })

  describe('getCurrentUser', () => {
    it('should return formatted user data', async () => {
      const mockUser = {
        id: '123',
        email: 'test@example.com',
        user_metadata: { name: 'Test User' },
        created_at: '2023-01-01T00:00:00Z',
        updated_at: '2023-01-01T00:00:00Z',
        app_metadata: {},
        aud: 'authenticated',
      }
      const mockResponse = {
        data: { user: mockUser },
        error: null
      }
      const { supabase } = await import('../lib/supabase')
      ;(supabase.auth.getUser as any).mockResolvedValue(mockResponse)

      const result = await AuthService.getCurrentUser()

      expect(result).toEqual({
        id: '123',
        email: 'test@example.com',
        user_metadata: { name: 'Test User' },
        created_at: '2023-01-01T00:00:00Z',
        updated_at: '2023-01-01T00:00:00Z',
      })
    })

    it('should return null when no user', async () => {
      const mockResponse = { data: { user: null }, error: null }
      const { supabase } = await import('../lib/supabase')
      ;(supabase.auth.getUser as any).mockResolvedValue(mockResponse)

      const result = await AuthService.getCurrentUser()

      expect(result).toBeNull()
    })
  })
})
</file>

<file path="test/basic.test.ts">
import { describe, it, expect } from 'vitest'

describe('Frontend Tests', () => {
  it('should pass basic test', () => {
    expect(1 + 1).toBe(2)
  })

  it('should have proper environment', () => {
    expect(typeof window).toBe('object') // jsdom environment for React testing
  })
})
</file>

<file path="test/basic.test.ts">
import { describe, it, expect } from 'vitest'

describe('Frontend Tests', () => {
  it('should pass basic test', () => {
    expect(1 + 1).toBe(2)
  })

  it('should have proper environment', () => {
    expect(typeof window).toBe('object') // jsdom environment for React testing
  })
})
</file>

<file path="test/particle-audio-spawning.test.ts">
import { describe, it, expect, beforeEach } from 'vitest';
import { ParticleNetworkEffect } from '@/lib/visualizer/effects/ParticleNetworkEffect';
import { AudioAnalysisData, LiveMIDIData } from '@/types/visualizer';
import * as THREE from 'three';

describe('ParticleNetworkEffect Audio Spawning', () => {
  let effect: ParticleNetworkEffect;

  beforeEach(() => {
    effect = new ParticleNetworkEffect();
  });

  it('should have audio spawning parameters', () => {
    expect(effect.parameters.enableAudioSpawning).toBe(true);
    expect(effect.parameters.audioSpawnFeature).toBe('volume');
    expect(effect.parameters.audioSpawnThreshold).toBe(0.3);
    expect(effect.parameters.audioSpawnRate).toBe(0.1);
    expect(effect.parameters.audioParticleColor).toEqual([0.8, 0.4, 1.0]);
  });

  it('should handle audio feature value extraction', () => {
    const audioData: AudioAnalysisData = {
      frequencies: [],
      timeData: [],
      volume: 0.8,
      bass: 0.6,
      mid: 0.7,
      treble: 0.9
    };

    // Test different audio features
    const volumeValue = (effect as any).getAudioFeatureValue(audioData, 'volume');
    const bassValue = (effect as any).getAudioFeatureValue(audioData, 'bass');
    const midValue = (effect as any).getAudioFeatureValue(audioData, 'mid');
    const trebleValue = (effect as any).getAudioFeatureValue(audioData, 'treble');

    expect(volumeValue).toBe(0.8);
    expect(bassValue).toBe(0.6);
    expect(midValue).toBe(0.7);
    expect(trebleValue).toBe(0.9);
  });

  it('should update audio spawning parameters', () => {
    // Test parameter updates
    effect.updateParameter('enableAudioSpawning', false);
    effect.updateParameter('audioSpawnFeature', 'bass');
    effect.updateParameter('audioSpawnThreshold', 0.5);
    effect.updateParameter('audioSpawnRate', 0.2);
    effect.updateParameter('audioParticleColor', [1.0, 0.0, 0.0]);

    expect(effect.parameters.enableAudioSpawning).toBe(false);
    expect(effect.parameters.audioSpawnFeature).toBe('bass');
    expect(effect.parameters.audioSpawnThreshold).toBe(0.5);
    expect(effect.parameters.audioSpawnRate).toBe(0.2);
    expect(effect.parameters.audioParticleColor).toEqual([1.0, 0.0, 0.0]);
  });

  it('should create particles with correct spawn types', () => {
    const midiParticle = (effect as any).createParticle(60, 64, 'piano', 'midi');
    const audioParticle = (effect as any).createParticle(60, 64, 'audio', 'audio', 'volume', 0.8);

    expect(midiParticle.spawnType).toBe('midi');
    expect(audioParticle.spawnType).toBe('audio');
    expect(audioParticle.audioFeature).toBe('volume');
    expect(audioParticle.audioValue).toBe(0.8);
  });

  it('should generate different colors for MIDI vs audio particles', () => {
    const midiColor = (effect as any).getNoteColor(60, 64, 'midi');
    const audioColor = (effect as any).getNoteColor(60, 64, 'audio', 0.8);

    // Colors should be different (we can't predict exact values due to HSL calculations)
    expect(midiColor).toBeInstanceOf(THREE.Color);
    expect(audioColor).toBeInstanceOf(THREE.Color);
    
    // Audio color should use the audio particle color as base
    const expectedAudioColor = new THREE.Color(0.8, 0.4, 1.0);
    expect(audioColor.r).toBeCloseTo(expectedAudioColor.r, 1);
    expect(audioColor.g).toBeCloseTo(expectedAudioColor.g, 1);
    expect(audioColor.b).toBeCloseTo(expectedAudioColor.b, 1);
  });

  it('should calculate particle size correctly for different spawn types', () => {
    const midiParticle = (effect as any).createParticle(60, 64, 'piano', 'midi');
    const audioParticle = (effect as any).createParticle(60, 64, 'audio', 'audio', 'volume', 0.8);

    // MIDI particle size should be based on velocity
    expect(midiParticle.size).toBeGreaterThan(0);
    
    // Audio particle size should be based on audio value and audioParticleSize parameter
    expect(audioParticle.size).toBeGreaterThan(0);
    expect(audioParticle.size).toBeGreaterThan(midiParticle.size * 0.5); // Should be reasonably sized
  });

  it('should handle fallback audio feature values', () => {
    const audioData: AudioAnalysisData = {
      frequencies: [],
      timeData: [],
      volume: 0.5,
      bass: 0.3,
      mid: 0.4,
      treble: 0.6
    };

    // Test unknown feature falls back to volume
    const unknownValue = (effect as any).getAudioFeatureValue(audioData, 'unknown');
    expect(unknownValue).toBe(0.5); // Should fall back to volume
  });

  it('should handle rms and spectralCentroid feature mapping', () => {
    const audioData: AudioAnalysisData = {
      frequencies: [],
      timeData: [],
      volume: 0.7,
      bass: 0.3,
      mid: 0.4,
      treble: 0.8
    };

    // Test that rms maps to volume
    const rmsValue = (effect as any).getAudioFeatureValue(audioData, 'rms');
    expect(rmsValue).toBe(0.7);

    // Test that spectralCentroid maps to treble
    const spectralValue = (effect as any).getAudioFeatureValue(audioData, 'spectralCentroid');
    expect(spectralValue).toBe(0.8);
  });
});
</file>

<file path="test/protected-routes.test.tsx">
import { describe, it, expect, vi, beforeEach, Mock } from 'vitest'
import { render, screen, waitFor } from '@testing-library/react'
import React from 'react'
import { useRouter, useSearchParams } from 'next/navigation'
import { AuthGuard } from '@/components/auth/auth-guard'
import { useAuth } from '@/hooks/use-auth'

// Mock Next.js navigation
vi.mock('next/navigation', () => ({
  useRouter: vi.fn(),
  useSearchParams: vi.fn(),
}))

// Mock auth hook
vi.mock('@/hooks/use-auth', () => ({
  useAuth: vi.fn(),
}))

const mockPush = vi.fn()
const mockSearchParams = {
  get: vi.fn(),
}

beforeEach(() => {
  vi.clearAllMocks()
  ;(useRouter as Mock).mockReturnValue({
    push: mockPush,
  })
  ;(useSearchParams as Mock).mockReturnValue(mockSearchParams)
})

describe('AuthGuard Component', () => {
  const TestComponent = () => <div>Protected Content</div>

  it('shows loading spinner when authentication is loading', () => {
    ;(useAuth as Mock).mockReturnValue({
      user: null,
      loading: true,
    })

    render(
      <AuthGuard>
        <TestComponent />
      </AuthGuard>
    )

    const spinner = screen.getByTestId('auth-loading-spinner')
    expect(spinner).toBeInTheDocument()
    expect(screen.queryByText('Protected Content')).not.toBeInTheDocument()
  })

  it('renders children when user is authenticated', async () => {
    ;(useAuth as Mock).mockReturnValue({
      user: { id: '1', email: 'test@example.com' },
      loading: false,
    })

    render(
      <AuthGuard>
        <TestComponent />
      </AuthGuard>
    )

    await waitFor(() => {
      expect(screen.getByText('Protected Content')).toBeInTheDocument()
    })
  })

  it('redirects to login when user is not authenticated', async () => {
    ;(useAuth as Mock).mockReturnValue({
      user: null,
      loading: false,
    })

    // Mock window.location
    const mockLocation = {
      pathname: '/protected-route',
      origin: 'http://localhost:3000',
    }
    Object.defineProperty(window, 'location', {
      value: mockLocation,
      writable: true,
    })

    render(
      <AuthGuard>
        <TestComponent />
      </AuthGuard>
    )

    await waitFor(() => {
      expect(mockPush).toHaveBeenCalledWith(
        'http://localhost:3000/auth/login?redirectTo=%2Fprotected-route'
      )
    })
  })

  it('allows access when requireAuth is false', async () => {
    ;(useAuth as Mock).mockReturnValue({
      user: null,
      loading: false,
    })

    render(
      <AuthGuard requireAuth={false}>
        <TestComponent />
      </AuthGuard>
    )

    await waitFor(() => {
      expect(screen.getByText('Protected Content')).toBeInTheDocument()
    })
    expect(mockPush).not.toHaveBeenCalled()
  })

  it('redirects authenticated users away from auth pages', async () => {
    ;(useAuth as Mock).mockReturnValue({
      user: { id: '1', email: 'test@example.com' },
      loading: false,
    })

    mockSearchParams.get.mockReturnValue('/dashboard')

    // Mock window.location for auth page
    const mockLocation = {
      pathname: '/auth/login',
      origin: 'http://localhost:3000',
    }
    Object.defineProperty(window, 'location', {
      value: mockLocation,
      writable: true,
    })

    render(
      <AuthGuard>
        <TestComponent />
      </AuthGuard>
    )

    await waitFor(() => {
      expect(mockPush).toHaveBeenCalledWith('/dashboard')
    })
  })

  it('uses custom redirect URL', async () => {
    ;(useAuth as Mock).mockReturnValue({
      user: null,
      loading: false,
    })

    const customRedirect = '/custom-login'
    const mockLocation = {
      pathname: '/protected',
      origin: 'http://localhost:3000',
    }
    Object.defineProperty(window, 'location', {
      value: mockLocation,
      writable: true,
    })

    render(
      <AuthGuard redirectTo={customRedirect}>
        <TestComponent />
      </AuthGuard>
    )

    await waitFor(() => {
      expect(mockPush).toHaveBeenCalledWith(
        'http://localhost:3000/custom-login?redirectTo=%2Fprotected'
      )
    })
  })

  it('renders custom fallback during loading', () => {
    ;(useAuth as Mock).mockReturnValue({
      user: null,
      loading: true,
    })

    const CustomFallback = () => <div>Custom Loading...</div>

    render(
      <AuthGuard fallback={<CustomFallback />}>
        <TestComponent />
      </AuthGuard>
    )

    expect(screen.getByText('Custom Loading...')).toBeInTheDocument()
    expect(screen.queryByRole('progressbar', { hidden: true })).not.toBeInTheDocument()
  })

  it('handles authentication errors gracefully', async () => {
    const consoleSpy = vi.spyOn(console, 'error').mockImplementation(() => {})
    
    ;(useAuth as Mock).mockReturnValue({
      user: null,
      loading: false,
    })

    // Mock an error in window.location access
    Object.defineProperty(window, 'location', {
      get: () => {
        throw new Error('Location access error')
      },
    })

    render(
      <AuthGuard>
        <TestComponent />
      </AuthGuard>
    )

    await waitFor(() => {
      expect(consoleSpy).toHaveBeenCalledWith(
        'Auth guard error:',
        expect.any(Error)
      )
    })

    consoleSpy.mockRestore()
  })
})

describe('Route Protection Integration', () => {
  it('prevents access to dashboard without authentication', async () => {
    ;(useAuth as Mock).mockReturnValue({
      user: null,
      loading: false,
    })

    const mockLocation = {
      pathname: '/dashboard',
      origin: 'http://localhost:3000',
    }
    Object.defineProperty(window, 'location', {
      value: mockLocation,
      writable: true,
    })

    const DashboardPage = () => (
      <AuthGuard>
        <div>Dashboard Content</div>
      </AuthGuard>
    )

    render(<DashboardPage />)

    await waitFor(() => {
      expect(mockPush).toHaveBeenCalledWith(
        'http://localhost:3000/auth/login?redirectTo=%2Fdashboard'
      )
    })
    expect(screen.queryByText('Dashboard Content')).not.toBeInTheDocument()
  })

  it('allows access to profile page with authentication', async () => {
    ;(useAuth as Mock).mockReturnValue({
      user: { id: '1', email: 'test@example.com' },
      loading: false,
    })

    const ProfilePage = () => (
      <AuthGuard>
        <div>Profile Content</div>
      </AuthGuard>
    )

    render(<ProfilePage />)

    await waitFor(() => {
      expect(screen.getByText('Profile Content')).toBeInTheDocument()
    })
    expect(mockPush).not.toHaveBeenCalled()
  })
})
</file>

<file path="test/setup.ts">
import '@testing-library/jest-dom'
import { vi } from 'vitest'
import React from 'react'

// Make React available globally for JSX
global.React = React

// Mock window.location
Object.defineProperty(window, 'location', {
  value: {
    href: 'http://localhost:3000',
    origin: 'http://localhost:3000',
    pathname: '/',
    search: '',
    hash: '',
  },
  writable: true,
})

// Mock window.matchMedia
Object.defineProperty(window, 'matchMedia', {
  writable: true,
  value: vi.fn().mockImplementation(query => ({
    matches: false,
    media: query,
    onchange: null,
    addListener: vi.fn(), // deprecated
    removeListener: vi.fn(), // deprecated
    addEventListener: vi.fn(),
    removeEventListener: vi.fn(),
    dispatchEvent: vi.fn(),
  })),
})

// Mock ResizeObserver
global.ResizeObserver = vi.fn().mockImplementation(() => ({
  observe: vi.fn(),
  unobserve: vi.fn(),
  disconnect: vi.fn(),
}))
</file>

<file path="test/supabase-connection.test.ts">
import { describe, it, expect } from 'vitest'

describe('Supabase Configuration', () => {
  it('should have required environment variables defined', () => {
    // Mock environment variables for testing
    const mockEnv = {
      NEXT_PUBLIC_SUPABASE_URL: 'https://test.supabase.co',
      NEXT_PUBLIC_SUPABASE_ANON_KEY: 'test-anon-key'
    }
    
    // Verify the variables are defined
    expect(mockEnv.NEXT_PUBLIC_SUPABASE_URL).toBeDefined()
    expect(mockEnv.NEXT_PUBLIC_SUPABASE_ANON_KEY).toBeDefined()
    expect(mockEnv.NEXT_PUBLIC_SUPABASE_URL).toMatch(/https:\/\/.*\.supabase\.co/)
  })

  it('should create Supabase client successfully', async () => {
    // Mock the Supabase client import
    const mockCreateClient = (url: string, key: string) => ({
      auth: { getSession: () => Promise.resolve({ data: { session: null } }) },
      from: (table: string) => ({ select: () => Promise.resolve({ data: [], error: null }) })
    })

    const client = mockCreateClient('https://test.supabase.co', 'test-key')
    expect(client).toBeDefined()
    expect(client.auth).toBeDefined()
    expect(client.from).toBeDefined()
  })
})
</file>

<file path="test/supabase-connection.test.ts">
import { describe, it, expect } from 'vitest'

describe('Supabase Configuration', () => {
  it('should have required environment variables defined', () => {
    // Mock environment variables for testing
    const mockEnv = {
      NEXT_PUBLIC_SUPABASE_URL: 'https://test.supabase.co',
      NEXT_PUBLIC_SUPABASE_ANON_KEY: 'test-anon-key'
    }
    
    // Verify the variables are defined
    expect(mockEnv.NEXT_PUBLIC_SUPABASE_URL).toBeDefined()
    expect(mockEnv.NEXT_PUBLIC_SUPABASE_ANON_KEY).toBeDefined()
    expect(mockEnv.NEXT_PUBLIC_SUPABASE_URL).toMatch(/https:\/\/.*\.supabase\.co/)
  })

  it('should create Supabase client successfully', async () => {
    // Mock the Supabase client import
    const mockCreateClient = (url: string, key: string) => ({
      auth: { getSession: () => Promise.resolve({ data: { session: null } }) },
      from: (table: string) => ({ select: () => Promise.resolve({ data: [], error: null }) })
    })

    const client = mockCreateClient('https://test.supabase.co', 'test-key')
    expect(client).toBeDefined()
    expect(client.auth).toBeDefined()
    expect(client.from).toBeDefined()
  })
})
</file>

<file path="tests/audio-playback.test.ts">
import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';

// Mock Web Audio API
class MockAudioContext {
  state = 'running';
  sampleRate = 44100;
  currentTime = 0;
  destination = {};
  
  createBufferSource() {
    return {
      buffer: null,
      connect: vi.fn(),
      start: vi.fn(),
      stop: vi.fn()
    };
  }
  
  createGain() {
    return {
      gain: { value: 0.7 },
      connect: vi.fn()
    };
  }
  
  decodeAudioData(buffer: ArrayBuffer): Promise<AudioBuffer> {
    return Promise.resolve({
      duration: 10,
      sampleRate: 44100,
      numberOfChannels: 2,
      length: 441000,
      getChannelData: () => new Float32Array(441000),
      copyFromChannel: vi.fn(),
      copyToChannel: vi.fn()
    } as unknown as AudioBuffer);
  }
}

describe('Audio Playback Integration', () => {
  beforeEach(() => {
    // Setup mocks
    global.AudioContext = MockAudioContext as any;
    global.performance = {
      now: vi.fn(() => Date.now()),
      memory: {
        usedJSHeapSize: 50 * 1024 * 1024,
        jsHeapSizeLimit: 200 * 1024 * 1024
      }
    } as any;
  });

  afterEach(() => {
    vi.clearAllMocks();
  });

  it('should create audio context and decode audio buffers', async () => {
    const audioContext = new AudioContext();
    expect(audioContext).toBeDefined();
    expect(audioContext.sampleRate).toBe(44100);
    
    const mockBuffer = new ArrayBuffer(1024);
    const audioBuffer = await audioContext.decodeAudioData(mockBuffer);
    expect(audioBuffer).toBeDefined();
    expect(audioBuffer.duration).toBe(10);
  });

  it('should create gain nodes for volume control', () => {
    const audioContext = new AudioContext();
    const gainNode = audioContext.createGain();
    
    expect(gainNode).toBeDefined();
    expect(gainNode.gain.value).toBe(0.7);
  });

  it('should create buffer sources for playback', () => {
    const audioContext = new AudioContext();
    const source = audioContext.createBufferSource();
    
    expect(source).toBeDefined();
    expect(typeof source.start).toBe('function');
    expect(typeof source.stop).toBe('function');
    expect(typeof source.connect).toBe('function');
  });
});
</file>

<file path="tests/auth-service.test.ts">
import { describe, it, expect, vi, beforeEach } from 'vitest'
import { AuthService } from '../lib/auth'

// Mock Supabase client with any types to avoid complex type matching
vi.mock('../lib/supabase', () => ({
  supabase: {
    auth: {
      signUp: vi.fn(),
      signInWithPassword: vi.fn(),
      signInWithOAuth: vi.fn(),
      getUser: vi.fn(),
      getSession: vi.fn(),
      signOut: vi.fn(),
      resetPasswordForEmail: vi.fn(),
      updateUser: vi.fn(),
    },
  },
}))

describe('AuthService', () => {
  beforeEach(() => {
    vi.clearAllMocks()
  })

  describe('signUpWithEmail', () => {
    it('should sign up user with email and password', async () => {
      const mockResponse = { 
        data: { user: { id: '123' }, session: null }, 
        error: null 
      }
      const { supabase } = await import('../lib/supabase')
      ;(supabase.auth.signUp as any).mockResolvedValue(mockResponse)

      const credentials = {
        email: 'test@example.com',
        password: 'password123',
        name: 'Test User'
      }

      const result = await AuthService.signUpWithEmail(credentials)

      expect(supabase.auth.signUp).toHaveBeenCalledWith({
        email: 'test@example.com',
        password: 'password123',
        options: {
          data: {
            name: 'Test User',
          },
        },
      })
      expect(result).toEqual(mockResponse.data)
    })

    it('should throw error on signup failure', async () => {
      const mockResponse = { 
        data: { user: null, session: null }, 
        error: { message: 'Signup failed' } 
      }
      const { supabase } = await import('../lib/supabase')
      ;(supabase.auth.signUp as any).mockResolvedValue(mockResponse)

      const credentials = {
        email: 'test@example.com',
        password: 'password123'
      }

      await expect(AuthService.signUpWithEmail(credentials))
        .rejects
        .toThrow('Signup failed')
    })
  })

  describe('signInWithEmail', () => {
    it('should sign in user with email and password', async () => {
      const mockResponse = { 
        data: { user: { id: '123' }, session: {} }, 
        error: null 
      }
      const { supabase } = await import('../lib/supabase')
      ;(supabase.auth.signInWithPassword as any).mockResolvedValue(mockResponse)

      const credentials = {
        email: 'test@example.com',
        password: 'password123'
      }

      const result = await AuthService.signInWithEmail(credentials)

      expect(supabase.auth.signInWithPassword).toHaveBeenCalledWith({
        email: 'test@example.com',
        password: 'password123',
      })
      expect(result).toEqual(mockResponse.data)
    })
  })

  describe('signInWithOAuth', () => {
    it('should initiate OAuth sign in', async () => {
      const mockResponse = { 
        data: { provider: 'google', url: 'https://oauth-url.com' }, 
        error: null 
      }
      const { supabase } = await import('../lib/supabase')
      ;(supabase.auth.signInWithOAuth as any).mockResolvedValue(mockResponse)

      // Mock window.location.origin for Node environment
      Object.defineProperty(global, 'window', {
        value: {
          location: { origin: 'http://localhost:3000' }
        },
        writable: true,
      })

      const authProvider = {
        provider: 'google' as const,
        redirectTo: 'http://localhost:3000/dashboard'
      }

      const result = await AuthService.signInWithOAuth(authProvider)

      expect(supabase.auth.signInWithOAuth).toHaveBeenCalledWith({
        provider: 'google',
        options: {
          redirectTo: 'http://localhost:3000/dashboard',
        },
      })
      expect(result).toEqual(mockResponse.data)
    })
  })

  describe('getCurrentUser', () => {
    it('should return formatted user data', async () => {
      const mockUser = {
        id: '123',
        email: 'test@example.com',
        user_metadata: { name: 'Test User' },
        created_at: '2023-01-01T00:00:00Z',
        updated_at: '2023-01-01T00:00:00Z',
        app_metadata: {},
        aud: 'authenticated',
      }
      const mockResponse = {
        data: { user: mockUser },
        error: null
      }
      const { supabase } = await import('../lib/supabase')
      ;(supabase.auth.getUser as any).mockResolvedValue(mockResponse)

      const result = await AuthService.getCurrentUser()

      expect(result).toEqual({
        id: '123',
        email: 'test@example.com',
        user_metadata: { name: 'Test User' },
        created_at: '2023-01-01T00:00:00Z',
        updated_at: '2023-01-01T00:00:00Z',
      })
    })

    it('should return null when no user', async () => {
      const mockResponse = { data: { user: null }, error: null }
      const { supabase } = await import('../lib/supabase')
      ;(supabase.auth.getUser as any).mockResolvedValue(mockResponse)

      const result = await AuthService.getCurrentUser()

      expect(result).toBeNull()
    })
  })
})
</file>

<file path="tests/basic.test.ts">
import { describe, it, expect } from 'vitest'

describe('Frontend Tests', () => {
  it('should pass basic test', () => {
    expect(1 + 1).toBe(2)
  })

  it('should have proper environment', () => {
    expect(typeof window).toBe('object') // jsdom environment for React testing
  })
})
</file>

<file path="tests/protected-routes.test.tsx">
import { describe, it, expect, vi, beforeEach, Mock } from 'vitest'
import { render, screen, waitFor } from '@testing-library/react'
import React from 'react'
import { useRouter, useSearchParams } from 'next/navigation'
import { AuthGuard } from '@/components/auth/auth-guard'
import { useAuth } from '@/hooks/use-auth'

// Mock Next.js navigation
vi.mock('next/navigation', () => ({
  useRouter: vi.fn(),
  useSearchParams: vi.fn(),
}))

// Mock auth hook
vi.mock('@/hooks/use-auth', () => ({
  useAuth: vi.fn(),
}))

const mockPush = vi.fn()
const mockSearchParams = {
  get: vi.fn(),
}

beforeEach(() => {
  vi.clearAllMocks()
  ;(useRouter as Mock).mockReturnValue({
    push: mockPush,
  })
  ;(useSearchParams as Mock).mockReturnValue(mockSearchParams)
})

describe('AuthGuard Component', () => {
  const TestComponent = () => <div>Protected Content</div>

  it('shows loading spinner when authentication is loading', () => {
    ;(useAuth as Mock).mockReturnValue({
      user: null,
      loading: true,
    })

    render(
      <AuthGuard>
        <TestComponent />
      </AuthGuard>
    )

    const spinner = screen.getByTestId('auth-loading-spinner')
    expect(spinner).toBeInTheDocument()
    expect(screen.queryByText('Protected Content')).not.toBeInTheDocument()
  })

  it('renders children when user is authenticated', async () => {
    ;(useAuth as Mock).mockReturnValue({
      user: { id: '1', email: 'test@example.com' },
      loading: false,
    })

    render(
      <AuthGuard>
        <TestComponent />
      </AuthGuard>
    )

    await waitFor(() => {
      expect(screen.getByText('Protected Content')).toBeInTheDocument()
    })
  })

  it('redirects to login when user is not authenticated', async () => {
    ;(useAuth as Mock).mockReturnValue({
      user: null,
      loading: false,
    })

    // Mock window.location
    const mockLocation = {
      pathname: '/protected-route',
      origin: 'http://localhost:3000',
    }
    Object.defineProperty(window, 'location', {
      value: mockLocation,
      writable: true,
    })

    render(
      <AuthGuard>
        <TestComponent />
      </AuthGuard>
    )

    await waitFor(() => {
      expect(mockPush).toHaveBeenCalledWith(
        'http://localhost:3000/auth/login?redirectTo=%2Fprotected-route'
      )
    })
  })

  it('allows access when requireAuth is false', async () => {
    ;(useAuth as Mock).mockReturnValue({
      user: null,
      loading: false,
    })

    render(
      <AuthGuard requireAuth={false}>
        <TestComponent />
      </AuthGuard>
    )

    await waitFor(() => {
      expect(screen.getByText('Protected Content')).toBeInTheDocument()
    })
    expect(mockPush).not.toHaveBeenCalled()
  })

  it('redirects authenticated users away from auth pages', async () => {
    ;(useAuth as Mock).mockReturnValue({
      user: { id: '1', email: 'test@example.com' },
      loading: false,
    })

    mockSearchParams.get.mockReturnValue('/dashboard')

    // Mock window.location for auth page
    const mockLocation = {
      pathname: '/auth/login',
      origin: 'http://localhost:3000',
    }
    Object.defineProperty(window, 'location', {
      value: mockLocation,
      writable: true,
    })

    render(
      <AuthGuard>
        <TestComponent />
      </AuthGuard>
    )

    await waitFor(() => {
      expect(mockPush).toHaveBeenCalledWith('/dashboard')
    })
  })

  it('uses custom redirect URL', async () => {
    ;(useAuth as Mock).mockReturnValue({
      user: null,
      loading: false,
    })

    const customRedirect = '/custom-login'
    const mockLocation = {
      pathname: '/protected',
      origin: 'http://localhost:3000',
    }
    Object.defineProperty(window, 'location', {
      value: mockLocation,
      writable: true,
    })

    render(
      <AuthGuard redirectTo={customRedirect}>
        <TestComponent />
      </AuthGuard>
    )

    await waitFor(() => {
      expect(mockPush).toHaveBeenCalledWith(
        'http://localhost:3000/custom-login?redirectTo=%2Fprotected'
      )
    })
  })

  it('renders custom fallback during loading', () => {
    ;(useAuth as Mock).mockReturnValue({
      user: null,
      loading: true,
    })

    const CustomFallback = () => <div>Custom Loading...</div>

    render(
      <AuthGuard fallback={<CustomFallback />}>
        <TestComponent />
      </AuthGuard>
    )

    expect(screen.getByText('Custom Loading...')).toBeInTheDocument()
    expect(screen.queryByRole('progressbar', { hidden: true })).not.toBeInTheDocument()
  })

  it('handles authentication errors gracefully', async () => {
    const consoleSpy = vi.spyOn(console, 'error').mockImplementation(() => {})
    
    ;(useAuth as Mock).mockReturnValue({
      user: null,
      loading: false,
    })

    // Mock an error in window.location access
    Object.defineProperty(window, 'location', {
      get: () => {
        throw new Error('Location access error')
      },
    })

    render(
      <AuthGuard>
        <TestComponent />
      </AuthGuard>
    )

    await waitFor(() => {
      expect(consoleSpy).toHaveBeenCalledWith(
        'Auth guard error:',
        expect.any(Error)
      )
    })

    consoleSpy.mockRestore()
  })
})

describe('Route Protection Integration', () => {
  it('prevents access to dashboard without authentication', async () => {
    ;(useAuth as Mock).mockReturnValue({
      user: null,
      loading: false,
    })

    const mockLocation = {
      pathname: '/dashboard',
      origin: 'http://localhost:3000',
    }
    Object.defineProperty(window, 'location', {
      value: mockLocation,
      writable: true,
    })

    const DashboardPage = () => (
      <AuthGuard>
        <div>Dashboard Content</div>
      </AuthGuard>
    )

    render(<DashboardPage />)

    await waitFor(() => {
      expect(mockPush).toHaveBeenCalledWith(
        'http://localhost:3000/auth/login?redirectTo=%2Fdashboard'
      )
    })
    expect(screen.queryByText('Dashboard Content')).not.toBeInTheDocument()
  })

  it('allows access to profile page with authentication', async () => {
    ;(useAuth as Mock).mockReturnValue({
      user: { id: '1', email: 'test@example.com' },
      loading: false,
    })

    const ProfilePage = () => (
      <AuthGuard>
        <div>Profile Content</div>
      </AuthGuard>
    )

    render(<ProfilePage />)

    await waitFor(() => {
      expect(screen.getByText('Profile Content')).toBeInTheDocument()
    })
    expect(mockPush).not.toHaveBeenCalled()
  })
})
</file>

<file path="tests/setup.ts">
import '@testing-library/jest-dom'
import { vi } from 'vitest'
import React from 'react'

// Make React available globally for JSX
global.React = React

// Mock window.location
Object.defineProperty(window, 'location', {
  value: {
    href: 'http://localhost:3000',
    origin: 'http://localhost:3000',
    pathname: '/',
    search: '',
    hash: '',
  },
  writable: true,
})

// Mock window.matchMedia
Object.defineProperty(window, 'matchMedia', {
  writable: true,
  value: vi.fn().mockImplementation(query => ({
    matches: false,
    media: query,
    onchange: null,
    addListener: vi.fn(), // deprecated
    removeListener: vi.fn(), // deprecated
    addEventListener: vi.fn(),
    removeEventListener: vi.fn(),
    dispatchEvent: vi.fn(),
  })),
})

// Mock ResizeObserver
global.ResizeObserver = vi.fn().mockImplementation(() => ({
  observe: vi.fn(),
  unobserve: vi.fn(),
  disconnect: vi.fn(),
}))
</file>

<file path="tests/supabase-connection.test.ts">
import { describe, it, expect } from 'vitest'

describe('Supabase Configuration', () => {
  it('should have required environment variables defined', () => {
    // Mock environment variables for testing
    const mockEnv = {
      NEXT_PUBLIC_SUPABASE_URL: 'https://test.supabase.co',
      NEXT_PUBLIC_SUPABASE_ANON_KEY: 'test-anon-key'
    }
    
    // Verify the variables are defined
    expect(mockEnv.NEXT_PUBLIC_SUPABASE_URL).toBeDefined()
    expect(mockEnv.NEXT_PUBLIC_SUPABASE_ANON_KEY).toBeDefined()
    expect(mockEnv.NEXT_PUBLIC_SUPABASE_URL).toMatch(/https:\/\/.*\.supabase\.co/)
  })

  it('should create Supabase client successfully', async () => {
    // Mock the Supabase client import
    const mockCreateClient = (url: string, key: string) => ({
      auth: { getSession: () => Promise.resolve({ data: { session: null } }) },
      from: (table: string) => ({ select: () => Promise.resolve({ data: [], error: null }) })
    })

    const client = mockCreateClient('https://test.supabase.co', 'test-key')
    expect(client).toBeDefined()
    expect(client.auth).toBeDefined()
    expect(client.from).toBeDefined()
  })
})
</file>

<file path="types/audio-analysis.ts">
export interface AnalysisParams {
  transientThreshold: number;
  onsetThreshold: number;
  chromaSmoothing: number;
  rmsWindowSize: number;
  pitchConfidence: number;
  minNoteDuration: number;
}

export interface TransientData {
  time: number;
  intensity: number;
  frequency: number;
}

export interface ChromaData {
  time: number;
  pitch: number;
  confidence: number;
  note: string;
}

export interface RMSData {
  time: number;
  value: number;
}

export type AnalysisMethod = 'original' | 'enhanced' | 'both';
</file>

<file path="types/midi.ts">
// Re-export from centralized types package
export * from 'phonoglyph-types'
</file>

<file path="types/stem-audio-analysis.ts">
// Stem Audio Analysis Types for Story 5.2

export interface AudioFeature {
  type: 'rhythm' | 'pitch' | 'intensity' | 'timbre';
  value: number;
  confidence: number;
  timestamp: number;
}

export interface StemAnalysis {
  stemId: string;
  stemType: 'drums' | 'bass' | 'vocals' | 'other' | 'piano' | 'master'; // Includes master stem type
  features: {
    rhythm: AudioFeature[];
    pitch: AudioFeature[];
    intensity: AudioFeature[];
    timbre: AudioFeature[];
  };
  metadata: {
    bpm: number;
    key: string;
    energy: number;
    clarity: number; // Quality metric for Spleeter separation
  };
}

export interface StemProcessorConfig {
  bufferSize: number;
  analysisResolution: number;
  visualizationPreset?: string;
  deviceOptimization: 'mobile' | 'desktop' | 'auto';
  maxConcurrentStems: number;
}

export interface PerformanceMetrics {
  fps: number;
  analysisLatency: number;
  memoryUsage: number;
  cpuUsage: number;
  frameDrops: number;
}

export interface StemFeatureSet {
  stemType: StemAnalysis['stemType'];
  currentFeatures: Record<string, AudioFeature>;
  historicalFeatures: Record<string, AudioFeature[]>;
  correlationData: Record<string, number>; // Cross-stem correlations
}

export type VisualizationFeature = 
  | 'rms' 
  | 'spectralCentroid' 
  | 'spectralRolloff' 
  | 'loudness' 
  | 'perceptualSpread' 
  | 'spectralFlux'
  | 'mfcc'
  | 'chromaVector'
  | 'tempo'
  | 'rhythmPattern';

export interface AnalysisConfig {
  features: Set<VisualizationFeature>;
  bufferSize: number;
  frameRate: number;
  quality: 'low' | 'medium' | 'high';
  enableCrossStemAnalysis: boolean;
}

/**
 * Represents the detailed, time-series audio analysis data for a single track.
 * This is typically generated on the client-side by an analysis worker.
 * The keys are feature names (e.g., "rms", "spectralCentroid", "mfcc_0").
 * The values are Float32Array containing the value of that feature for each analysis frame.
 */
export interface AudioAnalysisDataForTrack {
  [feature: string]: Float32Array;
}
</file>

<file path="types/stem-visualization.ts">
// Simple types for the current stem visualization implementation
// These are the only types actually being used in the working system

export interface StemVisualizationMapping {
  stemType: 'drums' | 'bass' | 'vocals' | 'piano' | 'other' | 'master';
  enabled: boolean;
  priority: number;
  globalMultiplier: number;
  crossfade: number;
  solo: boolean;
  mute: boolean;
}

export interface VisualizationPreset {
  id: string;
  name: string;
  description: string;
  category: 'electronic' | 'rock' | 'classical' | 'ambient' | 'custom';
  tags: string[];
  mappings: Record<string, StemVisualizationMapping>;
  defaultSettings: {
    masterIntensity: number;
    transitionSpeed: number;
    backgroundAlpha: number;
    particleCount: number;
    qualityLevel: 'low' | 'medium' | 'high';
  };
  createdAt: string;
  updatedAt: string;
  userId?: string;
  isDefault: boolean;
  usageCount: number;
}

// Simple default preset for the current implementation
export const DEFAULT_PRESETS = [
  {
    id: 'default',
    name: 'Default',
    description: 'Default visualization preset',
    category: 'custom' as const,
    tags: ['default'],
    mappings: {},
    defaultSettings: {
      masterIntensity: 1.0,
      transitionSpeed: 1.0,
      backgroundAlpha: 0.1,
      particleCount: 100,
      qualityLevel: 'medium' as const
    },
    createdAt: new Date().toISOString(),
    updatedAt: new Date().toISOString(),
    isDefault: true,
    usageCount: 0
  }
];
</file>

<file path="types/video-composition.ts">
import type { AudioAnalysisData, LiveMIDIData } from './visualizer';

export interface AudioBinding {
  feature: keyof AudioAnalysisData;
  inputRange: [number, number];
  outputRange: [number, number];
  blendMode: 'add' | 'multiply' | 'replace';
  modulationAmount?: number; // 0-1, default 1.0 (100%)
}

export interface MIDIBinding {
  source: 'velocity' | 'cc' | 'pitchBend' | 'channelPressure';
  inputRange: [number, number];
  outputRange: [number, number];
  blendMode: 'add' | 'multiply' | 'replace';
}

export interface Layer {
  id: string;
  type: 'video' | 'image' | 'effect';
  src?: string;
  effectType?: EffectType;
  settings?: any;
  position: { x: number; y: number };
  scale: { x: number; y: number };
  rotation: number;
  opacity: number;
  audioBindings: AudioBinding[];
  midiBindings: MIDIBinding[];
  zIndex: number;
  blendMode: 'normal' | 'multiply' | 'screen' | 'overlay';
  startTime: number;
  endTime: number;
  duration: number;
}

export type EffectType = 'metaballs' | 'particles' | 'particleNetwork' | 'midihud' | 'bloom';
export type LayerType = 'video' | 'image' | 'effect';

export interface VideoComposition {
  id: string;
  projectId: string;
  name: string;
  layers: Layer[];
  width: number;
  height: number;
  duration: number;
  fps: number;
  createdAt: Date;
  updatedAt: Date;
}

export interface LayerClip {
  id: string;
  layerId: string;
  startTime: number;
  endTime: number;
  parameters: Record<string, any>;
}

export interface CompositionTimeline {
  duration: number;
  currentTime: number;
  isPlaying: boolean;
  layers: Layer[];
  clips: LayerClip[];
}
</file>

<file path="types/visualizer.ts">
import * as THREE from 'three';

export interface VisualEffect {
  id: string;
  name: string;
  description: string;
  enabled: boolean;
  parameters: Record<string, any>;
  init(scene: THREE.Scene, camera: THREE.Camera, renderer: THREE.WebGLRenderer): void;
  update(deltaTime: number, audioData: AudioAnalysisData, midiData: LiveMIDIData): void;
  destroy(): void;
}

export interface AudioAnalysisData {
  frequencies: number[];
  timeData: number[];
  volume: number;
  bass: number;
  mid: number;
  treble: number;
}

export interface LiveMIDIData {
  activeNotes: Array<{
    note: number;
    velocity: number;
    startTime: number;
    track: string;
  }>;
  currentTime: number;
  tempo: number;
  totalNotes: number;
  trackActivity: Record<string, boolean>;
}

export interface MetaballConfig {
  trailLength: number;
  baseRadius: number;
  smoothingFactor: number;
  colorPalette: string[];
  animationSpeed: number;
  noiseIntensity: number;
  highlightColor: [number, number, number];
}

export interface AspectRatioConfig {
  id: string;
  name: string;
  width: number;
  height: number;
  maxWidth?: string;
  maxHeight?: string;
  className?: string;
}

export interface VisualizerConfig {
  canvas: {
    width: number;
    height: number;
    pixelRatio?: number;
  };
  aspectRatio?: AspectRatioConfig;
  effects?: VisualEffect[];
  performance?: {
    targetFPS?: number;
    enableBloom?: boolean;
    enableShadows?: boolean;
  };
  midi: {
    velocitySensitivity: number;
    noteTrailDuration: number;
    trackColorMapping: Record<string, string>;
  };
}

export interface VisualizerControls {
  global: {
    intensity: number;
    colorShift: number;
    timeScale: number;
    resolution: number;
  };
  metaballs: MetaballConfig;
  particles: {
    count: number;
    size: number;
    speed: number;
    physics: boolean;
  };
  postProcessing: {
    bloom: number;
    contrast: number;
    saturation: number;
    noise: number;
  };
}

export type EffectType = 'metaballs' | 'particles' | 'waveforms' | 'geometry' | 'shaders' | 'postfx';

export interface EffectPreset {
  id: string;
  name: string;
  description: string;
  type: EffectType;
  config: Partial<VisualizerControls>;
  tags: string[];
}
</file>

<file path="config/package.json">
{
  "name": "@phonoglyph/config",
  "version": "0.1.0",
  "private": true,
  "description": "Shared configurations for the Phonoglyph monorepo",
  "main": "index.js",
  "files": [
    "eslint",
    "typescript"
  ],
  "devDependencies": {
    "typescript": "5.3.3",
    "eslint": "^8.56.0",
    "@typescript-eslint/eslint-plugin": "^6.19.0",
    "@typescript-eslint/parser": "^6.19.0"
  }
}
</file>

<file path="types/dist/audio.d.ts">
/**
 * Comprehensive Audio Processing Type Definitions
 * Replaces all `any` types with proper TypeScript interfaces
 */
export type StemType = 'drums' | 'bass' | 'vocals' | 'other' | 'piano' | 'master';
export interface AudioFeature {
    timestamp: number;
    rms: number;
    spectralCentroid: number;
    energy: number;
    bpm?: number;
    key?: string;
    clarity: number;
}
export interface ExtendedAudioFeature extends AudioFeature {
    spectralRolloff: number;
    loudness: number;
    perceptualSpread: number;
    spectralFlux: number;
    mfcc: number[];
    chromaVector: number[];
    tempo: number;
    rhythmPattern: number[];
    zcr: number;
    spectralFlatness: number;
}
export interface StemAnalysisData {
    features: ExtendedAudioFeature[];
    markers: AudioMarker[];
    frequencies: number[];
    timeData: number[];
    volume: number[];
    bass: number[];
    mid: number[];
    treble: number[];
    fft: number[];
    fftFrequencies: number[];
    metadata: StemMetadata;
}
export interface AudioMarker {
    timestamp: number;
    type: 'beat' | 'bar' | 'section' | 'key_change' | 'tempo_change';
    confidence: number;
    value?: string | number;
}
export interface AudioEvent {
    timestamp: number;
    type: string;
    data: Record<string, unknown>;
    confidence?: number;
}
export interface AudioTimeline {
    events: AudioEvent[];
    markers: AudioMarker[];
    duration: number;
    sampleRate: number;
    metadata?: Record<string, unknown>;
}
export interface StemMetadata {
    bpm: number;
    key: string;
    energy: number;
    clarity: number;
    duration: number;
    sampleRate: number;
    channels: number;
    bitDepth: number;
}
export type AudioFeatureData = {
    [K in StemType]?: StemAnalysisData;
};
export interface CachedStemAnalysis {
    id: string;
    fileMetadataId: string;
    stemType: StemType;
    analysisData: StemAnalysisData;
    createdAt: string;
    updatedAt: string;
}
export interface AudioAnalysisData {
    frequencies: number[];
    timeData: number[];
    volume: number;
    bass: number;
    mid: number;
    treble: number;
    rms: number;
    spectralCentroid: number;
    spectralRolloff: number;
    zcr: number;
    timestamp: number;
}
export type RealtimeAudioFeatures = {
    [K in StemType]?: AudioAnalysisData;
};
export interface AudioTextureData {
    audioData: Float32Array;
    featureData: Float32Array;
    timeData: Float32Array;
    dimensions: {
        width: number;
        height: number;
        depth: number;
    };
}
export interface GPUAudioBuffer {
    textureId: string;
    data: AudioTextureData;
    format: 'RGBA32F' | 'RGB32F' | 'RG32F' | 'R32F';
    usage: 'static' | 'dynamic' | 'stream';
    lastUpdated: number;
}
export interface AudioPerformanceMetrics {
    fps: number;
    analysisLatency: number;
    memoryUsage: number;
    cpuUsage: number;
    frameDrops: number;
    audioLatency: number;
    bufferUnderruns: number;
    processingTime: number;
}
export interface DeviceAudioCapabilities {
    maxSampleRate: number;
    maxChannels: number;
    supportedFormats: string[];
    hasWebAudio: boolean;
    hasAudioWorklet: boolean;
    latencyHint: 'interactive' | 'balanced' | 'playback';
    bufferSize: number;
}
export interface VisualizationParameters {
    colorScheme: ColorScheme;
    effectSettings: EffectSettings;
    cameraSettings: CameraSettings;
    lightingSettings: LightingSettings;
    postProcessing: PostProcessingSettings;
}
export interface ColorScheme {
    primary: string;
    secondary: string;
    accent: string;
    background: string;
    palette: string[];
    mode: 'static' | 'dynamic' | 'audio_reactive';
}
export interface EffectSettings {
    bloom: BloomSettings;
    distortion: DistortionSettings;
    particles: ParticleSettings;
    waveform: WaveformSettings;
    spectrum: SpectrumSettings;
}
export interface BloomSettings {
    enabled: boolean;
    intensity: number;
    threshold: number;
    radius: number;
}
export interface DistortionSettings {
    enabled: boolean;
    amount: number;
    frequency: number;
    type: 'sine' | 'noise' | 'fractal';
}
export interface ParticleSettings {
    enabled: boolean;
    count: number;
    size: number;
    speed: number;
    lifetime: number;
    emissionRate: number;
}
export interface WaveformSettings {
    enabled: boolean;
    thickness: number;
    smoothing: number;
    amplitude: number;
    frequency: number;
}
export interface SpectrumSettings {
    enabled: boolean;
    bars: number;
    smoothing: number;
    scale: 'linear' | 'logarithmic';
    range: [number, number];
}
export interface CameraSettings {
    position: [number, number, number];
    target: [number, number, number];
    fov: number;
    near: number;
    far: number;
    autoRotate: boolean;
    rotationSpeed: number;
}
export interface LightingSettings {
    ambient: {
        color: string;
        intensity: number;
    };
    directional: {
        color: string;
        intensity: number;
        position: [number, number, number];
    };
    point: Array<{
        color: string;
        intensity: number;
        position: [number, number, number];
        distance: number;
    }>;
}
export interface PostProcessingSettings {
    enabled: boolean;
    effects: {
        bloom: boolean;
        filmGrain: boolean;
        vignette: boolean;
        colorGrading: boolean;
        chromaticAberration: boolean;
    };
    quality: 'low' | 'medium' | 'high' | 'ultra';
}
export interface ExportConfiguration {
    format: ExportFormat;
    quality: ExportQuality;
    resolution: ExportResolution;
    frameRate: number;
    duration: number;
    audioSettings: AudioExportSettings;
    videoSettings: VideoExportSettings;
    metadata: ExportMetadata;
}
export interface ExportFormat {
    container: 'mp4' | 'webm' | 'mov' | 'avi';
    videoCodec: 'h264' | 'h265' | 'vp8' | 'vp9' | 'av1';
    audioCodec: 'aac' | 'mp3' | 'opus' | 'vorbis';
}
export interface ExportQuality {
    preset: 'draft' | 'standard' | 'high' | 'ultra';
    videoBitrate: number;
    audioBitrate: number;
    crf?: number;
}
export interface ExportResolution {
    width: number;
    height: number;
    aspectRatio: string;
    pixelFormat: 'yuv420p' | 'yuv444p' | 'rgb24';
}
export interface AudioExportSettings {
    sampleRate: number;
    channels: number;
    bitDepth: number;
    normalize: boolean;
    fadeIn: number;
    fadeOut: number;
}
export interface VideoExportSettings {
    keyframeInterval: number;
    bFrames: number;
    profile: string;
    level: string;
    pixelFormat: string;
    colorSpace: 'rec709' | 'rec2020' | 'srgb';
}
export interface ExportMetadata {
    title: string;
    artist: string;
    album?: string;
    year?: number;
    genre?: string;
    description?: string;
    tags: string[];
}
export interface AudioProcessingError {
    code: string;
    message: string;
    details?: Record<string, unknown>;
    timestamp: number;
    recoverable: boolean;
    context: 'analysis' | 'playback' | 'export' | 'gpu' | 'worker';
}
export interface AudioValidationError extends AudioProcessingError {
    field: string;
    expectedType: string;
    actualType: string;
    value: unknown;
}
export declare function isAudioFeatureData(value: unknown): value is AudioFeatureData;
export declare function isStemAnalysisData(value: unknown): value is StemAnalysisData;
export declare function isAudioAnalysisData(value: unknown): value is AudioAnalysisData;
</file>

<file path="types/dist/audio.js">
"use strict";
/**
 * Comprehensive Audio Processing Type Definitions
 * Replaces all `any` types with proper TypeScript interfaces
 */
Object.defineProperty(exports, "__esModule", { value: true });
exports.isAudioAnalysisData = exports.isStemAnalysisData = exports.isAudioFeatureData = void 0;
// ===== TYPE GUARDS =====
function isAudioFeatureData(value) {
    if (!value || typeof value !== 'object')
        return false;
    const data = value;
    return Object.keys(data).every(key => {
        const stemType = key;
        return ['drums', 'bass', 'vocals', 'other', 'piano', 'master'].includes(stemType) &&
            isStemAnalysisData(data[key]);
    });
}
exports.isAudioFeatureData = isAudioFeatureData;
function isStemAnalysisData(value) {
    if (!value || typeof value !== 'object')
        return false;
    const data = value;
    return Array.isArray(data.features) &&
        Array.isArray(data.frequencies) &&
        Array.isArray(data.timeData) &&
        typeof data.metadata === 'object';
}
exports.isStemAnalysisData = isStemAnalysisData;
function isAudioAnalysisData(value) {
    if (!value || typeof value !== 'object')
        return false;
    const data = value;
    return Array.isArray(data.frequencies) &&
        Array.isArray(data.timeData) &&
        typeof data.volume === 'number' &&
        typeof data.timestamp === 'number';
}
exports.isAudioAnalysisData = isAudioAnalysisData;
</file>

<file path="types/dist/index.d.ts">
import { z } from 'zod';
export declare const createProjectSchema: z.ZodObject<{
    name: z.ZodString;
    description: z.ZodOptional<z.ZodString>;
    privacy_setting: z.ZodDefault<z.ZodEnum<["private", "unlisted", "public"]>>;
    midi_file_path: z.ZodOptional<z.ZodString>;
    audio_file_path: z.ZodOptional<z.ZodString>;
    user_video_path: z.ZodOptional<z.ZodString>;
    render_configuration: z.ZodDefault<z.ZodRecord<z.ZodString, z.ZodAny>>;
}, "strip", z.ZodTypeAny, {
    name: string;
    privacy_setting: "private" | "unlisted" | "public";
    render_configuration: Record<string, any>;
    description?: string | undefined;
    midi_file_path?: string | undefined;
    audio_file_path?: string | undefined;
    user_video_path?: string | undefined;
}, {
    name: string;
    description?: string | undefined;
    privacy_setting?: "private" | "unlisted" | "public" | undefined;
    midi_file_path?: string | undefined;
    audio_file_path?: string | undefined;
    user_video_path?: string | undefined;
    render_configuration?: Record<string, any> | undefined;
}>;
export declare const updateProjectSchema: z.ZodObject<{
    id: z.ZodString;
    name: z.ZodOptional<z.ZodString>;
    description: z.ZodOptional<z.ZodString>;
    privacy_setting: z.ZodOptional<z.ZodEnum<["private", "unlisted", "public"]>>;
    thumbnail_url: z.ZodOptional<z.ZodString>;
    primary_midi_file_id: z.ZodOptional<z.ZodString>;
    audio_file_path: z.ZodOptional<z.ZodString>;
    user_video_path: z.ZodOptional<z.ZodString>;
    render_configuration: z.ZodOptional<z.ZodRecord<z.ZodString, z.ZodAny>>;
}, "strip", z.ZodTypeAny, {
    id: string;
    name?: string | undefined;
    description?: string | undefined;
    privacy_setting?: "private" | "unlisted" | "public" | undefined;
    audio_file_path?: string | undefined;
    user_video_path?: string | undefined;
    render_configuration?: Record<string, any> | undefined;
    thumbnail_url?: string | undefined;
    primary_midi_file_id?: string | undefined;
}, {
    id: string;
    name?: string | undefined;
    description?: string | undefined;
    privacy_setting?: "private" | "unlisted" | "public" | undefined;
    audio_file_path?: string | undefined;
    user_video_path?: string | undefined;
    render_configuration?: Record<string, any> | undefined;
    thumbnail_url?: string | undefined;
    primary_midi_file_id?: string | undefined;
}>;
export declare const loginCredentialsSchema: z.ZodObject<{
    email: z.ZodString;
    password: z.ZodString;
}, "strip", z.ZodTypeAny, {
    email: string;
    password: string;
}, {
    email: string;
    password: string;
}>;
export declare const signupCredentialsSchema: z.ZodObject<{
    email: z.ZodString;
    password: z.ZodString;
    name: z.ZodOptional<z.ZodString>;
}, "strip", z.ZodTypeAny, {
    email: string;
    password: string;
    name?: string | undefined;
}, {
    email: string;
    password: string;
    name?: string | undefined;
}>;
interface SupabaseUser {
    id: string;
    email?: string;
    user_metadata?: {
        name?: string;
        avatar_url?: string;
        provider?: string;
    };
    created_at?: string;
    updated_at?: string;
}
export interface User {
    id: string;
    email: string;
    name?: string;
    image?: string;
    created_at: string;
    updated_at: string;
}
export interface WebUser {
    id: string;
    email: string;
    user_metadata: {
        name?: string;
        avatar_url?: string;
        provider?: string;
    };
    created_at: string;
    updated_at: string;
}
export interface NormalizedUser {
    id: string;
    email: string;
    name?: string;
    image?: string;
    created_at: string;
    updated_at: string;
}
export interface UserProfile {
    id: string;
    display_name?: string;
    avatar_url?: string;
    bio?: string;
    preferences: Record<string, any>;
    subscription_tier: 'free' | 'premium' | 'enterprise';
    created_at: string;
    updated_at: string;
}
export interface UserWithProfile extends User {
    profile: UserProfile;
}
export interface Project {
    id: string;
    name: string;
    user_id: string;
    midi_file_path: string;
    audio_file_path?: string;
    user_video_path?: string;
    render_configuration: Record<string, any>;
    description?: string;
    privacy_setting: 'private' | 'unlisted' | 'public';
    thumbnail_url?: string;
    primary_midi_file_id?: string;
    created_at: string;
    updated_at: string;
}
export interface ProjectCollaborator {
    id: string;
    project_id: string;
    user_id: string;
    role: 'owner' | 'editor' | 'viewer';
    created_at: string;
}
export interface ProjectShare {
    id: string;
    project_id: string;
    share_token: string;
    access_type: 'view' | 'embed';
    expires_at?: string;
    view_count: number;
    created_at: string;
    updated_at: string;
}
export interface ProjectWithCollaborators extends Project {
    collaborators: ProjectCollaborator[];
}
export interface ProjectExtended extends Project {
    file_count?: number;
    total_file_size?: number;
    last_accessed?: string;
}
export interface AuthState {
    user: User | null;
    loading: boolean;
    error: string | null;
}
export interface LoginCredentials {
    email: string;
    password: string;
}
export interface SignupCredentials {
    email: string;
    password: string;
    name?: string;
}
export interface AuthProvider {
    provider: 'google' | 'github' | 'discord';
    redirectTo?: string;
}
export interface AuthError {
    message: string;
    code?: string;
}
export interface AuthContext {
    user: User | null;
    session: any | null;
    supabase: any;
}
export interface AuditLog {
    id: string;
    user_id?: string;
    action: string;
    resource_type: string;
    resource_id?: string;
    metadata: Record<string, any>;
    ip_address?: string;
    user_agent?: string;
    created_at: string;
}
export interface MIDINote {
    id: string;
    track: number | string;
    channel: number;
    note: number;
    pitch: number;
    velocity: number;
    startTime: number;
    start: number;
    duration: number;
    name: string;
    noteName?: string;
}
export interface TempoEvent {
    tick: number;
    bpm: number;
    microsecondsPerQuarter: number;
}
export interface TempoChange {
    tick: number;
    bpm: number;
    microsecondsPerQuarter: number;
}
export interface MIDITrack {
    id: string;
    name: string;
    instrument: string;
    channel: number;
    notes: MIDINote[];
    color: string;
    visible?: boolean;
}
export interface MIDIData {
    file: {
        name: string;
        size: number;
        duration: number;
        ticksPerQuarter: number;
        timeSignature: [number, number];
        keySignature: string;
    };
    tracks: MIDITrack[];
    tempoChanges: TempoEvent[] | TempoChange[];
}
export interface MIDIParsingResult {
    success: boolean;
    data?: MIDIData;
    error?: string;
}
export interface VisualizationSettings {
    colorScheme: 'sage' | 'slate' | 'dusty-rose' | 'mixed';
    pixelsPerSecond: number;
    showTrackLabels: boolean;
    showVelocity: boolean;
    minKey: number;
    maxKey: number;
}
export declare const COLOR_SCHEMES: {
    readonly sage: "#84a98c";
    readonly slate: "#6b7c93";
    readonly 'dusty-rose': "#b08a8a";
    readonly mixed: readonly ["#84a98c", "#6b7c93", "#b08a8a", "#a8a29e", "#8da3b0"];
};
export declare const DEFAULT_VISUALIZATION_SETTINGS: VisualizationSettings;
export declare function transformSupabaseUser(supabaseUser: SupabaseUser): User;
export declare function normalizeUser(user: User): NormalizedUser;
export type CreateProjectInput = z.infer<typeof createProjectSchema>;
export type UpdateProjectInput = z.infer<typeof updateProjectSchema>;
export type LoginCredentialsInput = z.infer<typeof loginCredentialsSchema>;
export type SignupCredentialsInput = z.infer<typeof signupCredentialsSchema>;
export {};
</file>

<file path="types/dist/index.js">
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.normalizeUser = exports.transformSupabaseUser = exports.DEFAULT_VISUALIZATION_SETTINGS = exports.COLOR_SCHEMES = exports.signupCredentialsSchema = exports.loginCredentialsSchema = exports.updateProjectSchema = exports.createProjectSchema = void 0;
const zod_1 = require("zod");
// ===== VALIDATION SCHEMAS =====
exports.createProjectSchema = zod_1.z.object({
    name: zod_1.z.string().min(1, 'Project name is required').max(100, 'Project name too long'),
    description: zod_1.z.string().max(500, 'Description too long').optional(),
    privacy_setting: zod_1.z.enum(['private', 'unlisted', 'public']).default('private'),
    midi_file_path: zod_1.z.string().optional(),
    audio_file_path: zod_1.z.string().optional(),
    user_video_path: zod_1.z.string().optional(),
    render_configuration: zod_1.z.record(zod_1.z.any()).default({}),
});
exports.updateProjectSchema = zod_1.z.object({
    id: zod_1.z.string().min(1, 'Project ID is required'),
    name: zod_1.z.string().min(1, 'Project name is required').max(100, 'Project name too long').optional(),
    description: zod_1.z.string().max(500, 'Description too long').optional(),
    privacy_setting: zod_1.z.enum(['private', 'unlisted', 'public']).optional(),
    thumbnail_url: zod_1.z.string().url('Invalid thumbnail URL').optional(),
    primary_midi_file_id: zod_1.z.string().uuid('Invalid file ID').optional(),
    audio_file_path: zod_1.z.string().optional(),
    user_video_path: zod_1.z.string().optional(),
    render_configuration: zod_1.z.record(zod_1.z.any()).optional(),
});
exports.loginCredentialsSchema = zod_1.z.object({
    email: zod_1.z.string().email('Invalid email address'),
    password: zod_1.z.string().min(6, 'Password must be at least 6 characters'),
});
exports.signupCredentialsSchema = zod_1.z.object({
    email: zod_1.z.string().email('Invalid email address'),
    password: zod_1.z.string().min(6, 'Password must be at least 6 characters'),
    name: zod_1.z.string().min(1, 'Name is required').optional(),
});
// Color scheme mappings
exports.COLOR_SCHEMES = {
    sage: '#84a98c',
    slate: '#6b7c93',
    'dusty-rose': '#b08a8a',
    mixed: ['#84a98c', '#6b7c93', '#b08a8a', '#a8a29e', '#8da3b0']
};
// Default visualization settings
exports.DEFAULT_VISUALIZATION_SETTINGS = {
    colorScheme: 'mixed',
    pixelsPerSecond: 50,
    showTrackLabels: true,
    showVelocity: true,
    minKey: 21,
    maxKey: 108
};
// ===== UTILITY FUNCTIONS =====
// Helper to convert Supabase user to our User type
function transformSupabaseUser(supabaseUser) {
    return {
        id: supabaseUser.id,
        email: supabaseUser.email || '',
        name: supabaseUser.user_metadata?.name,
        image: supabaseUser.user_metadata?.avatar_url,
        created_at: supabaseUser.created_at || '',
        updated_at: supabaseUser.updated_at || '',
    };
}
exports.transformSupabaseUser = transformSupabaseUser;
function normalizeUser(user) {
    return {
        id: user.id,
        email: user.email,
        name: user.name,
        image: user.image,
        created_at: user.created_at,
        updated_at: user.updated_at,
    };
}
exports.normalizeUser = normalizeUser;
</file>

<file path="types/dist/performance.d.ts">
/**
 * Performance Monitoring Type Definitions
 * Comprehensive types for performance tracking and optimization
 */
export interface PerformanceMetrics {
    fps: number;
    frameTime: number;
    cpuUsage: number;
    memoryUsage: number;
    gpuMemory: number;
    activeEffects: number;
    activeLayers: number;
    audioTextureEnabled: boolean;
    multiLayerCompositingEnabled: boolean;
    timestamp: number;
}
export interface DetailedPerformanceMetrics extends PerformanceMetrics {
    drawCalls: number;
    triangles: number;
    geometries: number;
    textures: number;
    shaderPrograms: number;
    analysisLatency: number;
    audioLatency: number;
    bufferUnderruns: number;
    frameDrops: number;
    memoryBreakdown: {
        geometries: number;
        textures: number;
        shaders: number;
        audioBuffers: number;
        other: number;
    };
    inputLag: number;
    parameterUpdateLatency: number;
    visualResponseTime: number;
    memoryLeaks: number;
    errorCount: number;
    warningCount: number;
}
export interface PerformanceAlert {
    id: string;
    type: 'critical' | 'warning' | 'info';
    category: 'performance' | 'memory' | 'audio' | 'gpu' | 'user_experience';
    title: string;
    description: string;
    recommendation: string;
    impact: 'high' | 'medium' | 'low';
    canAutoFix: boolean;
    autoFixAction?: () => Promise<void>;
    timestamp: number;
    acknowledged: boolean;
}
export interface OptimizationRecommendation {
    id: string;
    category: 'quality' | 'performance' | 'memory' | 'battery';
    title: string;
    description: string;
    expectedImpact: string;
    difficulty: 'easy' | 'medium' | 'advanced';
    action: () => Promise<boolean>;
    currentValue?: unknown;
    recommendedValue?: unknown;
}
export interface PerformanceThresholds {
    targetFrameRate: number;
    minFrameRate: number;
    maxMemoryUsage: number;
    maxGpuMemoryUsage: number;
    maxLatency: number;
    maxAudioLatency: number;
    maxCpuUsage: number;
    maxInputLag: number;
    maxDrawCalls: number;
    maxTriangles: number;
}
export interface PerformanceMonitorConfig {
    enabled: boolean;
    sampleInterval: number;
    historyLength: number;
    alertThresholds: PerformanceThresholds;
    enableAutoOptimization: boolean;
    enablePredictiveAnalysis: boolean;
    debugMode: boolean;
    categories: {
        rendering: boolean;
        audio: boolean;
        memory: boolean;
        userExperience: boolean;
    };
}
export interface DeviceCapabilities {
    deviceClass: 'ultra-high' | 'high' | 'medium' | 'low' | 'potato';
    cpuCores: number;
    estimatedRam: number;
    gpuTier: 'high' | 'medium' | 'low';
    supportsWebGL2: boolean;
    supportsWebAudio: boolean;
    supportsWorkers: boolean;
    supportsSIMD: boolean;
    isMobile: boolean;
    batteryLevel?: number;
    thermalState?: 'nominal' | 'fair' | 'serious' | 'critical';
    networkSpeed: 'slow' | 'medium' | 'fast';
    webglCapabilities: {
        maxTextureSize: number;
        maxRenderBufferSize: number;
        maxVertexUniforms: number;
        maxFragmentUniforms: number;
        maxVaryingVectors: number;
        maxVertexAttribs: number;
        maxCombinedTextureImageUnits: number;
        floatTextures: boolean;
        depthTextures: boolean;
        instancedArrays: boolean;
        vertexArrayObjects: boolean;
    };
    audioCapabilities: {
        maxSampleRate: number;
        maxChannels: number;
        supportedFormats: string[];
        hasWebAudio: boolean;
        hasAudioWorklet: boolean;
        latencyHint: 'interactive' | 'balanced' | 'playback';
        bufferSize: number;
    };
}
export interface PerformanceHistoryEntry {
    timestamp: number;
    metrics: DetailedPerformanceMetrics;
    context: {
        activeEffects: string[];
        activeLayers: string[];
        currentScene: string;
        audioPlaying: boolean;
        exportInProgress: boolean;
    };
}
export interface PerformanceHistory {
    entries: PerformanceHistoryEntry[];
    maxEntries: number;
    startTime: number;
    totalSamples: number;
}
export interface PerformanceAnalysis {
    summary: {
        averageFps: number;
        minFps: number;
        maxFps: number;
        frameTimeP95: number;
        memoryTrend: 'stable' | 'increasing' | 'decreasing';
        overallHealth: 'excellent' | 'good' | 'fair' | 'poor';
    };
    bottlenecks: {
        cpu: boolean;
        gpu: boolean;
        memory: boolean;
        audio: boolean;
        network: boolean;
    };
    recommendations: OptimizationRecommendation[];
    alerts: PerformanceAlert[];
    trends: {
        fps: TrendData;
        memory: TrendData;
        cpuUsage: TrendData;
        audioLatency: TrendData;
    };
}
export interface TrendData {
    values: number[];
    timestamps: number[];
    slope: number;
    correlation: number;
    prediction: number;
}
export interface OptimizationStrategy {
    id: string;
    name: string;
    description: string;
    category: 'quality' | 'performance' | 'memory' | 'battery';
    impact: 'low' | 'medium' | 'high';
    difficulty: 'easy' | 'medium' | 'hard';
    conditions: {
        minDeviceTier?: DeviceCapabilities['deviceClass'];
        maxMemoryUsage?: number;
        minFps?: number;
        batteryLevel?: number;
    };
    actions: OptimizationAction[];
}
export interface OptimizationAction {
    type: 'setting_change' | 'effect_disable' | 'quality_reduction' | 'memory_cleanup';
    target: string;
    value: unknown;
    reversible: boolean;
    description: string;
}
export interface PerformanceTest {
    id: string;
    name: string;
    description: string;
    duration: number;
    expectedResults: {
        minFps: number;
        maxMemoryUsage: number;
        maxLatency: number;
    };
    setup: () => Promise<void>;
    run: () => Promise<PerformanceTestResult>;
    cleanup: () => Promise<void>;
}
export interface PerformanceTestResult {
    testId: string;
    passed: boolean;
    metrics: DetailedPerformanceMetrics[];
    summary: {
        averageFps: number;
        peakMemoryUsage: number;
        averageLatency: number;
        frameDrops: number;
    };
    issues: string[];
    recommendations: string[];
    duration: number;
}
export interface PerformanceTestSuite {
    tests: PerformanceTest[];
    results: PerformanceTestResult[];
    overallScore: number;
    deviceProfile: DeviceCapabilities;
    timestamp: number;
}
export interface RealTimeMonitor {
    start(): void;
    stop(): void;
    pause(): void;
    resume(): void;
    getMetrics(): DetailedPerformanceMetrics;
    getHistory(): PerformanceHistory;
    getAnalysis(): PerformanceAnalysis;
    addAlert(alert: PerformanceAlert): void;
    clearAlerts(): void;
    exportData(): string;
}
export interface MonitoringEvent {
    type: 'metric_update' | 'alert_triggered' | 'optimization_applied' | 'test_completed';
    timestamp: number;
    data: unknown;
}
export declare function isPerformanceMetrics(value: unknown): value is PerformanceMetrics;
export declare function isPerformanceAlert(value: unknown): value is PerformanceAlert;
export declare function isDeviceCapabilities(value: unknown): value is DeviceCapabilities;
export declare function isOptimizationRecommendation(value: unknown): value is OptimizationRecommendation;
</file>

<file path="types/dist/performance.js">
"use strict";
/**
 * Performance Monitoring Type Definitions
 * Comprehensive types for performance tracking and optimization
 */
Object.defineProperty(exports, "__esModule", { value: true });
exports.isOptimizationRecommendation = exports.isDeviceCapabilities = exports.isPerformanceAlert = exports.isPerformanceMetrics = void 0;
// ===== TYPE GUARDS =====
function isPerformanceMetrics(value) {
    if (!value || typeof value !== 'object')
        return false;
    const metrics = value;
    return typeof metrics.fps === 'number' &&
        typeof metrics.frameTime === 'number' &&
        typeof metrics.memoryUsage === 'number' &&
        typeof metrics.timestamp === 'number';
}
exports.isPerformanceMetrics = isPerformanceMetrics;
function isPerformanceAlert(value) {
    if (!value || typeof value !== 'object')
        return false;
    const alert = value;
    return typeof alert.id === 'string' &&
        typeof alert.type === 'string' &&
        typeof alert.category === 'string' &&
        typeof alert.title === 'string' &&
        typeof alert.timestamp === 'number';
}
exports.isPerformanceAlert = isPerformanceAlert;
function isDeviceCapabilities(value) {
    if (!value || typeof value !== 'object')
        return false;
    const caps = value;
    return typeof caps.deviceClass === 'string' &&
        typeof caps.cpuCores === 'number' &&
        typeof caps.estimatedRam === 'number' &&
        typeof caps.gpuTier === 'string';
}
exports.isDeviceCapabilities = isDeviceCapabilities;
function isOptimizationRecommendation(value) {
    if (!value || typeof value !== 'object')
        return false;
    const rec = value;
    return typeof rec.id === 'string' &&
        typeof rec.category === 'string' &&
        typeof rec.title === 'string' &&
        typeof rec.action === 'function';
}
exports.isOptimizationRecommendation = isOptimizationRecommendation;
</file>

<file path="types/dist/type-guards.d.ts">
/**
 * Comprehensive Type Guards and Runtime Validation
 * Ensures type safety at runtime for all audio processing data
 */
import { AudioFeatureData, StemAnalysisData, AudioAnalysisData, CachedStemAnalysis, StemType, AudioFeature, ExtendedAudioFeature, StemMetadata, AudioMarker } from './audio';
import { LiveMIDIData, MIDINote } from './visualization';
import { PerformanceMetrics, DetailedPerformanceMetrics, PerformanceAlert, DeviceCapabilities } from './performance';
export declare function isString(value: unknown): value is string;
export declare function isNumber(value: unknown): value is number;
export declare function isBoolean(value: unknown): value is boolean;
export declare function isArray<T>(value: unknown, itemGuard?: (item: unknown) => item is T): value is T[];
export declare function isObject(value: unknown): value is Record<string, unknown>;
export declare function isStemType(value: unknown): value is StemType;
export declare function isAudioFeature(value: unknown): value is AudioFeature;
export declare function isExtendedAudioFeature(value: unknown): value is ExtendedAudioFeature;
export declare function isAudioMarker(value: unknown): value is AudioMarker;
export declare function isStemMetadata(value: unknown): value is StemMetadata;
export declare function isStemAnalysisData(value: unknown): value is StemAnalysisData;
export declare function isAudioFeatureData(value: unknown): value is AudioFeatureData;
export declare function isCachedStemAnalysis(value: unknown): value is CachedStemAnalysis;
export declare function isAudioAnalysisData(value: unknown): value is AudioAnalysisData;
export declare function isMIDINote(value: unknown): value is MIDINote;
export declare function isLiveMIDIData(value: unknown): value is LiveMIDIData;
export declare function isPerformanceMetrics(value: unknown): value is PerformanceMetrics;
export declare function isDetailedPerformanceMetrics(value: unknown): value is DetailedPerformanceMetrics;
export declare function isPerformanceAlert(value: unknown): value is PerformanceAlert;
export declare function isDeviceCapabilities(value: unknown): value is DeviceCapabilities;
export declare function validateAndTransform<T>(value: unknown, guard: (value: unknown) => value is T, errorMessage?: string): T;
export declare function safeValidate<T>(value: unknown, guard: (value: unknown) => value is T, defaultValue: T): T;
export declare function createArrayValidator<T>(itemGuard: (value: unknown) => value is T): (value: unknown) => value is T[];
export declare function createOptionalValidator<T>(guard: (value: unknown) => value is T): (value: unknown) => value is T | undefined;
export declare function assertType<T>(value: unknown, guard: (value: unknown) => value is T, context?: string): asserts value is T;
export declare function isValidEnum<T extends Record<string, string | number>>(enumObject: T, value: unknown): value is T[keyof T];
</file>

<file path="types/dist/type-guards.js">
"use strict";
/**
 * Comprehensive Type Guards and Runtime Validation
 * Ensures type safety at runtime for all audio processing data
 */
Object.defineProperty(exports, "__esModule", { value: true });
exports.isValidEnum = exports.assertType = exports.createOptionalValidator = exports.createArrayValidator = exports.safeValidate = exports.validateAndTransform = exports.isDeviceCapabilities = exports.isPerformanceAlert = exports.isDetailedPerformanceMetrics = exports.isPerformanceMetrics = exports.isLiveMIDIData = exports.isMIDINote = exports.isAudioAnalysisData = exports.isCachedStemAnalysis = exports.isAudioFeatureData = exports.isStemAnalysisData = exports.isStemMetadata = exports.isAudioMarker = exports.isExtendedAudioFeature = exports.isAudioFeature = exports.isStemType = exports.isObject = exports.isArray = exports.isBoolean = exports.isNumber = exports.isString = void 0;
// ===== BASIC TYPE GUARDS =====
function isString(value) {
    return typeof value === 'string';
}
exports.isString = isString;
function isNumber(value) {
    return typeof value === 'number' && !isNaN(value) && isFinite(value);
}
exports.isNumber = isNumber;
function isBoolean(value) {
    return typeof value === 'boolean';
}
exports.isBoolean = isBoolean;
function isArray(value, itemGuard) {
    if (!Array.isArray(value))
        return false;
    if (!itemGuard)
        return true;
    return value.every(itemGuard);
}
exports.isArray = isArray;
function isObject(value) {
    return value !== null && typeof value === 'object' && !Array.isArray(value);
}
exports.isObject = isObject;
// ===== STEM TYPE GUARDS =====
function isStemType(value) {
    return isString(value) && ['drums', 'bass', 'vocals', 'other', 'piano', 'master'].includes(value);
}
exports.isStemType = isStemType;
function isAudioFeature(value) {
    if (!isObject(value))
        return false;
    return isNumber(value.timestamp) &&
        isNumber(value.rms) &&
        isNumber(value.spectralCentroid) &&
        isNumber(value.energy) &&
        isNumber(value.clarity) &&
        (value.bpm === undefined || isNumber(value.bpm)) &&
        (value.key === undefined || isString(value.key));
}
exports.isAudioFeature = isAudioFeature;
function isExtendedAudioFeature(value) {
    if (!isAudioFeature(value))
        return false;
    const extended = value;
    return isNumber(extended.spectralRolloff) &&
        isNumber(extended.loudness) &&
        isNumber(extended.perceptualSpread) &&
        isNumber(extended.spectralFlux) &&
        isArray(extended.mfcc, isNumber) &&
        isArray(extended.chromaVector, isNumber) &&
        isNumber(extended.tempo) &&
        isArray(extended.rhythmPattern, isNumber) &&
        isNumber(extended.zcr) &&
        isNumber(extended.spectralFlatness);
}
exports.isExtendedAudioFeature = isExtendedAudioFeature;
function isAudioMarker(value) {
    if (!isObject(value))
        return false;
    return isNumber(value.timestamp) &&
        isString(value.type) &&
        ['beat', 'bar', 'section', 'key_change', 'tempo_change'].includes(value.type) &&
        isNumber(value.confidence) &&
        (value.value === undefined || isString(value.value) || isNumber(value.value));
}
exports.isAudioMarker = isAudioMarker;
function isStemMetadata(value) {
    if (!isObject(value))
        return false;
    return isNumber(value.bpm) &&
        isString(value.key) &&
        isNumber(value.energy) &&
        isNumber(value.clarity) &&
        isNumber(value.duration) &&
        isNumber(value.sampleRate) &&
        isNumber(value.channels) &&
        isNumber(value.bitDepth);
}
exports.isStemMetadata = isStemMetadata;
function isStemAnalysisData(value) {
    if (!isObject(value))
        return false;
    return isArray(value.features, isExtendedAudioFeature) &&
        isArray(value.markers, isAudioMarker) &&
        isArray(value.frequencies, isNumber) &&
        isArray(value.timeData, isNumber) &&
        isArray(value.volume, isNumber) &&
        isArray(value.bass, isNumber) &&
        isArray(value.mid, isNumber) &&
        isArray(value.treble, isNumber) &&
        isArray(value.fft, isNumber) &&
        isArray(value.fftFrequencies, isNumber) &&
        isStemMetadata(value.metadata);
}
exports.isStemAnalysisData = isStemAnalysisData;
function isAudioFeatureData(value) {
    if (!isObject(value))
        return false;
    return Object.entries(value).every(([key, val]) => {
        return isStemType(key) && (val === undefined || isStemAnalysisData(val));
    });
}
exports.isAudioFeatureData = isAudioFeatureData;
function isCachedStemAnalysis(value) {
    if (!isObject(value))
        return false;
    return isString(value.id) &&
        isString(value.fileMetadataId) &&
        isStemType(value.stemType) &&
        isStemAnalysisData(value.analysisData) &&
        isString(value.createdAt) &&
        isString(value.updatedAt);
}
exports.isCachedStemAnalysis = isCachedStemAnalysis;
function isAudioAnalysisData(value) {
    if (!isObject(value))
        return false;
    return isArray(value.frequencies, isNumber) &&
        isArray(value.timeData, isNumber) &&
        isNumber(value.volume) &&
        isNumber(value.bass) &&
        isNumber(value.mid) &&
        isNumber(value.treble) &&
        isNumber(value.rms) &&
        isNumber(value.spectralCentroid) &&
        isNumber(value.spectralRolloff) &&
        isNumber(value.zcr) &&
        isNumber(value.timestamp);
}
exports.isAudioAnalysisData = isAudioAnalysisData;
// ===== MIDI TYPE GUARDS =====
function isMIDINote(value) {
    if (!isObject(value))
        return false;
    return isNumber(value.note) &&
        isNumber(value.velocity) &&
        isNumber(value.startTime) &&
        isString(value.track) &&
        isNumber(value.channel) &&
        (value.endTime === undefined || isNumber(value.endTime)) &&
        (value.instrument === undefined || isString(value.instrument));
}
exports.isMIDINote = isMIDINote;
function isLiveMIDIData(value) {
    if (!isObject(value))
        return false;
    return isArray(value.activeNotes, isMIDINote) &&
        isNumber(value.currentTime) &&
        isNumber(value.tempo) &&
        isNumber(value.totalNotes) &&
        isObject(value.trackActivity) &&
        isArray(value.timeSignature) &&
        value.timeSignature.length === 2 &&
        isNumber(value.timeSignature[0]) &&
        isNumber(value.timeSignature[1]) &&
        isString(value.keySignature);
}
exports.isLiveMIDIData = isLiveMIDIData;
// ===== PERFORMANCE TYPE GUARDS =====
function isPerformanceMetrics(value) {
    if (!isObject(value))
        return false;
    return isNumber(value.fps) &&
        isNumber(value.frameTime) &&
        isNumber(value.cpuUsage) &&
        isNumber(value.memoryUsage) &&
        isNumber(value.gpuMemory) &&
        isNumber(value.activeEffects) &&
        isNumber(value.activeLayers) &&
        isBoolean(value.audioTextureEnabled) &&
        isBoolean(value.multiLayerCompositingEnabled) &&
        isNumber(value.timestamp);
}
exports.isPerformanceMetrics = isPerformanceMetrics;
function isDetailedPerformanceMetrics(value) {
    if (!isPerformanceMetrics(value))
        return false;
    const detailed = value;
    return isNumber(detailed.drawCalls) &&
        isNumber(detailed.triangles) &&
        isNumber(detailed.geometries) &&
        isNumber(detailed.textures) &&
        isNumber(detailed.shaderPrograms) &&
        isNumber(detailed.analysisLatency) &&
        isNumber(detailed.audioLatency) &&
        isNumber(detailed.bufferUnderruns) &&
        isNumber(detailed.frameDrops) &&
        isObject(detailed.memoryBreakdown) &&
        isNumber(detailed.inputLag) &&
        isNumber(detailed.parameterUpdateLatency) &&
        isNumber(detailed.visualResponseTime) &&
        isNumber(detailed.memoryLeaks) &&
        isNumber(detailed.errorCount) &&
        isNumber(detailed.warningCount);
}
exports.isDetailedPerformanceMetrics = isDetailedPerformanceMetrics;
function isPerformanceAlert(value) {
    if (!isObject(value))
        return false;
    return isString(value.id) &&
        isString(value.type) &&
        ['critical', 'warning', 'info'].includes(value.type) &&
        isString(value.category) &&
        ['performance', 'memory', 'audio', 'gpu', 'user_experience'].includes(value.category) &&
        isString(value.title) &&
        isString(value.description) &&
        isString(value.recommendation) &&
        isString(value.impact) &&
        ['high', 'medium', 'low'].includes(value.impact) &&
        isBoolean(value.canAutoFix) &&
        isNumber(value.timestamp) &&
        isBoolean(value.acknowledged);
}
exports.isPerformanceAlert = isPerformanceAlert;
function isDeviceCapabilities(value) {
    if (!isObject(value))
        return false;
    return isString(value.deviceClass) &&
        ['ultra-high', 'high', 'medium', 'low', 'potato'].includes(value.deviceClass) &&
        isNumber(value.cpuCores) &&
        isNumber(value.estimatedRam) &&
        isString(value.gpuTier) &&
        ['high', 'medium', 'low'].includes(value.gpuTier) &&
        isBoolean(value.supportsWebGL2) &&
        isBoolean(value.supportsWebAudio) &&
        isBoolean(value.supportsWorkers) &&
        isBoolean(value.supportsSIMD) &&
        isBoolean(value.isMobile) &&
        isString(value.networkSpeed) &&
        ['slow', 'medium', 'fast'].includes(value.networkSpeed);
}
exports.isDeviceCapabilities = isDeviceCapabilities;
// ===== VALIDATION UTILITIES =====
function validateAndTransform(value, guard, errorMessage) {
    if (guard(value)) {
        return value;
    }
    throw new Error(errorMessage || `Validation failed for value: ${JSON.stringify(value)}`);
}
exports.validateAndTransform = validateAndTransform;
function safeValidate(value, guard, defaultValue) {
    return guard(value) ? value : defaultValue;
}
exports.safeValidate = safeValidate;
function createArrayValidator(itemGuard) {
    return (value) => isArray(value, itemGuard);
}
exports.createArrayValidator = createArrayValidator;
function createOptionalValidator(guard) {
    return (value) => value === undefined || guard(value);
}
exports.createOptionalValidator = createOptionalValidator;
// ===== RUNTIME TYPE CHECKING UTILITIES =====
function assertType(value, guard, context) {
    if (!guard(value)) {
        const contextMsg = context ? ` in ${context}` : '';
        throw new TypeError(`Type assertion failed${contextMsg}: ${JSON.stringify(value)}`);
    }
}
exports.assertType = assertType;
function isValidEnum(enumObject, value) {
    return Object.values(enumObject).includes(value);
}
exports.isValidEnum = isValidEnum;
</file>

<file path="types/dist/visualization.d.ts">
/**
 * Visualization Type Definitions
 * Comprehensive types for Three.js visualizations and effects
 */
import * as THREE from 'three';
import { AudioAnalysisData, StemType, VisualizationParameters } from './audio';
export interface VisualEffect {
    id: string;
    name: string;
    description: string;
    enabled: boolean;
    parameters: EffectParameters;
    init(scene: THREE.Scene, camera: THREE.Camera, renderer: THREE.WebGLRenderer): Promise<void>;
    update(deltaTime: number, audioData: AudioAnalysisData, midiData: LiveMIDIData): void;
    destroy(): void;
    getShaderUniforms(): Record<string, THREE.IUniform>;
}
export interface EffectParameters {
    [key: string]: EffectParameter;
}
export interface EffectParameter {
    value: number | string | boolean | number[];
    min?: number;
    max?: number;
    step?: number;
    type: 'number' | 'string' | 'boolean' | 'color' | 'vector2' | 'vector3' | 'vector4';
    label: string;
    description?: string;
    category?: string;
}
export interface LiveMIDIData {
    activeNotes: MIDINote[];
    currentTime: number;
    tempo: number;
    totalNotes: number;
    trackActivity: Record<string, boolean>;
    timeSignature: [number, number];
    keySignature: string;
}
export interface MIDINote {
    note: number;
    velocity: number;
    startTime: number;
    endTime?: number;
    track: string;
    channel: number;
    instrument?: string;
}
export interface MIDITrack {
    id: string;
    name: string;
    channel: number;
    instrument: string;
    notes: MIDINote[];
    controlChanges: MIDIControlChange[];
    programChanges: MIDIProgramChange[];
}
export interface MIDIControlChange {
    timestamp: number;
    controller: number;
    value: number;
    channel: number;
}
export interface MIDIProgramChange {
    timestamp: number;
    program: number;
    channel: number;
}
export interface VisualizerInstance {
    id: string;
    scene: THREE.Scene;
    camera: THREE.Camera;
    renderer: THREE.WebGLRenderer;
    effects: Map<string, VisualEffect>;
    mediaLayers: Map<string, MediaLayer>;
    audioTextureManager: AudioTextureManager;
    isInitialized: boolean;
    isPlaying: boolean;
    currentTime: number;
}
export interface MediaLayer {
    id: string;
    type: 'audio' | 'video' | 'image' | 'text' | 'effect';
    enabled: boolean;
    opacity: number;
    blendMode: BlendMode;
    transform: LayerTransform;
    content: MediaContent;
    effects: string[];
}
export type BlendMode = 'normal' | 'multiply' | 'screen' | 'overlay' | 'soft-light' | 'hard-light' | 'color-dodge' | 'color-burn' | 'darken' | 'lighten' | 'difference' | 'exclusion';
export interface LayerTransform {
    position: THREE.Vector3;
    rotation: THREE.Euler;
    scale: THREE.Vector3;
    anchor: THREE.Vector2;
}
export interface MediaContent {
    type: 'texture' | 'geometry' | 'text' | 'particles';
    data: TextureContent | GeometryContent | TextContent | ParticleContent;
}
export interface TextureContent {
    texture: THREE.Texture;
    uvTransform: THREE.Matrix3;
    wrapS: THREE.Wrapping;
    wrapT: THREE.Wrapping;
    magFilter: THREE.TextureFilter;
    minFilter: THREE.TextureFilter;
}
export interface GeometryContent {
    geometry: THREE.BufferGeometry;
    material: THREE.Material;
    castShadow: boolean;
    receiveShadow: boolean;
}
export interface TextContent {
    text: string;
    font: string;
    size: number;
    color: string;
    align: 'left' | 'center' | 'right';
    verticalAlign: 'top' | 'middle' | 'bottom';
}
export interface ParticleContent {
    count: number;
    positions: Float32Array;
    velocities: Float32Array;
    colors: Float32Array;
    sizes: Float32Array;
    lifetimes: Float32Array;
    emissionRate: number;
}
export interface AudioTextureManager {
    loadAudioAnalysis(audioData: Record<StemType, unknown>): Promise<void>;
    updateAudioData(stemType: StemType, data: AudioAnalysisData): void;
    getShaderUniforms(): Record<string, THREE.IUniform>;
    setCurrentTime(time: number): void;
    dispose(): void;
}
export interface AudioTextureConfig {
    textureWidth: number;
    textureHeight: number;
    maxFeatures: number;
    maxTimeSteps: number;
    format: THREE.PixelFormat;
    type: THREE.TextureDataType;
}
export interface ShaderMaterial extends THREE.ShaderMaterial {
    uniforms: {
        [key: string]: THREE.IUniform;
    };
    vertexShader: string;
    fragmentShader: string;
}
export interface ShaderUniforms {
    uTime: THREE.IUniform<number>;
    uDeltaTime: THREE.IUniform<number>;
    uAudioTexture: THREE.IUniform<THREE.Texture>;
    uAudioTextureSize: THREE.IUniform<THREE.Vector2>;
    uAudioTime: THREE.IUniform<number>;
    uColorPrimary: THREE.IUniform<THREE.Color>;
    uColorSecondary: THREE.IUniform<THREE.Color>;
    uIntensity: THREE.IUniform<number>;
    uScale: THREE.IUniform<number>;
    uCameraPosition: THREE.IUniform<THREE.Vector3>;
    uViewMatrix: THREE.IUniform<THREE.Matrix4>;
    uProjectionMatrix: THREE.IUniform<THREE.Matrix4>;
    uResolution: THREE.IUniform<THREE.Vector2>;
    uPixelRatio: THREE.IUniform<number>;
}
export interface VisualizationPerformanceMetrics {
    frameRate: number;
    frameTime: number;
    drawCalls: number;
    triangles: number;
    geometries: number;
    textures: number;
    shaderPrograms: number;
    memoryUsage: {
        geometries: number;
        textures: number;
        total: number;
    };
    gpuMemoryUsage: number;
    renderTime: number;
    updateTime: number;
}
export interface PerformanceThresholds {
    minFrameRate: number;
    maxFrameTime: number;
    maxDrawCalls: number;
    maxMemoryUsage: number;
    maxGpuMemoryUsage: number;
}
export interface VisualizationExportSettings {
    resolution: {
        width: number;
        height: number;
    };
    frameRate: number;
    duration: number;
    quality: 'draft' | 'preview' | 'high' | 'ultra';
    format: 'mp4' | 'webm' | 'gif' | 'image_sequence';
    audioSync: boolean;
    effects: string[];
    layers: string[];
}
export interface ExportProgress {
    currentFrame: number;
    totalFrames: number;
    percentage: number;
    estimatedTimeRemaining: number;
    currentStage: 'preparing' | 'rendering' | 'encoding' | 'finalizing';
    errors: string[];
}
export interface DeviceProfile {
    tier: 'low' | 'medium' | 'high' | 'ultra';
    capabilities: {
        webgl2: boolean;
        floatTextures: boolean;
        depthTextures: boolean;
        instancedArrays: boolean;
        vertexArrayObjects: boolean;
        maxTextureSize: number;
        maxRenderBufferSize: number;
        maxVertexUniforms: number;
        maxFragmentUniforms: number;
    };
    recommendedSettings: {
        maxParticles: number;
        textureResolution: number;
        shadowMapSize: number;
        antialias: boolean;
        postProcessing: boolean;
    };
}
export declare function isVisualEffect(value: unknown): value is VisualEffect;
export declare function isLiveMIDIData(value: unknown): value is LiveMIDIData;
export declare function isMediaLayer(value: unknown): value is MediaLayer;
export declare function isVisualizationParameters(value: unknown): value is VisualizationParameters;
</file>

<file path="types/dist/visualization.js">
"use strict";
/**
 * Visualization Type Definitions
 * Comprehensive types for Three.js visualizations and effects
 */
Object.defineProperty(exports, "__esModule", { value: true });
exports.isVisualizationParameters = exports.isMediaLayer = exports.isLiveMIDIData = exports.isVisualEffect = void 0;
// ===== TYPE GUARDS =====
function isVisualEffect(value) {
    if (!value || typeof value !== 'object')
        return false;
    const effect = value;
    return typeof effect.id === 'string' &&
        typeof effect.name === 'string' &&
        typeof effect.enabled === 'boolean' &&
        typeof effect.init === 'function' &&
        typeof effect.update === 'function' &&
        typeof effect.destroy === 'function';
}
exports.isVisualEffect = isVisualEffect;
function isLiveMIDIData(value) {
    if (!value || typeof value !== 'object')
        return false;
    const data = value;
    return Array.isArray(data.activeNotes) &&
        typeof data.currentTime === 'number' &&
        typeof data.tempo === 'number' &&
        typeof data.totalNotes === 'number' &&
        typeof data.trackActivity === 'object';
}
exports.isLiveMIDIData = isLiveMIDIData;
function isMediaLayer(value) {
    if (!value || typeof value !== 'object')
        return false;
    const layer = value;
    return typeof layer.id === 'string' &&
        typeof layer.type === 'string' &&
        typeof layer.enabled === 'boolean' &&
        typeof layer.opacity === 'number';
}
exports.isMediaLayer = isMediaLayer;
function isVisualizationParameters(value) {
    if (!value || typeof value !== 'object')
        return false;
    const params = value;
    return typeof params.colorScheme === 'object' &&
        typeof params.effectSettings === 'object' &&
        typeof params.cameraSettings === 'object';
}
exports.isVisualizationParameters = isVisualizationParameters;
</file>

<file path="types/index.ts">
import { z } from 'zod'

// ===== VALIDATION SCHEMAS =====
export const createProjectSchema = z.object({
  name: z.string().min(1, 'Project name is required').max(100, 'Project name too long'),
  description: z.string().max(500, 'Description too long').optional(),
  privacy_setting: z.enum(['private', 'unlisted', 'public']).default('private'),
  midi_file_path: z.string().optional(),
  audio_file_path: z.string().optional(),
  user_video_path: z.string().optional(),
  render_configuration: z.record(z.any()).default({}),
})

export const updateProjectSchema = z.object({
  id: z.string().min(1, 'Project ID is required'),
  name: z.string().min(1, 'Project name is required').max(100, 'Project name too long').optional(),
  description: z.string().max(500, 'Description too long').optional(),
  privacy_setting: z.enum(['private', 'unlisted', 'public']).optional(),
  thumbnail_url: z.string().url('Invalid thumbnail URL').optional(),
  primary_midi_file_id: z.string().uuid('Invalid file ID').optional(),
  audio_file_path: z.string().optional(),
  user_video_path: z.string().optional(),
  render_configuration: z.record(z.any()).optional(),
})

export const loginCredentialsSchema = z.object({
  email: z.string().email('Invalid email address'),
  password: z.string().min(6, 'Password must be at least 6 characters'),
})

export const signupCredentialsSchema = z.object({
  email: z.string().email('Invalid email address'),
  password: z.string().min(6, 'Password must be at least 6 characters'),
  name: z.string().min(1, 'Name is required').optional(),
})

// ===== CORE USER TYPES =====
// Internal Supabase user interface for API use
interface SupabaseUser {
  id: string
  email?: string
  user_metadata?: {
    name?: string
    avatar_url?: string
    provider?: string
  }
  created_at?: string
  updated_at?: string
}

// Standardized User interface for both API and web
export interface User {
  id: string // UUID from Supabase auth.users
  email: string
  name?: string
  image?: string
  created_at: string // ISO timestamp
  updated_at: string // ISO timestamp
}

// Web-specific User interface with user_metadata
export interface WebUser {
  id: string // UUID from Supabase auth.users
  email: string
  user_metadata: {
    name?: string
    avatar_url?: string
    provider?: string
  }
  created_at: string // ISO timestamp
  updated_at: string // ISO timestamp
}

// Normalized User interface for internal API use
export interface NormalizedUser {
  id: string
  email: string
  name?: string
  image?: string
  created_at: string
  updated_at: string
}

export interface UserProfile {
  id: string // UUID from auth.users
  display_name?: string
  avatar_url?: string
  bio?: string
  preferences: Record<string, any>
  subscription_tier: 'free' | 'premium' | 'enterprise'
  created_at: string
  updated_at: string
}

export interface UserWithProfile extends User {
  profile: UserProfile
}

// ===== PROJECT TYPES =====
export interface Project {
  id: string
  name: string
  user_id: string // UUID from auth.users
  midi_file_path: string
  audio_file_path?: string
  user_video_path?: string
  render_configuration: Record<string, any>
  description?: string
  privacy_setting: 'private' | 'unlisted' | 'public'
  thumbnail_url?: string
  primary_midi_file_id?: string
  created_at: string
  updated_at: string
}

export interface ProjectCollaborator {
  id: string
  project_id: string
  user_id: string // UUID from auth.users
  role: 'owner' | 'editor' | 'viewer'
  created_at: string
}

export interface ProjectShare {
  id: string
  project_id: string
  share_token: string // unique URL token
  access_type: 'view' | 'embed'
  expires_at?: string
  view_count: number
  created_at: string
  updated_at: string
}

export interface ProjectWithCollaborators extends Project {
  collaborators: ProjectCollaborator[]
}

export interface ProjectExtended extends Project {
  // Computed fields
  file_count?: number
  total_file_size?: number
  last_accessed?: string
}

// ===== AUTH TYPES =====
export interface AuthState {
  user: User | null
  loading: boolean
  error: string | null
}

export interface LoginCredentials {
  email: string
  password: string
}

export interface SignupCredentials {
  email: string
  password: string
  name?: string
}

export interface AuthProvider {
  provider: 'google' | 'github' | 'discord'
  redirectTo?: string
}

export interface AuthError {
  message: string
  code?: string
}

export interface AuthContext {
  user: User | null
  session: any | null
  supabase: any
}

// ===== AUDIT TYPES =====
export interface AuditLog {
  id: string
  user_id?: string // UUID from auth.users
  action: string
  resource_type: string
  resource_id?: string
  metadata: Record<string, any>
  ip_address?: string
  user_agent?: string
  created_at: string
}

// ===== MIDI TYPES =====
export interface MIDINote {
  id: string
  track: number | string
  channel: number
  note: number // MIDI note number (0-127)
  pitch: number // Alternative name for note (required for web compatibility)
  velocity: number // Note velocity (0-127)
  startTime: number // Time in ticks or seconds
  start: number // Alternative name for startTime (required for web compatibility)
  duration: number // Note duration
  name: string // Note name (e.g., "C4")
  noteName?: string // Alternative name for name
}

export interface TempoEvent {
  tick: number
  bpm: number
  microsecondsPerQuarter: number
}

export interface TempoChange {
  tick: number
  bpm: number
  microsecondsPerQuarter: number
}

export interface MIDITrack {
  id: string
  name: string
  instrument: string
  channel: number
  notes: MIDINote[]
  color: string
  visible?: boolean
}

export interface MIDIData {
  file: {
    name: string
    size: number
    duration: number
    ticksPerQuarter: number
    timeSignature: [number, number]
    keySignature: string
  }
  tracks: MIDITrack[]
  tempoChanges: TempoEvent[] | TempoChange[]
}

export interface MIDIParsingResult {
  success: boolean
  data?: MIDIData
  error?: string
}

export interface VisualizationSettings {
  colorScheme: 'sage' | 'slate' | 'dusty-rose' | 'mixed'
  pixelsPerSecond: number
  showTrackLabels: boolean
  showVelocity: boolean
  minKey: number
  maxKey: number
}

// Color scheme mappings
export const COLOR_SCHEMES = {
  sage: '#84a98c',
  slate: '#6b7c93', 
  'dusty-rose': '#b08a8a',
  mixed: ['#84a98c', '#6b7c93', '#b08a8a', '#a8a29e', '#8da3b0']
} as const

// Default visualization settings
export const DEFAULT_VISUALIZATION_SETTINGS: VisualizationSettings = {
  colorScheme: 'mixed',
  pixelsPerSecond: 50,
  showTrackLabels: true,
  showVelocity: true,
  minKey: 21,
  maxKey: 108
}

// ===== UTILITY FUNCTIONS =====
// Helper to convert Supabase user to our User type
export function transformSupabaseUser(supabaseUser: SupabaseUser): User {
  return {
    id: supabaseUser.id,
    email: supabaseUser.email || '',
    name: supabaseUser.user_metadata?.name,
    image: supabaseUser.user_metadata?.avatar_url,
    created_at: supabaseUser.created_at || '',
    updated_at: supabaseUser.updated_at || '',
  }
}

export function normalizeUser(user: User): NormalizedUser {
  return {
    id: user.id,
    email: user.email,
    name: user.name,
    image: user.image,
    created_at: user.created_at,
    updated_at: user.updated_at,
  }
}

// ===== EXPORT INFERRED TYPES =====
export type CreateProjectInput = z.infer<typeof createProjectSchema>
export type UpdateProjectInput = z.infer<typeof updateProjectSchema>
export type LoginCredentialsInput = z.infer<typeof loginCredentialsSchema>
export type SignupCredentialsInput = z.infer<typeof signupCredentialsSchema>
</file>

<file path="types/midi-parser-js.d.ts">
declare module 'midi-parser-js' {
  interface MidiEvent {
    deltaTime: number;
    type: number;
    metaType?: number;
    data?: number[];
    channel?: number;
  }

  interface MidiTrack {
    event?: MidiEvent[];
  }

  interface MidiData {
    formatType: number;
    timeDivision: number;
    track: MidiTrack[];
  }

  class MidiParser {
    static parse(buffer: Buffer | Uint8Array): MidiData;
  }

  export default MidiParser;
}
</file>

<file path="types/package.json">
{
  "name": "phonoglyph-types",
  "version": "0.2.0",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "scripts": {
    "build": "tsc",
    "type-check": "tsc --noEmit"
  },
  "dependencies": {
    "zod": "^3.25.67"
  },
  "devDependencies": {
    "typescript": "5.3.3"
  }
}
</file>

<file path="types/tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "commonjs",
    "lib": ["ES2020"],
    "declaration": true,
    "outDir": "./dist",
    "rootDir": "./",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "moduleResolution": "node"
  },
  "include": [
    "*.ts"
  ],
  "exclude": [
    "node_modules",
    "dist"
  ]
}
</file>

</files>
